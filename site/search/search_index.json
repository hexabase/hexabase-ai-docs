{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Hexabase.AI Documentation","text":"<p>AI-Oriented Kubernetes as a Service - Deploy, scale, and manage AI applications with intelligent automation</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li> <p> AI Developers</p> <p>Quick deployment of AI applications and agents to production-ready Kubernetes</p> <p> Start Building</p> </li> <li> <p> Teams</p> <p>Collaborate and scale AI workloads on dedicated infrastructure with workspace isolation</p> <p> Team Setup</p> </li> <li> <p> Enterprise</p> <p>Deploy private, on-premise AI infrastructure with full control and compliance</p> <p> Enterprise Guide</p> </li> <li> <p> Quick Start</p> <p>Get your first AI application running in minutes with our guided setup</p> <p> Quick Deploy</p> </li> </ul>"},{"location":"#platform-features","title":"Platform Features","text":"<ul> <li> <p> Core Concepts</p> <p>Understand the fundamental concepts of Hexabase.AI</p> <p> Learn Concepts</p> </li> <li> <p> Use Cases</p> <p>Explore how organizations use Hexabase.AI</p> <p> View Use Cases</p> </li> <li> <p> Architecture</p> <p>Deep dive into the technical architecture</p> <p> Architecture Docs</p> </li> <li> <p> RBAC</p> <p>Role-based access control and security</p> <p> RBAC Guide</p> </li> </ul>"},{"location":"#advanced-features","title":"Advanced Features","text":"<ul> <li> <p> CronJobs</p> <p>Schedule and manage periodic tasks</p> <p> CronJobs Guide</p> </li> <li> <p> Functions</p> <p>Deploy serverless functions on Kubernetes</p> <p> Functions Docs</p> </li> <li> <p> Observability</p> <p>Monitor, log, and trace your applications</p> <p> Observability Platform</p> </li> <li> <p> AIOps</p> <p>AI-powered operations and automation</p> <p> AIOps Features</p> </li> </ul>"},{"location":"#developer-resources","title":"Developer Resources","text":"<ul> <li> <p> \u65e5\u672c\u8a9e</p> <p>Japanese language documentation</p> <p> \u65e5\u672c\u8a9e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8</p> </li> <li> <p> API Reference</p> <p>Auto-generated API documentation (coming soon)</p> <p> API Reference</p> </li> </ul>"},{"location":"#what-is-hexabaseai","title":"What is Hexabase.AI?","text":"<p>Hexabase.AI (HKS) is an AI-Oriented Kubernetes as a Service platform designed specifically for developers building AI applications and agents. Built on CNCF open-source standards, it provides intelligent automation, monitoring, and scaling capabilities that understand AI workload patterns.</p>"},{"location":"#why-choose-hexabaseai","title":"Why Choose Hexabase.AI?","text":"<ul> <li>AI-First Design: Optimized for AI applications, agents, and machine learning workloads</li> <li>Instant Production: Deploy AI applications to production in minutes, not weeks</li> <li>Smart Scaling: AI-powered resource optimization that learns from your workload patterns  </li> <li>Team Collaboration: Multi-tenant workspaces with fine-grained access control</li> <li>Enterprise Ready: Private, on-premise deployment with full compliance and control</li> <li>Open Standards: Built on CNCF OSS - no vendor lock-in, use familiar tools</li> </ul>"},{"location":"#perfect-for","title":"Perfect For","text":"<ul> <li>AI Developers coding applications with LLMs, ML models, and AI agents</li> <li>Startups needing quick, scalable AI infrastructure without DevOps overhead</li> <li>Teams requiring isolated environments for different AI projects and experiments</li> <li>Enterprises wanting private AI infrastructure with governance and compliance</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p>Development</p> <ul> <li>Platform Concepts</li> <li>API Reference (auto-generated)</li> <li>CLI Tool Documentation</li> </ul> </li> <li> <p>Resources</p> <ul> <li>GitHub Repository</li> <li>Community Support</li> <li>Release Notes</li> </ul> </li> </ul>"},{"location":"#support","title":"Support","text":"<p>Need help? Check out our:</p> <ul> <li>Community Forum</li> <li>Issue Tracker</li> <li>Contact Support</li> </ul>"},{"location":"service-scope/","title":"Hexabase KaaS Service Scope of Services and Responsibility Boundary","text":"<p>Hexabase KaaS (Kubernetes as a Service) is a platform that facilitates the operation of container applications with an intuitive UI and auxiliary functions that are fully compatible with Kubernetes and can be operated even by those without specialized knowledge. The purpose of this document is to clarify the scope of service provision and the boundary of responsibility between our company (Hexabase) and the customer when using Hexabase KaaS.</p>"},{"location":"service-scope/#1-summary-of-responsibility-boundary-points","title":"1. Summary of Responsibility Boundary Points","text":"<p>The scope of liability in Hexabase KaaS follows the general cloud service liability sharing model. The table below summarizes the responsibility boundary for each type of service provision.</p> Layer Content KaaS version Other company's cloud version On-premise version Application Application itself, data, security measures, container image management Customer Customer Customer Kubernetes infrastructure Container orchestration, monitoring and logging capabilities, resource management, access control Hexabase Hexabase Hexabase Virtual Infrastructure Virtual machines, virtual networks, virtual storage Hexabase Customer (*1) Customer (*1) Physical Infrastructure Physical Servers, Network Devices, Data Center Hexabase Customer (*1) Customer (*1) <p>(*1) For other companies' cloud and on-premise versions of infrastructure</p> <ul> <li>Cloud version of other companies: The customer is responsible for managing the account of the cloud service (AWS, Azure, GCP, etc.) that the customer subscribes to and the Kubernetes (EKS, AKS, GKE, etc.) running on that account.</li> <li>On-Premise Version: You are responsible for managing your physical servers and virtualization infrastructure (Proxmox, etc.).</li> </ul> <p>[Construction and operation support] For the scope of the above (1), Hexabase can also perform construction and operation on behalf of the customer by separately contracting for Hexabase's **Initial Construction Service* or Managed Service. Please contact us for details.</p>"},{"location":"service-scope/#2-details-of-responsibility-boundary-points-at-each-layer","title":"2. Details of Responsibility Boundary Points at Each Layer","text":""},{"location":"service-scope/#21-application-layer-scope-of-customers-responsibility","title":"2.1. Application Layer (Scope of Customer's Responsibility)","text":"<p>Hexabase provides a powerful platform and functionality to run your application, but is not responsible for managing the application itself.</p> Item Scope of Customer Responsibility Application Operation Assurance Ensuring the proper operation, performance, and quality of the application developed and deployed by the customer. Application Security Vulnerability countermeasures for application code, use of appropriate libraries, and container image vulnerability scanning and countermeasures. Data Backup and Restoration Development of backup plans for persistent data used by the application, such as databases and files, execution of such plans on a regular basis, and data restoration work by the customer itself in the event of a failure. Updating Container Images Preparing and deploying (modernizing) new container images with additional application functionality, bug fixes, and security patches applied by the customer itself."},{"location":"service-scope/#22-kubernetes-platform-layer-hexabases-scope-of-responsibility","title":"2.2. Kubernetes Platform Layer (Hexabase's Scope of Responsibility)","text":"<p>Hexabase will be responsible for managing and operating the complex Kubernetes environment so that the customer can focus on operating the application.</p> Item Scope of Hexabase Offerings Container Orchestration Provides automated container deployment, scaling, and lifecycle management capabilities. Resource Management and Optimization Provision of functions to efficiently manage and optimize CPU, memory, storage, and other resources required by containers. Platform Monitoring and Logging Provides integrated functionality for monitoring, logging, and analyzing the availability and performance of Kubernetes clusters and containers. Networking and Storage Management Provides networking capabilities for secure communication between containers and storage capabilities for data persistence. Security and Compliance Provides functions for maintaining security of the Kubernetes cluster itself, access control, network policies, and resource isolation in multi-tenant environments. Platform Updates Platform maintenance, such as upgrading Kubernetes itself and applying security patches. VM/Container Integration Management Provides the ability to centrally manage virtual machines (VMs) and containers on Kubernetes. Support and Documentation Provision of technical support and various documentation to ensure smooth use of the service by customers."},{"location":"service-scope/#23-infrastructure-layer-divided-by-type-of-provision","title":"2.3. Infrastructure Layer (divided by type of provision)","text":"<p>The division of responsibility for the infrastructure layer depends on the type of provision chosen by the customer.</p>"},{"location":"service-scope/#if-you-use-the-kaas-version-hexabases-area-of-responsibility","title":"If you use the KaaS version (Hexabase's area of responsibility)","text":"<p>Hexabase provides the physical servers, network, storage, and the infrastructure to virtualize them, all fully managed by Hexabase. Customers can use the service as if it were serverless, without being aware of the existence of infrastructure.</p>"},{"location":"service-scope/#in-case-of-using-another-companys-cloud-or-on-premise-version-customers-responsibility","title":"In case of using another company's cloud or on-premise version (customer's responsibility)","text":"<p>As mentioned above, the construction, management, and operation of the underlying cloud environment or on-premise physical/virtual environment is the responsibility of the customer.</p>"},{"location":"aiops/","title":"AI Operations (AIOps)","text":"<p>Hexabase.AI revolutionizes DevOps practices by integrating advanced AI capabilities throughout the software development lifecycle. From intelligent code reviews to predictive scaling and automated incident response, AI agents work alongside your teams to enhance productivity and reliability.</p>"},{"location":"aiops/#overview","title":"Overview","text":"<p>Hexabase.AI's AIOps (Artificial Intelligence for IT Operations) transforms how you manage Kubernetes infrastructure by applying machine learning to operational data. Our AI-powered platform predicts issues before they impact users, automatically optimizes resource allocation, and provides intelligent recommendations to improve reliability and reduce costs.</p>"},{"location":"aiops/#the-ai-devops-revolution","title":"The AI-DevOps Revolution","text":""},{"location":"aiops/#traditional-devops-challenges","title":"Traditional DevOps Challenges","text":"<ul> <li>Manual processes: Time-consuming and error-prone</li> <li>Alert fatigue: Too many false positives</li> <li>Reactive operations: Issues discovered after impact</li> <li>Knowledge silos: Expertise concentrated in few individuals</li> </ul>"},{"location":"aiops/#ai-enhanced-solutions","title":"AI-Enhanced Solutions","text":"<ul> <li>Intelligent automation: AI-driven decision making</li> <li>Predictive analytics: Anticipate issues before they occur</li> <li>Self-healing systems: Automated remediation</li> <li>Knowledge synthesis: AI agents with collective intelligence</li> </ul>"},{"location":"aiops/#core-ai-capabilities","title":"Core AI Capabilities","text":"<ul> <li> Intelligent CI/CD</li> </ul> <p>AI-powered code reviews and build optimization</p> <p> Smart Development</p> <ul> <li> Predictive Analytics</li> </ul> <p>Forecast issues and capacity needs</p> <p> Predictive Features</p> <ul> <li> Auto-Remediation</li> </ul> <p>Self-healing systems and incident response</p> <p> Remediation Guide</p> <ul> <li> Cost Optimization</li> </ul> <p>AI-driven resource and cost optimization</p> <p> Cost Optimization</p>"},{"location":"aiops/#1-intelligent-cicd","title":"1. Intelligent CI/CD","text":""},{"location":"aiops/#smart-code-reviews","title":"Smart Code Reviews","text":"<pre><code># AI-powered code review configuration\nai_review:\n  enabled: true\n  checks:\n    - security_vulnerabilities\n    - performance_optimization\n    - code_quality\n    - architectural_patterns\n  models:\n    - gpt-4\n    - code-llama\n    - custom-trained-model\n</code></pre>"},{"location":"aiops/#predictive-build-optimization","title":"Predictive Build Optimization","text":"<ul> <li>Analyze historical build data</li> <li>Predict build failures</li> <li>Optimize build parallelization</li> <li>Intelligent test selection</li> </ul>"},{"location":"aiops/#2-intelligent-deployment","title":"2. Intelligent Deployment","text":""},{"location":"aiops/#canary-analysis","title":"Canary Analysis","text":"<ul> <li>AI-driven canary deployment decisions</li> <li>Real-time performance comparison</li> <li>Automatic rollback triggers</li> <li>Learning from deployment history</li> </ul>"},{"location":"aiops/#traffic-management","title":"Traffic Management","text":"<pre><code># AI-optimized traffic routing\ntraffic_policy:\n  ai_routing:\n    enabled: true\n    objectives:\n      - minimize_latency\n      - maximize_throughput\n      - ensure_reliability\n    learning_rate: 0.1\n    update_interval: 5m\n</code></pre>"},{"location":"aiops/#how-aiops-works","title":"How AIOps Works","text":""},{"location":"aiops/#1-data-collection","title":"1. Data Collection","text":"<p>Continuous gathering of operational data:</p> <ul> <li>Metrics: Performance, resource usage, availability</li> <li>Logs: Application and system logs</li> <li>Traces: Request flows and dependencies</li> <li>Events: Kubernetes events and changes</li> </ul>"},{"location":"aiops/#2-ai-analysis","title":"2. AI Analysis","text":"<p>Machine learning models process data to:</p> <ul> <li>Detect Anomalies: Identify unusual patterns</li> <li>Predict Failures: Forecast potential issues</li> <li>Find Correlations: Connect related events</li> <li>Generate Insights: Provide actionable recommendations</li> </ul>"},{"location":"aiops/#3-automated-actions","title":"3. Automated Actions","text":"<p>AI-driven automation for:</p> <ul> <li>Scaling: Adjust resources based on predictions</li> <li>Healing: Fix issues automatically</li> <li>Optimization: Improve performance and efficiency</li> <li>Alerting: Smart, contextual notifications</li> </ul>"},{"location":"aiops/#key-capabilities","title":"Key Capabilities","text":""},{"location":"aiops/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code>Normal Behavior Learned \u2500\u2500\u25b6 Real-time Monitoring \u2500\u2500\u25b6 Anomaly Alert\n        \u2502                            \u2502                      \u2502\n        \u2514\u2500\u2500 ML Model Training        \u2514\u2500\u2500 Pattern Analysis   \u2514\u2500\u2500 Root Cause\n</code></pre> <ul> <li>Adaptive Baselines: Learn normal behavior patterns</li> <li>Multi-dimensional Analysis: Correlate multiple metrics</li> <li>Contextual Awareness: Consider time, workload, and dependencies</li> <li>Low False Positives: Smart filtering reduces noise</li> </ul>"},{"location":"aiops/#predictive-scaling","title":"Predictive Scaling","text":"<pre><code>Prediction: Traffic spike expected in 2 hours\nAction: Pre-scale deployment from 3 to 10 replicas\nResult: Zero downtime during traffic surge\nSavings: 70% vs keeping 10 replicas running constantly\n</code></pre>"},{"location":"aiops/#intelligent-remediation","title":"Intelligent Remediation","text":"<p>Common auto-remediation scenarios:</p> <ul> <li>Pod Crashes: Analyze logs and restart with fixes</li> <li>Memory Leaks: Detect and schedule pod rotation</li> <li>Disk Pressure: Clean up logs and temporary files</li> <li>Network Issues: Reroute traffic or restart network components</li> </ul>"},{"location":"aiops/#ai-powered-use-case-scenarios","title":"AI-Powered Use Case Scenarios","text":""},{"location":"aiops/#scenario-1-zero-downtime-deployments","title":"Scenario 1: Zero-Downtime Deployments","text":"<p>Challenge: Deploy critical updates without service interruption</p> <p>AI Solution:</p> <ol> <li>Pre-deployment Analysis</li> <li>AI reviews code changes</li> <li>Predicts potential issues</li> <li> <p>Suggests optimal deployment strategy</p> </li> <li> <p>Smart Canary Rollout</p> </li> <li>AI monitors canary metrics</li> <li>Adjusts traffic dynamically</li> <li> <p>Makes go/no-go decisions</p> </li> <li> <p>Post-deployment Validation</p> </li> <li>Continuous performance monitoring</li> <li>Automatic issue detection</li> <li>Self-healing activation if needed</li> </ol>"},{"location":"aiops/#scenario-2-incident-response-automation","title":"Scenario 2: Incident Response Automation","text":"<p>Challenge: Reduce MTTR for production incidents</p> <p>AI Solution:</p> <pre><code># AI incident responder configuration\nincident_response:\n  ai_agent:\n    name: \"IncidentBot\"\n    capabilities:\n      - log_analysis\n      - metric_correlation\n      - runbook_execution\n      - team_notification\n    escalation:\n      level_1: ai_remediation\n      level_2: ai_assisted_human\n      level_3: human_intervention\n</code></pre> <p>Workflow: 1. AI detects anomaly 2. Analyzes logs and metrics 3. Identifies root cause 4. Executes remediation 5. Documents resolution</p>"},{"location":"aiops/#scenario-3-performance-optimization","title":"Scenario 3: Performance Optimization","text":"<p>Challenge: Optimize application performance continuously</p> <p>AI Solution: - Continuous profiling - Resource optimization recommendations - Auto-scaling predictions - Code optimization suggestions</p>"},{"location":"aiops/#real-world-examples","title":"Real-World Examples","text":""},{"location":"aiops/#e-commerce-platform","title":"E-commerce Platform","text":"<p>Challenge: Handle Black Friday traffic spikes Solution: AI-predicted traffic patterns, pre-emptive scaling Result: 99.99% uptime during peak</p>"},{"location":"aiops/#financial-services","title":"Financial Services","text":"<p>Challenge: Ensure compliance in deployments Solution: AI compliance checking, automated audit trails Result: 100% compliance rate</p>"},{"location":"aiops/#saas-provider","title":"SaaS Provider","text":"<p>Challenge: Reduce customer-impacting incidents Solution: Predictive failure detection, automated remediation Result: 85% reduction in incidents</p>"},{"location":"aiops/#aiops-dashboard","title":"AIOps Dashboard","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    AIOps Dashboard                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Health Score   \u2502 Active Predictions \u2502 Cost Savings     \u2502\n\u2502      98/100     \u2502        12         \u2502    $2,450/mo     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                 Anomalies Detected (24h)                \u2502\n\u2502  \u2022 CPU spike on payment-service (resolved)             \u2502\n\u2502  \u2022 Unusual traffic pattern on API gateway (monitoring) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                  AI Recommendations                     \u2502\n\u2502  \u2022 Scale down staging environment after hours          \u2502\n\u2502  \u2022 Upgrade database pod for better performance        \u2502\n\u2502  \u2022 Enable caching on frequently accessed endpoints    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aiops/#getting-started-with-aiops","title":"Getting Started with AIOps","text":""},{"location":"aiops/#phase-1-enable-aiops-agent","title":"Phase 1: Enable AIOps Agent","text":"<pre><code># Enable AIOps for your workspace\nhb aiops enable --workspace production\n\n# Configure chat integration\nhb aiops chat-bot setup \\\n  --platform slack \\\n  --webhook-url $SLACK_WEBHOOK_URL \\\n  --channel \"#ops-alerts\"\n\n# Set monitoring preferences\nhb aiops monitoring configure \\\n  --daily-reports true \\\n  --alert-threshold medium \\\n  --auto-investigation true\n</code></pre>"},{"location":"aiops/#phase-2-chat-bot-registration","title":"Phase 2: Chat Bot Registration","text":""},{"location":"aiops/#slack-integration","title":"Slack Integration","text":"<pre><code># Register AIOps bot in Slack\nhb aiops chat-bot register slack \\\n  --app-token $SLACK_APP_TOKEN \\\n  --bot-token $SLACK_BOT_TOKEN \\\n  --signing-secret $SLACK_SIGNING_SECRET\n</code></pre>"},{"location":"aiops/#microsoft-teams-integration","title":"Microsoft Teams Integration","text":"<pre><code># Register AIOps bot in Teams\nhb aiops chat-bot register teams \\\n  --app-id $TEAMS_APP_ID \\\n  --app-password $TEAMS_APP_PASSWORD \\\n  --tenant-id $TEAMS_TENANT_ID\n</code></pre>"},{"location":"aiops/#phase-3-configure-automation","title":"Phase 3: Configure Automation","text":"<pre><code># Set up automated issue management\nhb aiops issues configure \\\n  --system jira \\\n  --project-key \"OPS\" \\\n  --auto-create true \\\n  --severity-mapping critical:P1,high:P2,medium:P3\n\n# Enable automated PR creation\nhb aiops automation enable pr-creation \\\n  --repository github.com/myorg/infrastructure \\\n  --branch-prefix \"aiops/fix-\" \\\n  --auto-assign-reviewers ops-team\n\n# Configure deployment support\nhb aiops deployment configure \\\n  --auto-generate-configs true \\\n  --test-environment staging \\\n  --approval-required false\n</code></pre>"},{"location":"aiops/#ai-models-and-algorithms","title":"AI Models and Algorithms","text":""},{"location":"aiops/#time-series-analysis","title":"Time Series Analysis","text":"<ul> <li>LSTM Networks: For complex pattern recognition</li> <li>Prophet: For seasonal trend detection</li> <li>ARIMA: For short-term predictions</li> </ul>"},{"location":"aiops/#anomaly-detection_1","title":"Anomaly Detection","text":"<ul> <li>Isolation Forest: For multivariate anomalies</li> <li>Autoencoders: For complex pattern anomalies</li> <li>Statistical Methods: For simple threshold detection</li> </ul>"},{"location":"aiops/#optimization","title":"Optimization","text":"<ul> <li>Reinforcement Learning: For resource allocation</li> <li>Genetic Algorithms: For configuration optimization</li> <li>Linear Programming: For cost optimization</li> </ul>"},{"location":"aiops/#ai-agent-architecture","title":"AI Agent Architecture","text":""},{"location":"aiops/#agent-hierarchy","title":"Agent Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Orchestrator Agent             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Code     \u2502 Deploy   \u2502 Monitor      \u2502\n\u2502 Agent    \u2502 Agent    \u2502 Agent        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Security \u2502 Performance\u2502 Cost        \u2502\n\u2502 Agent    \u2502 Agent      \u2502 Agent       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aiops/#agent-capabilities","title":"Agent Capabilities","text":""},{"location":"aiops/#code-agent","title":"Code Agent","text":"<ul> <li>Static code analysis</li> <li>Security vulnerability detection</li> <li>Performance optimization suggestions</li> <li>Dependency analysis</li> </ul>"},{"location":"aiops/#deploy-agent","title":"Deploy Agent","text":"<ul> <li>Deployment strategy selection</li> <li>Risk assessment</li> <li>Rollback decision making</li> <li>Environment validation</li> </ul>"},{"location":"aiops/#monitor-agent","title":"Monitor Agent","text":"<ul> <li>Real-time anomaly detection</li> <li>Predictive alerting</li> <li>Capacity planning</li> <li>SLO tracking</li> </ul>"},{"location":"aiops/#best-practices","title":"Best Practices","text":""},{"location":"aiops/#ai-model-selection","title":"AI Model Selection","text":"<ul> <li>Choose appropriate models for each use case</li> <li>Fine-tune on your specific data</li> <li>Implement feedback loops</li> <li>Regular model updates</li> </ul>"},{"location":"aiops/#human-ai-collaboration","title":"Human-AI Collaboration","text":"<ul> <li>Define clear escalation paths</li> <li>Maintain human oversight</li> <li>Document AI decisions</li> <li>Continuous training</li> </ul>"},{"location":"aiops/#security-considerations","title":"Security Considerations","text":"<ul> <li>Secure AI model access</li> <li>Audit AI actions</li> <li>Implement safety checks</li> <li>Regular security reviews</li> </ul>"},{"location":"aiops/#integration-with-devops","title":"Integration with DevOps","text":""},{"location":"aiops/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># .hexabase/aiops.yaml\ndeployment:\n  analyze_before_deploy: true\n  rollback_on_anomaly: true\n  performance_regression_threshold: 10%\n</code></pre>"},{"location":"aiops/#gitops-workflow","title":"GitOps Workflow","text":"<pre><code># AI-suggested configuration changes create PRs\nhb aiops suggestions --create-pr --repo myapp\n</code></pre>"},{"location":"aiops/#incident-management","title":"Incident Management","text":"<ul> <li>Automatic ticket creation</li> <li>Root cause analysis reports</li> <li>Suggested fix procedures</li> <li>Post-incident learning</li> </ul>"},{"location":"aiops/#benefits-and-roi","title":"Benefits and ROI","text":""},{"location":"aiops/#productivity-gains","title":"Productivity Gains","text":"<ul> <li>70% reduction in code review time</li> <li>50% faster incident resolution</li> <li>80% fewer production issues</li> <li>90% reduction in false alerts</li> </ul>"},{"location":"aiops/#quality-improvements","title":"Quality Improvements","text":"<ul> <li>Higher code quality scores</li> <li>Increased test coverage</li> <li>Better security posture</li> <li>Improved system reliability</li> </ul>"},{"location":"aiops/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Reduced infrastructure waste</li> <li>Optimized resource allocation</li> <li>Lower operational overhead</li> <li>Decreased downtime costs</li> </ul>"},{"location":"aiops/#success-metrics","title":"Success Metrics","text":"<p>Track your AIOps effectiveness:</p> <pre><code>hb aiops metrics --period 30d\n</code></pre>"},{"location":"aiops/#security-and-permissions","title":"Security and Permissions","text":""},{"location":"aiops/#access-control","title":"Access Control","text":"<p>The AIOps agent operates under strict security guidelines:</p> <ul> <li>User-Scoped Permissions: Agent actions are limited to the same permissions as the logged-in user</li> <li>Audit Logging: All agent activities are logged with full traceability</li> <li>Secure Communication: All chat integrations use encrypted channels</li> <li>Role-Based Access: Different functionality available based on user roles</li> </ul>"},{"location":"aiops/#permission-levels","title":"Permission Levels","text":"User Role Available Functions Viewer Resource monitoring, log viewing, status reports Developer + Deployment support, testing, PR creation Operator + Resource management, issue raising, automation Admin + All functions, agent configuration, security settings"},{"location":"aiops/#operational-scope","title":"Operational Scope","text":"<p>The AIOps agent is designed specifically for Kubernetes operations and will:</p> <p>\u2705 Respond to requests within scope: - System monitoring and status queries - Log analysis and troubleshooting - Resource management operations - Deployment and testing support - Issue investigation and resolution - Performance optimization recommendations</p> <p>\u274c Not respond to requests outside scope: - General AI assistance unrelated to operations - Code development or programming help - Business or strategic advice - Personal or non-technical questions - Operations outside user's permission scope</p>"},{"location":"aiops/#next-steps","title":"Next Steps","text":""},{"location":"aiops/#quick-setup-checklist","title":"Quick Setup Checklist","text":"<ol> <li>\u2705 Enable AIOps: Activate the AI agent for your workspace</li> <li>\u2705 Configure Chat Bot: Set up integration with your preferred chat platform</li> <li>\u2705 Set Permissions: Configure user roles and access levels</li> <li>\u2705 Test Integration: Verify the agent responds to basic commands</li> <li>\u2705 Configure Automation: Set up automated workflows and issue management</li> </ol>"},{"location":"aiops/#best-practices_1","title":"Best Practices","text":"<ul> <li>Start Small: Begin with monitoring and alerting before enabling automation</li> <li>Set Clear Boundaries: Configure the agent's operational scope appropriately</li> <li>Monitor Agent Activity: Regular review of behavior logs and decisions</li> <li>User Training: Ensure team members understand how to interact with the AI agent</li> <li>Gradual Automation: Progressively enable more automated features as confidence builds</li> </ul>"},{"location":"aiops/#getting-help","title":"Getting Help","text":"<pre><code># Get help with AIOps commands\nhb aiops help\n\n# Check agent status\nhb aiops status\n\n# View recent agent activity\nhb aiops logs --recent\n\n# Test chat integration\nhb aiops chat-bot test\n</code></pre>"},{"location":"aiops/#related-documentation","title":"Related Documentation","text":"<ul> <li>Observability Platform</li> <li>Architecture Overview</li> <li>API Reference</li> <li>Best Practices</li> </ul>"},{"location":"aiops/agent-hierarchy/","title":"AI Agent Hierarchy","text":"<p>The Hexabase.AI platform implements a sophisticated hierarchical agent system to provide intelligent automation and assistance across your Kubernetes infrastructure.</p>"},{"location":"aiops/agent-hierarchy/#overview","title":"Overview","text":"<p>The AIOps system uses a multi-layered agent architecture designed to efficiently manage tasks, provide intelligent responses, and automate complex operations while maintaining security and user permissions.</p>"},{"location":"aiops/agent-hierarchy/#agent-hierarchy-structure","title":"Agent Hierarchy Structure","text":""},{"location":"aiops/agent-hierarchy/#1-user-facing-chat-agent","title":"1. User-Facing Chat Agent","text":"<p>The top-level agent that interacts directly with users through the platform interface.</p> <p>Responsibilities: - Natural language understanding and response - Request routing to appropriate specialized agents - Context maintenance across conversations - User permission verification</p> <p>Key Features: - Conversational interface for all platform operations - Context-aware responses based on user's current workspace - Multi-language support (English and Japanese)</p>"},{"location":"aiops/agent-hierarchy/#2-orchestrator-agent","title":"2. Orchestrator Agent","text":"<p>The central coordination layer that manages task distribution and agent collaboration.</p> <p>Responsibilities: - Task decomposition and planning - Agent selection and coordination - Result aggregation and synthesis - Error handling and recovery</p> <p>Key Features: - Intelligent routing based on task type - Parallel task execution when possible - Progress tracking and status updates</p>"},{"location":"aiops/agent-hierarchy/#3-specialized-worker-agents","title":"3. Specialized Worker Agents","text":""},{"location":"aiops/agent-hierarchy/#infrastructure-analysis-agent","title":"Infrastructure Analysis Agent","text":"<ul> <li>Monitors cluster health and performance</li> <li>Identifies optimization opportunities</li> <li>Provides capacity planning recommendations</li> <li>Detects anomalies and potential issues</li> </ul>"},{"location":"aiops/agent-hierarchy/#deployment-assistant-agent","title":"Deployment Assistant Agent","text":"<ul> <li>Guides users through application deployments</li> <li>Validates configurations before deployment</li> <li>Suggests best practices and optimizations</li> <li>Troubleshoots deployment issues</li> </ul>"},{"location":"aiops/agent-hierarchy/#cost-optimization-agent","title":"Cost Optimization Agent","text":"<ul> <li>Analyzes resource utilization</li> <li>Identifies cost-saving opportunities</li> <li>Recommends right-sizing strategies</li> <li>Tracks spending trends</li> </ul>"},{"location":"aiops/agent-hierarchy/#security-compliance-agent","title":"Security Compliance Agent","text":"<ul> <li>Monitors security policies</li> <li>Identifies compliance violations</li> <li>Suggests remediation steps</li> <li>Maintains audit trails</li> </ul>"},{"location":"aiops/agent-hierarchy/#troubleshooting-agent","title":"Troubleshooting Agent","text":"<ul> <li>Diagnoses application and infrastructure issues</li> <li>Provides step-by-step resolution guidance</li> <li>Accesses logs and metrics for analysis</li> <li>Suggests preventive measures</li> </ul>"},{"location":"aiops/agent-hierarchy/#agent-communication-flow","title":"Agent Communication Flow","text":"<pre><code>User Request\n    \u2193\nChat Agent (Understanding &amp; Routing)\n    \u2193\nOrchestrator Agent (Planning &amp; Coordination)\n    \u2193\nSpecialized Agents (Execution)\n    \u2193\nResult Aggregation\n    \u2193\nUser Response\n</code></pre>"},{"location":"aiops/agent-hierarchy/#security-model","title":"Security Model","text":"<p>All agents operate within the platform's security framework:</p> <ol> <li>Permission Inheritance: Agents inherit user permissions through JWT tokens</li> <li>Action Authorization: All actions are authorized by the Control Plane</li> <li>Audit Logging: Complete audit trail of all agent actions</li> <li>Sandboxed Execution: Agents run in isolated environments</li> </ol>"},{"location":"aiops/agent-hierarchy/#best-practices","title":"Best Practices","text":""},{"location":"aiops/agent-hierarchy/#effective-agent-interaction","title":"Effective Agent Interaction","text":"<ol> <li>Be Specific: Provide clear, detailed requests for better results</li> <li>Use Context: Reference specific resources or namespaces</li> <li>Iterative Refinement: Build on previous responses for complex tasks</li> </ol>"},{"location":"aiops/agent-hierarchy/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>\"Analyze the performance of my production cluster\"</li> <li>\"Help me deploy a new application with auto-scaling\"</li> <li>\"Find cost optimization opportunities in workspace 'dev'\"</li> <li>\"Troubleshoot why my pods are failing to start\"</li> </ul>"},{"location":"aiops/agent-hierarchy/#integration-with-platform-features","title":"Integration with Platform Features","text":"<p>The agent hierarchy integrates seamlessly with:</p> <ul> <li>Observability Stack: Access to metrics, logs, and traces</li> <li>CI/CD Pipelines: Deployment automation and validation</li> <li>RBAC System: Permission-aware operations</li> <li>Resource Management: Cluster and application lifecycle</li> </ul>"},{"location":"aiops/agent-hierarchy/#limitations-and-considerations","title":"Limitations and Considerations","text":"<ul> <li>Agents operate within user permissions</li> <li>Complex operations may require multiple steps</li> <li>Real-time constraints for certain operations</li> <li>LLM model limitations for specialized domains</li> </ul>"},{"location":"aiops/agent-hierarchy/#future-enhancements","title":"Future Enhancements","text":"<p>The agent system is continuously evolving with planned improvements:</p> <ul> <li>Additional specialized agents for new use cases</li> <li>Enhanced collaboration between agents</li> <li>Improved learning from user interactions</li> <li>Extended automation capabilities</li> </ul>"},{"location":"aiops/ai-devops-use-cases/","title":"AI-Powered DevOps Use Cases","text":"<p>This guide provides comprehensive scenarios and real-world applications of AI-powered DevOps capabilities within Hexabase.AI, demonstrating how artificial intelligence transforms traditional development and operations workflows.</p>"},{"location":"aiops/ai-devops-use-cases/#core-ai-devops-scenarios","title":"Core AI DevOps Scenarios","text":""},{"location":"aiops/ai-devops-use-cases/#1-zero-downtime-deployments","title":"1. Zero-Downtime Deployments","text":"<p>Challenge: Deploy critical updates without service interruption</p> <p>Traditional Approach Problems: - Manual deployment decisions - Risk of failed rollouts - Reactive incident response - Limited rollback capabilities</p> <p>AI-Enhanced Solution:</p>"},{"location":"aiops/ai-devops-use-cases/#pre-deployment-analysis","title":"Pre-deployment Analysis","text":"<pre><code># AI agent for pre-deployment analysis\nclass PreDeploymentAnalyzer(AIAgent):\n    def analyze_deployment(self, deployment_config, historical_data):\n        # Analyze code changes for risk factors\n        risk_score = self.assess_risk(deployment_config.changes)\n\n        # Predict deployment success probability\n        success_probability = self.predict_success(\n            deployment_config, \n            historical_data\n        )\n\n        # Recommend deployment strategy\n        strategy = self.recommend_strategy(risk_score, success_probability)\n\n        return {\n            'risk_score': risk_score,\n            'success_probability': success_probability,\n            'recommended_strategy': strategy,\n            'rollback_plan': self.generate_rollback_plan()\n        }\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#smart-canary-rollout","title":"Smart Canary Rollout","text":"<ul> <li>AI monitors canary metrics in real-time</li> <li>Dynamically adjusts traffic distribution</li> <li>Makes autonomous go/no-go decisions</li> <li>Learns from each deployment for future optimization</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#implementation-example","title":"Implementation Example","text":"<pre><code># AI-enhanced deployment configuration\ndeployment:\n  strategy: smart_canary\n  ai_config:\n    models:\n      - deployment_risk_assessment\n      - traffic_pattern_analysis\n      - performance_prediction\n    decision_criteria:\n      error_rate_threshold: 0.1%\n      latency_increase_threshold: 5%\n      success_rate_threshold: 99.9%\n    automation_level: full  # supervised, assisted, full\n</code></pre> <p>Results: - 95% reduction in failed deployments - 70% faster deployment cycles - Zero human intervention required for standard deployments</p>"},{"location":"aiops/ai-devops-use-cases/#2-intelligent-incident-response","title":"2. Intelligent Incident Response","text":"<p>Challenge: Reduce Mean Time to Resolution (MTTR) for production incidents</p> <p>Traditional Approach Problems: - Manual log analysis - Time-consuming root cause identification - Inconsistent response procedures - Knowledge gaps during off-hours</p> <p>AI-Enhanced Solution:</p>"},{"location":"aiops/ai-devops-use-cases/#automated-incident-detection","title":"Automated Incident Detection","text":"<pre><code># AI-powered incident detection\nclass IncidentDetector(AIAgent):\n    def monitor_system_health(self, metrics, logs, traces):\n        # Multi-modal analysis\n        anomalies = self.detect_anomalies(metrics)\n        error_patterns = self.analyze_log_patterns(logs)\n        trace_issues = self.analyze_distributed_traces(traces)\n\n        # Correlate across data sources\n        incidents = self.correlate_issues(anomalies, error_patterns, trace_issues)\n\n        # Prioritize and classify\n        for incident in incidents:\n            incident.severity = self.assess_severity(incident)\n            incident.category = self.classify_incident(incident)\n            incident.affected_services = self.identify_impact(incident)\n\n        return incidents\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#intelligent-root-cause-analysis","title":"Intelligent Root Cause Analysis","text":"<pre><code># AI incident responder configuration\nincident_response:\n  ai_agent:\n    name: \"IncidentBot\"\n    capabilities:\n      - log_analysis\n      - metric_correlation\n      - dependency_mapping\n      - historical_pattern_matching\n      - remediation_planning\n    escalation:\n      level_1: ai_remediation\n      level_2: ai_assisted_human\n      level_3: human_intervention\n    learning:\n      feedback_loop: enabled\n      model_updates: continuous\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#automated-response-workflow","title":"Automated Response Workflow","text":"<ol> <li>Detection: AI identifies anomaly in real-time</li> <li>Analysis: Correlates logs, metrics, and traces</li> <li>Diagnosis: Identifies root cause using historical patterns</li> <li>Remediation: Executes automated fix procedures</li> <li>Validation: Confirms resolution and monitors for regression</li> <li>Documentation: Creates incident report with timeline</li> </ol> <p>Results: - 80% reduction in MTTR - 60% of incidents resolved without human intervention - 95% accuracy in root cause identification</p>"},{"location":"aiops/ai-devops-use-cases/#3-performance-optimization","title":"3. Performance Optimization","text":"<p>Challenge: Continuously optimize application performance and resource utilization</p> <p>AI-Enhanced Solution:</p>"},{"location":"aiops/ai-devops-use-cases/#continuous-performance-profiling","title":"Continuous Performance Profiling","text":"<pre><code># AI performance optimizer\nclass PerformanceOptimizer(AIAgent):\n    def optimize_application(self, app_metrics, resource_usage):\n        # Identify performance bottlenecks\n        bottlenecks = self.identify_bottlenecks(app_metrics)\n\n        # Analyze resource patterns\n        resource_patterns = self.analyze_resource_usage(resource_usage)\n\n        # Generate optimization recommendations\n        optimizations = []\n        for bottleneck in bottlenecks:\n            optimization = self.generate_optimization(\n                bottleneck, \n                resource_patterns\n            )\n            optimizations.append(optimization)\n\n        return optimizations\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#smart-resource-allocation","title":"Smart Resource Allocation","text":"<ul> <li>ML-based prediction of resource needs</li> <li>Dynamic scaling based on workload patterns</li> <li>Cost-optimized instance selection</li> <li>Automatic rightsizing recommendations</li> </ul> <p>Results: - 40% improvement in application response times - 35% reduction in infrastructure costs - 90% reduction in over-provisioned resources</p>"},{"location":"aiops/ai-devops-use-cases/#4-code-quality-and-security","title":"4. Code Quality and Security","text":"<p>Challenge: Maintain high code quality and security standards at scale</p> <p>AI-Enhanced Solution:</p>"},{"location":"aiops/ai-devops-use-cases/#intelligent-code-reviews","title":"Intelligent Code Reviews","text":"<pre><code># AI code review configuration\ncode_review:\n  ai_models:\n    - security_scanner\n    - performance_analyzer\n    - code_quality_checker\n    - architectural_advisor\n\n  checks:\n    security:\n      - vulnerability_detection\n      - secret_scanning\n      - dependency_analysis\n    performance:\n      - algorithm_efficiency\n      - resource_usage_patterns\n      - database_query_optimization\n    quality:\n      - code_complexity\n      - maintainability_score\n      - test_coverage_analysis\n    architecture:\n      - design_pattern_compliance\n      - coupling_analysis\n      - cohesion_assessment\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#automated-security-scanning","title":"Automated Security Scanning","text":"<ul> <li>Real-time vulnerability detection</li> <li>Dependency security analysis</li> <li>Infrastructure security assessment</li> <li>Compliance validation</li> </ul> <p>Results: - 75% reduction in security vulnerabilities - 60% improvement in code quality scores - 50% faster code review process</p>"},{"location":"aiops/ai-devops-use-cases/#advanced-ai-devops-scenarios","title":"Advanced AI DevOps Scenarios","text":""},{"location":"aiops/ai-devops-use-cases/#5-predictive-capacity-planning","title":"5. Predictive Capacity Planning","text":"<p>Challenge: Anticipate infrastructure needs and prevent capacity-related incidents</p> <p>AI Solution: <pre><code># Predictive capacity planning\nclass CapacityPlanner(AIAgent):\n    def predict_capacity_needs(self, historical_usage, business_metrics):\n        # Time series forecasting\n        usage_forecast = self.forecast_resource_usage(historical_usage)\n\n        # Business-driven predictions\n        business_forecast = self.correlate_business_metrics(\n            business_metrics, \n            historical_usage\n        )\n\n        # Combine forecasts\n        capacity_plan = self.generate_capacity_plan(\n            usage_forecast, \n            business_forecast\n        )\n\n        return capacity_plan\n</code></pre></p>"},{"location":"aiops/ai-devops-use-cases/#6-multi-cloud-optimization","title":"6. Multi-Cloud Optimization","text":"<p>Challenge: Optimize workload placement across multiple cloud providers</p> <p>AI Solution: - Cost-performance optimization across clouds - Latency-based placement decisions - Failure domain distribution - Compliance-aware resource allocation</p>"},{"location":"aiops/ai-devops-use-cases/#7-developer-experience-enhancement","title":"7. Developer Experience Enhancement","text":"<p>Challenge: Improve developer productivity and reduce friction</p> <p>AI Solution: - Intelligent development environment setup - Automated testing strategy recommendations - Code completion and generation - Documentation auto-generation</p>"},{"location":"aiops/ai-devops-use-cases/#implementation-patterns","title":"Implementation Patterns","text":""},{"location":"aiops/ai-devops-use-cases/#ai-agent-integration","title":"AI Agent Integration","text":""},{"location":"aiops/ai-devops-use-cases/#code-repository-integration","title":"Code Repository Integration","text":"<pre><code># GitHub Actions with AI\nname: AI-Enhanced CI/CD\non: [push, pull_request]\njobs:\n  ai-analysis:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: AI Code Review\n        uses: hexabase/ai-code-review@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n          models: security,performance,quality\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#kubernetes-integration","title":"Kubernetes Integration","text":"<pre><code># AI operator deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ai-devops-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ai-devops-operator\n  template:\n    spec:\n      containers:\n      - name: operator\n        image: hexabase/ai-devops-operator:latest\n        env:\n        - name: AI_MODEL_ENDPOINT\n          value: \"https://api.hexabase.ai/ai\"\n        - name: CLUSTER_SCOPE\n          value: \"production\"\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#monitoring-and-feedback-loops","title":"Monitoring and Feedback Loops","text":""},{"location":"aiops/ai-devops-use-cases/#ai-decision-tracking","title":"AI Decision Tracking","text":"<pre><code># Track AI decision effectiveness\nclass AIDecisionTracker:\n    def track_deployment_decision(self, deployment_id, ai_decision, outcome):\n        # Record decision and outcome\n        self.record_decision(deployment_id, ai_decision, outcome)\n\n        # Update model based on feedback\n        if outcome.success != ai_decision.predicted_success:\n            self.update_model_weights(ai_decision, outcome)\n\n    def generate_feedback_report(self):\n        # Analyze AI decision accuracy\n        accuracy_metrics = self.calculate_accuracy()\n\n        # Identify improvement areas\n        improvement_areas = self.identify_model_gaps()\n\n        return {\n            'accuracy_metrics': accuracy_metrics,\n            'improvement_areas': improvement_areas,\n            'recommended_actions': self.recommend_improvements()\n        }\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#best-practices-for-ai-devops","title":"Best Practices for AI DevOps","text":""},{"location":"aiops/ai-devops-use-cases/#1-gradual-ai-adoption","title":"1. Gradual AI Adoption","text":"<ul> <li>Start with recommendation-only mode</li> <li>Gradually increase automation levels</li> <li>Maintain human oversight for critical decisions</li> <li>Implement proper rollback mechanisms</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#2-data-quality-and-training","title":"2. Data Quality and Training","text":"<ul> <li>Ensure high-quality training data</li> <li>Implement continuous learning loops</li> <li>Regular model retraining and validation</li> <li>A/B testing for AI decisions</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#3-security-and-compliance","title":"3. Security and Compliance","text":"<ul> <li>Secure AI model endpoints</li> <li>Audit AI decision logs</li> <li>Implement bias detection and mitigation</li> <li>Regular security assessments</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#4-team-integration","title":"4. Team Integration","text":"<ul> <li>Provide AI decision transparency</li> <li>Train teams on AI-assisted workflows</li> <li>Establish clear escalation procedures</li> <li>Encourage feedback and improvement suggestions</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#measuring-ai-devops-success","title":"Measuring AI DevOps Success","text":""},{"location":"aiops/ai-devops-use-cases/#key-performance-indicators","title":"Key Performance Indicators","text":""},{"location":"aiops/ai-devops-use-cases/#development-velocity","title":"Development Velocity","text":"<ul> <li>Deployment frequency increase</li> <li>Lead time reduction</li> <li>Change failure rate decrease</li> <li>Recovery time improvement</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#quality-metrics","title":"Quality Metrics","text":"<ul> <li>Bug detection rate improvement</li> <li>Security vulnerability reduction</li> <li>Code quality score increase</li> <li>Test coverage improvement</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#operational-efficiency","title":"Operational Efficiency","text":"<ul> <li>MTTR reduction</li> <li>Incident prevention rate</li> <li>Resource utilization optimization</li> <li>Cost reduction achieved</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#team-satisfaction","title":"Team Satisfaction","text":"<ul> <li>Developer experience scores</li> <li>Time saved on routine tasks</li> <li>Learning and skill development</li> <li>Overall job satisfaction</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#future-roadmap","title":"Future Roadmap","text":""},{"location":"aiops/ai-devops-use-cases/#near-term-enhancements-q1-q2","title":"Near-term Enhancements (Q1-Q2)","text":"<ul> <li>GPT-4 model integration</li> <li>Advanced anomaly detection</li> <li>Automated documentation generation</li> <li>Smart resource optimization</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#medium-term-goals-q3-q4","title":"Medium-term Goals (Q3-Q4)","text":"<ul> <li>Custom model marketplace</li> <li>Multi-language support enhancement</li> <li>Advanced collaboration features</li> <li>Quantum-resistant security measures</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#long-term-vision-next-year","title":"Long-term Vision (Next Year)","text":"<ul> <li>Autonomous operations capabilities</li> <li>Predictive architecture evolution</li> <li>Full-stack optimization</li> <li>Industry-specific AI models</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#getting-started","title":"Getting Started","text":""},{"location":"aiops/ai-devops-use-cases/#prerequisites","title":"Prerequisites","text":"<ul> <li>Hexabase.AI platform access</li> <li>Basic Kubernetes knowledge</li> <li>CI/CD pipeline in place</li> <li>Monitoring infrastructure</li> </ul>"},{"location":"aiops/ai-devops-use-cases/#quick-start-guide","title":"Quick Start Guide","text":"<pre><code># Install AI DevOps module\nhb module install ai-devops\n\n# Configure AI agents\nhb ai configure \\\n  --openai-key $OPENAI_API_KEY \\\n  --enable-code-review \\\n  --enable-monitoring \\\n  --enable-incident-response\n\n# Deploy your first AI-enhanced pipeline\nhb pipeline create smart-pipeline \\\n  --ai-enabled \\\n  --template microservice \\\n  --monitoring-level advanced\n</code></pre>"},{"location":"aiops/ai-devops-use-cases/#related-topics","title":"Related Topics","text":"<ul> <li>AIOps Architecture - Technical architecture and design</li> <li>Agent Hierarchy - AI agent organization and capabilities</li> <li>LLM Integration - Large language model integration</li> <li>Secure Sandbox - AI execution security</li> <li>Observability Platform - Monitoring and logging integration</li> </ul>"},{"location":"aiops/architecture/","title":"AIOps Architecture and Implementation Summary","text":"<p>This document provides a detailed overview of the Hexabase KaaS AIOps system, covering its architecture, technology stack, integration with the main control plane, and security model.</p>"},{"location":"aiops/architecture/#1-architectural-vision","title":"1. Architectural Vision","text":"<p>The AIOps system is designed as a distinct, Python-based subsystem that operates alongside the Go-based Hexabase Control Plane. This separation allows for leveraging the rich Python AI/ML ecosystem while maintaining a clear boundary between the core KaaS operations and the AI-driven intelligence layer.</p> <p>Core Principles:</p> <ul> <li>Decoupled Systems: The AIOps system is a separate deployment, communicating with the Control Plane via internal, secured APIs.</li> <li>Optimized Tech Stack: Utilizes Python, FastAPI, LangChain/LlamaIndex, and Ollama for rapid development and access to state-of-the-art AI tooling.</li> <li>Hierarchical Agents: Employs a multi-layered agent architecture, from a user-facing chat agent to a central orchestrator and specialized worker agents, to efficiently manage tasks and analysis.</li> <li>Secure by Design: Inherits user permissions via a short-lived JWT model, with all actions ultimately authorized and executed by the Control Plane.</li> <li>Extensible LLM Support: Provides a flexible model for using both internally-hosted open-source LLMs and external commercial LLM APIs, with configuration available at both the organization and workspace levels.</li> <li>Observable and Traceable: All agent interactions are designed to be logged and traced, providing clear visibility into the system's reasoning and actions for debugging and analysis.</li> </ul>"},{"location":"aiops/architecture/#2-system-components-and-deployment","title":"2. System Components and Deployment","text":"<pre><code>graph TD\n    subgraph \"Hexabase Namespace\"\n        direction LR\n        HKS_Control_Plane[HKS Control Plane (Go)]\n        HKS_Service[hks-control-plane-svc]\n        HKS_Control_Plane -- exposes --&gt; HKS_Service\n    end\n\n    subgraph \"AIOps Namespace\"\n        direction LR\n        AIOps_System[AIOps API (Python/FastAPI)]\n        AIOps_Service[ai-ops-svc]\n        AIOps_System -- exposes --&gt; AIOps_Service\n    end\n\n    subgraph \"AIOps LLM Namespace\"\n        direction LR\n        Ollama_DaemonSet[Ollama DaemonSet]\n        Ollama_Service[ollama-svc]\n        OLLAMA_NODE[GPU/CPU Node&lt;br/&gt;(label: node-role=private-llm)]\n        Ollama_DaemonSet -- runs on --&gt; OLLAMA_NODE\n        Ollama_DaemonSet -- exposes --&gt; Ollama_Service\n    end\n\n    HKS_Control_Plane -- \"Internal API Call w/ JWT\" --&gt; AIOps_Service\n    AIOps_System -- \"Internal Ops API Call w/ JWT\" --&gt; HKS_Service\n    AIOps_System -- \"LLM Inference\" --&gt; Ollama_Service</code></pre>"},{"location":"aiops/architecture/#21-agent-based-architecture","title":"2.1 Agent-based Architecture","text":"<p>The AIOps system employs a hierarchical, multi-agent architecture to manage user requests and interact with the HKS platform. This separation of concerns allows for specialized agents, better maintainability, and more complex reasoning capabilities.</p> <pre><code>graph TD\n    subgraph \"User Interaction Layer\"\n        User[HKS User]\n        ChatClient[Chat Client &lt;br/&gt; (UI, Slack, Teams, etc.)]\n        User -- Interacts with --&gt; ChatClient\n    end\n\n    subgraph \"AIOps System (Python)\"\n        direction LR\n        UserChatAgent[UserChatAgent]\n        OrchestrationAgent[Orchestration Agent]\n        WorkerAgents[Worker Agents &lt;br/&gt; - Kubernetes Agent &lt;br/&gt; - Prometheus Agent &lt;br/&gt; - ClickHouse Agent &lt;br/&gt; - Storage Agent &lt;br/&gt; - Helm Agent &lt;br/&gt; - etc.]\n\n        UserChatAgent -- \"User Query\" --&gt; OrchestrationAgent\n        OrchestrationAgent -- \"Sub-task\" --&gt; WorkerAgents\n        WorkerAgents -- \"Tool Output\" --&gt; OrchestrationAgent\n        OrchestrationAgent -- \"Synthesized Response\" --&gt; UserChatAgent\n    end\n\n    subgraph \"HKS Control Plane (Go)\"\n        HKS_InternalAPI[HKS Internal Ops API]\n        HKS_DB[HKS Database]\n        HKS_InternalAPI -- Accesses --&gt; HKS_DB\n    end\n\n    subgraph \"LLM Services\"\n        Ollama[Private LLM (Ollama)]\n        LLM_APIs[External LLM APIs &lt;br/&gt; (OpenAI, Anthropic, etc.)]\n    end\n\n    ChatClient -- \"API Call w/ User Auth\" --&gt; HKS_Control_Plane\n    HKS_Control_Plane -- \"Generates JWT, forwards to\" --&gt; UserChatAgent\n    UserChatAgent -- \"Conversational Logic\" --&gt; LLM_APIs\n    WorkerAgents -- \"Executes Actions via\" --&gt; HKS_InternalAPI\n    WorkerAgents -- \"Inference (optional)\" --&gt; Ollama</code></pre> <ul> <li> <p>UserChatAgent: The primary point of contact for the end-user.</p> </li> <li> <p>Responsible for managing the conversation flow, maintaining session state, and providing a user-friendly experience.</p> </li> <li>To handle nuanced human conversation, this agent is designed to use powerful external, commercial LLMs (e.g., GPT-4, Claude 3).</li> <li> <p>It forwards the user's core intent to the Orchestration Agent.</p> </li> <li> <p>Orchestration Agent: The central \"brain\" or router of the AIOps system.</p> </li> <li> <p>It receives a task from the <code>UserChatAgent</code>, breaks it down into smaller, executable steps, and dispatches those steps to the appropriate <code>Worker Agent(s)</code>.</p> </li> <li> <p>It synthesizes the results from the workers into a coherent final answer for the <code>UserChatAgent</code>.</p> </li> <li> <p>Worker Agents: A collection of specialized, tool-using agents.</p> </li> <li>Each worker is an expert on a specific domain (e.g., interacting with the Kubernetes API, querying Prometheus, analyzing logs in ClickHouse, monitoring storage, managing Helm releases).</li> <li>They execute concrete tasks using predefined tools and APIs. These agents may use smaller, local LLMs for simple data processing but often do not require an LLM for their core function.</li> <li>All actions that modify the HKS state are performed by making secure calls to the HKS Internal Operations API, never directly.</li> </ul> <p>This structure allows for future integration with various chat clients (Slack, Teams, Discord) and even as a backend for tools like Cursor, as the <code>UserChatAgent</code> abstracts the interaction logic.</p> <ul> <li>HKS Control Plane (Go): The existing main application.</li> <li>AIOps System (Python): A new deployment in a separate <code>ai-ops</code> namespace. It consists of:</li> <li>API Server: A FastAPI application that serves as the entry point for the HKS Control Plane.</li> <li>Orchestrators &amp; Agents: Implemented in Python using frameworks like LlamaIndex or LangChain.</li> <li>Private LLM Server (Ollama): Deployed as a <code>DaemonSet</code> onto dedicated nodes (labeled <code>node-role: private-llm</code>) in an <code>ai-ops-llm</code> namespace. This ensures LLM workloads are isolated.</li> </ul>"},{"location":"aiops/architecture/#3-llm-configuration-and-management","title":"3. LLM Configuration and Management","text":"<p>The AIOps system supports a flexible approach to LLM usage, accommodating both private, self-hosted models for internal tasks and powerful commercial models for user-facing interactions.</p>"},{"location":"aiops/architecture/#31-llm-providers","title":"3.1 LLM Providers","text":"<ul> <li> <p>Private LLMs (Ollama): We use Ollama to simplify the deployment and management of open-source LLMs (e.g., Llama 3, Phi-3). These are used for internal tasks like routing, data extraction, or simple analysis where data residency is critical. The setup involves:</p> </li> <li> <p>Provisioning Nodes: Designating Kubernetes nodes with the label <code>node-role: private-llm</code>.</p> </li> <li>Deploying Ollama: Using a <code>DaemonSet</code> with a <code>nodeSelector</code> for <code>node-role: private-llm</code>.</li> <li>Exposing Service: Creating a <code>Service</code> (<code>ollama-service</code>) as a stable internal endpoint.</li> <li>Pre-pulling Models: Using an <code>initContainer</code> or a <code>Job</code> to pull required models into Ollama.</li> <li> <p>Integration: The Python code points to <code>http://ollama-service.ai-ops-llm.svc.cluster.local</code> for inference.</p> </li> <li> <p>External LLMs: For the <code>UserChatAgent</code>, which requires advanced conversational abilities, the system will integrate with external commercial LLM providers (e.g., OpenAI, Google, Anthropic). API keys and model preferences are managed securely.</p> </li> </ul>"},{"location":"aiops/architecture/#32-configuration-hierarchy","title":"3.2 Configuration Hierarchy","text":"<p>To provide flexibility, LLM settings can be configured at two levels:</p> <ol> <li>Organization Level (Default): A default LLM configuration (e.g., for the <code>UserChatAgent</code>) is set for the entire HKS organization. This configuration is managed via environment variables in the AIOps system's deployment.</li> <li>Workspace Level (Override): Workspace Admins can override the default LLM settings for their specific workspace. This allows them to choose a different model or provide their own API key. This requires:<ul> <li>An API endpoint in the HKS Control Plane to store and retrieve workspace-specific LLM settings.</li> <li>A corresponding UI for Workspace Admins to manage these settings.</li> <li>The AIOps system will first check for a workspace-specific configuration and fall back to the organization-level default if none is found.</li> </ul> </li> </ol>"},{"location":"aiops/architecture/#4-security-model-aiops-sandbox-and-session-management","title":"4. Security Model: AIOps Sandbox and Session Management","text":"<p>The security model is critical and is based on user impersonation via short-lived, scoped tokens. The AIOps system acts as a sandboxed advisor, with the HKS Control Plane as the sole enforcer of permissions.</p>"},{"location":"aiops/architecture/#41-authorization-flow","title":"4.1 Authorization Flow","text":"<ol> <li>A user initiates a chat session via a client (HKS UI, Slack, etc.).</li> <li>The HKS Control Plane authenticates the user and generates a short-lived Internal JWT. This JWT contains the user's ID, their roles, and the scope of their request (e.g., <code>workspace_id</code>).</li> <li>The Control Plane calls the <code>UserChatAgent</code> in the AIOps system, passing the user's request and the Internal JWT.</li> <li>The AIOps system's agents (<code>UserChatAgent</code>, <code>Orchestrator</code>, <code>Workers</code>) pass this JWT internally for context and subsequent API calls. The agents themselves have no inherent privileges.</li> <li>To execute an action (e.g., scale a deployment), a <code>Worker Agent</code> makes a call back to a specific, non-public Internal Operations API on the HKS Control Plane (e.g., <code>POST /internal/v1/operations/scale</code>).</li> <li>This request must include the original Internal JWT.</li> <li>The HKS Control Plane receives the request. It re-validates the JWT and performs a final authorization check: \"Does this user (<code>sub</code> from JWT) have permission to perform this action on this resource, according to the latest data in our database?\"</li> <li>If authorized, the Control Plane executes the operation using its own privileged service account. If not, it returns a permission error.</li> </ol> <p>This flow ensures that the AIOps system is fully sandboxed. It can request actions, but the Control Plane remains the sole, authoritative \"executor,\" enforcing all security and RBAC policies at the moment of execution.</p>"},{"location":"aiops/architecture/#42-session-management","title":"4.2 Session Management","text":"<p>User sessions with the <code>UserChatAgent</code> are stateful but must adapt to changes in user permissions.</p> <ul> <li>Session Timeout: Sessions will have a defined idle timeout, after which the <code>UserChatAgent</code> will effectively \"log out\". The next user interaction will trigger a new authentication flow with the HKS Control Plane.</li> <li>Permission Change Detection: HKS user permissions can change. To ensure the AIOps system never operates on stale permissions, the session must be re-validated. On each request that requires an action, the final authorization check by the Control Plane (Step 7 above) implicitly handles this. If a user's permissions were revoked, the action will fail. The AIOps system should interpret this as a potential permission change and can prompt the user to re-authenticate to \"resume\" the session with updated credentials.</li> </ul> <p>Thorough security test cases for this entire flow, especially covering permission changes and token validation, will be a critical part of the development process.</p>"},{"location":"aiops/architecture/#5-llmops-and-observability","title":"5. LLMOps and Observability","text":"<p>To ensure the AIOps system is transparent, debuggable, and continuously improving, its interactions are tracked in two primary ways: AI Tracing for development and Audit Logging for user-visible actions.</p> <ul> <li>AI Tracing with Langfuse: We will integrate the AIOps system with Langfuse. This is a developer-focused tool that captures the entire internal reasoning lifecycle of a request:</li> <li>The initial prompt from the <code>UserChatAgent</code>.</li> <li>The reasoning and task breakdown from the <code>Orchestration Agent</code>.</li> <li>The specific tools called and results returned by the <code>Worker Agents</code>.</li> <li>The final synthesized response.</li> <li>Benefits: This detailed tracing provides invaluable data for debugging complex agent behaviors, analyzing performance, evaluating LLM quality, and creating datasets for future fine-tuning. The Langfuse SDK will be integrated directly into the Python AIOps application.</li> <li>Audit Logging: All definitive actions taken by an agent on behalf of a user (e.g., modifying a Kubernetes resource) are logged in the central HKS Audit Log system (ClickHouse). This provides a compliant, user-visible record of all changes. For more details, see the main <code>Logging and Auditing Architecture</code> document.</li> </ul>"},{"location":"aiops/architecture/#6-development-and-repository-structure","title":"6. Development and Repository Structure","text":"<p>Initially, the AIOps system will be developed in a subdirectory of the main repository to facilitate close integration.</p>"},{"location":"aiops/llm-integration/","title":"LLM Integration","text":"<p>Hexabase.AI provides flexible Large Language Model (LLM) integration to power its AI-driven features, supporting both self-hosted open-source models and external commercial LLM APIs.</p>"},{"location":"aiops/llm-integration/#overview","title":"Overview","text":"<p>The platform's LLM integration is designed to give organizations complete control over their AI infrastructure while maintaining flexibility to use the best models for their specific needs.</p>"},{"location":"aiops/llm-integration/#supported-llm-options","title":"Supported LLM Options","text":""},{"location":"aiops/llm-integration/#1-self-hosted-open-source-models","title":"1. Self-Hosted Open Source Models","text":"<p>Run LLMs directly within your infrastructure for maximum privacy and control.</p> <p>Supported Models: - Llama \u2154: Meta's open-source foundation models - Mistral: High-performance open models - CodeLlama: Specialized for code generation - Custom Models: Support for GGUF format models</p> <p>Benefits: - Complete data privacy - no data leaves your infrastructure - No per-token costs - Full control over model selection and updates - Compliance with strict data residency requirements</p>"},{"location":"aiops/llm-integration/#2-commercial-llm-apis","title":"2. Commercial LLM APIs","text":"<p>Integrate with leading commercial LLM providers for access to state-of-the-art models.</p> <p>Supported Providers: - OpenAI (GPT-4, GPT-3.5) - Anthropic (Claude) - Google (PaLM, Gemini) - Azure OpenAI Service</p> <p>Benefits: - Access to cutting-edge models - No infrastructure management - Automatic model updates - Higher performance for complex tasks</p>"},{"location":"aiops/llm-integration/#configuration-levels","title":"Configuration Levels","text":""},{"location":"aiops/llm-integration/#organization-level-configuration","title":"Organization-Level Configuration","text":"<p>Set default LLM preferences for your entire organization:</p> <pre><code>llm_config:\n  provider: \"ollama\"  # or \"openai\", \"anthropic\", etc.\n  model: \"llama3:8b\"\n  temperature: 0.7\n  max_tokens: 4096\n</code></pre>"},{"location":"aiops/llm-integration/#workspace-level-configuration","title":"Workspace-Level Configuration","text":"<p>Override organization defaults for specific workspaces:</p> <pre><code>workspaces:\n  production:\n    llm_override:\n      provider: \"openai\"\n      model: \"gpt-4\"\n      # More conservative settings for production\n      temperature: 0.3\n  development:\n    llm_override:\n      provider: \"ollama\"\n      model: \"codellama:13b\"\n</code></pre>"},{"location":"aiops/llm-integration/#technical-architecture","title":"Technical Architecture","text":""},{"location":"aiops/llm-integration/#self-hosted-model-deployment","title":"Self-Hosted Model Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GPU/CPU Nodes     \u2502\n\u2502 (node-role=llm)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Ollama DaemonSet   \u2502\n\u2502  - Model Management \u2502\n\u2502  - Inference Engine \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AIOps Service     \u2502\n\u2502  - Request Router   \u2502\n\u2502  - Context Manager  \u2502\n\u2502  - Response Cache   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aiops/llm-integration/#api-integration-architecture","title":"API Integration Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AIOps Service     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  LLM Gateway        \u2502\n\u2502  - API Management   \u2502\n\u2502  - Rate Limiting    \u2502\n\u2502  - Cost Tracking    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  External LLM APIs  \u2502\n\u2502  - OpenAI          \u2502\n\u2502  - Anthropic       \u2502\n\u2502  - Google          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aiops/llm-integration/#security-and-privacy","title":"Security and Privacy","text":""},{"location":"aiops/llm-integration/#data-protection","title":"Data Protection","text":"<ol> <li>Encryption: All LLM communications encrypted in transit</li> <li>Sanitization: Automatic removal of sensitive data before processing</li> <li>Audit Logs: Complete audit trail of all LLM interactions</li> <li>Access Control: RBAC-based access to LLM features</li> </ol>"},{"location":"aiops/llm-integration/#compliance-features","title":"Compliance Features","text":"<ul> <li>Data Residency: Keep all data within your infrastructure</li> <li>GDPR Compliance: Right to deletion and data portability</li> <li>HIPAA Ready: Healthcare-compliant configurations available</li> <li>SOC 2: Audit-ready logging and controls</li> </ul>"},{"location":"aiops/llm-integration/#performance-optimization","title":"Performance Optimization","text":""},{"location":"aiops/llm-integration/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Response caching for common queries</li> <li>Embedding cache for semantic search</li> <li>Model warm-up for faster first responses</li> </ul>"},{"location":"aiops/llm-integration/#resource-management","title":"Resource Management","text":"<ul> <li>GPU Allocation: Dedicated GPU nodes for model inference</li> <li>Auto-scaling: Dynamic scaling based on request load</li> <li>Queue Management: Priority queuing for critical requests</li> </ul>"},{"location":"aiops/llm-integration/#use-cases-by-model-type","title":"Use Cases by Model Type","text":""},{"location":"aiops/llm-integration/#when-to-use-self-hosted-models","title":"When to Use Self-Hosted Models","text":"<ul> <li>Sensitive data processing</li> <li>Predictable costs at scale</li> <li>Specific compliance requirements</li> <li>Custom model fine-tuning needs</li> </ul>"},{"location":"aiops/llm-integration/#when-to-use-commercial-apis","title":"When to Use Commercial APIs","text":"<ul> <li>Need for latest model capabilities</li> <li>Variable or low-volume usage</li> <li>Rapid prototyping</li> <li>Complex reasoning tasks</li> </ul>"},{"location":"aiops/llm-integration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"aiops/llm-integration/#basic-self-hosted-setup","title":"Basic Self-Hosted Setup","text":"<pre><code># Enable LLM features\nhb llm enable --provider ollama\n\n# Install a model\nhb llm install llama3:8b\n\n# Configure organization defaults\nhb org set-llm --model llama3:8b --temperature 0.7\n</code></pre>"},{"location":"aiops/llm-integration/#commercial-api-setup","title":"Commercial API Setup","text":"<pre><code># Configure OpenAI integration\nhb llm enable --provider openai\n\n# Set API credentials (stored securely)\nhb secret create openai-api-key --from-literal=key=sk-...\n\n# Configure model preferences\nhb workspace set-llm --model gpt-4 --max-tokens 8192\n</code></pre>"},{"location":"aiops/llm-integration/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"aiops/llm-integration/#metrics-tracked","title":"Metrics Tracked","text":"<ul> <li>Request latency and throughput</li> <li>Token usage and costs</li> <li>Model performance metrics</li> <li>Error rates and types</li> </ul>"},{"location":"aiops/llm-integration/#dashboards-available","title":"Dashboards Available","text":"<ul> <li>LLM usage overview</li> <li>Cost analysis (for API models)</li> <li>Performance trends</li> <li>User interaction patterns</li> </ul>"},{"location":"aiops/llm-integration/#best-practices","title":"Best Practices","text":"<ol> <li>Start with Self-Hosted: Begin with open-source models for testing</li> <li>Monitor Costs: Track API usage to control expenses</li> <li>Optimize Prompts: Well-crafted prompts improve results and reduce costs</li> <li>Cache Strategically: Use caching for repetitive queries</li> <li>Regular Reviews: Periodically review model performance and costs</li> </ol>"},{"location":"aiops/llm-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aiops/llm-integration/#common-issues","title":"Common Issues","text":"<ol> <li>Slow Responses: Check GPU allocation and model size</li> <li>API Errors: Verify credentials and rate limits</li> <li>Quality Issues: Adjust temperature and prompt engineering</li> <li>Cost Overruns: Review usage patterns and implement limits</li> </ol>"},{"location":"aiops/llm-integration/#getting-help","title":"Getting Help","text":"<ul> <li>Check AIOps logs: <code>hb logs -n hexabase-aiops</code></li> <li>Review model metrics in dashboards</li> <li>Contact support with correlation IDs</li> </ul>"},{"location":"aiops/secure-sandbox/","title":"Secure Sandbox Environment","text":"<p>The Hexabase.AI platform provides a secure sandbox environment for AI operations, ensuring that AI agents can perform complex tasks while maintaining strict security boundaries and preventing unauthorized access to resources.</p>"},{"location":"aiops/secure-sandbox/#overview","title":"Overview","text":"<p>The secure sandbox is a isolated execution environment where AI agents can safely analyze, test, and execute operations without risking the integrity of your production systems. This environment is crucial for maintaining security while leveraging the full power of AI automation.</p>"},{"location":"aiops/secure-sandbox/#architecture","title":"Architecture","text":""},{"location":"aiops/secure-sandbox/#sandbox-components","title":"Sandbox Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         User Request                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Permission Validator           \u2502\n\u2502   (JWT Token Verification)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       Sandbox Controller            \u2502\n\u2502   - Resource Limits                 \u2502\n\u2502   - Network Policies                \u2502\n\u2502   - Security Policies               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Isolated Execution Pod           \u2502\n\u2502   - Ephemeral Environment          \u2502\n\u2502   - Limited Resources              \u2502\n\u2502   - No Persistent Storage          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aiops/secure-sandbox/#security-features","title":"Security Features","text":""},{"location":"aiops/secure-sandbox/#1-resource-isolation","title":"1. Resource Isolation","text":"<p>CPU and Memory Limits - Strict resource quotas per sandbox - Automatic termination on limit exceed - Fair resource allocation across users</p> <p>Network Isolation - No direct internet access - Controlled API access only - Internal service mesh communication</p> <p>Storage Isolation - Read-only filesystem - No persistent volume access - Temporary workspace only</p>"},{"location":"aiops/secure-sandbox/#2-permission-model","title":"2. Permission Model","text":"<p>JWT-Based Authorization - Short-lived tokens (15-minute expiry) - Inherited from user session - Automatic token refresh</p> <p>Capability Restrictions - No cluster-admin operations - Limited to user's RBAC permissions - Audit logging of all actions</p>"},{"location":"aiops/secure-sandbox/#3-execution-controls","title":"3. Execution Controls","text":"<p>Time Limits - Maximum execution time per operation - Automatic cleanup after timeout - Queue management for long operations</p> <p>Code Execution Policies - Whitelisted operations only - No system-level commands - Sandboxed script interpreters</p>"},{"location":"aiops/secure-sandbox/#use-cases","title":"Use Cases","text":""},{"location":"aiops/secure-sandbox/#1-safe-code-analysis","title":"1. Safe Code Analysis","text":"<p>AI agents can analyze application code and configurations without accessing the actual running systems:</p> <pre><code># Example: Analyzing deployment configuration\ndef analyze_deployment(yaml_content):\n    # AI agent reviews configuration\n    # Identifies potential issues\n    # Suggests improvements\n    # All within sandbox - no actual deployment\n    pass\n</code></pre>"},{"location":"aiops/secure-sandbox/#2-dry-run-operations","title":"2. Dry-Run Operations","text":"<p>Test changes before applying them to production:</p> <ul> <li>Configuration validation</li> <li>Resource requirement analysis</li> <li>Impact assessment</li> <li>Compatibility checking</li> </ul>"},{"location":"aiops/secure-sandbox/#3-learning-and-experimentation","title":"3. Learning and Experimentation","text":"<p>AI agents can learn from simulated environments:</p> <ul> <li>Pattern recognition from sanitized data</li> <li>Training on historical scenarios</li> <li>A/B testing of optimizations</li> <li>Performance modeling</li> </ul>"},{"location":"aiops/secure-sandbox/#configuration","title":"Configuration","text":""},{"location":"aiops/secure-sandbox/#sandbox-policies","title":"Sandbox Policies","text":"<p>Configure sandbox behavior at the organization level:</p> <pre><code>sandbox_config:\n  execution:\n    max_duration: 300s      # 5 minutes max\n    max_memory: 2Gi\n    max_cpu: 1000m\n  network:\n    allowed_endpoints:\n      - hexabase-api.hexabase.svc.cluster.local\n      - ollama.hexabase-aiops.svc.cluster.local\n    blocked_cidrs:\n      - 0.0.0.0/0          # No external access\n  storage:\n    temp_space: 1Gi\n    readonly_mounts:\n      - /configs\n      - /templates\n</code></pre>"},{"location":"aiops/secure-sandbox/#security-policies","title":"Security Policies","text":"<p>Define what operations are allowed:</p> <pre><code>security_policies:\n  allowed_operations:\n    - read_configurations\n    - analyze_logs\n    - generate_recommendations\n    - validate_yaml\n  blocked_operations:\n    - execute_kubectl\n    - modify_resources\n    - access_secrets\n    - network_scan\n</code></pre>"},{"location":"aiops/secure-sandbox/#monitoring-and-auditing","title":"Monitoring and Auditing","text":""},{"location":"aiops/secure-sandbox/#audit-logs","title":"Audit Logs","text":"<p>All sandbox operations are logged:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"user\": \"user@example.com\",\n  \"agent\": \"deployment-analyzer\",\n  \"operation\": \"analyze_config\",\n  \"duration\": \"2.5s\",\n  \"result\": \"success\",\n  \"resources_used\": {\n    \"cpu\": \"250m\",\n    \"memory\": \"512Mi\"\n  }\n}\n</code></pre>"},{"location":"aiops/secure-sandbox/#metrics-and-alerts","title":"Metrics and Alerts","text":"<p>Monitor sandbox usage:</p> <ul> <li>Execution count by user/agent</li> <li>Resource utilization trends</li> <li>Security policy violations</li> <li>Performance bottlenecks</li> </ul>"},{"location":"aiops/secure-sandbox/#best-practices","title":"Best Practices","text":""},{"location":"aiops/secure-sandbox/#1-principle-of-least-privilege","title":"1. Principle of Least Privilege","text":"<ul> <li>Grant minimum required permissions</li> <li>Use time-limited access tokens</li> <li>Regular permission audits</li> </ul>"},{"location":"aiops/secure-sandbox/#2-data-sanitization","title":"2. Data Sanitization","text":"<ul> <li>Remove sensitive information before analysis</li> <li>Use synthetic data for testing</li> <li>Implement data masking policies</li> </ul>"},{"location":"aiops/secure-sandbox/#3-regular-security-reviews","title":"3. Regular Security Reviews","text":"<ul> <li>Monitor sandbox escape attempts</li> <li>Review audit logs regularly</li> <li>Update security policies based on threats</li> </ul>"},{"location":"aiops/secure-sandbox/#integration-with-ai-agents","title":"Integration with AI Agents","text":""},{"location":"aiops/secure-sandbox/#agent-capabilities-in-sandbox","title":"Agent Capabilities in Sandbox","text":"<p>Agents operating in the sandbox can:</p> <ol> <li>Analyze: Review configurations and logs</li> <li>Simulate: Test scenarios without impact</li> <li>Recommend: Provide optimization suggestions</li> <li>Validate: Check configurations before deployment</li> </ol>"},{"location":"aiops/secure-sandbox/#agent-limitations","title":"Agent Limitations","text":"<p>Agents cannot:</p> <ol> <li>Modify: Make direct changes to resources</li> <li>Access: Read secrets or sensitive data</li> <li>Communicate: Contact external services</li> <li>Persist: Store data beyond session</li> </ol>"},{"location":"aiops/secure-sandbox/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aiops/secure-sandbox/#common-issues","title":"Common Issues","text":"<p>1. Execution Timeouts - Check operation complexity - Increase timeout if justified - Break into smaller operations</p> <p>2. Resource Limits - Review resource requests - Optimize agent algorithms - Request limit increase if needed</p> <p>3. Permission Denied - Verify user RBAC roles - Check JWT token validity - Review security policies</p>"},{"location":"aiops/secure-sandbox/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging for troubleshooting:</p> <pre><code># Enable sandbox debug logs\nhb aiops sandbox debug --enable\n\n# View sandbox logs\nhb logs -n hexabase-aiops -l component=sandbox\n\n# Check sandbox metrics\nhb aiops sandbox metrics\n</code></pre>"},{"location":"aiops/secure-sandbox/#future-enhancements","title":"Future Enhancements","text":"<p>Planned improvements to the sandbox environment:</p> <ol> <li>Enhanced Isolation: Container runtime sandboxing</li> <li>Policy Templates: Pre-configured security profiles</li> <li>Distributed Execution: Multi-node sandbox clusters</li> <li>Advanced Analytics: ML-based threat detection</li> </ol>"},{"location":"aiops/use-cases/","title":"AIOps Use Cases","text":"<p>Discover how Hexabase.AI's AIOps capabilities can transform your Kubernetes operations through real-world use cases and practical examples.</p>"},{"location":"aiops/use-cases/#overview","title":"Overview","text":"<p>AIOps in Hexabase.AI combines artificial intelligence with operations to automate complex tasks, provide intelligent insights, and enhance decision-making across your Kubernetes infrastructure.</p>"},{"location":"aiops/use-cases/#use-case-categories","title":"Use Case Categories","text":""},{"location":"aiops/use-cases/#1-intelligent-troubleshooting","title":"1. Intelligent Troubleshooting","text":""},{"location":"aiops/use-cases/#automated-root-cause-analysis","title":"Automated Root Cause Analysis","text":"<p>Scenario: Application experiencing intermittent failures in production</p> <p>How AIOps Helps: <pre><code>User: \"My app is failing randomly in production\"\n\nAI Agent:\n1. Analyzes application logs across all pods\n2. Correlates with metrics (CPU, memory, network)\n3. Identifies pattern: OOM kills during traffic spikes\n4. Recommends: Increase memory limits and implement HPA\n\nResolution provided in &lt; 2 minutes vs hours of manual debugging\n</code></pre></p>"},{"location":"aiops/use-cases/#smart-log-analysis","title":"Smart Log Analysis","text":"<p>Scenario: Searching through millions of log entries for errors</p> <p>Traditional Approach: - Manual grep commands - Time-consuming pattern matching - Easy to miss correlated events</p> <p>AIOps Approach: - Natural language queries: \"Show me all database connection errors in the last hour\" - Automatic pattern recognition - Correlation with deployment events</p>"},{"location":"aiops/use-cases/#2-proactive-performance-optimization","title":"2. Proactive Performance Optimization","text":""},{"location":"aiops/use-cases/#resource-right-sizing","title":"Resource Right-Sizing","text":"<p>Scenario: Over-provisioned resources leading to unnecessary costs</p> <p>AIOps Analysis: <pre><code>Current State:\n  CPU Request: 2000m\n  CPU Usage (P95): 200m\n  Memory Request: 4Gi\n  Memory Usage (P95): 1.2Gi\n\nAI Recommendation:\n  CPU Request: 500m\n  Memory Request: 2Gi\n  Estimated Savings: $450/month\n  Risk Assessment: Low\n</code></pre></p>"},{"location":"aiops/use-cases/#intelligent-scaling-strategies","title":"Intelligent Scaling Strategies","text":"<p>Use Case: E-commerce platform with variable traffic</p> <p>AI-Driven Solution: - Learns traffic patterns from historical data - Predicts load before it happens - Pre-scales resources for expected demand - Reduces response time by 40%</p>"},{"location":"aiops/use-cases/#3-automated-deployment-assistance","title":"3. Automated Deployment Assistance","text":""},{"location":"aiops/use-cases/#configuration-validation","title":"Configuration Validation","text":"<p>Scenario: Deploying a new microservice</p> <p>AI Agent Actions: 1. Reviews deployment YAML 2. Identifies missing health checks 3. Suggests resource limits based on similar services 4. Recommends security policies 5. Validates service mesh configuration</p> <p>Example Interaction: <pre><code>User: \"Deploy my new payment service\"\n\nAI: \"I've reviewed your configuration. Here are my recommendations:\n- Add liveness probe (suggested config provided)\n- Set memory limit to 1Gi based on similar services\n- Enable mTLS for service mesh\n- Add PodDisruptionBudget for high availability\nWould you like me to apply these improvements?\"\n</code></pre></p>"},{"location":"aiops/use-cases/#progressive-rollout-management","title":"Progressive Rollout Management","text":"<p>Capabilities: - Monitors canary deployments - Analyzes metrics in real-time - Automatically rolls back on anomalies - Provides deployment confidence scores</p>"},{"location":"aiops/use-cases/#4-cost-optimization","title":"4. Cost Optimization","text":""},{"location":"aiops/use-cases/#multi-dimensional-cost-analysis","title":"Multi-Dimensional Cost Analysis","text":"<p>Scenario: Reducing cloud spend without impacting performance</p> <p>AI Analysis Provides: - Unused resource identification - Spot instance recommendations - Reserved instance planning - Cross-region optimization</p> <p>Real Example: <pre><code>Monthly Savings Identified:\n- Idle resources: $1,200\n- Right-sizing: $3,500\n- Spot instances: $2,100\n- Total potential: $6,800 (32% reduction)\n</code></pre></p>"},{"location":"aiops/use-cases/#predictive-budget-management","title":"Predictive Budget Management","text":"<ul> <li>Forecasts monthly costs based on trends</li> <li>Alerts on unusual spending patterns</li> <li>Recommends budget adjustments</li> <li>Tracks optimization impact</li> </ul>"},{"location":"aiops/use-cases/#5-security-and-compliance","title":"5. Security and Compliance","text":""},{"location":"aiops/use-cases/#automated-security-scanning","title":"Automated Security Scanning","text":"<p>Continuous Security Monitoring: <pre><code>AI Security Agent detects:\n- Exposed service without authentication\n- Container running as root\n- Outdated image with CVEs\n- Suspicious network traffic pattern\n\nImmediate notifications with remediation steps\n</code></pre></p>"},{"location":"aiops/use-cases/#compliance-verification","title":"Compliance Verification","text":"<p>Use Case: Healthcare application requiring HIPAA compliance</p> <p>AI Actions: - Scans all deployments for compliance violations - Checks encryption at rest and in transit - Verifies access controls - Generates compliance reports - Suggests required changes</p>"},{"location":"aiops/use-cases/#6-intelligent-capacity-planning","title":"6. Intelligent Capacity Planning","text":""},{"location":"aiops/use-cases/#predictive-scaling","title":"Predictive Scaling","text":"<p>Scenario: Preparing for Black Friday traffic</p> <p>AI Predictions Based On: - Historical traffic patterns - Current growth trends - External events calendar - Resource utilization trends</p> <p>Output: <pre><code>Capacity Requirements for Nov 24:\n- Expected traffic: 10x normal\n- Required pods: 450 (current: 45)\n- Memory needed: 1.8TB\n- Recommended pre-scaling: Nov 23, 10 PM\n- Confidence: 94%\n</code></pre></p>"},{"location":"aiops/use-cases/#7-developer-productivity","title":"7. Developer Productivity","text":""},{"location":"aiops/use-cases/#instant-environment-debugging","title":"Instant Environment Debugging","text":"<p>Common Developer Question: \"Why is my app not working in staging?\"</p> <p>AI Investigation: 1. Compares staging vs development configs 2. Identifies missing environment variable 3. Shows recent changes to staging 4. Provides fix command</p> <p>Time Saved: 30 minutes \u2192 30 seconds</p>"},{"location":"aiops/use-cases/#automated-documentation","title":"Automated Documentation","text":"<ul> <li>Generates API documentation from code</li> <li>Creates architecture diagrams</li> <li>Documents deployment procedures</li> <li>Maintains runbooks automatically</li> </ul>"},{"location":"aiops/use-cases/#real-world-success-stories","title":"Real-World Success Stories","text":""},{"location":"aiops/use-cases/#case-study-1-e-commerce-platform","title":"Case Study 1: E-Commerce Platform","text":"<p>Challenge: Frequent outages during flash sales</p> <p>AIOps Solution: - Implemented predictive scaling - Automated health check remediation - Real-time performance optimization</p> <p>Results: - 99.99% uptime achieved - 60% reduction in incident response time - $200K annual savings</p>"},{"location":"aiops/use-cases/#case-study-2-financial-services","title":"Case Study 2: Financial Services","text":"<p>Challenge: Complex compliance requirements</p> <p>AIOps Solution: - Continuous compliance scanning - Automated report generation - Policy enforcement automation</p> <p>Results: - 100% audit compliance - 80% reduction in manual checks - Zero compliance violations</p>"},{"location":"aiops/use-cases/#case-study-3-saas-provider","title":"Case Study 3: SaaS Provider","text":"<p>Challenge: Unpredictable scaling needs</p> <p>AIOps Solution: - ML-based traffic prediction - Automated resource optimization - Intelligent workload placement</p> <p>Results: - 45% infrastructure cost reduction - 3x improvement in response times - 90% reduction in manual interventions</p>"},{"location":"aiops/use-cases/#getting-started-with-aiops","title":"Getting Started with AIOps","text":""},{"location":"aiops/use-cases/#quick-wins","title":"Quick Wins","text":"<p>Start with these high-impact use cases:</p> <ol> <li>Cost Analysis: \"Show me cost optimization opportunities\"</li> <li>Performance Review: \"Analyze my cluster performance\"</li> <li>Security Scan: \"Check for security vulnerabilities\"</li> <li>Troubleshooting: \"Why is my app slow?\"</li> </ol>"},{"location":"aiops/use-cases/#best-practices","title":"Best Practices","text":"<ol> <li>Start Small: Begin with one use case</li> <li>Learn Patterns: Observe AI recommendations</li> <li>Build Trust: Verify AI suggestions initially</li> <li>Expand Gradually: Add more use cases over time</li> </ol>"},{"location":"aiops/use-cases/#measuring-success","title":"Measuring Success","text":"<p>Track these metrics: - Mean Time To Resolution (MTTR) - Cost savings achieved - Automation percentage - Developer productivity gains - Incident reduction rate</p>"},{"location":"aiops/use-cases/#future-capabilities","title":"Future Capabilities","text":"<p>Coming soon to Hexabase.AI AIOps:</p> <ol> <li>Predictive Failure Prevention: Stop issues before they occur</li> <li>Automated Remediation: Self-healing infrastructure</li> <li>Advanced Anomaly Detection: ML-powered pattern recognition</li> <li>Custom AI Agents: Build your own specialized agents</li> </ol>"},{"location":"applications/","title":"Applications","text":"<p>This section provides comprehensive guidance on deploying, managing, and optimizing applications in Hexabase.AI (HKS). Learn how to leverage the platform's capabilities to run your workloads efficiently and reliably.</p>"},{"location":"applications/#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Application Deployment: Step-by-step guides for deploying various application types</li> <li>Configuration Management: Managing application configurations, secrets, and environment variables</li> <li>Service Mesh: Implementing and managing service-to-service communication</li> <li>Application Monitoring: Observability, logging, and performance tracking</li> <li>Best Practices: Recommended patterns for cloud-native applications</li> </ul>"},{"location":"applications/#key-topics","title":"Key Topics","text":"<ul> <li>Containerizing applications for Kubernetes</li> <li>Helm charts and package management</li> <li>StatefulSets vs. Deployments</li> <li>Multi-tenant application isolation</li> <li>Application networking and ingress</li> <li>Integration with HKS AI-Ops for intelligent workload management</li> <li>Application lifecycle management</li> <li>Rolling updates and rollback strategies</li> </ul> <p>From simple web applications to complex microservices architectures, this section will help you make the most of HKS's application platform.</p>"},{"location":"applications/deployment/","title":"Application Deployment","text":"<p>This guide covers deployment strategies and best practices for deploying applications to Hexabase.AI.</p>"},{"location":"applications/deployment/#deployment-methods","title":"Deployment Methods","text":""},{"location":"applications/deployment/#1-direct-kubernetes-manifests","title":"1. Direct Kubernetes Manifests","text":"<p>Deploy applications using standard Kubernetes YAML manifests:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n        - name: app\n          image: myregistry/myapp:v1.0.0\n          ports:\n            - containerPort: 8080\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n</code></pre> <p>Deploy using HKS CLI:</p> <pre><code>hb apply -f deployment.yaml\n</code></pre>"},{"location":"applications/deployment/#2-helm-charts","title":"2. Helm Charts","text":"<p>Deploy applications using Helm for templating and package management:</p> <pre><code># Add a Helm repository\nhb helm repo add bitnami https://charts.bitnami.com/bitnami\n\n# Install an application\nhb helm install myapp bitnami/wordpress \\\n  --set wordpressBlogName=\"My Blog\" \\\n  --namespace production\n</code></pre> <p>Custom Helm chart structure:</p> <pre><code>myapp/\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u2514\u2500\u2500 configmap.yaml\n\u2514\u2500\u2500 charts/\n</code></pre>"},{"location":"applications/deployment/#3-hks-application-templates","title":"3. HKS Application Templates","text":"<p>Use pre-configured application templates:</p> <pre><code># app.hks.yaml\napiVersion: hks.io/v1\nkind: Application\nmetadata:\n  name: myapp\nspec:\n  template: nodejs-web\n  source:\n    git:\n      url: https://github.com/myorg/myapp\n      branch: main\n  build:\n    dockerfile: Dockerfile\n  deploy:\n    replicas: 3\n    autoscaling:\n      enabled: true\n      minReplicas: 2\n      maxReplicas: 10\n</code></pre>"},{"location":"applications/deployment/#4-gitops-deployment","title":"4. GitOps Deployment","text":"<p>Implement GitOps workflow with automatic synchronization:</p> <pre><code># gitops-app.yaml\napiVersion: hks.io/v1\nkind: GitOpsApplication\nmetadata:\n  name: myapp\nspec:\n  source:\n    repoURL: https://github.com/myorg/myapp-config\n    path: overlays/production\n    targetRevision: main\n  destination:\n    namespace: production\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre>"},{"location":"applications/deployment/#container-image-management","title":"Container Image Management","text":""},{"location":"applications/deployment/#image-registry-integration","title":"Image Registry Integration","text":"<pre><code># Configure private registry\napiVersion: v1\nkind: Secret\nmetadata:\n  name: registry-credentials\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: &lt;base64-encoded-docker-config&gt;\n</code></pre>"},{"location":"applications/deployment/#image-scanning-and-security","title":"Image Scanning and Security","text":"<pre><code>deploy:\n  imagePolicy:\n    scan:\n      enabled: true\n      failThreshold: HIGH\n    sign:\n      enabled: true\n      keyRef: cosign-key\n</code></pre>"},{"location":"applications/deployment/#configuration-management","title":"Configuration Management","text":""},{"location":"applications/deployment/#configmaps","title":"ConfigMaps","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  database.url: \"postgres://db:5432/myapp\"\n  log.level: \"info\"\n  feature.flags: |\n    new-ui=true\n    beta-features=false\n</code></pre>"},{"location":"applications/deployment/#secrets-management","title":"Secrets Management","text":"<pre><code># Using HKS secret management\nhb secret create app-secrets \\\n--from-literal=db-password=mypassword \\\n--from-file=tls.crt=/path/to/cert\n</code></pre>"},{"location":"applications/deployment/#environment-variables","title":"Environment Variables","text":"<pre><code>containers:\n  - name: app\n    env:\n      - name: DATABASE_URL\n        valueFrom:\n          secretKeyRef:\n            name: app-secrets\n            key: database-url\n      - name: LOG_LEVEL\n        valueFrom:\n          configMapKeyRef:\n            name: app-config\n            key: log.level\n</code></pre>"},{"location":"applications/deployment/#health-checks","title":"Health Checks","text":""},{"location":"applications/deployment/#readiness-probe","title":"Readiness Probe","text":"<pre><code>readinessProbe:\n  httpGet:\n    path: /health/ready\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  successThreshold: 1\n  failureThreshold: 3\n</code></pre>"},{"location":"applications/deployment/#liveness-probe","title":"Liveness Probe","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health/live\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n</code></pre>"},{"location":"applications/deployment/#startup-probe","title":"Startup Probe","text":"<pre><code>startupProbe:\n  httpGet:\n    path: /health/startup\n    port: 8080\n  initialDelaySeconds: 0\n  periodSeconds: 10\n  failureThreshold: 30\n</code></pre>"},{"location":"applications/deployment/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"applications/deployment/#rolling-update","title":"Rolling Update","text":"<pre><code>spec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n</code></pre>"},{"location":"applications/deployment/#blue-green-deployment","title":"Blue-Green Deployment","text":"<pre><code># Deploy green version\nhb deploy myapp-green --image myapp:v2.0.0\n\n# Test green version\nhb test myapp-green\n\n# Switch traffic\nhb switch-traffic myapp --to green\n\n# Remove blue version\nhb delete deployment myapp-blue\n</code></pre>"},{"location":"applications/deployment/#canary-deployment","title":"Canary Deployment","text":"<pre><code># Using HKS canary feature\napiVersion: hks.io/v1\nkind: CanaryDeployment\nmetadata:\n  name: myapp-canary\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  canarySpec:\n    image: myapp:v2.0.0\n    percentage: 10\n    stepWeight: 10\n    stepDuration: 10m\n</code></pre>"},{"location":"applications/deployment/#persistent-storage","title":"Persistent Storage","text":""},{"location":"applications/deployment/#volume-claims","title":"Volume Claims","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-storage\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n</code></pre>"},{"location":"applications/deployment/#volume-mounts","title":"Volume Mounts","text":"<pre><code>containers:\n  - name: app\n    volumeMounts:\n      - name: data\n        mountPath: /var/lib/app/data\n      - name: config\n        mountPath: /etc/app\n        readOnly: true\nvolumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: app-storage\n  - name: config\n    configMap:\n      name: app-config\n</code></pre>"},{"location":"applications/deployment/#network-configuration","title":"Network Configuration","text":""},{"location":"applications/deployment/#service-definition","title":"Service Definition","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"applications/deployment/#ingress-configuration","title":"Ingress Configuration","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"applications/deployment/#multi-environment-deployment","title":"Multi-Environment Deployment","text":""},{"location":"applications/deployment/#environment-separation","title":"Environment Separation","text":"<pre><code># base/kustomization.yaml\nresources:\n  - deployment.yaml\n  - service.yaml\n\n# overlays/dev/kustomization.yaml\nbases:\n  - ../../base\npatchesStrategicMerge:\n  - deployment-patch.yaml\nconfigMapGenerator:\n  - name: app-config\n    literals:\n      - environment=development\n\n# overlays/prod/kustomization.yaml\nbases:\n  - ../../base\nreplicas:\n  - name: myapp\n    count: 5\n</code></pre>"},{"location":"applications/deployment/#namespace-isolation","title":"Namespace Isolation","text":"<pre><code># Create environments\nhb namespace create dev\nhb namespace create staging\nhb namespace create production\n\n# Deploy to specific environment\nhb deploy --namespace production\n</code></pre>"},{"location":"applications/deployment/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"applications/deployment/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code>metadata:\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\n    prometheus.io/path: \"/metrics\"\n</code></pre>"},{"location":"applications/deployment/#application-logs","title":"Application Logs","text":"<pre><code># Configure log aggregation\nspec:\n  containers:\n    - name: app\n      env:\n        - name: LOG_FORMAT\n          value: \"json\"\n        - name: LOG_OUTPUT\n          value: \"stdout\"\n</code></pre>"},{"location":"applications/deployment/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Container Best Practices</p> </li> <li> <p>Use minimal base images</p> </li> <li>Run as non-root user</li> <li>One process per container</li> <li> <p>Handle signals properly</p> </li> <li> <p>Resource Management</p> </li> <li> <p>Always set resource requests and limits</p> </li> <li>Use horizontal pod autoscaling</li> <li> <p>Implement proper health checks</p> </li> <li> <p>Security</p> </li> <li> <p>Scan images for vulnerabilities</p> </li> <li>Use network policies</li> <li>Implement RBAC</li> <li> <p>Encrypt secrets at rest</p> </li> <li> <p>High Availability</p> </li> <li> <p>Deploy across multiple zones</p> </li> <li>Use pod disruption budgets</li> <li>Implement circuit breakers</li> <li> <p>Design for failure</p> </li> <li> <p>Deployment Hygiene</p> </li> <li>Use declarative configuration</li> <li>Version everything</li> <li>Automate deployments</li> <li>Monitor deployment metrics</li> </ol>"},{"location":"applications/deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"applications/deployment/#common-issues","title":"Common Issues","text":"<pre><code># Check deployment status\nhb get deployments -n production\n\n# View pod logs\nhb logs -f deployment/myapp\n\n# Describe pod for events\nhb describe pod myapp-xyz\n\n# Check resource usage\nhb top pods -n production\n\n# Debug running container\nhb exec -it myapp-xyz -- /bin/sh\n</code></pre>"},{"location":"applications/deployment/#rollback-procedures","title":"Rollback Procedures","text":"<pre><code># View rollout history\nhb rollout history deployment/myapp\n\n# Rollback to previous version\nhb rollout undo deployment/myapp\n\n# Rollback to specific revision\nhb rollout undo deployment/myapp --to-revision=2\n</code></pre>"},{"location":"applications/load-balancing/","title":"Load Balancing","text":"<p>Load balancing is crucial for distributing traffic across multiple instances of your applications in Hexabase.AI. This guide covers various load balancing strategies and configurations.</p>"},{"location":"applications/load-balancing/#overview","title":"Overview","text":"<p>Hexabase.AI provides multiple levels of load balancing:</p> <ul> <li>Service-level load balancing (Layer 4)</li> <li>Ingress-level load balancing (Layer 7)</li> <li>Global load balancing (Multi-region)</li> <li>Service mesh load balancing (Advanced traffic management)</li> </ul>"},{"location":"applications/load-balancing/#service-load-balancing","title":"Service Load Balancing","text":""},{"location":"applications/load-balancing/#clusterip-service","title":"ClusterIP Service","text":"<p>Basic load balancing within the cluster:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  type: ClusterIP\n  sessionAffinity: None # Round-robin by default\n</code></pre>"},{"location":"applications/load-balancing/#session-affinity","title":"Session Affinity","text":"<p>Maintain sticky sessions:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 3600 # 1 hour\n</code></pre>"},{"location":"applications/load-balancing/#headless-service","title":"Headless Service","text":"<p>For client-side load balancing:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-headless\nspec:\n  clusterIP: None\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre>"},{"location":"applications/load-balancing/#ingress-load-balancing","title":"Ingress Load Balancing","text":""},{"location":"applications/load-balancing/#nginx-ingress","title":"NGINX Ingress","text":"<p>Configure NGINX-based load balancing:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/load-balance: \"round_robin\"\n    nginx.ingress.kubernetes.io/upstream-hash-by: \"$request_uri\"\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"applications/load-balancing/#load-balancing-algorithms","title":"Load Balancing Algorithms","text":"<p>Available algorithms for NGINX:</p> <pre><code>annotations:\n  # Round Robin (default)\n  nginx.ingress.kubernetes.io/load-balance: \"round_robin\"\n\n  # Least Connections\n  nginx.ingress.kubernetes.io/load-balance: \"least_conn\"\n\n  # IP Hash\n  nginx.ingress.kubernetes.io/load-balance: \"ip_hash\"\n\n  # Consistent Hashing\n  nginx.ingress.kubernetes.io/upstream-hash-by: \"$request_uri\"\n</code></pre>"},{"location":"applications/load-balancing/#advanced-nginx-configuration","title":"Advanced NGINX Configuration","text":"<pre><code>annotations:\n  # Connection limits\n  nginx.ingress.kubernetes.io/limit-connections: \"10\"\n  nginx.ingress.kubernetes.io/limit-rps: \"100\"\n\n  # Timeouts\n  nginx.ingress.kubernetes.io/proxy-connect-timeout: \"5\"\n  nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n  nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n\n  # Retries\n  nginx.ingress.kubernetes.io/proxy-next-upstream: \"error timeout\"\n  nginx.ingress.kubernetes.io/proxy-next-upstream-tries: \"3\"\n</code></pre>"},{"location":"applications/load-balancing/#service-mesh-load-balancing","title":"Service Mesh Load Balancing","text":""},{"location":"applications/load-balancing/#istio-configuration","title":"Istio Configuration","text":"<p>Advanced traffic management with Istio:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: myapp-destination\nspec:\n  host: myapp-service\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 50\n        http2MaxRequests: 100\n        maxRequestsPerConnection: 2\n    loadBalancer:\n      simple: LEAST_REQUEST # or ROUND_ROBIN, RANDOM, PASSTHROUGH\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n</code></pre>"},{"location":"applications/load-balancing/#circuit-breaking","title":"Circuit Breaking","text":"<p>Implement circuit breakers:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: myapp-circuit-breaker\nspec:\n  host: myapp-service\n  trafficPolicy:\n    outlierDetection:\n      consecutive5xxErrors: 5\n      consecutiveGatewayErrors: 5\n      interval: 10s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n      minHealthPercent: 30\n      splitExternalLocalOriginErrors: true\n</code></pre>"},{"location":"applications/load-balancing/#retry-configuration","title":"Retry Configuration","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-retry\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - timeout: 30s\n      retries:\n        attempts: 3\n        perTryTimeout: 10s\n        retryOn: gateway-error,connect-failure,refused-stream\n        retryRemoteLocalities: true\n</code></pre>"},{"location":"applications/load-balancing/#global-load-balancing","title":"Global Load Balancing","text":""},{"location":"applications/load-balancing/#multi-region-setup","title":"Multi-Region Setup","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: global-ingress\n  annotations:\n    external-dns.alpha.kubernetes.io/hostname: myapp.global.example.com\n    external-dns.alpha.kubernetes.io/ttl: \"60\"\nspec:\n  rules:\n    - host: myapp.global.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"applications/load-balancing/#geographic-load-balancing","title":"Geographic Load Balancing","text":"<p>Using HKS global load balancer:</p> <pre><code>apiVersion: hks.io/v1\nkind: GlobalLoadBalancer\nmetadata:\n  name: myapp-global\nspec:\n  selector:\n    app: myapp\n  regions:\n    - name: us-east-1\n      weight: 40\n      healthCheck:\n        path: /health\n        interval: 10s\n    - name: eu-west-1\n      weight: 30\n    - name: ap-southeast-1\n      weight: 30\n  routing:\n    policy: geographic # or weighted, latency, failover\n    stickyRegion: true\n</code></pre>"},{"location":"applications/load-balancing/#health-checks","title":"Health Checks","text":""},{"location":"applications/load-balancing/#service-health-checks","title":"Service Health Checks","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  healthCheckNodePort: 30000\n</code></pre>"},{"location":"applications/load-balancing/#ingress-health-checks","title":"Ingress Health Checks","text":"<pre><code>annotations:\n  nginx.ingress.kubernetes.io/health-check-path: \"/health\"\n  nginx.ingress.kubernetes.io/health-check-interval: \"10\"\n  nginx.ingress.kubernetes.io/health-check-timeout: \"5\"\n  nginx.ingress.kubernetes.io/health-check-max-fails: \"3\"\n</code></pre>"},{"location":"applications/load-balancing/#load-balancer-types","title":"Load Balancer Types","text":""},{"location":"applications/load-balancing/#network-load-balancer-layer-4","title":"Network Load Balancer (Layer 4)","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-nlb\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre>"},{"location":"applications/load-balancing/#application-load-balancer-layer-7","title":"Application Load Balancer (Layer 7)","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-alb\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"applications/load-balancing/#traffic-distribution","title":"Traffic Distribution","text":""},{"location":"applications/load-balancing/#weighted-routing","title":"Weighted Routing","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-weighted\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - match:\n        - headers:\n            version:\n              exact: v2\n      route:\n        - destination:\n            host: myapp-service\n            subset: v2\n          weight: 20\n        - destination:\n            host: myapp-service\n            subset: v1\n          weight: 80\n</code></pre>"},{"location":"applications/load-balancing/#ab-testing","title":"A/B Testing","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-ab-test\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - match:\n        - headers:\n            user-group:\n              exact: beta\n      route:\n        - destination:\n            host: myapp-service\n            subset: v2\n    - route:\n        - destination:\n            host: myapp-service\n            subset: v1\n</code></pre>"},{"location":"applications/load-balancing/#canary-deployments","title":"Canary Deployments","text":"<pre><code>apiVersion: flagger.app/v1beta1\nkind: Canary\nmetadata:\n  name: myapp-canary\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  service:\n    port: 80\n    targetPort: 8080\n  analysis:\n    interval: 1m\n    threshold: 10\n    maxWeight: 50\n    stepWeight: 10\n    metrics:\n      - name: request-success-rate\n        thresholdRange:\n          min: 99\n        interval: 1m\n</code></pre>"},{"location":"applications/load-balancing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"applications/load-balancing/#connection-pooling","title":"Connection Pooling","text":"<pre><code>trafficPolicy:\n  connectionPool:\n    tcp:\n      maxConnections: 100\n      connectTimeout: 30s\n      tcpKeepalive:\n        time: 7200\n        interval: 75\n        probes: 10\n    http:\n      http1MaxPendingRequests: 100\n      http2MaxRequests: 100\n      maxRequestsPerConnection: 2\n      h2UpgradePolicy: UPGRADE\n</code></pre>"},{"location":"applications/load-balancing/#keep-alive-settings","title":"Keep-Alive Settings","text":"<pre><code>annotations:\n  nginx.ingress.kubernetes.io/upstream-keepalive-connections: \"32\"\n  nginx.ingress.kubernetes.io/upstream-keepalive-timeout: \"60\"\n  nginx.ingress.kubernetes.io/upstream-keepalive-requests: \"100\"\n</code></pre>"},{"location":"applications/load-balancing/#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"applications/load-balancing/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/path: \"/metrics\"\n    prometheus.io/port: \"9090\"\nspec:\n  selector:\n    app: myapp\n  ports:\n    - name: http\n      port: 80\n      targetPort: 8080\n    - name: metrics\n      port: 9090\n      targetPort: 9090\n</code></pre>"},{"location":"applications/load-balancing/#load-balancer-metrics","title":"Load Balancer Metrics","text":"<p>Monitor key metrics:</p> <ul> <li>Request rate per backend</li> <li>Response time distribution</li> <li>Error rates</li> <li>Connection pool usage</li> <li>Circuit breaker status</li> </ul> <pre><code># Check load balancer status\nhb lb status myapp-service\n\n# View backend health\nhb lb backends myapp-service\n\n# Monitor traffic distribution\nhb lb traffic myapp-service --watch\n</code></pre>"},{"location":"applications/load-balancing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"applications/load-balancing/#common-issues","title":"Common Issues","text":"<ol> <li>Uneven Load Distribution</li> </ol> <pre><code># Check pod distribution\nhb get pods -o wide\n\n# Verify service endpoints\nhb get endpoints myapp-service\n</code></pre> <ol> <li>Session Affinity Not Working</li> </ol> <pre><code># Test session affinity\nfor i in {1..10}; do\n  curl -b cookies.txt -c cookies.txt http://myapp.example.com\ndone\n</code></pre> <ol> <li>Health Check Failures</li> </ol> <pre><code># Check health endpoint\nhb exec -it myapp-pod -- curl localhost:8080/health\n\n# View ingress controller logs\nhb logs -n ingress-nginx deployment/ingress-nginx-controller\n</code></pre>"},{"location":"applications/load-balancing/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Choose the Right Load Balancer</p> </li> <li> <p>Use Service for internal traffic</p> </li> <li>Use Ingress for HTTP/HTTPS traffic</li> <li> <p>Use Service Mesh for advanced traffic management</p> </li> <li> <p>Health Checks</p> </li> <li> <p>Implement comprehensive health checks</p> </li> <li>Use appropriate timeouts and thresholds</li> <li> <p>Monitor health check metrics</p> </li> <li> <p>Performance</p> </li> <li> <p>Enable connection pooling</p> </li> <li>Configure appropriate timeouts</li> <li> <p>Use HTTP/2 when possible</p> </li> <li> <p>Reliability</p> </li> <li> <p>Implement circuit breakers</p> </li> <li>Configure retries appropriately</li> <li> <p>Use outlier detection</p> </li> <li> <p>Monitoring</p> </li> <li>Track load distribution</li> <li>Monitor error rates</li> <li>Alert on anomalies</li> </ol>"},{"location":"applications/resource-management/","title":"Resource Management","text":"<p>Effective resource management is critical for optimal application performance and cluster efficiency in Hexabase.AI. This guide covers CPU, memory, storage, and other resource allocation strategies.</p>"},{"location":"applications/resource-management/#resource-types","title":"Resource Types","text":""},{"location":"applications/resource-management/#cpu-resources","title":"CPU Resources","text":"<p>CPU resources are measured in CPU units:</p> <ul> <li><code>1</code> = 1 vCPU/Core</li> <li><code>1000m</code> = 1 CPU (m = millicpu)</li> <li><code>100m</code> = 0.1 CPU</li> </ul> <pre><code>resources:\n  requests:\n    cpu: \"100m\" # Guaranteed minimum\n  limits:\n    cpu: \"500m\" # Maximum allowed\n</code></pre>"},{"location":"applications/resource-management/#memory-resources","title":"Memory Resources","text":"<p>Memory is measured in bytes with unit suffixes:</p> <ul> <li><code>Ki</code> = Kibibyte (1024 bytes)</li> <li><code>Mi</code> = Mebibyte (1024 Ki)</li> <li><code>Gi</code> = Gibibyte (1024 Mi)</li> </ul> <pre><code>resources:\n  requests:\n    memory: \"256Mi\" # Guaranteed minimum\n  limits:\n    memory: \"512Mi\" # Maximum allowed\n</code></pre>"},{"location":"applications/resource-management/#resource-requests-and-limits","title":"Resource Requests and Limits","text":""},{"location":"applications/resource-management/#basic-configuration","title":"Basic Configuration","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  template:\n    spec:\n      containers:\n        - name: app\n          image: myapp:latest\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"250m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n</code></pre>"},{"location":"applications/resource-management/#understanding-requests-vs-limits","title":"Understanding Requests vs Limits","text":"<ul> <li>Requests: Guaranteed resources for scheduling</li> <li>Limits: Maximum resources a container can use</li> </ul> <pre><code># Burstable QoS class\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n\n# Guaranteed QoS class (requests = limits)\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n</code></pre>"},{"location":"applications/resource-management/#quality-of-service-qos-classes","title":"Quality of Service (QoS) Classes","text":""},{"location":"applications/resource-management/#1-guaranteed","title":"1. Guaranteed","text":"<p>Highest priority, never killed unless exceeding limits:</p> <pre><code>containers:\n  - name: critical-app\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"1\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"1\"\n</code></pre>"},{"location":"applications/resource-management/#2-burstable","title":"2. Burstable","text":"<p>Medium priority, can burst above requests:</p> <pre><code>containers:\n  - name: web-app\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n</code></pre>"},{"location":"applications/resource-management/#3-besteffort","title":"3. BestEffort","text":"<p>Lowest priority, first to be evicted:</p> <pre><code>containers:\n  - name: batch-job\n    # No resources specified\n</code></pre>"},{"location":"applications/resource-management/#resource-quotas","title":"Resource Quotas","text":""},{"location":"applications/resource-management/#namespace-resource-limits","title":"Namespace Resource Limits","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-resources\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: \"200Gi\"\n    limits.cpu: \"200\"\n    limits.memory: \"400Gi\"\n    persistentvolumeclaims: \"10\"\n    services.loadbalancers: \"2\"\n</code></pre>"},{"location":"applications/resource-management/#object-count-quotas","title":"Object Count Quotas","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: object-counts\n  namespace: production\nspec:\n  hard:\n    pods: \"50\"\n    services: \"10\"\n    replicationcontrollers: \"20\"\n    secrets: \"100\"\n    configmaps: \"100\"\n</code></pre>"},{"location":"applications/resource-management/#limit-ranges","title":"Limit Ranges","text":""},{"location":"applications/resource-management/#default-container-limits","title":"Default Container Limits","text":"<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: default-limits\n  namespace: production\nspec:\n  limits:\n    - default:\n        cpu: \"500m\"\n        memory: \"512Mi\"\n      defaultRequest:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      max:\n        cpu: \"2\"\n        memory: \"2Gi\"\n      min:\n        cpu: \"50m\"\n        memory: \"64Mi\"\n      type: Container\n</code></pre>"},{"location":"applications/resource-management/#pod-level-limits","title":"Pod-Level Limits","text":"<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: pod-limits\nspec:\n  limits:\n    - max:\n        cpu: \"4\"\n        memory: \"8Gi\"\n      min:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      type: Pod\n</code></pre>"},{"location":"applications/resource-management/#horizontal-pod-autoscaling-hpa","title":"Horizontal Pod Autoscaling (HPA)","text":""},{"location":"applications/resource-management/#cpu-based-autoscaling","title":"CPU-Based Autoscaling","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n</code></pre>"},{"location":"applications/resource-management/#memory-based-autoscaling","title":"Memory-Based Autoscaling","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-memory-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 80\n</code></pre>"},{"location":"applications/resource-management/#custom-metrics-autoscaling","title":"Custom Metrics Autoscaling","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-custom-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 20\n  metrics:\n    - type: Pods\n      pods:\n        metric:\n          name: requests_per_second\n        target:\n          type: AverageValue\n          averageValue: \"100\"\n    - type: Object\n      object:\n        metric:\n          name: queue_length\n        describedObject:\n          apiVersion: v1\n          kind: Service\n          name: myapp-queue\n        target:\n          type: Value\n          value: \"30\"\n</code></pre>"},{"location":"applications/resource-management/#vertical-pod-autoscaling-vpa","title":"Vertical Pod Autoscaling (VPA)","text":""},{"location":"applications/resource-management/#vpa-configuration","title":"VPA Configuration","text":"<pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: myapp-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  updatePolicy:\n    updateMode: \"Auto\" # or \"Off\", \"Initial\"\n  resourcePolicy:\n    containerPolicies:\n      - containerName: app\n        minAllowed:\n          cpu: 100m\n          memory: 128Mi\n        maxAllowed:\n          cpu: 2\n          memory: 2Gi\n        controlledResources: [\"cpu\", \"memory\"]\n</code></pre>"},{"location":"applications/resource-management/#storage-resources","title":"Storage Resources","text":""},{"location":"applications/resource-management/#persistent-volume-claims","title":"Persistent Volume Claims","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: myapp-storage\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n</code></pre>"},{"location":"applications/resource-management/#storage-classes","title":"Storage Classes","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\nallowVolumeExpansion: true\n</code></pre>"},{"location":"applications/resource-management/#volume-resource-limits","title":"Volume Resource Limits","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: storage-quota\nspec:\n  hard:\n    requests.storage: \"100Gi\"\n    persistentvolumeclaims: \"10\"\n    fast-ssd.storageclass.storage.k8s.io/requests.storage: \"50Gi\"\n    fast-ssd.storageclass.storage.k8s.io/persistentvolumeclaims: \"5\"\n</code></pre>"},{"location":"applications/resource-management/#network-resources","title":"Network Resources","text":""},{"location":"applications/resource-management/#bandwidth-limits","title":"Bandwidth Limits","text":"<pre><code>metadata:\n  annotations:\n    kubernetes.io/ingress-bandwidth: \"10M\"\n    kubernetes.io/egress-bandwidth: \"10M\"\n</code></pre>"},{"location":"applications/resource-management/#network-policies","title":"Network Policies","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: myapp-network-policy\nspec:\n  podSelector:\n    matchLabels:\n      app: myapp\n  policyTypes:\n    - Ingress\n    - Egress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              role: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"applications/resource-management/#gpu-resources","title":"GPU Resources","text":""},{"location":"applications/resource-management/#gpu-allocation","title":"GPU Allocation","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-pod\nspec:\n  containers:\n    - name: cuda-container\n      image: nvidia/cuda:11.0-base\n      resources:\n        limits:\n          nvidia.com/gpu: 1 # Request 1 GPU\n</code></pre>"},{"location":"applications/resource-management/#gpu-sharing","title":"GPU Sharing","text":"<pre><code># Using fractional GPUs with NVIDIA MIG\nresources:\n  limits:\n    nvidia.com/mig-3g.20gb: 1\n</code></pre>"},{"location":"applications/resource-management/#resource-monitoring","title":"Resource Monitoring","text":""},{"location":"applications/resource-management/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Enable resource metrics\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: metrics-config\ndata:\n  metrics.yaml: |\n    collection_interval: 30s\n    resources:\n      - cpu\n      - memory\n      - disk\n      - network\n</code></pre>"},{"location":"applications/resource-management/#resource-usage-commands","title":"Resource Usage Commands","text":"<pre><code># View node resource usage\nhb top nodes\n\n# View pod resource usage\nhb top pods -n production\n\n# View container resource usage\nhb top pod myapp-pod --containers\n\n# Get resource quota status\nhb get resourcequota -n production\n\n# Describe resource usage\nhb describe node worker-1\n</code></pre>"},{"location":"applications/resource-management/#best-practices","title":"Best Practices","text":""},{"location":"applications/resource-management/#1-right-sizing","title":"1. Right-Sizing","text":"<pre><code># Start with monitoring\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n\n# After analysis, adjust to actual usage\nresources:\n  requests:\n    memory: \"384Mi\"  # P95 usage\n    cpu: \"150m\"      # P95 usage\n  limits:\n    memory: \"512Mi\"  # P99 usage + buffer\n    cpu: \"300m\"      # P99 usage + buffer\n</code></pre>"},{"location":"applications/resource-management/#2-resource-ratios","title":"2. Resource Ratios","text":"<pre><code># Good practice: 2:1 limit to request ratio\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"1Gi\" # 2x request\n    cpu: \"1000m\" # 2x request\n</code></pre>"},{"location":"applications/resource-management/#3-namespace-organization","title":"3. Namespace Organization","text":"<pre><code># Create resource-isolated namespaces\nhb create namespace dev --quota small\nhb create namespace staging --quota medium\nhb create namespace production --quota large\n</code></pre>"},{"location":"applications/resource-management/#4-resource-planning","title":"4. Resource Planning","text":"<pre><code># Resource allocation strategy\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: resource-tiers\ndata:\n  small: |\n    cpu: 100m-500m\n    memory: 128Mi-512Mi\n  medium: |\n    cpu: 500m-2000m\n    memory: 512Mi-2Gi\n  large: |\n    cpu: 2000m-8000m\n    memory: 2Gi-8Gi\n</code></pre>"},{"location":"applications/resource-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"applications/resource-management/#common-issues","title":"Common Issues","text":"<ol> <li>OOMKilled Pods</li> </ol> <pre><code># Check for OOM kills\nhb describe pod myapp-pod | grep -i oom\n\n# Increase memory limits\nhb set resources deployment myapp --limits=memory=1Gi\n</code></pre> <ol> <li>CPU Throttling</li> </ol> <pre><code># Check CPU throttling\nhb exec myapp-pod -- cat /sys/fs/cgroup/cpu/cpu.stat\n\n# Adjust CPU limits\nhb set resources deployment myapp --limits=cpu=1000m\n</code></pre> <ol> <li>Pending Pods</li> </ol> <pre><code># Check why pods are pending\nhb describe pod myapp-pod\n\n# View node resources\nhb describe nodes | grep -A 5 \"Allocated resources\"\n</code></pre>"},{"location":"applications/resource-management/#resource-optimization","title":"Resource Optimization","text":"<pre><code># Get recommendations from VPA\nhb get vpa myapp-vpa -o yaml\n\n# Analyze resource usage patterns\nhb top pods --sort-by=cpu\nhb top pods --sort-by=memory\n\n# Export metrics for analysis\nhb get --raw /metrics | grep container_\n</code></pre>"},{"location":"applications/resource-management/#hks-specific-features","title":"HKS-Specific Features","text":""},{"location":"applications/resource-management/#ai-driven-resource-optimization","title":"AI-Driven Resource Optimization","text":"<pre><code>apiVersion: hks.io/v1\nkind: ResourceOptimizer\nmetadata:\n  name: ai-optimizer\nspec:\n  target:\n    kind: Deployment\n    name: myapp\n  optimization:\n    mode: aggressive # or conservative, balanced\n    metrics:\n      - cpu\n      - memory\n    constraints:\n      minReplicas: 2\n      maxCost: 100 # USD per month\n</code></pre>"},{"location":"applications/resource-management/#cost-based-scaling","title":"Cost-Based Scaling","text":"<pre><code>apiVersion: hks.io/v1\nkind: CostAwareHPA\nmetadata:\n  name: cost-aware-scaler\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  costConstraints:\n    maxMonthlyCost: 500\n    preferSpotInstances: true\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n</code></pre>"},{"location":"applications/service-discovery/","title":"Service Discovery","text":"<p>Service discovery is essential for microservices communication in Hexabase.AI. This guide covers DNS-based discovery, service mesh integration, and advanced service discovery patterns.</p>"},{"location":"applications/service-discovery/#overview","title":"Overview","text":"<p>Hexabase.AI provides multiple service discovery mechanisms:</p> <ul> <li>Kubernetes DNS (CoreDNS)</li> <li>Service mesh discovery (Istio/Linkerd)</li> <li>External service discovery (Consul, etcd)</li> <li>Headless services for direct pod discovery</li> </ul>"},{"location":"applications/service-discovery/#kubernetes-dns-service-discovery","title":"Kubernetes DNS Service Discovery","text":""},{"location":"applications/service-discovery/#basic-service-discovery","title":"Basic Service Discovery","text":"<p>Every service gets a DNS entry:</p> <pre><code>&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local\n</code></pre> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: backend-api\n  namespace: production\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 8080\n      targetPort: 8080\n</code></pre> <p>Access patterns:</p> <pre><code># From same namespace\ncurl http://backend-api:8080\n\n# From different namespace\ncurl http://backend-api.production:8080\n\n# Fully qualified\ncurl http://backend-api.production.svc.cluster.local:8080\n</code></pre>"},{"location":"applications/service-discovery/#dns-policies","title":"DNS Policies","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  dnsPolicy: ClusterFirst # Default\n  # Other options: Default, None, ClusterFirstWithHostNet\n  dnsConfig:\n    nameservers:\n      - 1.1.1.1\n    searches:\n      - production.svc.cluster.local\n      - svc.cluster.local\n    options:\n      - name: ndots\n        value: \"5\"\n</code></pre>"},{"location":"applications/service-discovery/#headless-services","title":"Headless Services","text":""},{"location":"applications/service-discovery/#direct-pod-discovery","title":"Direct Pod Discovery","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: database-cluster\nspec:\n  clusterIP: None # Headless service\n  selector:\n    app: postgres\n  ports:\n    - port: 5432\n</code></pre> <p>DNS returns all pod IPs:</p> <pre><code># Returns A records for all pods\nnslookup database-cluster.default.svc.cluster.local\n\n# Individual pod DNS\n&lt;pod-name&gt;.&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local\n</code></pre>"},{"location":"applications/service-discovery/#statefulset-service-discovery","title":"StatefulSet Service Discovery","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-headless\nspec:\n  clusterIP: None\n  selector:\n    app: postgres\n  ports:\n    - port: 5432\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\nspec:\n  serviceName: postgres-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n        - name: postgres\n          image: postgres:14\n</code></pre> <p>Predictable pod names:</p> <pre><code># Access specific replicas\npostgres-0.postgres-headless.default.svc.cluster.local\npostgres-1.postgres-headless.default.svc.cluster.local\npostgres-2.postgres-headless.default.svc.cluster.local\n</code></pre>"},{"location":"applications/service-discovery/#service-mesh-discovery","title":"Service Mesh Discovery","text":""},{"location":"applications/service-discovery/#istio-service-discovery","title":"Istio Service Discovery","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: ServiceEntry\nmetadata:\n  name: external-api\nspec:\n  hosts:\n    - api.external.com\n  ports:\n    - number: 443\n      name: https\n      protocol: HTTPS\n  location: MESH_EXTERNAL\n  resolution: DNS\n</code></pre>"},{"location":"applications/service-discovery/#virtual-services","title":"Virtual Services","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews-route\nspec:\n  hosts:\n    - reviews\n  http:\n    - match:\n        - headers:\n            version:\n              exact: v2\n      route:\n        - destination:\n            host: reviews\n            subset: v2\n    - route:\n        - destination:\n            host: reviews\n            subset: v1\n</code></pre>"},{"location":"applications/service-discovery/#destination-rules","title":"Destination Rules","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: reviews-destination\nspec:\n  host: reviews\n  subsets:\n    - name: v1\n      labels:\n        version: v1\n    - name: v2\n      labels:\n        version: v2\n</code></pre>"},{"location":"applications/service-discovery/#endpointslices","title":"EndpointSlices","text":""},{"location":"applications/service-discovery/#modern-endpoint-management","title":"Modern Endpoint Management","text":"<pre><code>apiVersion: discovery.k8s.io/v1\nkind: EndpointSlice\nmetadata:\n  name: myapp-endpoints\n  labels:\n    kubernetes.io/service-name: myapp\naddressType: IPv4\nendpoints:\n  - addresses:\n      - \"10.1.2.3\"\n    conditions:\n      ready: true\n      serving: true\n      terminating: false\nports:\n  - port: 8080\n    protocol: TCP\n</code></pre>"},{"location":"applications/service-discovery/#service-discovery-patterns","title":"Service Discovery Patterns","text":""},{"location":"applications/service-discovery/#client-side-load-balancing","title":"Client-Side Load Balancing","text":"<pre><code>// Go example with client-side discovery\npackage main\n\nimport (\n    \"fmt\"\n    \"net\"\n    \"math/rand\"\n)\n\nfunc discoverService(service string) ([]string, error) {\n    _, addrs, err := net.LookupSRV(\"\", \"\", service)\n    if err != nil {\n        return nil, err\n    }\n\n    var endpoints []string\n    for _, addr := range addrs {\n        endpoints = append(endpoints, fmt.Sprintf(\"%s:%d\", addr.Target, addr.Port))\n    }\n    return endpoints, nil\n}\n\nfunc getRandomEndpoint(service string) (string, error) {\n    endpoints, err := discoverService(service)\n    if err != nil {\n        return \"\", err\n    }\n    return endpoints[rand.Intn(len(endpoints))], nil\n}\n</code></pre>"},{"location":"applications/service-discovery/#health-aware-discovery","title":"Health-Aware Discovery","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  annotations:\n    service.alpha.kubernetes.io/tolerate-unready-endpoints: \"false\"\nspec:\n  selector:\n    app: api\n  ports:\n    - port: 80\n  publishNotReadyAddresses: false # Only discover ready pods\n</code></pre>"},{"location":"applications/service-discovery/#external-service-discovery","title":"External Service Discovery","text":""},{"location":"applications/service-discovery/#consul-integration","title":"Consul Integration","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: consul-config\ndata:\n  consul.json: |\n    {\n      \"datacenter\": \"dc1\",\n      \"services\": [\n        {\n          \"name\": \"web-app\",\n          \"tags\": [\"production\", \"v1\"],\n          \"port\": 8080,\n          \"check\": {\n            \"http\": \"http://localhost:8080/health\",\n            \"interval\": \"10s\"\n          }\n        }\n      ]\n    }\n</code></pre>"},{"location":"applications/service-discovery/#external-dns","title":"External DNS","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp\n  annotations:\n    external-dns.alpha.kubernetes.io/hostname: myapp.example.com\n    external-dns.alpha.kubernetes.io/ttl: \"60\"\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp\n                port:\n                  number: 80\n</code></pre>"},{"location":"applications/service-discovery/#multi-cluster-discovery","title":"Multi-Cluster Discovery","text":""},{"location":"applications/service-discovery/#cross-cluster-service-discovery","title":"Cross-Cluster Service Discovery","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: ServiceEntry\nmetadata:\n  name: cross-cluster-service\nspec:\n  hosts:\n    - remote-service.remote-cluster.local\n  location: MESH_EXTERNAL\n  ports:\n    - number: 8080\n      name: http\n      protocol: HTTP\n  resolution: DNS\n  endpoints:\n    - address: cluster-2-gateway.example.com\n      ports:\n        http: 15443\n</code></pre>"},{"location":"applications/service-discovery/#multi-cluster-dns","title":"Multi-Cluster DNS","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns-custom\n  namespace: kube-system\ndata:\n  remote.server: |\n    remote-cluster.local:53 {\n        forward . 10.0.0.100:53\n    }\n</code></pre>"},{"location":"applications/service-discovery/#service-discovery-security","title":"Service Discovery Security","text":""},{"location":"applications/service-discovery/#network-policies","title":"Network Policies","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-discovery-policy\nspec:\n  podSelector:\n    matchLabels:\n      app: api\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: production\n        - podSelector:\n            matchLabels:\n              role: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"applications/service-discovery/#mtls-for-service-communication","title":"mTLS for Service Communication","text":"<pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\nspec:\n  mtls:\n    mode: STRICT\n</code></pre>"},{"location":"applications/service-discovery/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"applications/service-discovery/#service-registry-pattern","title":"Service Registry Pattern","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: service-registry\ndata:\n  services.yaml: |\n    services:\n      - name: user-service\n        endpoints:\n          - host: user-service.production\n            port: 8080\n            weight: 100\n      - name: order-service\n        endpoints:\n          - host: order-service-v1.production\n            port: 8080\n            weight: 80\n          - host: order-service-v2.production\n            port: 8080\n            weight: 20\n</code></pre>"},{"location":"applications/service-discovery/#circuit-breaker-with-discovery","title":"Circuit Breaker with Discovery","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: circuit-breaker\nspec:\n  host: backend-service\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n      minHealthPercent: 30\n</code></pre>"},{"location":"applications/service-discovery/#monitoring-service-discovery","title":"Monitoring Service Discovery","text":""},{"location":"applications/service-discovery/#metrics","title":"Metrics","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/path: \"/metrics\"\nspec:\n  selector:\n    app: myapp\n  ports:\n    - name: web\n      port: 80\n    - name: metrics\n      port: 9090\n</code></pre>"},{"location":"applications/service-discovery/#discovery-health-checks","title":"Discovery Health Checks","text":"<pre><code># Check DNS resolution\nhb exec -it debug-pod -- nslookup myservice\n\n# Check endpoints\nhb get endpoints myservice\n\n# Check endpoint slices\nhb get endpointslices -l kubernetes.io/service-name=myservice\n\n# Test service discovery\nhb run test --rm -it --image=busybox -- wget -O- http://myservice\n</code></pre>"},{"location":"applications/service-discovery/#troubleshooting","title":"Troubleshooting","text":""},{"location":"applications/service-discovery/#common-issues","title":"Common Issues","text":"<ol> <li>DNS Resolution Failures</li> </ol> <pre><code># Check CoreDNS logs\nhb logs -n kube-system -l k8s-app=kube-dns\n\n# Test DNS from pod\nhb exec -it myapp -- nslookup kubernetes.default\n</code></pre> <ol> <li>Service Not Found</li> </ol> <pre><code># Verify service exists\nhb get svc myservice\n\n# Check service selector\nhb describe svc myservice\n\n# Verify matching pods\nhb get pods -l app=myapp\n</code></pre> <ol> <li>Endpoint Not Ready</li> </ol> <pre><code># Check endpoint status\nhb get endpoints myservice\n\n# Check pod readiness\nhb get pods -l app=myapp -o wide\n</code></pre>"},{"location":"applications/service-discovery/#debugging-tools","title":"Debugging Tools","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: network-debug\nspec:\n  containers:\n    - name: debug\n      image: nicolaka/netshoot\n      command: [\"/bin/bash\"]\n      args: [\"-c\", \"sleep 3600\"]\n</code></pre> <p>Debug commands:</p> <pre><code># DNS debugging\ndig @10.96.0.10 myservice.default.svc.cluster.local\n\n# Service discovery test\ncurl -v http://myservice.default.svc.cluster.local\n\n# Trace network path\ntraceroute myservice.default.svc.cluster.local\n</code></pre>"},{"location":"applications/service-discovery/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Appropriate Discovery Method</p> </li> <li> <p>DNS for simple service discovery</p> </li> <li>Headless services for stateful applications</li> <li> <p>Service mesh for advanced traffic management</p> </li> <li> <p>Implement Health Checks</p> </li> <li> <p>Always define readiness probes</p> </li> <li>Use liveness probes for self-healing</li> <li> <p>Configure appropriate timeouts</p> </li> <li> <p>Cache Discovery Results</p> </li> <li> <p>Implement client-side caching</p> </li> <li>Use TTL appropriately</li> <li> <p>Handle cache invalidation</p> </li> <li> <p>Monitor Discovery Health</p> </li> <li> <p>Track DNS query latency</p> </li> <li>Monitor endpoint changes</li> <li> <p>Alert on discovery failures</p> </li> <li> <p>Security Considerations</p> </li> <li>Use network policies</li> <li>Implement mTLS where possible</li> <li>Limit service exposure</li> </ol>"},{"location":"applications/service-discovery/#hks-specific-features","title":"HKS-Specific Features","text":""},{"location":"applications/service-discovery/#ai-enhanced-discovery","title":"AI-Enhanced Discovery","text":"<pre><code>apiVersion: hks.io/v1\nkind: SmartDiscovery\nmetadata:\n  name: intelligent-routing\nspec:\n  service: myapp\n  optimization:\n    - latency\n    - cost\n    - reliability\n  learning:\n    enabled: true\n    window: 7d\n</code></pre>"},{"location":"applications/service-discovery/#global-service-catalog","title":"Global Service Catalog","text":"<pre><code># List all services across clusters\nhb catalog list --global\n\n# Search services by capability\nhb catalog search --tag \"user-auth\"\n\n# Get service details\nhb catalog describe user-service --detailed\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":"<p>Explore the technical architecture of Hexabase.AI, from high-level system design to detailed component interactions.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<p>Hexabase.AI is built on a modern, cloud-native architecture that combines the power of Kubernetes with intelligent automation. Our architecture prioritizes scalability, security, and extensibility while maintaining operational simplicity.</p>"},{"location":"architecture/#architecture-documentation","title":"Architecture Documentation","text":"<ul> <li> System Overview</li> </ul> <p>High-level architecture and component relationships</p> <p> View System Architecture</p> <ul> <li> Platform Components</li> </ul> <p>Detailed breakdown of control plane and data plane components</p> <p> Explore Components</p> <ul> <li> Networking</li> </ul> <p>Network architecture, service mesh, and traffic management</p> <p> Technical Design</p> <ul> <li> Security Architecture</li> </ul> <p>Security layers, authentication, and compliance features</p> <p> Security Architecture</p>"},{"location":"architecture/#key-architectural-principles","title":"Key Architectural Principles","text":""},{"location":"architecture/#1-multi-tenancy-first","title":"1. Multi-tenancy First","text":"<ul> <li>Hard isolation between organizations</li> <li>Soft isolation between workspaces</li> <li>Resource quotas and limits enforcement</li> </ul>"},{"location":"architecture/#2-api-driven-design","title":"2. API-Driven Design","text":"<ul> <li>Everything accessible via REST APIs</li> <li>GraphQL for complex queries</li> <li>WebSocket for real-time updates</li> </ul>"},{"location":"architecture/#3-cloud-native-patterns","title":"3. Cloud-Native Patterns","text":"<ul> <li>Microservices architecture</li> <li>Container-first approach</li> <li>Declarative configuration</li> </ul>"},{"location":"architecture/#4-intelligent-automation","title":"4. Intelligent Automation","text":"<ul> <li>AI/ML integration for operations</li> <li>Predictive scaling and optimization</li> <li>Anomaly detection and remediation</li> </ul>"},{"location":"architecture/#system-layers","title":"System Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          User Interface Layer           \u2502\n\u2502    (Web Portal, CLI, Mobile Apps)       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           API Gateway Layer             \u2502\n\u2502  (Authentication, Rate Limiting, etc.)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Control Plane Services          \u2502\n\u2502 (Orchestration, Scheduling, Monitoring) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           Data Plane Layer              \u2502\n\u2502   (Kubernetes Clusters, Workloads)      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502        Infrastructure Layer             \u2502\n\u2502    (Compute, Storage, Networking)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"architecture/#core-technologies","title":"Core Technologies","text":"<ul> <li>Kubernetes: Container orchestration</li> <li>Istio: Service mesh for traffic management</li> <li>Prometheus: Metrics and monitoring</li> <li>Grafana: Visualization and dashboards</li> <li>ArgoCD: GitOps and continuous deployment</li> </ul>"},{"location":"architecture/#aiml-stack","title":"AI/ML Stack","text":"<ul> <li>TensorFlow: Model training and inference</li> <li>Kubeflow: ML workflow orchestration</li> <li>Custom Models: Resource optimization and anomaly detection</li> </ul>"},{"location":"architecture/#development-stack","title":"Development Stack","text":"<ul> <li>Go: Control plane services</li> <li>Python: AI/ML components</li> <li>React: Web interface</li> <li>PostgreSQL: Metadata storage</li> <li>Redis: Caching and queuing</li> </ul>"},{"location":"architecture/#architecture-decision-records","title":"Architecture Decision Records","text":"<p>We maintain Architecture Decision Records (ADRs) to document significant architectural choices:</p> <p> View Technical Design</p>"},{"location":"architecture/#deployment-models","title":"Deployment Models","text":""},{"location":"architecture/#saas-deployment","title":"SaaS Deployment","text":"<ul> <li>Fully managed by Hexabase team</li> <li>Multi-region availability</li> <li>Automatic updates and maintenance</li> </ul>"},{"location":"architecture/#on-premises-deployment","title":"On-Premises Deployment","text":"<ul> <li>Deploy in your data center</li> <li>Full control over infrastructure</li> <li>Support for air-gapped environments</li> </ul>"},{"location":"architecture/#hybrid-deployment","title":"Hybrid Deployment","text":"<ul> <li>Control plane in cloud</li> <li>Data plane on-premises</li> <li>Best of both worlds</li> </ul>"},{"location":"architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Deep Dive: Explore Platform Components for detailed technical information</li> <li>Security Focus: Review Security Architecture for compliance requirements</li> <li>Design Decisions: Browse Technical Design to understand our architectural choices</li> <li>Integration: Check API Documentation for integration options</li> </ul>"},{"location":"architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>Core Concepts</li> <li>Kubernetes RBAC</li> <li>Observability</li> <li>API Reference</li> </ul>"},{"location":"architecture/security-architecture/","title":"Hexabase KaaS: OAuth Security Implementation Specification","text":""},{"location":"architecture/security-architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Security Architecture</li> <li>OAuth2/OIDC Implementation</li> <li>JWT Token Management</li> <li>Session Management</li> <li>Security Middleware</li> <li>Rate Limiting and DDoS Protection</li> <li>Audit Logging</li> <li>Testing Strategy</li> <li>Security Best Practices</li> <li>AIOps Security Sandbox Model</li> </ol>"},{"location":"architecture/security-architecture/#1-overview","title":"1. Overview","text":"<p>The Hexabase KaaS platform implements a comprehensive OAuth2/OIDC-based authentication system with enhanced security features. This specification documents the security architecture, implementation details, and best practices for maintaining a secure multi-tenant Kubernetes platform.</p>"},{"location":"architecture/security-architecture/#11-security-goals","title":"1.1 Security Goals","text":"<ul> <li>Zero Trust Architecture: No implicit trust; every request is authenticated and authorized</li> <li>Defense in Depth: Multiple layers of security controls</li> <li>Least Privilege: Users and services have minimal required permissions</li> <li>Audit Trail: Complete logging of all security-relevant events</li> <li>Compliance: OWASP Top 10, OAuth 2.0 RFC 6749, OIDC standards</li> </ul>"},{"location":"architecture/security-architecture/#12-threat-model","title":"1.2 Threat Model","text":"<p>Key threats addressed:</p> <ul> <li>Token Theft: JWT hijacking, session fixation</li> <li>Man-in-the-Middle: TLS enforcement, HSTS</li> <li>Cross-Site Attacks: CSRF, XSS, clickjacking</li> <li>Brute Force: Rate limiting, account lockout</li> <li>Session Hijacking: IP/device validation, concurrent session limits</li> </ul>"},{"location":"architecture/security-architecture/#2-security-architecture","title":"2. Security Architecture","text":""},{"location":"architecture/security-architecture/#21-component-overview","title":"2.1 Component Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2502   Frontend UI   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   API Gateway   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Auth Service   \u2502\n\u2502   (Next.js)     \u2502     \u2502   (Security)    \u2502     \u2502   (OAuth/JWT)   \u2502\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2502                       \u2502                       \u2502\n         \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2502  Session Store  \u2502     \u2502  Rate Limiter   \u2502     \u2502  Audit Logger   \u2502\n\u2502    (Redis)      \u2502     \u2502    (Redis)      \u2502     \u2502  (PostgreSQL)   \u2502\n\u2502                 \u2502     \u2502                 \u2502     \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/security-architecture/#22-security-layers","title":"2.2 Security Layers","text":"<ol> <li> <p>Network Layer</p> </li> <li> <p>TLS 1.3 minimum</p> </li> <li>HSTS enforcement</li> <li> <p>Certificate pinning for critical endpoints</p> </li> <li> <p>Application Layer</p> </li> <li> <p>OAuth2/OIDC authentication</p> </li> <li>JWT token validation</li> <li> <p>RBAC authorization</p> </li> <li> <p>Session Layer</p> </li> <li> <p>Secure session management</p> </li> <li>Device fingerprinting</li> <li> <p>Concurrent session control</p> </li> <li> <p>Data Layer</p> </li> <li>Encryption at rest</li> <li>Secure key management</li> <li>Database access controls</li> </ol>"},{"location":"architecture/security-architecture/#3-oauth2oidc-implementation","title":"3. OAuth2/OIDC Implementation","text":""},{"location":"architecture/security-architecture/#31-supported-providers","title":"3.1 Supported Providers","text":"<pre><code>type OAuthProvider struct {\n    ClientID     string\n    ClientSecret string\n    RedirectURL  string\n    Scopes       []string\n    AuthURL      string\n    TokenURL     string\n    UserInfoURL  string\n}\n\n// Configured providers\nproviders := map[string]OAuthProvider{\n    \"google\": {...},\n    \"github\": {...},\n    \"gitlab\": {...},\n}\n</code></pre>"},{"location":"architecture/security-architecture/#32-oauth-flow-with-pkce","title":"3.2 OAuth Flow with PKCE","text":"<p>The implementation supports PKCE (Proof Key for Code Exchange) for enhanced security:</p> <pre><code>// 1. Generate code verifier and challenge\nverifier := GenerateCodeVerifier()  // 128 chars base64url\nchallenge := GenerateCodeChallenge(verifier)  // SHA256(verifier)\n\n// 2. Authorization request\nauthURL := provider.AuthCodeURL(state,\n    oauth2.SetAuthURLParam(\"code_challenge\", challenge),\n    oauth2.SetAuthURLParam(\"code_challenge_method\", \"S256\"),\n)\n\n// 3. Token exchange with verifier\ntoken := provider.Exchange(ctx, code,\n    oauth2.SetAuthURLParam(\"code_verifier\", verifier),\n)\n</code></pre>"},{"location":"architecture/security-architecture/#33-state-parameter-validation","title":"3.3 State Parameter Validation","text":"<p>CSRF protection using cryptographically secure state parameters:</p> <pre><code>// State generation and storage\nstate := GenerateSecureState()  // 32 bytes random\nredis.SetWithTTL(\"oauth_state:\"+state, \"valid\", 10*time.Minute)\n\n// State validation and consumption\nfunc ValidateAndConsumeState(state string) error {\n    _, err := redis.GetDel(\"oauth_state:\"+state)\n    return err  // State can only be used once\n}\n</code></pre>"},{"location":"architecture/security-architecture/#4-jwt-token-management","title":"4. JWT Token Management","text":""},{"location":"architecture/security-architecture/#41-token-structure","title":"4.1 Token Structure","text":"<pre><code>type EnhancedClaims struct {\n    jwt.RegisteredClaims\n    UserID        string   `json:\"uid\"`\n    Email         string   `json:\"email\"`\n    Provider      string   `json:\"provider\"`\n    Organizations []string `json:\"orgs\"`\n    Permissions   []string `json:\"perms\"`\n    Fingerprint   string   `json:\"fp\"`\n    TokenType     string   `json:\"typ\"`\n    SessionID     string   `json:\"sid\"`\n}\n</code></pre>"},{"location":"architecture/security-architecture/#42-token-pair-system","title":"4.2 Token Pair System","text":"<p>Access and refresh tokens with different lifetimes:</p> <ul> <li>Access Token: 15 minutes, contains user permissions</li> <li>Refresh Token: 7 days, used to obtain new access tokens</li> </ul> <pre><code>type TokenPair struct {\n    AccessToken  string    `json:\"access_token\"`\n    RefreshToken string    `json:\"refresh_token\"`\n    TokenType    string    `json:\"token_type\"`\n    ExpiresIn    int       `json:\"expires_in\"`\n    ExpiresAt    time.Time `json:\"expires_at\"`\n}\n</code></pre>"},{"location":"architecture/security-architecture/#43-token-security-features","title":"4.3 Token Security Features","text":"<ol> <li>RSA-256 Signing: 2048-bit RSA keys</li> <li>Fingerprinting: Device ID + IP address hash</li> <li>Revocation: Redis-based revocation list</li> <li>Rotation: Automatic token rotation on refresh</li> </ol>"},{"location":"architecture/security-architecture/#44-jwks-endpoint","title":"4.4 JWKS Endpoint","text":"<p>Public key exposure for token verification:</p> <pre><code>{\n  \"keys\": [\n    {\n      \"kty\": \"RSA\",\n      \"use\": \"sig\",\n      \"kid\": \"2024-01-01\",\n      \"alg\": \"RS256\",\n      \"n\": \"0Z0VS5JJcds3xfNn...\",\n      \"e\": \"AQAB\"\n    }\n  ]\n}\n</code></pre>"},{"location":"architecture/security-architecture/#5-session-management","title":"5. Session Management","text":""},{"location":"architecture/security-architecture/#51-session-structure","title":"5.1 Session Structure","text":"<pre><code>type SecureSession struct {\n    ID           string    `json:\"id\"`\n    UserID       string    `json:\"user_id\"`\n    DeviceID     string    `json:\"device_id\"`\n    IPAddress    string    `json:\"ip_address\"`\n    UserAgent    string    `json:\"user_agent\"`\n    Provider     string    `json:\"provider\"`\n    CreatedAt    time.Time `json:\"created_at\"`\n    LastActive   time.Time `json:\"last_active\"`\n    ExpiresAt    time.Time `json:\"expires_at\"`\n    RefreshToken string    `json:\"refresh_token\"`\n}\n</code></pre>"},{"location":"architecture/security-architecture/#52-session-security","title":"5.2 Session Security","text":"<ol> <li>Idle Timeout: 30 minutes of inactivity</li> <li>Absolute Timeout: 24 hours maximum</li> <li>Concurrent Sessions: Maximum 3 per user</li> <li>Device Tracking: Fingerprint validation</li> <li>IP Validation: Session bound to IP address</li> </ol>"},{"location":"architecture/security-architecture/#53-session-storage","title":"5.3 Session Storage","text":"<p>Redis-based session storage with automatic expiration:</p> <pre><code>// Session key pattern\nkey := fmt.Sprintf(\"session:%s\", sessionID)\n\n// User sessions index\nuserKey := fmt.Sprintf(\"user_sessions:%s\", userID)\n</code></pre>"},{"location":"architecture/security-architecture/#6-security-middleware","title":"6. Security Middleware","text":""},{"location":"architecture/security-architecture/#61-security-headers","title":"6.1 Security Headers","text":"<pre><code>func SecurityHeadersMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        // HSTS - Enforce HTTPS\n        w.Header().Set(\"Strict-Transport-Security\",\n            \"max-age=31536000; includeSubDomains\")\n\n        // Prevent MIME type sniffing\n        w.Header().Set(\"X-Content-Type-Options\", \"nosniff\")\n\n        // Prevent clickjacking\n        w.Header().Set(\"X-Frame-Options\", \"DENY\")\n\n        // XSS Protection\n        w.Header().Set(\"X-XSS-Protection\", \"1; mode=block\")\n\n        // Content Security Policy\n        w.Header().Set(\"Content-Security-Policy\",\n            \"default-src 'self'; \" +\n            \"script-src 'self' 'unsafe-inline' 'unsafe-eval' https://accounts.google.com; \" +\n            \"style-src 'self' 'unsafe-inline'; \" +\n            \"img-src 'self' data: https:; \" +\n            \"font-src 'self' data:; \" +\n            \"connect-src 'self' https://api.github.com https://accounts.google.com\")\n\n        // Referrer Policy\n        w.Header().Set(\"Referrer-Policy\", \"strict-origin-when-cross-origin\")\n\n        // Permissions Policy\n        w.Header().Set(\"Permissions-Policy\",\n            \"geolocation=(), microphone=(), camera=()\")\n\n        next.ServeHTTP(w, r)\n    })\n}\n</code></pre>"},{"location":"architecture/security-architecture/#62-cors-configuration","title":"6.2 CORS Configuration","text":"<p>Strict CORS policy with allowed origins:</p> <pre><code>func ConfigureCORS(allowedOrigins []string) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            origin := r.Header.Get(\"Origin\")\n\n            // Validate origin\n            for _, allowed := range allowedOrigins {\n                if origin == allowed {\n                    w.Header().Set(\"Access-Control-Allow-Origin\", origin)\n                    w.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n                    w.Header().Set(\"Access-Control-Allow-Methods\",\n                        \"GET, POST, PUT, DELETE, OPTIONS\")\n                    w.Header().Set(\"Access-Control-Allow-Headers\",\n                        \"Authorization, Content-Type, X-Requested-With, X-CSRF-Token\")\n                    w.Header().Set(\"Access-Control-Max-Age\", \"86400\")\n                    break\n                }\n            }\n\n            if r.Method == \"OPTIONS\" {\n                w.WriteHeader(http.StatusNoContent)\n                return\n            }\n\n            next.ServeHTTP(w, r)\n        })\n    }\n}\n</code></pre>"},{"location":"architecture/security-architecture/#7-rate-limiting-and-ddos-protection","title":"7. Rate Limiting and DDoS Protection","text":""},{"location":"architecture/security-architecture/#71-rate-limiting-strategy","title":"7.1 Rate Limiting Strategy","text":"<pre><code>type RateLimiter struct {\n    redis    RedisClient\n    limit    int\n    window   time.Duration\n}\n\n// Different limits for different endpoints\nrateLimits := map[string]RateLimit{\n    \"auth.login\":    {10, time.Minute},    // 10 attempts per minute\n    \"auth.refresh\":  {30, time.Minute},    // 30 refreshes per minute\n    \"api.write\":     {100, time.Minute},   // 100 writes per minute\n    \"api.read\":      {1000, time.Minute},  // 1000 reads per minute\n}\n</code></pre>"},{"location":"architecture/security-architecture/#72-ddos-protection","title":"7.2 DDoS Protection","text":"<ol> <li>Connection Limits: Per-IP connection limits</li> <li>Request Size Limits: Maximum request body size</li> <li>Timeout Configuration: Request timeout limits</li> <li>Geographic Restrictions: Optional geo-blocking</li> </ol>"},{"location":"architecture/security-architecture/#8-audit-logging","title":"8. Audit Logging","text":""},{"location":"architecture/security-architecture/#81-audit-event-structure","title":"8.1 Audit Event Structure","text":"<pre><code>type AuditEvent struct {\n    ID        string                 `json:\"id\"`\n    Type      string                 `json:\"type\"`\n    UserID    string                 `json:\"user_id\"`\n    IP        string                 `json:\"ip\"`\n    UserAgent string                 `json:\"user_agent\"`\n    Provider  string                 `json:\"provider\"`\n    Success   bool                   `json:\"success\"`\n    Error     string                 `json:\"error\"`\n    Metadata  map[string]interface{} `json:\"metadata\"`\n    Timestamp time.Time              `json:\"timestamp\"`\n}\n</code></pre>"},{"location":"architecture/security-architecture/#82-logged-events","title":"8.2 Logged Events","text":"<ul> <li>Authentication attempts (success/failure)</li> <li>Token generation and refresh</li> <li>Permission changes</li> <li>Resource access</li> <li>Configuration changes</li> <li>Security violations</li> </ul>"},{"location":"architecture/security-architecture/#83-log-retention","title":"8.3 Log Retention","text":"<ul> <li>Security Events: 90 days minimum</li> <li>Failed Attempts: 30 days</li> <li>Successful Operations: 30 days</li> <li>Compliance Logs: As per requirements</li> </ul>"},{"location":"architecture/security-architecture/#9-testing-strategy","title":"9. Testing Strategy","text":""},{"location":"architecture/security-architecture/#91-security-test-coverage","title":"9.1 Security Test Coverage","text":"<pre><code>// Test suite structure\ntype OAuthSecurityTestSuite struct {\n    suite.Suite\n    client      *SecureOAuthClient\n    jwtManager  *EnhancedJWTManager\n    redisClient *MockSecureRedisClient\n}\n\n// Test scenarios\n- TestPKCEFlow\n- TestJWTRefreshTokenFlow\n- TestJWTFingerprinting\n- TestSecureSessionManagement\n- TestRateLimiting\n- TestSecurityHeaders\n- TestCORSConfiguration\n- TestAuditLogging\n- TestTokenRevocation\n- TestMultiProviderOAuth\n- TestSessionHijackingPrevention\n</code></pre>"},{"location":"architecture/security-architecture/#92-security-testing-tools","title":"9.2 Security Testing Tools","text":"<ol> <li>Static Analysis: gosec, staticcheck</li> <li>Dependency Scanning: nancy, snyk</li> <li>Penetration Testing: OWASP ZAP</li> <li>Load Testing: k6, vegeta</li> </ol>"},{"location":"architecture/security-architecture/#10-security-best-practices","title":"10. Security Best Practices","text":""},{"location":"architecture/security-architecture/#101-development-guidelines","title":"10.1 Development Guidelines","text":"<ol> <li> <p>Input Validation</p> </li> <li> <p>Validate all user input</p> </li> <li>Use parameterized queries</li> <li> <p>Sanitize output</p> </li> <li> <p>Error Handling</p> </li> <li> <p>Don't expose internal errors</p> </li> <li>Log security events</li> <li> <p>Return generic error messages</p> </li> <li> <p>Cryptography</p> </li> <li>Use standard libraries</li> <li>Never roll your own crypto</li> <li>Rotate keys regularly</li> </ol>"},{"location":"architecture/security-architecture/#102-operational-security","title":"10.2 Operational Security","text":"<ol> <li> <p>Monitoring</p> </li> <li> <p>Real-time security alerts</p> </li> <li>Anomaly detection</li> <li> <p>Failed login tracking</p> </li> <li> <p>Incident Response</p> </li> <li> <p>Security incident playbooks</p> </li> <li>Automated responses</li> <li> <p>Post-incident reviews</p> </li> <li> <p>Compliance</p> </li> <li>Regular security audits</li> <li>Vulnerability assessments</li> <li>Compliance reporting</li> </ol>"},{"location":"architecture/security-architecture/#103-future-enhancements","title":"10.3 Future Enhancements","text":"<ol> <li> <p>Multi-Factor Authentication (MFA)</p> </li> <li> <p>TOTP support</p> </li> <li>SMS backup codes</li> <li> <p>Hardware token support</p> </li> <li> <p>WebAuthn/FIDO2</p> </li> <li> <p>Passwordless authentication</p> </li> <li>Biometric support</li> <li> <p>Platform authenticators</p> </li> <li> <p>Advanced Threat Detection</p> </li> <li>ML-based anomaly detection</li> <li>Behavioral analysis</li> <li>Risk scoring</li> </ol>"},{"location":"architecture/security-architecture/#11-aiops-security-sandbox-model","title":"11. AIOps Security Sandbox Model","text":"<p>The introduction of AIOps, where AI agents can perform operations on behalf of users, requires a robust security model to prevent unintended actions and ensure all operations are auditable and authorized. The Hexabase KaaS platform implements a security sandbox model for the AIOps system based on the principle of least privilege and zero trust between internal systems.</p>"},{"location":"architecture/security-architecture/#111-core-principles","title":"11.1. Core Principles","text":"<ul> <li>Zero Trust: The Go-based Control Plane does not inherently trust the Python-based AIOps system. Every request from AIOps must be independently authenticated and authorized.</li> <li>User Context Impersonation: AI agents do not have their own permissions. They temporarily \"impersonate\" the user who initiated the chat or request, and all actions are performed within that user's permission scope.</li> <li>Final Authority: The Control Plane is the single source of truth for authorization and the sole executor of privileged operations. The AIOps system can only request actions; it cannot execute them directly.</li> </ul>"},{"location":"architecture/security-architecture/#112-architecture-and-flow","title":"11.2. Architecture and Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant HKS_Control_Plane as Hexabase Control Plane (Go)\n    participant AIOps_System as AIOps System (Python)\n    participant K8s_API as Kubernetes API\n\n    User-&gt;&gt;HKS_Control_Plane: 1. AI Chat Request (e.g., \"Scale my app to 3 replicas\")\n    HKS_Control_Plane-&gt;&gt;HKS_Control_Plane: 2. Authenticate User, Create Internal JWT\n    Note right of HKS_Control_Plane: JWT contains: user_id, org_id, roles&lt;br/&gt;Expiry: 10 seconds\n    HKS_Control_Plane-&gt;&gt;AIOps_System: 3. Forward request with Internal JWT\n\n    AIOps_System-&gt;&gt;AIOps_System: 4. Process request, formulate execution plan\n    Note left of AIOps_System: Plan: \"Scale deployment 'my-app' in 'project-x' to 3\"\n\n    AIOps_System-&gt;&gt;HKS_Control_Plane: 5. Request operation via internal API&lt;br&gt;(`POST /internal/op/scale_deployment`)\n    Note right of HKS_Control_Plane: Request includes plan and original Internal JWT\n\n    HKS_Control_Plane-&gt;&gt;HKS_Control_Plane: 6. Final Authorization Check&lt;br/&gt;- Verify JWT&lt;br/&gt;- Check if user has permission for 'my-app'\n\n    alt Access Granted\n        HKS_Control_Plane-&gt;&gt;K8s_API: 7. Execute operation\n        K8s_API--&gt;&gt;HKS_Control_Plane: 8. Success\n        HKS_Control_Plane--&gt;&gt;AIOps_System: 9. Operation successful\n    else Access Denied\n        HKS_Control_Plane--&gt;&gt;AIOps_System: 9. Permission denied error\n    end\n\n    AIOps_System--&gt;&gt;HKS_Control_Plane: 10. Forward response\n    HKS_Control_Plane--&gt;&gt;User: 11. Send final response to user</code></pre>"},{"location":"architecture/security-architecture/#113-implementation-details","title":"11.3. Implementation Details","text":"<ul> <li>Internal JWT: A short-lived (e.g., 10-second) JSON Web Token signed by the Control Plane. It contains the user's identity, scope (organization, workspace), and roles. This token is only used for internal, server-to-server communication and is never exposed to the outside world.</li> <li>Internal Operations API: A dedicated set of internal API endpoints (e.g., <code>/internal/v1/operations/...</code>) on the Control Plane that the AIOps system can call. These endpoints are not exposed publicly.</li> <li>Strict Validation: When the Control Plane receives a request on the internal operations API, it performs the same rigorous permission checks it would if the user were making the API call directly. It validates the JWT, checks the user's RBAC permissions for the target resource, and only then executes the command.</li> </ul> <p>This model ensures that even if the AIOps system were compromised or had a bug, it could not perform any action that the impersonated user wasn't already explicitly permitted to do, providing a strong security guarantee.</p>"},{"location":"architecture/security-architecture/#conclusion","title":"Conclusion","text":"<p>The Hexabase KaaS OAuth security implementation provides a robust, scalable, and secure authentication system suitable for a multi-tenant Kubernetes platform. By following these specifications and best practices, the platform maintains a strong security posture while providing a seamless user experience.</p> <p>For implementation details, refer to the source code in:</p> <ul> <li><code>/api/internal/auth/oauth_security.go</code></li> <li><code>/api/internal/auth/oauth_security_test.go</code></li> <li><code>/api/internal/auth/oauth_client.go</code></li> <li><code>/api/internal/auth/jwt.go</code></li> </ul>"},{"location":"architecture/system-architecture/","title":"Hexabase AI: Architecture Specification","text":""},{"location":"architecture/system-architecture/#1-project-overview","title":"1. Project Overview","text":""},{"location":"architecture/system-architecture/#11-vision","title":"1.1. Vision","text":"<p>This project aims to develop and provide an open-source, observable, and intuitive multi-tenant Kubernetes as a Service (KaaS) platform based on <code>K3s</code> and <code>vCluster</code>. While Kubernetes has become the de facto standard in modern application development, its high learning curve, complex operational management, and difficulty in securing resources for small teams and individual developers remain barriers to adoption. Hexabase AI is designed to solve these challenges.</p> <p>Specifically, it provides the following value:</p> <ul> <li> <p>Ease of Deployment: Based on <code>K3s</code>, a lightweight Kubernetes distribution, and utilizing <code>vCluster</code> virtualization technology, users are freed from the complexity of physical cluster management and can quickly start using isolated Kubernetes environments. This ease of use encourages developers and teams with limited Kubernetes expertise to embrace new technologies. Traditional Kubernetes cluster construction required extensive expertise in network configuration, security policy formulation, storage provisioning, and more. Hexabase AI automates and abstracts much of this, providing a ready-to-use state with just a few clicks.</p> </li> <li> <p>Intuitive Operation: Kubernetes' powerful features are abstracted through a sophisticated UI/UX, making them easily accessible to users without specialized knowledge. Resources can be managed using intuitive concepts such as Organization, Workspace, and Project. For example, common operations like application deployment, scaling, and monitoring can be performed from a graphical interface without directly editing YAML files. Error messages and logs are also displayed in an understandable way to support problem resolution.</p> </li> <li> <p>Strong Tenant Isolation: <code>vCluster</code> provides each tenant (Workspace) with dedicated API servers and control plane components, ensuring significantly higher security and independence than namespace-based isolation. This minimizes cross-tenant impact and allows resources to be used with confidence. For example, even if one tenant accidentally consumes excessive resources or causes security issues, other tenant environments are designed to remain unaffected. This is particularly crucial when hosting multiple customers or projects on the same physical infrastructure.</p> </li> <li> <p>Cloud-Native Operations: Equipped with a comprehensive monitoring stack using <code>Prometheus</code>, <code>Grafana</code>, and <code>Loki</code>, enabling real-time visibility into system health and tenant resource usage. Adopting a GitOps approach with <code>Flux</code> enables declarative configuration management and reproducible deployments. Policy management with <code>Kyverno</code> supports enhanced security compliance and governance. This ensures that infrastructure configuration changes, application deployments, and security policy applications are performed through version-controlled code, facilitating audit trails and rollbacks.</p> </li> <li> <p>Open Source Transparency and Community: By releasing this project as open source, we ensure technical transparency and actively welcome feedback and contributions from developers worldwide. We aim to build a reliable platform that grows with the community and can address more use cases. We also anticipate use in educational institutions and as a learning/validation platform for new cloud-native technologies. Open source code publication leads to early discovery and correction of security vulnerabilities. Additionally, incorporating diverse perspectives enables more innovative and practical feature development.</p> </li> </ul> <p>Hexabase AI envisions being a catalyst for delivering the power of Kubernetes to more people and accelerating innovation. Developers will be freed from infrastructure complexity and able to focus on the essential value creation of application development.</p>"},{"location":"architecture/system-architecture/#2-system-architecture","title":"2. System Architecture","text":"<p>The Hexabase AI system architecture consists of the Hexabase UI (Next.js) that users directly interact with, the Hexabase API (control plane, Go language) that manages and controls the entire system, various supporting middleware (PostgreSQL, Redis, NATS, etc.), and a new AIOps System (Python). All these components are containerized and run on the operational foundation Host K3s Cluster. Per-tenant Kubernetes environments are virtually constructed within the Host K3s Cluster using vCluster technology, providing strong isolation and independence. This multi-layered architecture is designed with scalability, availability, maintainability, and intelligence in mind.</p> <p>Architectural Diagram:</p> <pre><code>graph TD\n    subgraph \"User Interaction\"\n        direction LR\n        User -- \"Browser, Slack, etc.\" --&gt; Frontend\n        Frontend[Hexabase UI / Chat Client]\n    end\n\n    subgraph \"Hexabase Control Plane (Go)\"\n        direction LR\n        Frontend -- \"REST/WebSocket\" --&gt; API_Server[API Server]\n        API_Server -- \"Publish Tasks\" --&gt; NATS[NATS Messaging]\n        NATS -- \"Consume Tasks\" --&gt; Workers[Async Workers]\n    end\n\n    subgraph \"AIOps System (Python)\"\n        direction LR\n        AIOps_API[AIOps API]\n        AIOps_Orchestrator[Orchestrator]\n        AIOps_Agents[Specialized Agents]\n        Private_LLM[Private LLMs on Ollama]\n\n        AIOps_API --&gt; AIOps_Orchestrator\n        AIOps_Orchestrator --&gt; AIOps_Agents\n        AIOps_Agents --&gt; Private_LLM\n        AIOps_Orchestrator -- \"External LLM API\" --&gt; Internet\n    end\n\n    subgraph \"Data &amp; State\"\n        PostgreSQL\n        Redis\n        Central_Logging[Central Logging (ClickHouse)]\n        LLMOps[LLMOps (Langfuse)]\n    end\n\n    subgraph \"Host K3s Cluster\"\n        vClusters[vClusters per Tenant]\n        Shared_Observability[Shared Observability Stack]\n    end\n\n    API_Server -- \"Read/Write\" --&gt; PostgreSQL\n    API_Server -- \"Cache\" --&gt; Redis\n    API_Server -- \"Log\" --&gt; Central_Logging\n    Workers -- \"Read/Write\" --&gt; PostgreSQL\n\n    API_Server -- \"Internal JWT\" --&gt; AIOps_API\n    AIOps_API -- \"Log/Trace\" --&gt; LLMOps\n\n    API_Server -- \"Manage\" --&gt; vClusters\n    Workers -- \"Manage\" --&gt; vClusters\n\n    style Frontend fill:#d4f0ff\n    style AIOps_API fill:#e6ffc2</code></pre> <p>Key Component Interactions and Data Flow:</p> <ol> <li> <p>User Operations and UI: Users access the Hexabase UI through a web browser to perform operations such as creating Organizations, provisioning Workspaces (vClusters), managing Projects (Namespaces), inviting users, and setting permissions. The UI converts these operations into requests to the Hexabase API. The UI manages the user's authentication state and attaches authentication tokens to API requests. Real-time information updates (e.g., vCluster provisioning progress) will be implemented using technologies such as WebSocket or Server-Sent Events.</p> </li> <li> <p>API Request Processing: The Hexabase API receives requests from the UI and first performs authentication and authorization processing. After confirming that the authenticated user has permission to perform the requested operation, it executes the business logic. This includes updating the PostgreSQL database state and issuing instructions to the vCluster orchestrator. Time-consuming processes (e.g., vCluster creation, large-scale configuration changes) are registered as tasks in the NATS message queue and delegated to asynchronous workers to maintain API server responsiveness. The API also strictly validates requests and returns appropriate error responses for invalid input.</p> </li> <li> <p>vCluster Orchestration: The vCluster orchestrator interacts with the Host K3s cluster to manage the vCluster lifecycle (creation, configuration, deletion). Specifically, it uses <code>vcluster CLI</code> or Kubernetes API (<code>client-go</code>) to deploy vCluster Pods (typically as StatefulSets or Deployments), configure necessary network settings (Service, Ingress, etc.), and storage settings (PersistentVolumeClaim). It also handles applying OIDC settings to each vCluster, installing and configuring HNC (Hierarchical Namespace Controller), setting resource quotas according to tenant plans, and controlling Dedicated Node allocation (using Node Selectors and Taints/Tolerations). Additionally, this component executes configuration of Namespaces and RBAC (Role, RoleBinding, ClusterRole, ClusterRoleBinding) within vClusters based on user operations.</p> </li> <li> <p>Asynchronous Processing: Asynchronous workers receive tasks from the NATS message queue and execute background processing such as vCluster provisioning, Stripe API integration (billing processing), HNC setup, and backup/restore processing (future feature). This allows the API server to return responses quickly without being blocked for long periods. Workers record processing progress in the database and will notify the API server or notification system of results through NATS upon completion or error.</p> </li> <li> <p>State Persistence: The PostgreSQL database stores Organizations, Workspaces, Projects, Users, Groups, Roles, billing plans, subscription information, asynchronous task status, audit logs, and more. Transactions are used appropriately to maintain data consistency, and regular backup and restore strategies are planned. Schema changes are managed using migration tools (e.g., golang-migrate).</p> </li> <li> <p>Caching: Redis caches user session information, frequently accessed configuration data, public keys (JWKS) required for OIDC token validation, rate limit counters, etc., reducing database load and improving system responsiveness and scalability. Cache expiration and invalidation strategies are also properly designed.</p> </li> <li> <p>Monitoring and Logging:    The monitoring architecture employs a hybrid model based on the tenant's plan.</p> </li> <li> <p>Shared Plan: Each vCluster runs lightweight agents (<code>prometheus-agent</code>, <code>promtail</code>) that forward metrics and logs to a central, multi-tenant Prometheus and Loki stack on the host cluster. Tenant data is isolated using labels (<code>workspace_id</code>).</p> </li> <li>Dedicated Plan: A dedicated, fully independent observability stack (Prometheus, Grafana, Loki) can be deployed inside the tenant's vCluster for complete isolation.</li> <li> <p>Central Logging: All Hexabase control plane and AIOps system logs are aggregated into a central ClickHouse database for high-speed querying and analysis.</p> </li> <li> <p>GitOps Deployment: Deployment and updates of the Hexabase control plane itself are managed through GitOps workflows using Flux. Infrastructure configuration (Kubernetes manifests, Helm Charts), application settings, security policies, etc., are all declaratively managed in Git repositories. Changes are made through Git commits and pull requests, and once approved, Flux automatically applies them to the Host K3s cluster. This improves deployment reproducibility, auditability, and reliability.</p> </li> <li> <p>Policy Application: Kyverno operates as a Kubernetes Admission Controller, enforcing security and operational policies on the Host K3s cluster and within each vCluster (if configurable). For example, policies such as \"all Namespaces must have an <code>owner</code> label,\" \"prohibit launching privileged containers,\" or \"block image pulls from untrusted registries\" can be defined to maintain compliance. Policies should also be managed through GitOps.</p> </li> <li> <p>Serverless Backbone: Knative is installed on the host cluster to provide the underlying infrastructure for the HKS Functions (FaaS) offering. It manages the entire lifecycle of serverless containers, including scaling to zero.</p> </li> <li> <p>AIOps System Interaction: The AIOps system operates as a separate Python-based service. The Hexabase API server communicates with it via internal, RESTful APIs, passing a short-lived, scoped JWT for secure, context-aware operations. The AIOps system analyzes data from the observability stack and its own agents, and can request operational changes (e.g., scaling a deployment) by calling back to a secured internal API on the Hexabase control plane, which performs the final authorization and execution.</p> </li> </ol> <p>This architecture aims to realize a scalable, resilient, intelligent, and operationally friendly KaaS platform. By clarifying the division of responsibilities among components and utilizing standardized technologies and open-source products, we enhance development efficiency and system reliability.</p>"},{"location":"architecture/system-architecture/#3-core-concepts-and-entity-mapping","title":"3. Core Concepts and Entity Mapping","text":"<p>Hexabase AI provides unique abstracted concepts to allow users to use the service without being aware of Kubernetes complexity. These concepts are internally mapped to standard Kubernetes resources and features. Understanding this mapping is crucial for grasping system behavior and using it effectively.</p> Hexabase Concept Kubernetes Equivalent Scope Notes Organization (None) Hexabase Unit for billing, invoicing, and organizational user management. Business logic. Workspace vCluster Host K3s Cluster Strong tenant isolation boundary. Workspace Plan ResourceQuota / Node Configuration vCluster / Host Defines resource limits. Organization User (None) Hexabase Organization administrators and billing managers. Workspace Member User (OIDC Subject) vCluster Technical personnel operating vCluster. Authenticated via OIDC. Workspace Group Group (OIDC Claim) vCluster Unit for permission assignment. Hierarchy resolved by Hexabase. Workspace ClusterRole ClusterRole vCluster Preset permissions spanning entire Workspace (e.g., Admin, Viewer). Project Namespace vCluster Resource isolation unit within Workspace. Project Role Role vCluster Namespace Custom permissions that users can create within a Project. CronJob <code>batch/v1.CronJob</code> vCluster Namespace A scheduled task, configured via the UI but maps to a native CronJob resource. Function Knative Service (<code>serving.knative.dev/v1.Service</code>) vCluster Namespace A serverless function deployed via the <code>hks-func</code> CLI or dynamically by an AI agent."},{"location":"architecture/system-architecture/#4-functional-specifications-and-user-flows","title":"4. Functional Specifications and User Flows","text":""},{"location":"architecture/system-architecture/#41-signup-and-organization-management","title":"4.1. Signup and Organization Management","text":"<ul> <li> <p>New User Registration   Sign up via OpenID Connect with external IdPs (Google, GitHub, etc.). User is created in Hexabase DB.</p> </li> <li> <p>Organization Creation   Upon initial signup, a private Organization is automatically created for the user. The user becomes the first Organization User of this Org.</p> </li> <li> <p>Organization Management   Organization Users can manage billing information (Stripe integration) and invite other Organization Users.   *Note: This permission does not allow direct manipulation of resources within subordinate Workspaces (vClusters).</p> </li> </ul>"},{"location":"architecture/system-architecture/#42-workspace-vcluster-management","title":"4.2. Workspace (vCluster) Management","text":"<ul> <li> <p>Creation   Organization Users select a Plan (resource limits) to create a new Workspace.</p> </li> <li> <p>Provisioning   The Hexabase control plane provisions a vCluster on the Host cluster and configures itself as a trusted OIDC provider.</p> </li> <li> <p>Initial Setup (within vCluster)</p> </li> <li> <p>Create preset ClusterRoles:     Automatically create two ClusterRoles: <code>hexabase:workspace-admin</code> and <code>hexabase:workspace-viewer</code>.     *Note: Custom ClusterRole creation by users is prohibited.</p> </li> <li> <p>Create default ClusterRoleBinding:     Automatically create a ClusterRoleBinding that binds the <code>hexabase:workspace-admin</code> ClusterRole to the <code>WSAdmins</code> group.</p> </li> <li> <p>Initial Setup (within Hexabase DB)</p> </li> <li>Create default groups:     Create three groups in a hierarchical structure: <code>WorkspaceMembers</code> (top level), <code>WSAdmins</code>, and <code>WSUsers</code>.</li> <li>By assigning the Workspace creator to the <code>WSAdmins</code> group, they become the vCluster administrator.</li> </ul>"},{"location":"architecture/system-architecture/#43-project-namespace-management","title":"4.3. Project (Namespace) Management","text":"<ul> <li> <p>Creation   Workspace Members (WSAdmins, etc., users with permissions) create new Projects within a Workspace.</p> </li> <li> <p>Namespace Creation   The Hexabase control plane creates corresponding Namespaces within the vCluster.</p> </li> <li> <p>ResourceQuota Application   Automatically create default ResourceQuota objects defined in the Workspace Plan in the Namespace.</p> </li> <li> <p>Custom Role Creation   Custom Roles valid within a Project (Namespace) can be created and edited from the UI.</p> </li> </ul>"},{"location":"architecture/system-architecture/#44-permission-management-and-inheritance","title":"4.4. Permission Management and Inheritance","text":"<ul> <li> <p>Permission Assignment   Assign Project Roles or preset ClusterRoles to Workspace Groups through the UI.   Hexabase creates and deletes RoleBindings and ClusterRoleBindings within the vCluster.</p> </li> <li> <p>Permission Inheritance Resolution</p> </li> <li>When a user accesses a vCluster, the OIDC provider performs the following:<ol> <li>Recursively retrieve the user's groups and parent groups from the DB.</li> <li>Include a flattened group list in the <code>groups</code> claim of the OIDC token.</li> <li>The vCluster API server performs native RBAC authorization based on this information.</li> </ol> </li> </ul>"},{"location":"architecture/system-architecture/#5-technology-stack-and-infrastructure","title":"5. Technology Stack and Infrastructure","text":""},{"location":"architecture/system-architecture/#51-applications","title":"5.1. Applications","text":"<ul> <li>Frontend: Next.js</li> <li>Backend: Go (Golang)</li> </ul>"},{"location":"architecture/system-architecture/#52-data-stores","title":"5.2. Data Stores","text":"<ul> <li>Primary DB: PostgreSQL</li> <li>Cache: Redis</li> </ul>"},{"location":"architecture/system-architecture/#53-messaging-and-asynchronous-processing","title":"5.3. Messaging and Asynchronous Processing","text":"<ul> <li>Message Queue: NATS</li> </ul>"},{"location":"architecture/system-architecture/#54-cicd-continuous-integrationdelivery","title":"5.4. CI/CD (Continuous Integration/Delivery)","text":"<ul> <li> <p>Pipeline Engine: Tekton</p> </li> <li> <p>Reason: Enables building Kubernetes-native declarative pipelines. Automates container builds, tests, and security scans.</p> </li> <li> <p>Deployment (GitOps): ArgoCD or Flux</p> </li> <li>Reason:     Treats Git repositories as the single source of truth and declaratively manages cluster state.     ArgoCD has a powerful UI, while Flux excels in simplicity and extensibility. Choose based on project preferences.</li> </ul>"},{"location":"architecture/system-architecture/#55-security-and-policy-management","title":"5.5. Security and Policy Management","text":"<ul> <li> <p>Container Vulnerability Scanning: Trivy</p> </li> <li> <p>Role:     Integrated into CI pipelines (Tekton) to scan for known vulnerabilities (CVE) in OS packages and language libraries during container image builds. Can also detect IaC misconfigurations.</p> </li> <li> <p>Runtime Security Auditing: Falco</p> </li> <li> <p>Role:     Runtime threat detection tool (CNCF graduated project). Monitors system calls at the kernel level to detect and alert on events such as \"unexpected shell launches within containers\" or \"access to sensitive files\" in real-time.</p> </li> <li> <p>Policy Management Engine: Kyverno</p> </li> <li>Kyverno:     Low learning curve as policies can be written as Kubernetes resources (YAML), enabling intuitive management of policies like \"prohibit Pod creation without specific labels\" or \"block use of untrusted image registries.\"</li> </ul>"},{"location":"architecture/system-architecture/#6-installation-and-deployment-iac","title":"6. Installation and Deployment (IaC)","text":"<p>This project adopts Helm as Infrastructure as Code (IaC) to achieve \"easy installation.\"</p>"},{"location":"architecture/system-architecture/#61-helm-umbrella-chart","title":"6.1. Helm Umbrella Chart","text":"<p>Provides a Helm Umbrella Chart that enables deployment of all Hexabase components and dependent middleware with a single command.</p> <pre><code>apiVersion: v2\nname: hexabase-ai\ndescription: A Helm chart for deploying the Hexabase AI Control Plane\nversion: 0.1.0\nappVersion: \"0.1.0\"\n\ndependencies:\n  # Define official/community Helm Chart dependencies\n  - name: postgresql\n    version: \"14.x.x\"\n    repository: \"https://charts.bitnami.com/bitnami\"\n    condition: postgresql.enabled # Can be disabled if needed\n  - name: redis\n    version: \"18.x.x\"\n    repository: \"https://charts.bitnami.com/bitnami\"\n    condition: redis.enabled\n  - name: nats\n    version: \"1.x.x\"\n    repository: \"https://nats-io.github.io/k8s/helm/charts/\"\n    condition: nats.enabled\n</code></pre> <p>Template Examples within Chart (<code>templates/</code>):</p> <ul> <li>Hexabase API (Go) Deployment / Service</li> <li>Hexabase UI (Next.js) Deployment / Service</li> <li>Secrets for DB connection information (auto-generated on initial install)</li> <li>ConfigMaps for managing various settings</li> </ul>"},{"location":"architecture/system-architecture/#62-installation-flow","title":"6.2. Installation Flow","text":"<p>End users can deploy Hexabase AI following these steps after preparing a K3s cluster:</p>"},{"location":"architecture/system-architecture/#add-helm-repository","title":"Add Helm Repository","text":"<pre><code>helm repo add hexabase https://&lt;your-chart-repository-url&gt;\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\n</code></pre>"},{"location":"architecture/system-architecture/#edit-configuration-file-valuesyaml-optional","title":"Edit Configuration File (values.yaml) (Optional):","text":"<ul> <li>Edit items requiring customization such as domain names and resource allocations.</li> </ul>"},{"location":"architecture/system-architecture/#install-with-helm","title":"Install with Helm:","text":"<pre><code>helm install hexabase-ai hexabase/hexabase-ai -f values.yaml\n</code></pre> <p>This single command sets up the entire Hexabase control plane on the K3s cluster along with dependent components like PostgreSQL, Redis, and NATS.</p>"},{"location":"architecture/system-architecture/#7-conclusion","title":"7. Conclusion","text":"<p>This specification is a conceptual design blueprint for Hexabase AI based on modern technology stacks and cloud-native best practices. By incorporating simple deployment with Helm, efficient CI/CD with Tekton and GitOps, robust security with Trivy and Falco, and flexible policy management with Kyverno, we build a strong foundation for an open-source project that can be trusted by users worldwide and grow with the community.</p>"},{"location":"architecture/technical-design/","title":"Hexabase KaaS Control Plane Implementation Specification (Compact Edition)","text":""},{"location":"architecture/technical-design/#1-system-overview","title":"1. System Overview","text":"<p>Hexabase KaaS is a multi-tenant Kubernetes as a Service platform built on K3s and vCluster. This specification defines the design guidelines for the control plane implemented in Go.</p>"},{"location":"architecture/technical-design/#core-responsibilities","title":"Core Responsibilities","text":"<ul> <li>API Services: RESTful API for Next.js UI</li> <li>Authentication &amp; Authorization: External IdP integration and JWT session management</li> <li>OIDC Provider: Token issuance for kubectl access to each vCluster</li> <li>vCluster Management: Complete lifecycle management</li> <li>Billing Processing: Subscription management via Stripe integration</li> <li>Async Processing: NATS-based task processing</li> </ul>"},{"location":"architecture/technical-design/#2-architecture","title":"2. Architecture","text":""},{"location":"architecture/technical-design/#component-structure","title":"Component Structure","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Next.js UI \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  API Server \u2502\u2500\u2500\u2500\u2500\u25b6\u2502 PostgreSQL  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n              \u2502   NATS    \u2502 \u2502  Redis  \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502  Workers  \u2502\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/technical-design/#external-integrations","title":"External Integrations","text":"<ul> <li>Host K3s: Host environment for vClusters</li> <li>vCluster: Per-tenant Kubernetes environments</li> <li>External IdP: Google/GitHub OIDC authentication</li> <li>Stripe: Billing and payment processing</li> </ul>"},{"location":"architecture/technical-design/#3-database-design","title":"3. Database Design","text":""},{"location":"architecture/technical-design/#primary-tables","title":"Primary Tables","text":"Table Purpose users User accounts (external IdP linked) organizations Billing and management units plans Subscription plan definitions workspaces vCluster instances projects Namespaces (HNC hierarchy support) groups Workspace user groups roles Custom/preset Roles role_assignments Group to Role mappings"},{"location":"architecture/technical-design/#hierarchical-structure","title":"Hierarchical Structure","text":"<ul> <li>Organization \u2192 Workspace \u2192 Project</li> <li>Group (hierarchical) \u2192 Role Assignment</li> </ul>"},{"location":"architecture/technical-design/#4-api-design","title":"4. API Design","text":""},{"location":"architecture/technical-design/#endpoint-structure","title":"Endpoint Structure","text":"<pre><code>/auth\n  POST   /login/{provider}     # Initiate external IdP auth\n  GET    /callback/{provider}  # Auth callback\n  POST   /logout              # Logout\n  GET    /me                  # Current user info\n\n/api/v1/organizations\n  POST   /                    # Create organization\n  GET    /{orgId}            # Organization details\n  POST   /{orgId}/users      # Invite users\n\n/api/v1/organizations/{orgId}/workspaces\n  POST   /                    # Create workspace (async)\n  GET    /{wsId}             # Workspace details\n  GET    /{wsId}/kubeconfig  # Generate kubeconfig\n\n/api/v1/workspaces/{wsId}\n  /groups                    # Group management\n  /projects                  # Project (Namespace) management\n  /clusterroleassignments   # ClusterRole assignments\n\n/api/v1/projects/{projectId}\n  /roles                     # Custom Role management\n  /roleassignments          # Role assignments\n\n/webhooks/stripe            # Stripe webhook receiver\n</code></pre>"},{"location":"architecture/technical-design/#design-principles","title":"Design Principles","text":"<ul> <li>RESTful principles (resource-oriented URLs)</li> <li>JSON request/response format</li> <li>Versioning (/api/v1/)</li> <li>Idempotency guarantee</li> <li>Standard HTTP status codes</li> </ul>"},{"location":"architecture/technical-design/#5-oidc-provider-implementation","title":"5. OIDC Provider Implementation","text":""},{"location":"architecture/technical-design/#token-structure","title":"Token Structure","text":"<pre><code>{\n  \"sub\": \"hxb-usr-xxxxx\",\n  \"groups\": [\"WSAdmins\", \"WorkspaceMembers\", \"developers\"],\n  \"iss\": \"https://api.hexabase.ai\",\n  \"aud\": \"ws-xxxxx\",\n  \"exp\": 1234567890\n}\n</code></pre>"},{"location":"architecture/technical-design/#endpoints","title":"Endpoints","text":"<ul> <li><code>/.well-known/openid-configuration</code>: Discovery</li> <li><code>/.well-known/jwks.json</code>: Public key distribution</li> </ul>"},{"location":"architecture/technical-design/#6-vcluster-orchestration","title":"6. vCluster Orchestration","text":""},{"location":"architecture/technical-design/#provisioning-flow","title":"Provisioning Flow","text":"<ol> <li>Create vCluster (vcluster CLI)</li> <li>Apply OIDC configuration</li> <li>Install HNC</li> <li>Configure ResourceQuota</li> <li>Assign dedicated nodes (if applicable)</li> </ol>"},{"location":"architecture/technical-design/#dedicated-node-management","title":"Dedicated Node Management","text":"<pre><code>nodeSelector:\n  hexabase.ai/node-pool: ws-xxxxx\ntolerations:\n- key: dedicated\n  value: ws-xxxxx\n  effect: NoSchedule\n</code></pre>"},{"location":"architecture/technical-design/#7-asynchronous-processing","title":"7. Asynchronous Processing","text":""},{"location":"architecture/technical-design/#nats-topic-structure","title":"NATS Topic Structure","text":"<pre><code>vcluster.provisioning.*     # vCluster operations\nvcluster.hnc.*             # HNC configuration\nstripe.webhook.*           # Payment events\nuser.notification.*        # Notifications\nsystem.maintenance.*       # Periodic tasks\n</code></pre>"},{"location":"architecture/technical-design/#worker-implementation","title":"Worker Implementation","text":"<ul> <li>Queue group based load balancing</li> <li>Exponential backoff</li> <li>Task progress tracking in DB</li> </ul>"},{"location":"architecture/technical-design/#8-security-measures","title":"8. Security Measures","text":"<ul> <li>Input validation (go-playground/validator)</li> <li>SQL injection prevention (ORM usage)</li> <li>Rate limiting (per IP/user)</li> <li>Secrets management (Kubernetes Secrets)</li> <li>Stripe signature verification</li> <li>Principle of least privilege</li> </ul>"},{"location":"architecture/technical-design/#9-go-package-structure","title":"9. Go Package Structure","text":"<pre><code>/cmd\n  /api         # API server entry point\n  /worker      # Worker entry point\n/internal\n  /api         # HTTP handlers, middleware\n  /auth        # Authentication &amp; authorization\n  /billing     # Stripe integration\n  /config      # Configuration management\n  /db          # Models, repositories\n  /k8s         # vCluster/HNC management\n  /messaging   # NATS pub/sub\n  /service     # Business logic\n</code></pre>"},{"location":"architecture/technical-design/#10-testing-strategy","title":"10. Testing Strategy","text":""},{"location":"architecture/technical-design/#test-levels","title":"Test Levels","text":"<ol> <li>Unit Tests: 80%+ coverage target</li> <li>Integration Tests: API/DB/NATS integration</li> <li>E2E Tests: Complete user scenarios</li> </ol>"},{"location":"architecture/technical-design/#testing-tools","title":"Testing Tools","text":"<ul> <li>testify: Assertions</li> <li>mockgen: Mock generation</li> <li>httptest: API testing</li> <li>testcontainers: DB integration testing</li> </ul>"},{"location":"architecture/technical-design/#11-future-extensibility","title":"11. Future Extensibility","text":"<ul> <li>Plugin architecture</li> <li>gRPC API addition</li> <li>Multi-cloud support</li> <li>Marketplace platform</li> <li>AI/ML workload optimization</li> </ul>"},{"location":"architecture/technical-design/#12-key-implementation-decisions","title":"12. Key Implementation Decisions","text":"<ol> <li>Start with Monolith: Logical module separation with future microservice decomposition in mind</li> <li>Interface-Driven Design: For testability and extensibility</li> <li>Async-First: Long-running operations handled asynchronously to maintain API responsiveness</li> <li>Security-First: Multi-layered defense approach</li> <li>Cloud-Native: Designed to run on Kubernetes</li> </ol> <p>This specification provides comprehensive guidelines for building a production-ready KaaS platform. For detailed implementation, refer to individual module specifications.</p>"},{"location":"backups/","title":"Backups","text":"<p>This section covers backup and disaster recovery strategies for Hexabase.AI (HKS). Learn how to protect your data, applications, and configurations to ensure business continuity.</p>"},{"location":"backups/#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Backup Strategies: Comprehensive backup approaches for different workload types</li> <li>Backup Configuration: Setting up automated backups for clusters and applications</li> <li>Restore Procedures: Step-by-step guides for restoring from backups</li> <li>Disaster Recovery: Planning and implementing DR strategies</li> <li>Compliance: Meeting regulatory requirements for data protection</li> </ul>"},{"location":"backups/#key-topics","title":"Key Topics","text":"<ul> <li>Cluster-level backups with Velero</li> <li>Application data backup strategies</li> <li>Persistent volume snapshots</li> <li>Database backup and restore procedures</li> <li>Configuration and secret backup</li> <li>Cross-region backup replication</li> <li>Backup scheduling and retention policies</li> <li>Testing backup and restore procedures</li> <li>RTO/RPO planning and optimization</li> <li>AI-Ops predictive backup optimization</li> <li>Backup monitoring and alerting</li> </ul> <p>From protecting critical production data to ensuring rapid recovery from disasters, this section provides everything you need to implement robust backup strategies in HKS.</p>"},{"location":"backups/automated-backups/","title":"Automated Backups","text":"<p>Automating your backup process is a cornerstone of a reliable data protection strategy. Hexabase.AI allows you to define sophisticated, schedule-based backup plans that run automatically without manual intervention.</p>"},{"location":"backups/automated-backups/#how-automation-works","title":"How Automation Works","text":"<p>Backup automation is driven by Backup Plans, which are Kubernetes custom resources that specify:</p> <ul> <li>What to back up (the backup target).</li> <li>Where to store the backups (the storage location).</li> <li>When to run the backup (the cron schedule).</li> <li>How long to keep the backups (the retention policy).</li> </ul> <p>Once a <code>BackupPlan</code> is created, the HKS AIOps controller continuously monitors it and triggers backup jobs according to the defined schedule.</p>"},{"location":"backups/automated-backups/#creating-a-scheduled-backup-plan","title":"Creating a Scheduled Backup Plan","text":"<p>This example creates a plan that backs up all resources in the <code>production</code> namespace every night at 2:00 AM.</p>"},{"location":"backups/automated-backups/#step-1-define-the-backup-target","title":"Step 1: Define the Backup Target","text":"<p>First, ensure you have resources to back up. In this case, we're targeting an entire namespace.</p>"},{"location":"backups/automated-backups/#step-2-define-the-storage-location","title":"Step 2: Define the Storage Location","text":"<p>You must have a <code>BackupStorageLocation</code> configured. See the Backup Strategies guide for details. We'll assume a location named <code>s3-primary</code> exists.</p>"},{"location":"backups/automated-backups/#step-3-create-the-backup-plan","title":"Step 3: Create the Backup Plan","text":"<pre><code># automated-backup-plan.yaml\napiVersion: hks.io/v1\nkind: BackupPlan\nmetadata:\n  name: production-daily-backup\n  namespace: hks-system\nspec:\n  # Define what to back up\n  target:\n    includeNamespaces:\n      - production\n    # Optional: You can also include cluster-scoped resources\n    includeClusterResources: true\n\n  # Define where to store the backup\n  storageLocation: s3-primary\n\n  # Define the schedule\n  schedule:\n    # Runs at 2:00 AM UTC every day\n    cron: \"0 2 * * *\"\n\n  # Define the retention policy\n  retention:\n    # Keep the last 7 daily backups\n    daily: 7\n    # Keep the last 4 weekly backups (taken on Sunday)\n    weekly: 4\n    # Keep the last 12 monthly backups (taken on the 1st of the month)\n    monthly: 12\n    # Prune (delete) backups older than the retention policy\n    prune: true\n</code></pre> <p>Apply the plan to the cluster:</p> <pre><code>hb apply -f automated-backup-plan.yaml\n</code></pre>"},{"location":"backups/automated-backups/#managing-retention-policies-grandfather-father-son","title":"Managing Retention Policies (Grandfather-Father-Son)","text":"<p>The retention policy in the example above implements a common Grandfather-Father-Son (GFS) rotation scheme.</p> <ul> <li>Daily (Son): The most frequent backups, providing a short-term recovery window.</li> <li>Weekly (Father): Less frequent, for medium-term recovery. HKS automatically promotes the last successful daily backup of the week (e.g., on Sunday) to be the weekly backup.</li> <li>Monthly (Grandfather): The least frequent, for long-term archival. The last successful weekly backup of the month is promoted to a monthly backup.</li> </ul> <p>This strategy provides a good balance between recovery point objectives (RPO) and storage costs.</p>"},{"location":"backups/automated-backups/#disabling-and-enabling-a-backup-plan","title":"Disabling and Enabling a Backup Plan","text":"<p>You can temporarily pause a backup plan without deleting it.</p> <pre><code># To disable (pause) a plan\nhb backup-plan pause production-daily-backup\n\n# The plan's status will show 'Paused'\n# To re-enable it\nhb backup-plan resume production-daily-backup\n</code></pre> <p>This is useful during maintenance windows or when you need to prevent backups from running for a specific period.</p>"},{"location":"backups/automated-backups/#monitoring-automated-backups","title":"Monitoring Automated Backups","text":"<p>You can monitor the status and history of your automated backups through the HKS UI or CLI.</p>"},{"location":"backups/automated-backups/#from-the-cli","title":"From the CLI","text":"<pre><code># List all backups created by the plan\nhb get backups --selector hks.io/backup-plan=production-daily-backup\n\n# Describe the backup plan to see its status and last run time\nhb describe backup-plan production-daily-backup\n\n# View logs for a specific backup job\nhb backup logs &lt;backup-name&gt;\n</code></pre>"},{"location":"backups/automated-backups/#from-the-ui","title":"From the UI","text":"<p>The Hexabase.AI dashboard provides a visual overview of:</p> <ul> <li>All configured backup plans.</li> <li>The history of backup runs for each plan (success, failure, duration).</li> <li>The status of available backups ready for restore.</li> <li>Storage consumption per plan.</li> </ul>"},{"location":"backups/automated-backups/#automated-alerts","title":"Automated Alerts","text":"<p>Hexabase.AI AIOps can automatically notify you about the status of your backups.</p>"},{"location":"backups/automated-backups/#configure-alerts-for-backup-failures","title":"Configure Alerts for Backup Failures","text":"<pre><code>apiVersion: hks.io/v1\nkind: AlertPolicy\nmetadata:\n  name: backup-failure-alert\nspec:\n  metric: hks_backup_job_status\n  condition: \"value == 'Failed'\"\n  duration: 1m # Alert if failed for 1 minute\n  severity: critical\n  notification:\n    slack:\n      channel: \"#ops-alerts\"\n    email:\n      to: \"sre-team@example.com\"\n</code></pre> <p>This policy will send a critical alert to Slack and email if any backup job fails, enabling your team to investigate immediately.</p>"},{"location":"backups/automated-backups/#best-practices-for-automated-backups","title":"Best Practices for Automated Backups","text":"<ol> <li>Stagger Your Schedules: If you have multiple backup plans, stagger their start times to avoid creating a \"thundering herd\" problem where many jobs start simultaneously, potentially straining cluster and storage resources.</li> <li>Use Meaningful Names: Name your backup plans descriptively (e.g., <code>prod-db-hourly</code>, <code>dev-apps-daily</code>) so their purpose is clear.</li> <li>Monitor Storage Consumption: Keep an eye on the storage used by your backups. Adjust retention policies as needed to balance recovery needs with cost.</li> <li>Exclude Temporary Data: Use resource labels and selectors (<code>--exclude-resources</code>) in your backup targets to avoid backing up non-critical or transient data like cache pods.</li> <li>Review Policies Regularly: As your applications evolve, review your backup plans to ensure they still meet your RPO and RTO requirements.</li> </ol>"},{"location":"backups/disaster-recovery/","title":"Disaster Recovery (DR)","text":"<p>Disaster Recovery (DR) is the process of preparing for and recovering from a disaster that affects your applications and data. Hexabase.AI provides a suite of tools and features to help you implement a robust DR strategy, ensuring business continuity even in the face of major outages.</p>"},{"location":"backups/disaster-recovery/#dr-overview-in-hexabaseai","title":"DR Overview in Hexabase.AI","text":"<p>A comprehensive DR strategy involves more than just data backups. In Hexabase.AI, it encompasses:</p> <ul> <li>Data Replication: Replicating data to a secondary, geographically distinct location.</li> <li>Infrastructure Replication: The ability to quickly spin up infrastructure in a recovery site.</li> <li>Failover Mechanism: A process to switch traffic from the primary site to the recovery site.</li> <li>Failback Mechanism: A process to return traffic to the primary site once it has been restored.</li> </ul>"},{"location":"backups/disaster-recovery/#key-dr-scenarios","title":"Key DR Scenarios","text":""},{"location":"backups/disaster-recovery/#1-regional-outage","title":"1. Regional Outage","text":"<ul> <li>Scenario: An entire cloud region (e.g., <code>us-east-1</code>) becomes unavailable.</li> <li>HKS Solution: Cross-region replication of backups and infrastructure-as-code.</li> </ul>"},{"location":"backups/disaster-recovery/#2-data-corruption","title":"2. Data Corruption","text":"<ul> <li>Scenario: A bug or human error corrupts your production database.</li> <li>HKS Solution: Restore from a point-in-time backup taken before the corruption occurred.</li> </ul>"},{"location":"backups/disaster-recovery/#3-application-failure","title":"3. Application Failure","text":"<ul> <li>Scenario: A critical application deployment fails and cannot be rolled back.</li> <li>HKS Solution: Restore the application's configuration and data from a recent, known-good namespace backup.</li> </ul>"},{"location":"backups/disaster-recovery/#setting-up-a-dr-environment","title":"Setting up a DR Environment","text":"<p>Here's a high-level overview of setting up a basic DR plan in Hexabase.AI.</p>"},{"location":"backups/disaster-recovery/#step-1-configure-a-remote-storage-location","title":"Step 1: Configure a Remote Storage Location","text":"<p>Your primary and DR sites should not share storage. Configure a <code>BackupStorageLocation</code> in a different region or even a different cloud provider.</p> <pre><code># dr-storage-location.yaml\napiVersion: hks.io/v1\nkind: BackupStorageLocation\nmetadata:\n  name: s3-dr-storage\nspec:\n  provider: aws\n  objectStorage:\n    bucket: my-hexabase-backups-dr-site\n    region: us-west-2 # A different region from the primary\n</code></pre>"},{"location":"backups/disaster-recovery/#step-2-create-a-replication-plan","title":"Step 2: Create a Replication Plan","text":"<p>Replicate backups from your primary storage location to your DR storage location.</p> <pre><code>apiVersion: hks.io/v1\nkind: ReplicationPlan\nmetadata:\n  name: replicate-prod-backups\nspec:\n  source:\n    storageLocation: s3-primary\n  destination:\n    storageLocation: s3-dr-storage\n  # Replicate every hour\n  schedule:\n    cron: \"0 * * * *\"\n</code></pre> <p>The AIOps controller will automatically copy new backups from <code>s3-primary</code> to <code>s3-dr-storage</code> on schedule.</p>"},{"location":"backups/disaster-recovery/#step-3-prepare-the-recovery-site","title":"Step 3: Prepare the Recovery Site","text":"<p>The recovery site can be a \"cold,\" \"warm,\" or \"hot\" standby.</p> <ul> <li>Cold Site: Infrastructure is provisioned only when a disaster is declared. Lowest cost, highest Recovery Time Objective (RTO).</li> <li>Warm Site: Minimal infrastructure is running (e.g., the HKS control plane, a small node pool). Lower RTO.</li> <li>Hot Site: A fully scaled-out replica of the production site is running. Near-zero RTO, highest cost.</li> </ul> <p>For most use cases, a warm site is a good compromise. You can use HKS automation to provision the full infrastructure during a DR event.</p>"},{"location":"backups/disaster-recovery/#the-disaster-recovery-process","title":"The Disaster Recovery Process","text":""},{"location":"backups/disaster-recovery/#declaring-a-disaster","title":"Declaring a Disaster","text":"<p>When a disaster is confirmed, the first step is to officially declare it. This initiates the failover process.</p> <pre><code># Pause replication to prevent corrupted data from being copied\nhb replication-plan pause replicate-prod-backups\n\n# (External Step) Update DNS, notify stakeholders, etc.\n</code></pre>"},{"location":"backups/disaster-recovery/#initiating-failover","title":"Initiating Failover","text":"<p>The goal is to bring up the application in the recovery site using the latest replicated backups.</p> <pre><code># In the DR site cluster:\n\n# 1. Restore the entire namespace from the replicated backup\nhb restore create restore-production \\\n  --from-backup &lt;latest-replicated-backup-name&gt; \\\n  --from-storage-location s3-dr-storage\n\n# 2. HKS restores all deployments, services, PVCs, and data.\n#    The AIOps restore controller handles the entire workflow.\n\n# 3. Verify application health in the DR site\nhb get pods -n production\nhb check-health -n production\n\n# 4. (External Step) Switch public DNS to point to the DR site's load balancer.\n</code></pre>"},{"location":"backups/disaster-recovery/#failback-process","title":"Failback Process","text":"<p>Once the primary site is operational again, you need to fail back.</p>"},{"location":"backups/disaster-recovery/#step-1-resynchronize-data","title":"Step 1: Resynchronize Data","text":"<p>Data may have changed in the DR site while it was active. You need to replicate this data back to the primary site.</p> <pre><code># In the DR cluster:\n# 1. Back up the active DR namespace\nhb backup create dr-site-data --include-namespaces production --storage-location s3-dr-storage\n\n# In the Primary cluster:\n# 2. Ensure the primary site is clean and ready\n# 3. Restore from the backup of the DR site's data\nhb restore create restore-from-dr --from-backup dr-site-data\n</code></pre>"},{"location":"backups/disaster-recovery/#step-2-switch-traffic-back","title":"Step 2: Switch Traffic Back","text":"<ol> <li>Perform health checks on the restored primary site.</li> <li>Place the DR site application in maintenance mode.</li> <li>(External Step) Switch DNS back to the primary site's load balancer.</li> <li>Once traffic is flowing to the primary site, you can de-provision the DR application.</li> <li>Re-enable your backup and replication plans.</li> </ol> <pre><code>hb replication-plan resume replicate-prod-backups\n</code></pre>"},{"location":"backups/disaster-recovery/#automated-dr-testing","title":"Automated DR Testing","text":"<p>Manually testing DR is error-prone. Hexabase.AI allows you to automate DR tests.</p> <pre><code>apiVersion: hks.io/v1\nkind: DRTestPlan\nmetadata:\n  name: quarterly-dr-drill\nspec:\n  schedule:\n    # Run on the first Sunday of each quarter at 4 AM\n    cron: \"0 4 1 1,4,7,10 0\"\n\n  # The backup to test with\n  sourceBackup:\n    plan: production-daily-backup\n    select: latest-weekly\n\n  # The isolated environment to restore into\n  testEnvironment:\n    namespace: dr-test-zone\n    networkPolicy: isolate-all\n\n  # Tests to run against the restored environment\n  validation:\n    - type: httpGet\n      target: /health\n      service: frontend\n    - type: customScript\n      script: /scripts/verify-data.sh\n      image: my-test-tools:latest\n\n  onSuccess:\n    notify:\n      slack: { channel: \"#dr-tests-success\" }\n  onFailure:\n    notify:\n      slack: { channel: \"#dr-tests-failure\", mention: \"@oncall\" }\n</code></pre> <p>This plan will automatically perform a test restore into an isolated namespace, run validation checks, and report the results, giving you confidence in your DR strategy without impacting production.</p>"},{"location":"backups/disaster-recovery/#best-practices","title":"Best Practices","text":"<ul> <li>Automate Everything: Use HKS plans (<code>BackupPlan</code>, <code>ReplicationPlan</code>, <code>DRTestPlan</code>) to automate as much of the DR process as possible.</li> <li>Keep It Simple: The more complex your DR plan, the more likely it is to fail. Start with a simple, reliable plan and build on it.</li> <li>Document the Plan: Have a clear, written runbook that details the DR procedure, including manual steps (like DNS changes) and contact information for key personnel.</li> <li>Test Regularly: The only way to trust your DR plan is to test it. Use automated DR testing to do this frequently.</li> </ul>"},{"location":"backups/restore-procedures/","title":"Restore Procedures","text":"<p>Having backups is only half the battle; knowing how to restore them is critical. Hexabase.AI simplifies the restore process, allowing you to recover data, applications, or entire namespaces quickly and reliably.</p>"},{"location":"backups/restore-procedures/#creating-a-restore-job","title":"Creating a Restore Job","text":"<p>Restores are initiated by creating a <code>Restore</code> custom resource. This can be done via the HKS UI or by applying a YAML manifest with the CLI.</p>"},{"location":"backups/restore-procedures/#find-the-backup-to-restore","title":"Find the Backup to Restore","text":"<p>First, you need to identify the backup you want to restore from.</p> <pre><code># List all available backups\nhb get backups\n\n# List backups from a specific plan\nhb get backups --selector hks.io/backup-plan=production-daily-backup\n\n# Get details of a specific backup\nhb describe backup &lt;backup-name&gt;\n</code></pre>"},{"location":"backups/restore-procedures/#initiating-a-restore-via-cli","title":"Initiating a Restore via CLI","text":"<p>The <code>hb restore create</code> command is the primary way to start a restore.</p> <pre><code>hb restore create &lt;restore-name&gt; --from-backup &lt;backup-name&gt; [options]\n</code></pre>"},{"location":"backups/restore-procedures/#restore-scenarios","title":"Restore Scenarios","text":""},{"location":"backups/restore-procedures/#1-restore-a-full-namespace","title":"1. Restore a Full Namespace","text":"<p>This is the most common scenario for recovering from a major application failure or for migrating an environment.</p> <pre><code># Restore the 'production' namespace from a backup\nhb restore create restore-prod-ns \\\n  --from-backup production-daily-backup-20250615020000\n</code></pre> <p>By default, this restores all resources and associated volume data into the original <code>production</code> namespace.</p> <p>Important: The restore process will overwrite existing resources in the target namespace.</p>"},{"location":"backups/restore-procedures/#2-restore-to-a-different-namespace","title":"2. Restore to a Different Namespace","text":"<p>This is the recommended approach for testing restores or recovering specific data without impacting the live production environment.</p> <pre><code>hb restore create test-restore-prod \\\n  --from-backup production-daily-backup-20250615020000 \\\n  --namespace-mapping production:production-restored\n</code></pre> <p>This command restores the contents of the <code>production</code> namespace from the backup into a new namespace called <code>production-restored</code>.</p>"},{"location":"backups/restore-procedures/#3-restore-a-single-persistent-volume-claim-pvc","title":"3. Restore a Single Persistent Volume Claim (PVC)","text":"<p>If only a single volume's data was lost or corrupted, you can restore just that PVC.</p> <pre><code>hb restore create restore-db-volume \\\n  --from-backup &lt;backup-name&gt; \\\n  --include-resources persistentvolumeclaims \\\n  --selector app=postgres-db\n</code></pre> <p>This will create a new PVC and a new PV with the data from the backup. You will then need to manually update your application to use this new PVC.</p>"},{"location":"backups/restore-procedures/#4-restore-specific-resource-types","title":"4. Restore Specific Resource Types","text":"<p>You can choose to restore only specific types of resources from a backup.</p> <pre><code># Restore only Deployments and ConfigMaps from a backup\nhb restore create restore-deploy-cfgs \\\n  --from-backup &lt;backup-name&gt; \\\n  --include-resources deployments,configmaps\n</code></pre>"},{"location":"backups/restore-procedures/#advanced-restore-options","title":"Advanced Restore Options","text":""},{"location":"backups/restore-procedures/#modifying-resources-on-restore","title":"Modifying Resources on Restore","text":"<p>You can apply transformations to resources as they are being restored. This is useful for changing storage classes, node selectors, or other parameters.</p> <pre><code># restore-with-patch.yaml\napiVersion: hks.io/v1\nkind: Restore\nmetadata:\n  name: restore-and-modify\nspec:\n  backupName: &lt;backup-name&gt;\n  # Apply a strategic merge patch to all restored deployments\n  patches:\n    - target:\n        group: apps\n        version: v1\n        kind: Deployment\n      patch: |\n        spec:\n          template:\n            spec:\n              nodeSelector:\n                \"disktype\": \"ssd\"\n</code></pre>"},{"location":"backups/restore-procedures/#restoring-with-hooks","title":"Restoring with Hooks","text":"<p>Similar to backup hooks, you can define hooks that run before and after a restore operation.</p> <ul> <li>Pre-restore hook: Scale down an existing deployment before it's overwritten.</li> <li>Post-restore hook: Run a database migration script after the data has been restored.</li> </ul> <pre><code># restore-with-hooks.yaml\napiVersion: hks.io/v1\nkind: Restore\nmetadata:\n  name: restore-with-hooks\nspec:\n  backupName: &lt;backup-name&gt;\n  hooks:\n    preHooks:\n      - exec:\n          container: myapp\n          command: [\"/scripts/pre-restore.sh\"]\n          onError: Fail\n    postHooks:\n      - exec:\n          container: myapp\n          command: [\"/scripts/post-restore.sh\"]\n          timeout: 10m\n</code></pre>"},{"location":"backups/restore-procedures/#monitoring-a-restore","title":"Monitoring a Restore","text":"<p>You can monitor the progress of a restore job from the CLI or UI.</p> <pre><code># Get the status of a restore\nhb get restore restore-prod-ns\n\n# Describe the restore for detailed information and events\nhb describe restore restore-prod-ns\n\n# View the logs of the restore job\nhb restore logs restore-prod-ns\n</code></pre> <p>The restore status will cycle through phases like <code>New</code>, <code>InProgress</code>, <code>Completed</code>, or <code>Failed</code>.</p>"},{"location":"backups/restore-procedures/#troubleshooting-failed-restores","title":"Troubleshooting Failed Restores","text":"<ol> <li>Check the Logs: The first step is always <code>hb restore logs &lt;restore-name&gt;</code>. The logs will usually contain the specific error message.</li> <li>Examine Events: <code>hb describe restore &lt;restore-name&gt;</code> will show Kubernetes events related to the restore process, which can highlight issues like insufficient permissions or storage provisioning failures.</li> <li>Permissions: Ensure the HKS service account has the necessary permissions to create resources in the target namespace.</li> <li>Storage Provisioning: If a PV restore fails, check the status of the underlying storage provisioner and ensure there is enough capacity.</li> <li>Resource Conflicts: If you are not restoring to a clean namespace, there might be conflicts with existing resources. The logs will indicate if a resource <code>already exists</code>.</li> </ol>"},{"location":"backups/restore-procedures/#best-practices-for-restores","title":"Best Practices for Restores","text":"<ol> <li>Restore to a New Namespace: Always perform test restores (and even production restores, if possible) into a new, isolated namespace. This prevents any impact on your live environment and allows you to validate the restored application before directing traffic to it.</li> <li>Validate After Restore: Don't assume a <code>Completed</code> status means the application is working. Always run a suite of tests against the restored environment to ensure application functionality and data integrity.</li> <li>Have a Plan: Document your restore procedures in a runbook. Know which backups you will use for different scenarios (e.g., full DR vs. single volume recovery).</li> <li>Practice: Regularly perform restore drills so your team is comfortable and efficient with the process when a real disaster strikes.</li> </ol>"},{"location":"backups/strategies/","title":"Backup Strategies","text":"<p>A robust backup strategy is essential for data protection and business continuity. Hexabase.AI provides a flexible and powerful framework for creating and managing backups for your applications, data, and configurations.</p>"},{"location":"backups/strategies/#overview","title":"Overview","text":"<p>Backup strategies in Hexabase.AI are designed to be:</p> <ul> <li>Comprehensive: Back up everything from persistent volumes to entire namespace configurations.</li> <li>Automated: Schedule backups to run automatically at your desired frequency.</li> <li>Reliable: Store backups in secure, durable, and geo-redundant storage.</li> <li>Easy to Manage: Configure, monitor, and restore backups through a unified UI and CLI.</li> </ul>"},{"location":"backups/strategies/#key-concepts","title":"Key Concepts","text":"<ul> <li>Backup Target: The specific resource to be backed up (e.g., a Persistent Volume Claim, a namespace, a set of resources with a specific label).</li> <li>Backup Plan: A policy that defines what to back up, where to store it, and the schedule and retention policy.</li> <li>Storage Location: The destination for your backup data (e.g., S3-compatible object storage, NFS share).</li> <li>Snapshot: A point-in-time copy of a volume, typically using underlying storage provider capabilities.</li> </ul>"},{"location":"backups/strategies/#types-of-backups","title":"Types of Backups","text":""},{"location":"backups/strategies/#1-volume-snapshots","title":"1. Volume Snapshots","text":"<ul> <li>What it is: A point-in-time snapshot of a Persistent Volume (PV). This is the most common method for backing up stateful application data.</li> <li>Best for: Databases (PostgreSQL, MySQL), message queues, and any application that writes to a persistent disk.</li> <li>How it works: Uses the storage provider's snapshot capabilities (e.g., EBS snapshots in AWS, GCE PD snapshots in Google Cloud) for efficiency.</li> </ul> <pre><code># Example Volume Snapshot\napiVersion: snapshot.storage.k8s.io/v1\nkind: VolumeSnapshot\nmetadata:\n  name: postgres-db-snapshot\nspec:\n  volumeSnapshotClassName: csi-aws-vsc\n  source:\n    persistentVolumeClaimName: postgres-data\n</code></pre>"},{"location":"backups/strategies/#2-namespace-backups","title":"2. Namespace Backups","text":"<ul> <li>What it is: A complete backup of all Kubernetes resources within a specific namespace. This includes Deployments, Services, ConfigMaps, Secrets, etc.</li> <li>Best for: Capturing the entire state of an application or environment for disaster recovery or migration.</li> <li>How it works: It iterates through all resources in the namespace and saves their YAML definitions. It can optionally include volume snapshots for any PVCs in the namespace.</li> </ul> <pre><code># HKS CLI command for namespace backup\nhb backup create my-namespace-backup --include-namespaces production\n</code></pre>"},{"location":"backups/strategies/#3-resource-filtered-backups","title":"3. Resource-Filtered Backups","text":"<ul> <li>What it is: A backup of specific Kubernetes resources selected by labels.</li> <li>Best for: Backing up components of a larger application that are spread across your cluster, or backing up only critical components.</li> </ul> <pre><code># Back up all resources with the label \"app=mission-critical\"\nhb backup create critical-app-backup --selector app=mission-critical\n</code></pre>"},{"location":"backups/strategies/#backup-storage-locations","title":"Backup Storage Locations","text":"<p>Hexabase.AI supports various storage backends for your backups.</p>"},{"location":"backups/strategies/#s3-compatible-object-storage","title":"S3-Compatible Object Storage","text":"<ul> <li>Description: Use any S3-compatible service like AWS S3, MinIO, or Google Cloud Storage.</li> <li>Configuration:   <pre><code>apiVersion: hks.io/v1\nkind: BackupStorageLocation\nmetadata:\n  name: s3-main-storage\nspec:\n  provider: aws\n  objectStorage:\n    bucket: my-hexabase-backups\n    region: us-east-1\n</code></pre></li> </ul>"},{"location":"backups/strategies/#nfs-storage","title":"NFS Storage","text":"<ul> <li>Description: Use an existing Network File System (NFS) share.</li> <li>Configuration:   <pre><code>apiVersion: hks.io/v1\nkind: BackupStorageLocation\nmetadata:\n  name: nfs-onprem-storage\nspec:\n  provider: generic\n  nfs:\n    server: 192.168.1.100\n    path: /exports/backups\n</code></pre></li> </ul>"},{"location":"backups/strategies/#defining-a-backup-plan","title":"Defining a Backup Plan","text":"<p>A Backup Plan ties everything together: what, where, when, and for how long.</p> <pre><code>apiVersion: hks.io/v1\nkind: BackupPlan\nmetadata:\n  name: production-db-daily\nspec:\n  target:\n    # Target what to back up\n    namespace: production\n    selector:\n      app: postgres-db\n\n  storageLocation: s3-main-storage\n\n  schedule:\n    # When to back up\n    cron: \"0 2 * * *\" # Daily at 2 AM UTC\n\n  retention:\n    # How long to keep backups\n    daily: 7\n    weekly: 4\n    monthly: 6\n</code></pre>"},{"location":"backups/strategies/#pre-and-post-backup-hooks","title":"Pre- and Post-Backup Hooks","text":"<p>For application-consistent backups, you can execute commands inside your application's containers before and after a snapshot.</p> <ul> <li>Pre-backup hook: Quiesce the database or flush caches to disk.</li> <li>Post-backup hook: Unquiesce the database or resume operations.</li> </ul> <pre><code># Annotate your pod for backup hooks\napiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres-pod\n  annotations:\n    # Pre-backup hook: freeze the database\n    pre.hook.backup.hks.io/container: postgres\n    pre.hook.backup.hks.io/command: '[\"/bin/psql\", \"-c\", \"CHECKPOINT; SELECT pg_start_backup(\\'hks-backup\\');\"]'\n\n    # Post-backup hook: unfreeze the database\n    post.hook.backup.hks.io/container: postgres\n    post.hook.backup.hks.io/command: '[\"/bin/psql\", \"-c\", \"SELECT pg_stop_backup();\"]'\n</code></pre>"},{"location":"backups/strategies/#best-practices-for-backup-strategies","title":"Best Practices for Backup Strategies","text":"<ol> <li> <p>3-2-1 Rule:</p> <ul> <li>Keep 3 copies of your data (1 production, 2 backups).</li> <li>Store backups on 2 different media.</li> <li>Keep 1 backup copy off-site. Use a different region or cloud provider for one of your <code>BackupStorageLocation</code>s.</li> </ul> </li> <li> <p>Regularly Test Your Restores: A backup strategy is useless if you can't restore from it. Regularly perform test restores to a non-production environment.</p> </li> <li> <p>Use Application Hooks: For transactional applications like databases, always use pre- and post-backup hooks to ensure application consistency.</p> </li> <li> <p>Tag Your Backups: Use labels and annotations to organize your backups, making them easier to find during a restore operation.</p> </li> <li> <p>Separate Data and Configuration Backups: Consider having separate backup plans for your stateful data (volumes) and your stateless application configurations (namespaces/resources). This can provide more flexibility during restores.</p> </li> <li> <p>Secure Your Backups: Encrypt backup data both in-transit and at-rest. Use IAM roles or dedicated credentials with minimal permissions for your <code>BackupStorageLocation</code>.</p> </li> </ol>"},{"location":"cicd/","title":"CI/CD","text":"<p>This section covers Continuous Integration and Continuous Deployment (CI/CD) workflows in Hexabase.AI (HKS). Learn how to automate your application delivery pipeline and implement DevOps best practices.</p>"},{"location":"cicd/#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Pipeline Setup: Creating and configuring CI/CD pipelines for HKS</li> <li>Integration Guides: Connecting popular CI/CD tools with HKS</li> <li>Deployment Strategies: Blue-green, canary, and progressive deployments</li> <li>GitOps: Implementing GitOps workflows with HKS</li> <li>Automation: Automating testing, security scanning, and deployments</li> </ul>"},{"location":"cicd/#key-topics","title":"Key Topics","text":"<ul> <li>Jenkins integration with HKS</li> <li>GitLab CI/CD pipelines</li> <li>GitHub Actions workflows</li> <li>ArgoCD and Flux for GitOps</li> <li>Container registry management</li> <li>Automated testing in CI/CD pipelines</li> <li>Security scanning and compliance checks</li> <li>Multi-environment deployment strategies</li> <li>Rollback and disaster recovery procedures</li> <li>AI-Ops integration for intelligent deployment decisions</li> </ul> <p>Whether you're setting up your first pipeline or optimizing complex deployment workflows, this section provides the tools and knowledge you need for successful CI/CD implementation in HKS.</p>"},{"location":"cicd/build-strategies/","title":"Build Strategies","text":"<p>Optimize your application builds with various strategies supported by Hexabase.AI's CI/CD platform.</p>"},{"location":"cicd/build-strategies/#overview","title":"Overview","text":"<p>Hexabase.AI supports multiple build strategies to optimize for speed, security, and resource efficiency. Choose the right strategy based on your application requirements.</p>"},{"location":"cicd/build-strategies/#container-build-strategies","title":"Container Build Strategies","text":""},{"location":"cicd/build-strategies/#1-docker-build","title":"1. Docker Build","text":"<p>Traditional Docker builds with optimization features:</p> <pre><code># .hexabase/pipeline.yml\nstages:\n  - name: build\n    jobs:\n      - name: docker-build\n        type: docker\n        config:\n          dockerfile: ./Dockerfile\n          context: .\n          target: production  # Multi-stage build target\n          buildArgs:\n            - NODE_ENV=production\n            - VERSION=${GIT_TAG}\n          cache:\n            - type: registry\n              ref: myapp:buildcache\n            - type: local\n              path: /tmp/buildcache\n</code></pre>"},{"location":"cicd/build-strategies/#2-buildpack-build","title":"2. Buildpack Build","text":"<p>Cloud Native Buildpacks for automatic containerization:</p> <pre><code>stages:\n  - name: build\n    jobs:\n      - name: buildpack-build\n        type: buildpack\n        config:\n          builder: gcr.io/buildpacks/builder:v1\n          env:\n            - BP_NODE_VERSION=18.*\n            - BP_NODE_RUN_SCRIPTS=build\n          buildpacks:\n            - paketo-buildpacks/nodejs\n</code></pre>"},{"location":"cicd/build-strategies/#3-kaniko-build","title":"3. Kaniko Build","text":"<p>Daemon-less container builds for enhanced security:</p> <pre><code>stages:\n  - name: build\n    jobs:\n      - name: kaniko-build\n        type: kaniko\n        config:\n          dockerfile: ./Dockerfile\n          cache:\n            enabled: true\n            ttl: 168h  # 7 days\n          registry:\n            insecure: false\n            mirror: registry-mirror.hexabase.ai\n</code></pre>"},{"location":"cicd/build-strategies/#4-source-to-image-s2i","title":"4. Source-to-Image (S2I)","text":"<p>Direct source code to container image:</p> <pre><code>stages:\n  - name: build\n    jobs:\n      - name: s2i-build\n        type: s2i\n        config:\n          builderImage: registry.access.redhat.com/ubi8/nodejs-16\n          scripts: .s2i/bin/\n          incremental: true\n</code></pre>"},{"location":"cicd/build-strategies/#multi-architecture-builds","title":"Multi-Architecture Builds","text":""},{"location":"cicd/build-strategies/#cross-platform-support","title":"Cross-Platform Support","text":"<p>Build for multiple architectures:</p> <pre><code>stages:\n  - name: build\n    jobs:\n      - name: multi-arch-build\n        type: docker\n        config:\n          platforms:\n            - linux/amd64\n            - linux/arm64\n            - linux/arm/v7\n          push: true\n</code></pre>"},{"location":"cicd/build-strategies/#caching-strategies","title":"Caching Strategies","text":""},{"location":"cicd/build-strategies/#1-layer-caching","title":"1. Layer Caching","text":"<p>Optimize Docker layer caching:</p> <pre><code># Dockerfile with optimized layers\nFROM node:18-alpine AS dependencies\nWORKDIR /app\n# Cache dependencies\nCOPY package*.json ./\nRUN npm ci --only=production\n\nFROM node:18-alpine AS build\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\nFROM node:18-alpine AS runtime\nWORKDIR /app\nCOPY --from=dependencies /app/node_modules ./node_modules\nCOPY --from=build /app/dist ./dist\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>"},{"location":"cicd/build-strategies/#2-dependency-caching","title":"2. Dependency Caching","text":"<pre><code>cache:\n  paths:\n    - node_modules/\n    - .npm/\n    - vendor/\n    - .gradle/\n  key: ${GIT_BRANCH}-${CHECKSUM(\"package-lock.json\")}\n  policy: pull-push\n</code></pre>"},{"location":"cicd/build-strategies/#3-build-cache-mounting","title":"3. Build Cache Mounting","text":"<pre><code>stages:\n  - name: build\n    jobs:\n      - name: cached-build\n        volumes:\n          - name: npm-cache\n            path: /root/.npm\n          - name: build-cache\n            path: /app/.cache\n</code></pre>"},{"location":"cicd/build-strategies/#parallel-build-strategies","title":"Parallel Build Strategies","text":""},{"location":"cicd/build-strategies/#matrix-builds","title":"Matrix Builds","text":"<p>Test multiple versions simultaneously:</p> <pre><code>stages:\n  - name: build\n    strategy:\n      matrix:\n        node: [14, 16, 18]\n        os: [alpine, debian]\n    jobs:\n      - name: build-matrix\n        image: node:${matrix.node}-${matrix.os}\n        commands:\n          - npm install\n          - npm run build\n</code></pre>"},{"location":"cicd/build-strategies/#monorepo-builds","title":"Monorepo Builds","text":"<p>Efficient monorepo build strategies:</p> <pre><code>stages:\n  - name: detect-changes\n    jobs:\n      - name: change-detection\n        commands:\n          - hb monorepo detect --base main\n\n  - name: build\n    jobs:\n      - name: build-api\n        when: changes.includes(\"packages/api\")\n        workdir: packages/api\n        commands:\n          - npm run build\n\n      - name: build-web\n        when: changes.includes(\"packages/web\")\n        workdir: packages/web\n        commands:\n          - npm run build\n</code></pre>"},{"location":"cicd/build-strategies/#security-first-builds","title":"Security-First Builds","text":""},{"location":"cicd/build-strategies/#1-minimal-base-images","title":"1. Minimal Base Images","text":"<pre><code># Use distroless for minimal attack surface\nFROM gcr.io/distroless/nodejs18-debian11\nCOPY --from=build /app/dist /app\nWORKDIR /app\nCMD [\"index.js\"]\n</code></pre>"},{"location":"cicd/build-strategies/#2-build-time-security-scanning","title":"2. Build-Time Security Scanning","text":"<pre><code>stages:\n  - name: build\n    jobs:\n      - name: secure-build\n        commands:\n          - docker build -t myapp:${GIT_COMMIT} .\n          - trivy image myapp:${GIT_COMMIT}\n          - snyk container test myapp:${GIT_COMMIT}\n        failOn:\n          - severity: high\n          - cvss: 7.0\n</code></pre>"},{"location":"cicd/build-strategies/#3-signed-images","title":"3. Signed Images","text":"<pre><code>stages:\n  - name: sign\n    jobs:\n      - name: sign-image\n        commands:\n          - cosign sign --key cosign.key myapp:${GIT_COMMIT}\n          - cosign verify --key cosign.pub myapp:${GIT_COMMIT}\n</code></pre>"},{"location":"cicd/build-strategies/#optimization-techniques","title":"Optimization Techniques","text":""},{"location":"cicd/build-strategies/#1-build-time-optimization","title":"1. Build Time Optimization","text":"<ul> <li>Use specific versions: Pin all dependencies</li> <li>Minimize layers: Combine RUN commands</li> <li>Order matters: Put least-changing layers first</li> <li>Clean as you go: Remove temporary files</li> </ul>"},{"location":"cicd/build-strategies/#2-size-optimization","title":"2. Size Optimization","text":"<pre><code># Multi-stage build for size optimization\nFROM golang:1.21 AS builder\nWORKDIR /app\nCOPY . .\nRUN CGO_ENABLED=0 go build -ldflags=\"-s -w\" -o app\n\nFROM scratch\nCOPY --from=builder /app/app /\nCMD [\"/app\"]\n</code></pre>"},{"location":"cicd/build-strategies/#3-build-performance","title":"3. Build Performance","text":"<pre><code>build:\n  resources:\n    cpu: 4\n    memory: 8Gi\n  parallel: true\n  timeout: 30m\n</code></pre>"},{"location":"cicd/build-strategies/#language-specific-strategies","title":"Language-Specific Strategies","text":""},{"location":"cicd/build-strategies/#nodejs","title":"Node.js","text":"<pre><code>build:\n  type: node\n  config:\n    packageManager: npm  # or yarn, pnpm\n    script: build\n    prune: production\n    cache:\n      - .npm\n      - node_modules\n</code></pre>"},{"location":"cicd/build-strategies/#go","title":"Go","text":"<pre><code>build:\n  type: go\n  config:\n    version: 1.21\n    ldflags: \"-s -w\"\n    env:\n      - CGO_ENABLED=0\n      - GOOS=linux\n      - GOARCH=amd64\n</code></pre>"},{"location":"cicd/build-strategies/#python","title":"Python","text":"<pre><code>build:\n  type: python\n  config:\n    version: 3.11\n    requirements: requirements.txt\n    wheelhouse: true  # Pre-build wheels\n</code></pre>"},{"location":"cicd/build-strategies/#java","title":"Java","text":"<pre><code>build:\n  type: java\n  config:\n    version: 17\n    tool: gradle  # or maven\n    goals: [clean, build]\n    cache:\n      - .gradle\n      - .m2\n</code></pre>"},{"location":"cicd/build-strategies/#best-practices","title":"Best Practices","text":"<ol> <li>Choose the Right Strategy</li> <li>Docker for flexibility</li> <li>Buildpacks for standardization</li> <li>Kaniko for security</li> <li> <p>S2I for simplicity</p> </li> <li> <p>Optimize for Cache</p> </li> <li>Structure Dockerfiles for layer reuse</li> <li>Use cache mounts for dependencies</li> <li> <p>Implement smart cache invalidation</p> </li> <li> <p>Security Considerations</p> </li> <li>Scan during build</li> <li>Use minimal base images</li> <li>Sign and verify images</li> <li> <p>Never include secrets in images</p> </li> <li> <p>Performance Tips</p> </li> <li>Parallelize when possible</li> <li>Use appropriate resource limits</li> <li>Implement incremental builds</li> <li>Monitor build metrics</li> </ol>"},{"location":"cicd/build-strategies/#monitoring-build-performance","title":"Monitoring Build Performance","text":"<pre><code># View build metrics\nhb pipeline metrics --stage build\n\n# Analyze build times\nhb pipeline analyze --optimization-suggestions\n\n# Set up alerts\nhb alert create --metric build.duration --threshold 10m\n</code></pre>"},{"location":"cicd/deployment-automation/","title":"Deployment Automation","text":"<p>Hexabase.AI provides comprehensive deployment automation capabilities that streamline the process of deploying applications to Kubernetes clusters.</p>"},{"location":"cicd/deployment-automation/#overview","title":"Overview","text":"<p>Deployment automation in Hexabase.AI handles:</p> <ul> <li>Automatic rollouts with health checks</li> <li>Blue-green and canary deployments</li> <li>Rollback capabilities</li> <li>Multi-environment deployments</li> <li>GitOps integration</li> </ul>"},{"location":"cicd/deployment-automation/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"cicd/deployment-automation/#1-rolling-updates","title":"1. Rolling Updates","text":"<p>The default deployment strategy with zero-downtime updates:</p> <pre><code>deploy:\n  strategy: rolling\n  config:\n    maxSurge: 25%\n    maxUnavailable: 0\n    healthCheck:\n      enabled: true\n      path: /health\n      interval: 10s\n      timeout: 5s\n      successThreshold: 3\n</code></pre>"},{"location":"cicd/deployment-automation/#2-blue-green-deployments","title":"2. Blue-Green Deployments","text":"<p>Deploy to a parallel environment before switching traffic:</p> <pre><code>deploy:\n  strategy: blue-green\n  config:\n    preDeploymentTests:\n      enabled: true\n      tests:\n        - smoke-tests\n        - integration-tests\n    trafficSwitch:\n      mode: instant # or gradual\n      validation:\n        duration: 5m\n        rollbackOnError: true\n</code></pre>"},{"location":"cicd/deployment-automation/#3-canary-deployments","title":"3. Canary Deployments","text":"<p>Gradually roll out changes to a subset of users:</p> <pre><code>deploy:\n  strategy: canary\n  config:\n    steps:\n      - weight: 10\n        pause: 5m\n        analysis:\n          metrics:\n            - error-rate &lt; 1%\n            - latency-p99 &lt; 500ms\n      - weight: 50\n        pause: 10m\n      - weight: 100\n    rollback:\n      automatic: true\n      threshold:\n        errorRate: 5%\n</code></pre>"},{"location":"cicd/deployment-automation/#automated-deployment-pipeline","title":"Automated Deployment Pipeline","text":""},{"location":"cicd/deployment-automation/#basic-configuration","title":"Basic Configuration","text":"<pre><code># .hks/deploy.yaml\nstages:\n  - name: validate\n    jobs:\n      - name: lint\n        commands:\n          - hb validate deployment.yaml\n          - hb validate service.yaml\n\n  - name: deploy-staging\n    jobs:\n      - name: deploy\n        environment: staging\n        commands:\n          - hb deploy --environment staging\n          - hb wait --for condition=ready\n\n  - name: test\n    jobs:\n      - name: smoke-tests\n        commands:\n          - npm run test:smoke\n\n  - name: deploy-production\n    when: manual\n    jobs:\n      - name: deploy\n        environment: production\n        commands:\n          - hb deploy --environment production --strategy canary\n</code></pre>"},{"location":"cicd/deployment-automation/#environment-specific-deployments","title":"Environment-Specific Deployments","text":"<pre><code>environments:\n  development:\n    autoSync: true\n    namespace: dev\n    values:\n      replicas: 1\n      resources:\n        requests:\n          memory: 256Mi\n          cpu: 100m\n\n  staging:\n    namespace: staging\n    values:\n      replicas: 2\n      ingress:\n        enabled: true\n        host: staging.myapp.com\n\n  production:\n    namespace: prod\n    approval:\n      required: true\n      approvers: [\"sre-team\", \"platform-team\"]\n    values:\n      replicas: 3\n      autoscaling:\n        enabled: true\n        minReplicas: 3\n        maxReplicas: 10\n</code></pre>"},{"location":"cicd/deployment-automation/#gitops-integration","title":"GitOps Integration","text":""},{"location":"cicd/deployment-automation/#argocd-integration","title":"ArgoCD Integration","text":"<pre><code>gitops:\n  provider: argocd\n  config:\n    repo: https://github.com/myorg/deployments\n    path: environments/production\n    syncPolicy:\n      automated:\n        prune: true\n        selfHeal: true\n      retry:\n        limit: 5\n        backoff:\n          duration: 5s\n          maxDuration: 3m\n</code></pre>"},{"location":"cicd/deployment-automation/#flux-integration","title":"Flux Integration","text":"<pre><code>gitops:\n  provider: flux\n  config:\n    sourceRepo: https://github.com/myorg/app\n    targetRepo: https://github.com/myorg/deployments\n    branch: main\n    interval: 1m\n    automation:\n      enabled: true\n      updatePolicy: semver\n</code></pre>"},{"location":"cicd/deployment-automation/#deployment-hooks","title":"Deployment Hooks","text":""},{"location":"cicd/deployment-automation/#pre-deployment","title":"Pre-Deployment","text":"<pre><code>hooks:\n  preDeployment:\n    - name: database-migration\n      command: [\"migrate\", \"up\"]\n      timeout: 5m\n    - name: cache-warm\n      command: [\"cache\", \"warm\", \"--endpoints\", \"/api/v1/*\"]\n</code></pre>"},{"location":"cicd/deployment-automation/#post-deployment","title":"Post-Deployment","text":"<pre><code>hooks:\n  postDeployment:\n    - name: smoke-test\n      command: [\"test\", \"smoke\", \"--endpoint\", \"${SERVICE_URL}\"]\n    - name: notify\n      command: [\"notify\", \"slack\", \"--channel\", \"#deployments\"]\n</code></pre>"},{"location":"cicd/deployment-automation/#health-checks-and-readiness","title":"Health Checks and Readiness","text":""},{"location":"cicd/deployment-automation/#liveness-probes","title":"Liveness Probes","text":"<pre><code>health:\n  liveness:\n    httpGet:\n      path: /health/live\n      port: 8080\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    timeoutSeconds: 5\n    failureThreshold: 3\n</code></pre>"},{"location":"cicd/deployment-automation/#readiness-probes","title":"Readiness Probes","text":"<pre><code>health:\n  readiness:\n    httpGet:\n      path: /health/ready\n      port: 8080\n    initialDelaySeconds: 5\n    periodSeconds: 5\n    successThreshold: 2\n</code></pre>"},{"location":"cicd/deployment-automation/#startup-probes","title":"Startup Probes","text":"<pre><code>health:\n  startup:\n    httpGet:\n      path: /health/startup\n      port: 8080\n    initialDelaySeconds: 0\n    periodSeconds: 10\n    failureThreshold: 30\n</code></pre>"},{"location":"cicd/deployment-automation/#rollback-automation","title":"Rollback Automation","text":""},{"location":"cicd/deployment-automation/#automatic-rollback","title":"Automatic Rollback","text":"<pre><code>rollback:\n  automatic: true\n  conditions:\n    - metric: error_rate\n      threshold: 5%\n      window: 5m\n    - metric: latency_p99\n      threshold: 1000ms\n      window: 5m\n  strategy: immediate # or gradual\n</code></pre>"},{"location":"cicd/deployment-automation/#manual-rollback","title":"Manual Rollback","text":"<pre><code># Rollback to previous version\nhb rollback --app myapp\n\n# Rollback to specific version\nhb rollback --app myapp --version v1.2.3\n\n# Rollback with custom strategy\nhb rollback --app myapp --strategy gradual --steps 4\n</code></pre>"},{"location":"cicd/deployment-automation/#multi-region-deployments","title":"Multi-Region Deployments","text":"<pre><code>deploy:\n  multiRegion:\n    regions:\n      - name: us-east-1\n        primary: true\n        weight: 50\n      - name: eu-west-1\n        weight: 30\n      - name: ap-southeast-1\n        weight: 20\n    failover:\n      automatic: true\n      healthCheck:\n        interval: 30s\n        threshold: 3\n</code></pre>"},{"location":"cicd/deployment-automation/#deployment-monitoring","title":"Deployment Monitoring","text":""},{"location":"cicd/deployment-automation/#metrics-collection","title":"Metrics Collection","text":"<pre><code>monitoring:\n  deployment:\n    metrics:\n      - deployment_duration\n      - rollout_status\n      - replica_availability\n      - error_rate\n      - latency_percentiles\n    alerts:\n      - name: deployment-failed\n        condition: deployment_status == \"failed\"\n        severity: critical\n      - name: slow-rollout\n        condition: deployment_duration &gt; 15m\n        severity: warning\n</code></pre>"},{"location":"cicd/deployment-automation/#deployment-dashboard","title":"Deployment Dashboard","text":"<pre><code># View deployment status\nhb deployment status --app myapp\n\n# Watch deployment progress\nhb deployment watch --app myapp\n\n# View deployment history\nhb deployment history --app myapp --limit 10\n</code></pre>"},{"location":"cicd/deployment-automation/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Progressive Delivery</p> </li> <li> <p>Start with canary deployments for critical services</p> </li> <li>Use feature flags for gradual rollouts</li> <li> <p>Implement proper observability</p> </li> <li> <p>Automated Testing</p> </li> <li> <p>Run comprehensive tests in staging</p> </li> <li>Implement smoke tests for production</li> <li> <p>Use contract testing for APIs</p> </li> <li> <p>Rollback Strategy</p> </li> <li> <p>Always have a rollback plan</p> </li> <li>Test rollback procedures regularly</li> <li> <p>Keep previous versions available</p> </li> <li> <p>Security</p> </li> <li> <p>Scan images before deployment</p> </li> <li>Use signed images</li> <li> <p>Implement RBAC for deployments</p> </li> <li> <p>Documentation</p> </li> <li>Document deployment procedures</li> <li>Maintain runbooks for common issues</li> <li>Keep deployment configurations in version control</li> </ol>"},{"location":"cicd/deployment-automation/#cli-commands","title":"CLI Commands","text":"<pre><code># Deploy application\nhb deploy --app myapp --version v1.2.3\n\n# Deploy with specific strategy\nhb deploy --app myapp --strategy canary --steps 3\n\n# Promote canary to full deployment\nhb promote --app myapp --environment production\n\n# Pause deployment\nhb pause --deployment myapp-v1.2.3\n\n# Resume deployment\nhb resume --deployment myapp-v1.2.3\n\n# Abort deployment\nhb abort --deployment myapp-v1.2.3\n</code></pre>"},{"location":"cicd/deployment-automation/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"cicd/deployment-automation/#github-actions","title":"GitHub Actions","text":"<pre><code>- name: Deploy to Hexabase\n  uses: hexabase/deploy-action@v1\n  with:\n    app: myapp\n    environment: production\n    strategy: blue-green\n    wait: true\n</code></pre>"},{"location":"cicd/deployment-automation/#gitlab-ci","title":"GitLab CI","text":"<pre><code>deploy:\n  stage: deploy\n  script:\n    - hb deploy --app $CI_PROJECT_NAME --version $CI_COMMIT_TAG\n  environment:\n    name: production\n    url: https://myapp.example.com\n</code></pre>"},{"location":"cicd/github-integration/","title":"GitHub Integration","text":"<p>Seamlessly integrate your GitHub repositories with Hexabase.AI to enable automated CI/CD workflows, code deployments, and GitOps practices.</p>"},{"location":"cicd/github-integration/#overview","title":"Overview","text":"<p>Hexabase.AI provides native GitHub integration that allows you to connect your repositories, set up automated pipelines, and deploy applications directly from your GitHub workflow.</p>"},{"location":"cicd/github-integration/#initial-setup","title":"Initial Setup","text":""},{"location":"cicd/github-integration/#1-connect-your-github-account","title":"1. Connect Your GitHub Account","text":""},{"location":"cicd/github-integration/#via-ui","title":"Via UI","text":"<ol> <li>Navigate to Settings \u2192 Integrations \u2192 GitHub</li> <li>Click Connect GitHub Account</li> <li>Authorize Hexabase.AI to access your repositories</li> <li>Select repositories to integrate</li> </ol>"},{"location":"cicd/github-integration/#via-cli","title":"Via CLI","text":"<pre><code># Connect GitHub account\nhb github connect\n\n# List available repositories\nhb github repos list\n\n# Connect specific repository\nhb github repo connect owner/repo --workspace production\n</code></pre>"},{"location":"cicd/github-integration/#2-repository-configuration","title":"2. Repository Configuration","text":"<p>Once connected, configure your repository settings:</p> <pre><code># .hexabase/github.yml\nintegration:\n  provider: github\n  repository: myorg/myapp\n  branch:\n    main: production\n    develop: staging\n    feature/*: preview\n  secrets:\n    inherit: true  # Inherit GitHub secrets\n</code></pre>"},{"location":"cicd/github-integration/#webhook-configuration","title":"Webhook Configuration","text":""},{"location":"cicd/github-integration/#automatic-webhook-setup","title":"Automatic Webhook Setup","text":"<p>Hexabase.AI automatically configures webhooks when you connect a repository:</p> <ul> <li>Push events: Trigger builds on code pushes</li> <li>Pull request events: Run tests and preview deployments</li> <li>Release events: Deploy to production</li> <li>Issue comments: Trigger actions via comments</li> </ul>"},{"location":"cicd/github-integration/#manual-webhook-configuration","title":"Manual Webhook Configuration","text":"<p>If needed, manually configure webhooks:</p> <ol> <li>Go to GitHub repository \u2192 Settings \u2192 Webhooks</li> <li>Add webhook URL: <code>https://api.hexabase.ai/webhooks/github</code></li> <li>Select events:</li> <li>Push</li> <li>Pull requests</li> <li>Releases</li> <li>Issue comments</li> <li>Set content type to <code>application/json</code></li> </ol>"},{"location":"cicd/github-integration/#github-actions-integration","title":"GitHub Actions Integration","text":""},{"location":"cicd/github-integration/#using-hexabaseai-in-github-actions","title":"Using Hexabase.AI in GitHub Actions","text":"<p>Install the Hexabase.AI GitHub Action:</p> <pre><code># .github/workflows/deploy.yml\nname: Deploy to Hexabase\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to Hexabase\n        uses: hexabase/deploy-action@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n          workspace: production\n          manifest: ./k8s/\n</code></pre>"},{"location":"cicd/github-integration/#advanced-github-actions-workflow","title":"Advanced GitHub Actions Workflow","text":"<pre><code>name: Complete CI/CD Pipeline\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run Tests\n        run: |\n          npm install\n          npm test\n\n      - name: Security Scan\n        uses: hexabase/security-scan@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build Container\n        uses: hexabase/build-action@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n          dockerfile: ./Dockerfile\n          tags: |\n            latest\n            ${{ github.sha }}\n\n  deploy:\n    needs: build\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to Production\n        uses: hexabase/deploy-action@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n          workspace: production\n          image: ${{ github.sha }}\n          wait: true\n          timeout: 300\n</code></pre>"},{"location":"cicd/github-integration/#pull-request-workflows","title":"Pull Request Workflows","text":""},{"location":"cicd/github-integration/#preview-environments","title":"Preview Environments","text":"<p>Automatically create preview environments for pull requests:</p> <pre><code># .hexabase/preview.yml\npreview:\n  enabled: true\n  auto_deploy: true\n  resources:\n    cpu: 100m\n    memory: 256Mi\n  lifetime: 72h  # Auto-cleanup after 3 days\n  domains:\n    pattern: \"pr-{number}.preview.example.com\"\n</code></pre>"},{"location":"cicd/github-integration/#pr-comments-commands","title":"PR Comments Commands","text":"<p>Use comments to control deployments:</p> <ul> <li><code>/deploy</code> - Deploy PR to preview environment</li> <li><code>/deploy staging</code> - Deploy PR to staging</li> <li><code>/destroy</code> - Remove preview environment</li> <li><code>/test</code> - Run integration tests</li> <li><code>/approve</code> - Approve for production deployment</li> </ul>"},{"location":"cicd/github-integration/#status-checks","title":"Status Checks","text":"<p>Hexabase.AI provides GitHub status checks:</p> <pre><code># .hexabase/checks.yml\nchecks:\n  - name: build\n    required: true\n\n  - name: security-scan\n    required: true\n    severity: high\n\n  - name: integration-tests\n    required: true\n\n  - name: preview-deploy\n    required: false\n</code></pre>"},{"location":"cicd/github-integration/#secrets-management","title":"Secrets Management","text":""},{"location":"cicd/github-integration/#using-github-secrets","title":"Using GitHub Secrets","text":"<p>Reference GitHub secrets in your pipelines:</p> <pre><code># .hexabase/pipeline.yml\nstages:\n  - name: deploy\n    env:\n      - name: API_KEY\n        valueFrom:\n          githubSecret: API_KEY\n      - name: DATABASE_URL\n        valueFrom:\n          githubSecret: DATABASE_URL\n</code></pre>"},{"location":"cicd/github-integration/#syncing-secrets","title":"Syncing Secrets","text":"<p>Sync GitHub secrets to Hexabase.AI:</p> <pre><code># Sync all secrets\nhb github secrets sync\n\n# Sync specific secret\nhb github secrets sync API_KEY --workspace production\n</code></pre>"},{"location":"cicd/github-integration/#branch-protection","title":"Branch Protection","text":""},{"location":"cicd/github-integration/#automated-branch-protection","title":"Automated Branch Protection","text":"<p>Configure branch protection rules that integrate with Hexabase.AI:</p> <pre><code># .hexabase/protection.yml\nprotection:\n  branches:\n    main:\n      required_checks:\n        - hexabase/build\n        - hexabase/security\n        - hexabase/deploy-staging\n      require_up_to_date: true\n      enforce_admins: true\n\n    develop:\n      required_checks:\n        - hexabase/build\n        - hexabase/test\n</code></pre>"},{"location":"cicd/github-integration/#github-apps","title":"GitHub Apps","text":""},{"location":"cicd/github-integration/#creating-a-github-app","title":"Creating a GitHub App","text":"<p>For organization-wide integration:</p> <ol> <li>Create GitHub App in your organization</li> <li>Configure permissions:</li> <li>Repository: Read &amp; Write</li> <li>Pull requests: Read &amp; Write</li> <li>Checks: Write</li> <li>Webhooks: Read</li> <li>Install in Hexabase.AI:</li> </ol> <pre><code>hb github app install \\\n  --app-id 123456 \\\n  --private-key @private-key.pem \\\n  --organization myorg\n</code></pre>"},{"location":"cicd/github-integration/#monitoring-integration","title":"Monitoring Integration","text":""},{"location":"cicd/github-integration/#github-metrics","title":"GitHub Metrics","text":"<p>Monitor your GitHub integration:</p> <ul> <li>Webhook delivery success rate</li> <li>Build trigger latency</li> <li>PR deployment statistics</li> <li>Repository activity</li> </ul>"},{"location":"cicd/github-integration/#alerts","title":"Alerts","text":"<p>Configure alerts for GitHub events:</p> <pre><code>alerts:\n  - name: failed-deployment\n    condition: github.deployment.status == \"failure\"\n    notify:\n      - github-issue\n      - slack\n\n  - name: long-running-pr\n    condition: github.pr.age &gt; \"7d\"\n    notify:\n      - github-comment\n</code></pre>"},{"location":"cicd/github-integration/#best-practices","title":"Best Practices","text":""},{"location":"cicd/github-integration/#1-repository-structure","title":"1. Repository Structure","text":"<p>Organize your repository for Hexabase.AI:</p> <pre><code>myapp/\n\u251c\u2500\u2500 .hexabase/\n\u2502   \u251c\u2500\u2500 pipeline.yml\n\u2502   \u251c\u2500\u2500 preview.yml\n\u2502   \u2514\u2500\u2500 github.yml\n\u251c\u2500\u2500 k8s/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 ingress.yaml\n\u251c\u2500\u2500 src/\n\u2514\u2500\u2500 Dockerfile\n</code></pre>"},{"location":"cicd/github-integration/#2-commit-message-conventions","title":"2. Commit Message Conventions","text":"<p>Use conventional commits for better automation:</p> <ul> <li><code>feat:</code> - Triggers feature deployment</li> <li><code>fix:</code> - Triggers hotfix deployment</li> <li><code>docs:</code> - Skips deployment</li> <li><code>chore:</code> - Skips deployment</li> </ul>"},{"location":"cicd/github-integration/#3-security","title":"3. Security","text":"<ul> <li>Use GitHub secrets for sensitive data</li> <li>Enable secret scanning</li> <li>Require signed commits</li> <li>Use branch protection rules</li> </ul>"},{"location":"cicd/github-integration/#4-performance","title":"4. Performance","text":"<ul> <li>Use shallow clones for faster builds</li> <li>Cache dependencies in GitHub Actions</li> <li>Parallelize test execution</li> <li>Use build matrices wisely</li> </ul>"},{"location":"cicd/github-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cicd/github-integration/#common-issues","title":"Common Issues","text":"<p>Webhook Not Triggering <pre><code># Check webhook status\nhb github webhook status\n\n# Redeliver webhook\nhb github webhook redeliver &lt;delivery-id&gt;\n</code></pre></p> <p>Authentication Errors <pre><code># Refresh GitHub token\nhb github auth refresh\n\n# Check permissions\nhb github auth check\n</code></pre></p> <p>Build Not Starting - Verify branch patterns in configuration - Check GitHub App permissions - Review webhook delivery logs</p>"},{"location":"cicd/github-integration/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed GitHub integration logging:</p> <pre><code># Enable debug logs\nhb github debug --enable\n\n# View integration logs\nhb logs -n hexabase-system -l component=github-integration\n</code></pre>"},{"location":"cicd/github-integration/#migration-guide","title":"Migration Guide","text":""},{"location":"cicd/github-integration/#from-github-actions-to-hexabase-pipelines","title":"From GitHub Actions to Hexabase Pipelines","text":"<ol> <li> <p>Export existing workflow: <pre><code>hb github migrate workflow .github/workflows/deploy.yml\n</code></pre></p> </li> <li> <p>Review generated pipeline: <pre><code>cat .hexabase/pipeline.yml\n</code></pre></p> </li> <li> <p>Test in staging: <pre><code>hb pipeline run --workspace staging\n</code></pre></p> </li> <li> <p>Enable automatic triggers: <pre><code>hb github triggers enable\n</code></pre></p> </li> </ol>"},{"location":"cicd/gitlab-integration/","title":"GitLab Integration","text":"<p>Integrate your GitLab repositories with Hexabase.AI for automated CI/CD workflows and GitOps deployments.</p>"},{"location":"cicd/gitlab-integration/#overview","title":"Overview","text":"<p>Hexabase.AI supports full GitLab integration, enabling you to leverage GitLab CI/CD while deploying to Hexabase-managed Kubernetes clusters.</p>"},{"location":"cicd/gitlab-integration/#setup","title":"Setup","text":""},{"location":"cicd/gitlab-integration/#connect-gitlab","title":"Connect GitLab","text":"<pre><code># Connect GitLab instance\nhb gitlab connect --url https://gitlab.com --token &lt;token&gt;\n\n# For self-hosted GitLab\nhb gitlab connect --url https://gitlab.company.com --token &lt;token&gt;\n</code></pre>"},{"location":"cicd/gitlab-integration/#repository-integration","title":"Repository Integration","text":"<pre><code># .hexabase/gitlab.yml\nintegration:\n  provider: gitlab\n  project: mygroup/myproject\n  branches:\n    main: production\n    develop: staging\n    feature/*: preview\n</code></pre>"},{"location":"cicd/gitlab-integration/#gitlab-ci-integration","title":"GitLab CI Integration","text":""},{"location":"cicd/gitlab-integration/#basic-pipeline","title":"Basic Pipeline","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - test\n  - build\n  - deploy\n\nvariables:\n  HEXABASE_URL: https://api.hexabase.ai\n\ntest:\n  stage: test\n  script:\n    - npm install\n    - npm test\n\nbuild:\n  stage: build\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n\ndeploy:production:\n  stage: deploy\n  only:\n    - main\n  script:\n    - |\n      curl -X POST $HEXABASE_URL/deploy \\\n        -H \"Authorization: Bearer $HEXABASE_TOKEN\" \\\n        -d '{\n          \"workspace\": \"production\",\n          \"image\": \"'$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA'\",\n          \"manifest\": \"k8s/\"\n        }'\n</code></pre>"},{"location":"cicd/gitlab-integration/#using-hexabase-gitlab-runner","title":"Using Hexabase GitLab Runner","text":"<p>Deploy Hexabase-optimized GitLab runners:</p> <pre><code># Install runner in cluster\nhb gitlab runner install --workspace production\n\n# Register with GitLab\nhb gitlab runner register --token &lt;registration-token&gt;\n</code></pre>"},{"location":"cicd/gitlab-integration/#merge-request-integration","title":"Merge Request Integration","text":""},{"location":"cicd/gitlab-integration/#preview-environments","title":"Preview Environments","text":"<pre><code># .gitlab-ci.yml\ndeploy:preview:\n  stage: deploy\n  only:\n    - merge_requests\n  environment:\n    name: preview/$CI_MERGE_REQUEST_IID\n    url: https://mr-$CI_MERGE_REQUEST_IID.preview.example.com\n    on_stop: stop:preview\n  script:\n    - hb deploy --preview --mr-id $CI_MERGE_REQUEST_IID\n\nstop:preview:\n  stage: deploy\n  only:\n    - merge_requests\n  when: manual\n  environment:\n    name: preview/$CI_MERGE_REQUEST_IID\n    action: stop\n  script:\n    - hb destroy --preview --mr-id $CI_MERGE_REQUEST_IID\n</code></pre>"},{"location":"cicd/gitlab-integration/#mr-comments","title":"MR Comments","text":"<p>Use merge request comments for actions:</p> <ul> <li><code>/deploy</code> - Deploy to preview</li> <li><code>/deploy staging</code> - Deploy to staging</li> <li><code>/restart</code> - Restart deployment</li> <li><code>/logs</code> - Show deployment logs</li> <li><code>/destroy</code> - Remove preview</li> </ul>"},{"location":"cicd/gitlab-integration/#gitlab-container-registry","title":"GitLab Container Registry","text":""},{"location":"cicd/gitlab-integration/#automatic-integration","title":"Automatic Integration","text":"<pre><code># .hexabase/registry.yml\nregistry:\n  provider: gitlab\n  auto_sync: true\n  cleanup_policy:\n    keep_latest: 10\n    older_than: 30d\n</code></pre>"},{"location":"cicd/gitlab-integration/#manual-configuration","title":"Manual Configuration","text":"<pre><code># Configure registry credentials\nhb secret create gitlab-registry \\\n  --docker-server=$CI_REGISTRY \\\n  --docker-username=$CI_REGISTRY_USER \\\n  --docker-password=$CI_REGISTRY_PASSWORD\n</code></pre>"},{"location":"cicd/gitlab-integration/#security-integration","title":"Security Integration","text":""},{"location":"cicd/gitlab-integration/#gitlab-security-scanning","title":"GitLab Security Scanning","text":"<pre><code>include:\n  - template: Security/SAST.gitlab-ci.yml\n  - template: Security/Container-Scanning.gitlab-ci.yml\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n\nhexabase:security:sync:\n  stage: .post\n  script:\n    - hb security import --source gitlab --report gl-sast-report.json\n</code></pre>"},{"location":"cicd/gitlab-integration/#variables-and-secrets","title":"Variables and Secrets","text":""},{"location":"cicd/gitlab-integration/#cicd-variables","title":"CI/CD Variables","text":"<p>Sync GitLab CI/CD variables:</p> <pre><code># Sync all variables\nhb gitlab variables sync\n\n# Sync specific variable\nhb gitlab variables sync DATABASE_URL --workspace production\n</code></pre>"},{"location":"cicd/gitlab-integration/#protected-variables","title":"Protected Variables","text":"<pre><code># .hexabase/variables.yml\nvariables:\n  sync:\n    - name: API_KEY\n      protected: true\n      environments: [production]\n    - name: DEBUG\n      protected: false\n      environments: [staging, development]\n</code></pre>"},{"location":"cicd/gitlab-integration/#gitlab-pages-integration","title":"GitLab Pages Integration","text":"<p>Deploy documentation to GitLab Pages:</p> <pre><code>pages:\n  stage: deploy\n  script:\n    - mkdocs build\n    - mv site public\n  artifacts:\n    paths:\n      - public\n  only:\n    - main\n</code></pre>"},{"location":"cicd/gitlab-integration/#monitoring","title":"Monitoring","text":""},{"location":"cicd/gitlab-integration/#pipeline-metrics","title":"Pipeline Metrics","text":"<p>Monitor GitLab CI/CD performance:</p> <pre><code># View pipeline metrics\nhb gitlab metrics pipelines\n\n# Set up alerts\nhb gitlab alerts create \\\n  --name \"pipeline-failure\" \\\n  --condition \"failure_rate &gt; 0.1\" \\\n  --notify slack\n</code></pre>"},{"location":"cicd/gitlab-integration/#best-practices","title":"Best Practices","text":"<ol> <li>Use GitLab Flow: Follow GitLab's recommended branching strategy</li> <li>Leverage CI/CD Templates: Create reusable pipeline templates</li> <li>Secure Variables: Use protected and masked variables</li> <li>Cache Dependencies: Speed up builds with caching</li> <li>Parallel Testing: Use GitLab's parallel keyword</li> </ol>"},{"location":"cicd/gitlab-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cicd/gitlab-integration/#common-issues","title":"Common Issues","text":"<p>Runner Connection Issues <pre><code># Check runner status\nhb gitlab runner status\n\n# View runner logs\nhb logs -l app=gitlab-runner\n</code></pre></p> <p>Registry Authentication <pre><code># Test registry access\nhb gitlab registry test\n\n# Update credentials\nhb gitlab registry auth refresh\n</code></pre></p> <p>Pipeline Failures - Check job logs in GitLab UI - Verify Hexabase API connectivity - Review variable configuration - Check runner resource limits</p>"},{"location":"cicd/pipeline-configuration/","title":"Pipeline Configuration","text":"<p>Configure powerful CI/CD pipelines in Hexabase.AI to automate your application build, test, and deployment workflows.</p>"},{"location":"cicd/pipeline-configuration/#overview","title":"Overview","text":"<p>Hexabase.AI provides a flexible pipeline system that integrates with your existing Git repositories and follows GitOps principles. Pipelines are defined using YAML configuration files and support multiple stages, parallel execution, and conditional logic.</p>"},{"location":"cicd/pipeline-configuration/#pipeline-structure","title":"Pipeline Structure","text":""},{"location":"cicd/pipeline-configuration/#basic-pipeline-configuration","title":"Basic Pipeline Configuration","text":"<p>Create a <code>.hexabase/pipeline.yml</code> file in your repository:</p> <pre><code>apiVersion: cicd.hexabase.ai/v1\nkind: Pipeline\nmetadata:\n  name: my-app-pipeline\n  workspace: production\nspec:\n  triggers:\n    - type: push\n      branches: [main, develop]\n    - type: pull_request\n      branches: [main]\n\n  stages:\n    - name: build\n      jobs:\n        - name: build-app\n          image: node:18\n          commands:\n            - npm install\n            - npm run build\n            - npm test\n\n    - name: deploy\n      jobs:\n        - name: deploy-to-k8s\n          when: branch == 'main'\n          commands:\n            - hb deploy --manifest k8s/\n</code></pre>"},{"location":"cicd/pipeline-configuration/#pipeline-components","title":"Pipeline Components","text":""},{"location":"cicd/pipeline-configuration/#triggers","title":"Triggers","text":"<p>Define when pipelines should run:</p> <pre><code>triggers:\n  # Git push trigger\n  - type: push\n    branches: [main, develop, feature/*]\n\n  # Pull request trigger\n  - type: pull_request\n    branches: [main]\n\n  # Schedule trigger (cron)\n  - type: schedule\n    cron: \"0 2 * * *\"  # Daily at 2 AM\n\n  # Manual trigger\n  - type: manual\n</code></pre>"},{"location":"cicd/pipeline-configuration/#stages-and-jobs","title":"Stages and Jobs","text":"<p>Organize your pipeline into logical stages:</p> <pre><code>stages:\n  - name: test\n    jobs:\n      # Parallel jobs\n      - name: unit-tests\n        image: golang:1.21\n        commands:\n          - go test ./...\n\n      - name: lint\n        image: golangci/golangci-lint\n        commands:\n          - golangci-lint run\n\n  - name: build\n    # Sequential execution after test stage\n    dependsOn: [test]\n    jobs:\n      - name: docker-build\n        commands:\n          - docker build -t myapp:${GIT_COMMIT} .\n          - docker push registry.hexabase.ai/myapp:${GIT_COMMIT}\n</code></pre>"},{"location":"cicd/pipeline-configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"cicd/pipeline-configuration/#built-in-variables","title":"Built-in Variables","text":"<p>Available in all pipeline runs:</p> <ul> <li><code>${GIT_COMMIT}</code> - Git commit SHA</li> <li><code>${GIT_BRANCH}</code> - Current branch name</li> <li><code>${GIT_TAG}</code> - Git tag (if applicable)</li> <li><code>${WORKSPACE}</code> - Current workspace</li> <li><code>${PROJECT}</code> - Current project name</li> <li><code>${BUILD_ID}</code> - Unique build identifier</li> </ul>"},{"location":"cicd/pipeline-configuration/#custom-variables","title":"Custom Variables","text":"<p>Define custom environment variables:</p> <pre><code>env:\n  global:\n    - NODE_ENV=production\n    - API_VERSION=v2\n\nstages:\n  - name: build\n    env:\n      - BUILD_TARGET=production\n    jobs:\n      - name: compile\n        env:\n          - OPTIMIZATION_LEVEL=3\n</code></pre>"},{"location":"cicd/pipeline-configuration/#secrets-management","title":"Secrets Management","text":"<p>Access secrets securely in pipelines:</p> <pre><code>stages:\n  - name: deploy\n    secrets:\n      - name: docker-registry\n        keys: [username, password]\n      - name: api-keys\n        keys: [stripe-key, sendgrid-key]\n    jobs:\n      - name: push-image\n        commands:\n          # Secrets available as environment variables\n          - docker login -u $DOCKER_REGISTRY_USERNAME -p $DOCKER_REGISTRY_PASSWORD\n</code></pre>"},{"location":"cicd/pipeline-configuration/#advanced-features","title":"Advanced Features","text":""},{"location":"cicd/pipeline-configuration/#conditional-execution","title":"Conditional Execution","text":"<p>Control job execution with conditions:</p> <pre><code>jobs:\n  - name: deploy-prod\n    when: branch == 'main' &amp;&amp; tag =~ /^v\\d+\\.\\d+\\.\\d+$/\n\n  - name: deploy-staging\n    when: branch == 'develop'\n\n  - name: security-scan\n    when: pullRequest.labels contains 'security'\n</code></pre>"},{"location":"cicd/pipeline-configuration/#matrix-builds","title":"Matrix Builds","text":"<p>Test across multiple configurations:</p> <pre><code>stages:\n  - name: test\n    strategy:\n      matrix:\n        node_version: [16, 18, 20]\n        os: [ubuntu, alpine]\n    jobs:\n      - name: test-matrix\n        image: node:${{ matrix.node_version }}-${{ matrix.os }}\n        commands:\n          - npm test\n</code></pre>"},{"location":"cicd/pipeline-configuration/#artifacts","title":"Artifacts","text":"<p>Share data between stages:</p> <pre><code>stages:\n  - name: build\n    jobs:\n      - name: compile\n        commands:\n          - npm run build\n        artifacts:\n          paths:\n            - dist/\n            - build/\n          expire: 7d\n\n  - name: deploy\n    jobs:\n      - name: upload\n        commands:\n          # Artifacts from build stage available\n          - aws s3 sync dist/ s3://my-bucket/\n</code></pre>"},{"location":"cicd/pipeline-configuration/#caching","title":"Caching","text":"<p>Speed up builds with caching:</p> <pre><code>cache:\n  paths:\n    - node_modules/\n    - .npm/\n    - vendor/\n  key: ${GIT_BRANCH}-${CHECKSUM(\"package-lock.json\")}\n</code></pre>"},{"location":"cicd/pipeline-configuration/#pipeline-templates","title":"Pipeline Templates","text":""},{"location":"cicd/pipeline-configuration/#reusable-templates","title":"Reusable Templates","text":"<p>Create template pipelines:</p> <pre><code># .hexabase/templates/node-app.yml\napiVersion: cicd.hexabase.ai/v1\nkind: PipelineTemplate\nmetadata:\n  name: node-app-template\nspec:\n  parameters:\n    - name: nodeVersion\n      default: \"18\"\n  stages:\n    - name: test\n      jobs:\n        - name: test\n          image: node:{{ .nodeVersion }}\n          commands:\n            - npm install\n            - npm test\n</code></pre> <p>Use templates in pipelines:</p> <pre><code>apiVersion: cicd.hexabase.ai/v1\nkind: Pipeline\nmetadata:\n  name: my-app\nspec:\n  extends:\n    template: node-app-template\n    parameters:\n      nodeVersion: \"20\"\n  stages:\n    # Additional stages\n    - name: deploy\n      jobs:\n        - name: deploy\n          commands:\n            - hb deploy\n</code></pre>"},{"location":"cicd/pipeline-configuration/#integration-with-hexabase-features","title":"Integration with Hexabase Features","text":""},{"location":"cicd/pipeline-configuration/#automatic-kubernetes-deployment","title":"Automatic Kubernetes Deployment","text":"<pre><code>stages:\n  - name: deploy\n    jobs:\n      - name: k8s-deploy\n        type: kubernetes  # Special job type\n        config:\n          manifest: k8s/deployment.yaml\n          namespace: production\n          strategy: rolling\n          healthCheck:\n            enabled: true\n            timeout: 300s\n</code></pre>"},{"location":"cicd/pipeline-configuration/#function-deployment","title":"Function Deployment","text":"<p>Deploy serverless functions:</p> <pre><code>stages:\n  - name: deploy-functions\n    jobs:\n      - name: function-deploy\n        type: function\n        config:\n          source: ./functions/\n          runtime: node18\n          triggers:\n            - http:\n                path: /api/webhook\n                method: POST\n</code></pre>"},{"location":"cicd/pipeline-configuration/#monitoring-and-notifications","title":"Monitoring and Notifications","text":""},{"location":"cicd/pipeline-configuration/#pipeline-notifications","title":"Pipeline Notifications","text":"<p>Configure notifications for pipeline events:</p> <pre><code>notifications:\n  - type: slack\n    webhook: ${SLACK_WEBHOOK}\n    events: [failure, success]\n    channels: [\"#deployments\"]\n\n  - type: email\n    recipients: [\"team@example.com\"]\n    events: [failure]\n</code></pre>"},{"location":"cicd/pipeline-configuration/#pipeline-metrics","title":"Pipeline Metrics","text":"<p>Monitor pipeline performance:</p> <ul> <li>Build duration trends</li> <li>Success/failure rates</li> <li>Queue wait times</li> <li>Resource utilization</li> </ul>"},{"location":"cicd/pipeline-configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Version Control: Keep pipeline configs in version control</li> <li>Modular Stages: Break complex pipelines into logical stages</li> <li>Fail Fast: Run tests early in the pipeline</li> <li>Parallel Execution: Run independent jobs in parallel</li> <li>Cache Dependencies: Use caching to speed up builds</li> <li>Security Scanning: Include security checks in pipelines</li> <li>Environment Parity: Keep staging and production pipelines similar</li> </ol>"},{"location":"cicd/pipeline-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cicd/pipeline-configuration/#common-issues","title":"Common Issues","text":"<p>Pipeline Not Triggering - Verify branch patterns match - Check webhook configuration - Review trigger conditions</p> <p>Build Failures - Check build logs: <code>hb pipeline logs &lt;build-id&gt;</code> - Verify image availability - Check resource limits</p> <p>Slow Builds - Enable caching - Use smaller base images - Parallelize test execution</p>"},{"location":"cicd/pipeline-configuration/#debugging","title":"Debugging","text":"<p>Enable debug mode for detailed logs:</p> <pre><code>debug:\n  enabled: true\n  verbose: true\n</code></pre> <p>View pipeline execution:</p> <pre><code># List recent pipeline runs\nhb pipeline list\n\n# Get pipeline details\nhb pipeline get &lt;pipeline-id&gt;\n\n# Stream logs\nhb pipeline logs -f &lt;build-id&gt;\n</code></pre>"},{"location":"concept/","title":"Core Concepts","text":"<p>Welcome to the Hexabase.AI Core Concepts section. This guide introduces the fundamental concepts and terminology you need to understand when working with Hexabase.AI.</p>"},{"location":"concept/#overview","title":"Overview","text":"<p>Hexabase.AI is built on several key concepts that work together to provide a powerful, multi-tenant Kubernetes as a Service platform. Understanding these concepts is essential for effectively using and managing the platform.</p>"},{"location":"concept/#key-concepts","title":"Key Concepts","text":"<ul> <li> Organizations</li> </ul> <p>Top-level entities that represent companies or teams using Hexabase.AI</p> <p> Learn about Organizations</p> <ul> <li> Workspaces</li> </ul> <p>Isolated environments within organizations for different teams or projects</p> <p> Learn about Workspaces</p> <ul> <li> Projects</li> </ul> <p>Deployable units that contain your applications and configurations</p> <p> Learn about Projects</p> <ul> <li> Clusters</li> </ul> <p>Kubernetes clusters managed by Hexabase.AI for running your workloads</p> <p> Learn about Clusters</p>"},{"location":"concept/#hexabaseai-concept-mapping","title":"Hexabase.AI Concept Mapping","text":"<p>Understanding how Hexabase.AI concepts map to Kubernetes is essential for users and administrators:</p> Hexabase Concept Kubernetes Equivalent Scope Description Organization N/A Platform Billing and user management unit Workspace vCluster Host K3s Isolated Kubernetes environment Workspace Plan ResourceQuota/Nodes vCluster Resource limits and node allocation Organization User N/A Platform Billing/admin personnel Workspace Member OIDC Subject vCluster Technical users with kubectl access Workspace Group OIDC Claim vCluster Permission assignment unit (hierarchical) Project Namespace vCluster Resource isolation within workspace"},{"location":"concept/#multi-tenancy-model","title":"Multi-tenancy Model","text":"<p>Hexabase.AI implements a hierarchical multi-tenancy model:</p> <pre><code>Organization\n\u2514\u2500\u2500 Workspaces\n    \u2514\u2500\u2500 Projects\n        \u2514\u2500\u2500 Resources (Deployments, Services, etc.)\n</code></pre> <p>This structure provides:</p> <ul> <li>Isolation: Complete separation between different organizations</li> <li>Flexibility: Multiple workspaces for different teams or environments</li> <li>Security: Role-based access control at each level</li> <li>Resource Management: Quotas and limits per workspace</li> </ul>"},{"location":"concept/#platform-components","title":"Platform Components","text":""},{"location":"concept/#control-plane","title":"Control Plane","text":"<ul> <li>Manages the overall platform operations</li> <li>Handles authentication and authorization</li> <li>Orchestrates cluster provisioning and management</li> </ul>"},{"location":"concept/#data-plane","title":"Data Plane","text":"<ul> <li>Runs actual workloads in Kubernetes clusters</li> <li>Provides compute, storage, and networking resources</li> <li>Implements security policies and resource quotas</li> </ul>"},{"location":"concept/#aiops-engine","title":"AIOps Engine","text":"<ul> <li>Monitors resource usage and performance</li> <li>Provides intelligent recommendations</li> <li>Automates optimization and scaling decisions</li> </ul>"},{"location":"concept/#next-steps","title":"Next Steps","text":"<ul> <li>New to Hexabase.AI? Start with Organizations to understand the top-level structure</li> <li>Setting up a team? Learn about Workspaces and how to organize your environments</li> <li>Ready to deploy? Understand Projects and how to package your applications</li> <li>Managing infrastructure? Explore Clusters and their capabilities</li> </ul>"},{"location":"concept/#related-documentation","title":"Related Documentation","text":"<ul> <li>Overview</li> <li>Architecture Overview</li> <li>API Reference</li> </ul>"},{"location":"concept/multi-tenancy/","title":"Multi-Tenancy in Hexabase.AI","text":""},{"location":"concept/multi-tenancy/#overview","title":"Overview","text":"<p>Hexabase.AI provides enterprise-grade multi-tenancy through a hierarchical structure built on K3s and vCluster technology. This architecture enables organizations to securely share infrastructure while maintaining strict isolation between different teams, projects, and environments.</p>"},{"location":"concept/multi-tenancy/#hierarchical-structure","title":"Hierarchical Structure","text":"<p>Hexabase.AI implements a three-tier multi-tenancy model:</p> <pre><code>Organization (Billing Entity)\n\u2514\u2500\u2500 Workspaces (vCluster Isolation)\n    \u2514\u2500\u2500 Projects (Namespace Isolation)\n        \u2514\u2500\u2500 Applications &amp; Resources\n</code></pre>"},{"location":"concept/multi-tenancy/#organizations","title":"Organizations","text":"<ul> <li>Purpose: Top-level billing and administrative boundary</li> <li>Scope: Platform-wide entity managed by Hexabase.AI</li> <li>Users: Organization administrators manage billing, user invitations, and workspace creation</li> <li>Isolation: Complete separation between different organizations</li> </ul>"},{"location":"concept/multi-tenancy/#workspaces","title":"Workspaces","text":"<ul> <li>Purpose: Isolated Kubernetes environments for teams or environments (dev/staging/prod)</li> <li>Technology: Each workspace is a dedicated vCluster running on the host K3s cluster</li> <li>Benefits: </li> <li>Complete API server isolation</li> <li>Independent Kubernetes control plane</li> <li>Own RBAC system and resource quotas</li> <li>Optional dedicated nodes for premium plans</li> <li>Users: Workspace members with kubectl access and OIDC authentication</li> </ul>"},{"location":"concept/multi-tenancy/#projects","title":"Projects","text":"<ul> <li>Purpose: Application and resource isolation within a workspace</li> <li>Technology: Kubernetes namespaces within the vCluster</li> <li>Benefits:</li> <li>Resource quotas per project</li> <li>Network policies for isolation</li> <li>Project-specific RBAC roles</li> <li>Environment-specific configurations</li> </ul>"},{"location":"concept/multi-tenancy/#rbac-integration","title":"RBAC Integration","text":""},{"location":"concept/multi-tenancy/#hexabaseai-rbac-kubernetes-rbac","title":"Hexabase.AI RBAC + Kubernetes RBAC","text":"<p>Hexabase.AI implements a dual-layer RBAC system:</p>"},{"location":"concept/multi-tenancy/#platform-level-hexabaseai","title":"Platform Level (Hexabase.AI)","text":"<ul> <li>Organization Users: Platform-level access for billing and administration</li> <li>Workspace Members: Technical users with access to specific workspaces</li> <li>Workspace Groups: Hierarchical permission assignment units</li> </ul>"},{"location":"concept/multi-tenancy/#workspace-level-kubernetesvcluster","title":"Workspace Level (Kubernetes/vCluster)","text":"<ul> <li>ClusterRoles: Workspace-wide permissions (e.g., <code>hexabase:workspace-admin</code>, <code>hexabase:workspace-viewer</code>)</li> <li>Roles: Project-scoped permissions within namespaces</li> <li>OIDC Integration: Hexabase.AI acts as OIDC provider for vClusters</li> </ul>"},{"location":"concept/multi-tenancy/#default-rbac-setup","title":"Default RBAC Setup","text":"<p>When a workspace is created:</p> <ol> <li>Auto-create ClusterRoles:</li> <li><code>hexabase:workspace-admin</code> - Full workspace control</li> <li> <p><code>hexabase:workspace-viewer</code> - Read-only workspace access</p> </li> <li> <p>Create Default Groups:</p> </li> <li><code>WorkspaceMembers</code> \u2192 <code>WSAdmins</code> (administrators)</li> <li> <p><code>WorkspaceMembers</code> \u2192 <code>WSUsers</code> (regular users)</p> </li> <li> <p>Assign Creator: Workspace creator automatically added to <code>WSAdmins</code> group</p> </li> </ol>"},{"location":"concept/multi-tenancy/#permission-flow","title":"Permission Flow","text":"<pre><code>User Login \u2192 OIDC Token \u2192 Group Claims \u2192 vCluster RBAC \u2192 Project Access\n</code></pre> <ul> <li>Users authenticate via external IdP (Google/GitHub)</li> <li>Hexabase.AI adds group claims to OIDC tokens</li> <li>vCluster validates tokens and applies Kubernetes RBAC</li> <li>Users get appropriate access to projects/resources</li> </ul>"},{"location":"concept/multi-tenancy/#isolation-mechanisms","title":"Isolation Mechanisms","text":""},{"location":"concept/multi-tenancy/#vcluster-isolation-workspace-level","title":"vCluster Isolation (Workspace Level)","text":"<p>Each workspace provides complete isolation through:</p> <ul> <li>Dedicated API Server: Independent Kubernetes API server per workspace</li> <li>Separate etcd: Isolated data storage for each workspace</li> <li>Independent Controllers: Workspace-specific controller managers</li> <li>Network Isolation: vCluster networking prevents cross-workspace communication</li> <li>Resource Boundaries: CPU, memory, and storage quotas per workspace</li> </ul>"},{"location":"concept/multi-tenancy/#namespace-isolation-project-level","title":"Namespace Isolation (Project Level)","text":"<p>Within each workspace, projects are isolated via:</p> <ul> <li>Kubernetes Namespaces: Standard namespace-based resource isolation</li> <li>Resource Quotas: Per-project limits on compute and storage resources</li> <li>Network Policies: Project-to-project communication controls</li> <li>RBAC Boundaries: Project-specific roles and permissions</li> </ul>"},{"location":"concept/multi-tenancy/#workspace-management","title":"Workspace Management","text":""},{"location":"concept/multi-tenancy/#workspace-creation-flow","title":"Workspace Creation Flow","text":"<ol> <li>Organization Admin creates workspace through Hexabase.AI UI</li> <li>vCluster Provisioning: New vCluster deployed on host K3s cluster</li> <li>OIDC Configuration: Workspace configured to trust Hexabase.AI as OIDC provider</li> <li>Default Setup: ClusterRoles and groups automatically created</li> <li>User Assignment: Workspace creator added to admin group</li> </ol>"},{"location":"concept/multi-tenancy/#workspace-plans","title":"Workspace Plans","text":"<ul> <li>Shared Plan: Multiple workspaces share the same K3s nodes</li> <li>Dedicated Plan: Workspace gets dedicated K3s nodes for guaranteed resources</li> </ul>"},{"location":"concept/multi-tenancy/#project-management","title":"Project Management","text":"<p>Projects (namespaces) within workspaces can be managed via: - Hexabase.AI UI: Point-and-click project creation and management - kubectl: Direct Kubernetes CLI access with proper RBAC - API: Programmatic project management via Hexabase.AI API</p>"},{"location":"concept/multi-tenancy/#user-workflows","title":"User Workflows","text":""},{"location":"concept/multi-tenancy/#organization-admin-workflow","title":"Organization Admin Workflow","text":"<ol> <li>Create Organization: Automatic on first signup with external IdP</li> <li>Manage Billing: Configure Stripe billing and subscription plans</li> <li>Invite Users: Send invitations to join organization</li> <li>Create Workspaces: Provision isolated environments for teams</li> <li>Monitor Usage: Track resource consumption and costs across workspaces</li> </ol>"},{"location":"concept/multi-tenancy/#workspace-member-workflow","title":"Workspace Member Workflow","text":"<ol> <li>Join Workspace: Accept invitation from organization admin</li> <li>Get Kubeconfig: Download workspace-specific kubeconfig file</li> <li>Create Projects: Set up isolated environments for applications</li> <li>Deploy Applications: Use kubectl, Hexabase.AI UI, or CI/CD pipelines</li> <li>Manage Access: Add project-specific permissions for team members</li> </ol>"},{"location":"concept/multi-tenancy/#security-model","title":"Security Model","text":""},{"location":"concept/multi-tenancy/#authentication-flow","title":"Authentication Flow","text":"<pre><code>External IdP (Google/GitHub) \u2192 Hexabase.AI \u2192 vCluster OIDC \u2192 Kubernetes RBAC\n</code></pre>"},{"location":"concept/multi-tenancy/#key-security-features","title":"Key Security Features","text":"<ul> <li>External IdP Only: No local passwords, all authentication via trusted providers</li> <li>vCluster Isolation: Complete API server isolation prevents cross-workspace access</li> <li>OIDC Integration: Workspace authentication handled by Hexabase.AI OIDC provider</li> <li>Network Policies: Default deny-all policies with explicit allow rules</li> <li>Audit Logging: Complete audit trail of all API operations</li> <li>Policy Enforcement: Kyverno policies for security and compliance</li> </ul>"},{"location":"concept/multi-tenancy/#resource-management","title":"Resource Management","text":""},{"location":"concept/multi-tenancy/#workspace-level-quotas","title":"Workspace-Level Quotas","text":"<p>Each workspace can be configured with: - CPU and memory limits - Storage quotas - Network bandwidth limits - Number of allowed projects/namespaces</p>"},{"location":"concept/multi-tenancy/#project-level-quotas","title":"Project-Level Quotas","text":"<p>Within each workspace, projects have: - Resource requests and limits - Object count limits (pods, services, etc.) - Storage class restrictions - Priority class assignments</p>"},{"location":"concept/multi-tenancy/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"concept/multi-tenancy/#built-in-monitoring","title":"Built-in Monitoring","text":"<ul> <li>Prometheus: Metrics collection per workspace and project</li> <li>Grafana: Pre-built dashboards for workspace and project health</li> <li>Loki: Centralized logging with workspace/project filtering</li> <li>AIOps: AI-powered insights and recommendations per workspace</li> </ul>"},{"location":"concept/multi-tenancy/#cost-tracking","title":"Cost Tracking","text":"<ul> <li>Per-workspace billing: Resource usage tracked and billed separately</li> <li>Project-level costs: Granular cost breakdown within workspaces</li> <li>Resource optimization: AI-powered recommendations for cost reduction</li> </ul>"},{"location":"concept/multi-tenancy/#related-topics","title":"Related Topics","text":"<ul> <li>Technology Stack - Core technologies powering multi-tenancy</li> <li>RBAC Overview - Detailed RBAC implementation</li> <li>Architecture Overview - System architecture and design decisions</li> </ul>"},{"location":"concept/overview/","title":"Hexabase AI Overview","text":"<p>Welcome to Hexabase AI - the next-generation Kubernetes-as-a-Service platform with built-in AI capabilities.</p>"},{"location":"concept/overview/#what-is-hexabase-ai","title":"What is Hexabase AI?","text":"<p>Hexabase AI is a multi-tenant Kubernetes platform that simplifies application deployment and management while providing powerful AI-driven automation features. Built on K3s and vCluster technology, it offers isolated Kubernetes environments with enterprise-grade security and scalability.</p>"},{"location":"concept/overview/#key-features","title":"Key Features","text":""},{"location":"concept/overview/#instant-kubernetes-environments","title":"\ud83d\ude80 Instant Kubernetes Environments","text":"<ul> <li>Workspaces: Isolated vCluster environments provisioned in seconds</li> <li>Projects: Namespace-based resource organization</li> <li>Auto-scaling: Intelligent resource management</li> </ul>"},{"location":"concept/overview/#ai-powered-operations","title":"\ud83e\udd16 AI-Powered Operations","text":"<ul> <li>Smart Troubleshooting: AI agents analyze and fix issues</li> <li>Code Generation: Generate Kubernetes manifests and configurations</li> <li>Performance Optimization: AI-driven resource recommendations</li> </ul>"},{"location":"concept/overview/#developer-friendly","title":"\ud83d\udd27 Developer-Friendly","text":"<ul> <li>Simple CLI: Intuitive command-line interface</li> <li>Web Dashboard: Modern UI for visual management</li> <li>API-First: Complete REST and WebSocket APIs</li> </ul>"},{"location":"concept/overview/#enterprise-ready","title":"\ud83c\udfd7\ufe0f Enterprise Ready","text":"<ul> <li>Multi-tenancy: Complete isolation between workspaces</li> <li>RBAC: Fine-grained access control</li> <li>Compliance: SOC2, HIPAA, GDPR ready</li> <li>High Availability: Built-in redundancy and failover</li> </ul>"},{"location":"concept/overview/#built-in-services","title":"\ud83d\udcbc Built-in Services","text":"<ul> <li>CronJobs: Scheduled task management</li> <li>Serverless Functions: Event-driven compute with Knative</li> <li>Backup &amp; Restore: Automated data protection</li> <li>Monitoring: Integrated Prometheus and Grafana</li> </ul>"},{"location":"concept/overview/#use-cases","title":"Use Cases","text":""},{"location":"concept/overview/#development-teams","title":"Development Teams","text":"<ul> <li>Spin up isolated development environments</li> <li>Test applications in production-like settings</li> <li>Collaborate with built-in access controls</li> </ul>"},{"location":"concept/overview/#devops-engineers","title":"DevOps Engineers","text":"<ul> <li>Automate deployment pipelines</li> <li>Manage multiple environments from one place</li> <li>Monitor and optimize resource usage</li> </ul>"},{"location":"concept/overview/#enterprises","title":"Enterprises","text":"<ul> <li>Provide self-service Kubernetes to teams</li> <li>Maintain compliance and security standards</li> <li>Reduce infrastructure costs</li> </ul>"},{"location":"concept/overview/#aiml-engineers","title":"AI/ML Engineers","text":"<ul> <li>Deploy ML models as serverless functions</li> <li>Schedule training jobs with CronJobs</li> <li>Use AI agents for automated operations</li> </ul>"},{"location":"concept/overview/#how-it-works","title":"How It Works","text":"<ol> <li>Create Organization: Set up your billing and team unit</li> <li>Provision Workspace: Get an isolated Kubernetes environment</li> <li>Deploy Applications: Use kubectl, UI, or API</li> <li>Monitor &amp; Scale: Built-in observability and auto-scaling</li> <li>Collaborate: Invite team members with role-based access</li> </ol>"},{"location":"concept/overview/#platform-architecture","title":"Platform Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User Interface    \u2502\n\u2502  (Web UI / CLI)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Hexabase API      \u2502\n\u2502  (Control Plane)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Host K3s Cluster  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  vCluster       \u2502\n\u2502                     \u2502     \u2502  (Workspace)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Infrastructure    \u2502\n\u2502 (Storage, Network)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concept/overview/#pricing-plans","title":"Pricing Plans","text":""},{"location":"concept/overview/#starter","title":"Starter","text":"<ul> <li>1 workspace</li> <li>2 CPU, 4GB RAM</li> <li>Community support</li> <li>Perfect for individuals</li> </ul>"},{"location":"concept/overview/#pro","title":"Pro","text":"<ul> <li>5 workspaces</li> <li>8 CPU, 32GB RAM</li> <li>Email support</li> <li>Great for small teams</li> </ul>"},{"location":"concept/overview/#enterprise","title":"Enterprise","text":"<ul> <li>Unlimited workspaces</li> <li>Custom resources</li> <li>24/7 support</li> <li>SLA guarantees</li> </ul>"},{"location":"concept/overview/#compare-to-alternatives","title":"Compare to Alternatives","text":"Feature Hexabase AI Traditional K8s Other KaaS Setup Time &lt; 1 minute Hours/Days 10-30 minutes Multi-tenancy Built-in Complex setup Limited AI Operations \u2705 \u274c \u274c Cost Pay-per-use High fixed Variable Learning Curve Low High Medium"},{"location":"concept/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts</li> <li>System Architecture</li> <li>AIOps Engine</li> <li>Join Community</li> </ul>"},{"location":"concept/overview/#questions","title":"Questions?","text":"<ul> <li>Sales: sales@hexabase.ai</li> <li>Support: support@hexabase.ai</li> <li>Documentation: docs.hexabase.ai</li> <li>Status: status.hexabase.ai</li> </ul> <p>Hexabase AI - Kubernetes Made Simple, Powered by AI \ud83d\ude80</p>"},{"location":"concept/technology-stack/","title":"Technology Stack","text":""},{"location":"concept/technology-stack/#overview","title":"Overview","text":"<p>Hexabase.AI is built on a modern, cloud-native technology stack that combines proven CNCF open-source technologies with custom AI-oriented components to deliver a comprehensive AI-first Kubernetes platform.</p>"},{"location":"concept/technology-stack/#core-technologies","title":"Core Technologies","text":""},{"location":"concept/technology-stack/#container-orchestration","title":"Container Orchestration","text":""},{"location":"concept/technology-stack/#k3s-vcluster","title":"K3s + vCluster","text":"<ul> <li>K3s: Lightweight Kubernetes distribution as the host cluster</li> <li>vCluster: Virtual Kubernetes clusters for workspace isolation</li> <li>Benefits: </li> <li>Minimal resource overhead compared to full Kubernetes</li> <li>Complete API server isolation per workspace</li> <li>Production-ready with enterprise features</li> </ul>"},{"location":"concept/technology-stack/#programming-languages-frameworks","title":"Programming Languages &amp; Frameworks","text":""},{"location":"concept/technology-stack/#backend","title":"Backend","text":"<ul> <li>Go (Golang): API server, CLI tools, and core platform components</li> <li>Python: AI operations service, ML pipelines, and automation scripts</li> </ul>"},{"location":"concept/technology-stack/#frontend","title":"Frontend","text":"<ul> <li>Next.js: Modern React-based web UI</li> <li>TypeScript: Type-safe JavaScript for frontend development</li> </ul>"},{"location":"concept/technology-stack/#communication","title":"Communication","text":"<ul> <li>REST APIs: Primary interface for external integrations</li> <li>HTTP/HTTPS: Standard web protocols for all communications</li> <li>WebSocket: Real-time updates and notifications</li> </ul>"},{"location":"concept/technology-stack/#data-layer","title":"Data Layer","text":""},{"location":"concept/technology-stack/#databases","title":"Databases","text":"<ul> <li>PostgreSQL: Primary relational database for all platform data</li> <li>Redis: Caching, session management, and real-time data</li> <li>NATS: Messaging system for async processing and event handling</li> </ul>"},{"location":"concept/technology-stack/#storage","title":"Storage","text":"<ul> <li>Persistent Volumes: Kubernetes-native storage for workloads</li> <li>Cloud Storage: S3, GCS, Azure Blob for backup and object storage</li> <li>MinIO: S3-compatible object storage for on-premises deployments</li> </ul>"},{"location":"concept/technology-stack/#observability-stack","title":"Observability Stack","text":""},{"location":"concept/technology-stack/#monitoring-metrics","title":"Monitoring &amp; Metrics","text":"<ul> <li>Prometheus: Metrics collection and storage</li> <li>Grafana: Visualization and dashboards</li> <li>OpenTelemetry: Distributed tracing and metrics</li> <li>ClickHouse: Time-series analytics and aggregation</li> </ul>"},{"location":"concept/technology-stack/#logging","title":"Logging","text":"<ul> <li>Loki: Log aggregation and storage</li> <li>Grafana: Log visualization and querying</li> <li>Vector: High-performance log processing</li> </ul>"},{"location":"concept/technology-stack/#cicd-gitops","title":"CI/CD &amp; GitOps","text":""},{"location":"concept/technology-stack/#flux","title":"Flux","text":"<ul> <li>GitOps continuous delivery</li> <li>Multi-tenancy support</li> <li>Automatic synchronization with Git repositories</li> </ul>"},{"location":"concept/technology-stack/#tekton","title":"Tekton","text":"<ul> <li>Cloud-native CI/CD pipelines</li> <li>Kubernetes-native workflows</li> <li>Extensible task library</li> </ul>"},{"location":"concept/technology-stack/#security","title":"Security","text":""},{"location":"concept/technology-stack/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<ul> <li>OIDC: OAuth2/OpenID Connect for external identity providers</li> <li>RBAC: Kubernetes role-based access control</li> <li>vCluster Isolation: Complete API server isolation per workspace</li> </ul>"},{"location":"concept/technology-stack/#policy-management","title":"Policy Management","text":"<ul> <li>Kyverno: Kubernetes admission controller for policy enforcement</li> <li>Network Policies: Pod-to-pod communication control</li> <li>Pod Security Standards: Kubernetes-native pod security</li> </ul>"},{"location":"concept/technology-stack/#runtime-security","title":"Runtime Security","text":"<ul> <li>Falco: Runtime security monitoring and threat detection</li> <li>Trivy: Container and infrastructure vulnerability scanning</li> </ul>"},{"location":"concept/technology-stack/#ai-operations","title":"AI Operations","text":""},{"location":"concept/technology-stack/#ai-engine","title":"AI Engine","text":"<ul> <li>Python: Core AI operations service</li> <li>LangChain: LLM application framework for AI agents</li> <li>OpenAI/Claude API: Integration with large language models</li> </ul>"},{"location":"concept/technology-stack/#function-runtime","title":"Function Runtime","text":"<ul> <li>HKS Functions: Serverless function platform for AI workloads</li> <li>Python/Node.js: Supported runtime environments</li> <li>Auto-scaling: AI-powered resource optimization</li> </ul>"},{"location":"concept/technology-stack/#infrastructure","title":"Infrastructure","text":""},{"location":"concept/technology-stack/#virtualization","title":"Virtualization","text":"<ul> <li>Proxmox: VM management for dedicated node plans</li> <li>Cloud Providers: EKS, GKE, AKS, OKE integration</li> </ul>"},{"location":"concept/technology-stack/#networking","title":"Networking","text":"<ul> <li>Calico/Flannel: Container networking</li> <li>NGINX Ingress: HTTP/HTTPS routing and SSL termination</li> <li>Cert-Manager: Automatic TLS certificate management</li> </ul>"},{"location":"concept/technology-stack/#system-architecture","title":"System Architecture","text":""},{"location":"concept/technology-stack/#infrastructure-foundation","title":"Infrastructure Foundation","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Infrastructure              \u2502\n\u2502   Proxmox | AWS | GCP | Azure      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Host K3s Cluster            \u2502\n\u2502    (Lightweight Kubernetes)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concept/technology-stack/#platform-layer","title":"Platform Layer","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Hexabase.AI Control Plane     \u2502\n\u2502    (Go API + PostgreSQL + Redis)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         vClusters (Workspaces)      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502vCluster1\u2502 \u2502vCluster2\u2502 \u2502 ...  \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concept/technology-stack/#application-layer","title":"Application Layer","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          User Workloads             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 AI Apps \u2502 Functions \u2502 Web Services \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      Projects (Namespaces)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concept/technology-stack/#integration-points","title":"Integration Points","text":""},{"location":"concept/technology-stack/#external-services","title":"External Services","text":"<ul> <li>Identity Providers: Google, GitHub, and other OIDC providers</li> <li>Version Control: GitHub, GitLab integration for CI/CD</li> <li>Container Registries: Docker Hub, ECR, GCR, private registries</li> <li>Cloud Storage: S3, GCS, Azure Blob for backups and artifacts</li> <li>AI Services: OpenAI, Anthropic, and other LLM providers</li> </ul>"},{"location":"concept/technology-stack/#api-interfaces","title":"API Interfaces","text":"<ul> <li>REST APIs: Primary interface for all platform operations</li> <li>WebSocket: Real-time notifications and live updates</li> <li>OIDC Provider: Authentication for vClusters and workspaces</li> <li>Kubernetes API: Direct kubectl access to workspaces</li> </ul>"},{"location":"concept/technology-stack/#sdks-cli-tools","title":"SDKs &amp; CLI Tools","text":""},{"location":"concept/technology-stack/#hks-cli","title":"HKS CLI","text":"<ul> <li>Go-based: Native CLI for Hexabase.AI operations</li> <li>Functions: Deploy and manage serverless functions</li> <li>Workspaces: Create and manage isolated environments</li> <li>Projects: Application lifecycle management</li> </ul>"},{"location":"concept/technology-stack/#sdks","title":"SDKs","text":"<ul> <li>Python SDK: For AI/ML workflows and automation</li> <li>JavaScript/Node.js SDK: For web applications and functions</li> <li>REST API: Language-agnostic HTTP interface</li> </ul>"},{"location":"concept/technology-stack/#deployment-options","title":"Deployment Options","text":""},{"location":"concept/technology-stack/#cloud-deployments","title":"Cloud Deployments","text":"<ul> <li>Amazon EKS: Managed Kubernetes on AWS</li> <li>Google GKE: Managed Kubernetes on Google Cloud</li> <li>Azure AKS: Managed Kubernetes on Microsoft Azure</li> <li>Oracle OKE: Managed Kubernetes on Oracle Cloud</li> </ul>"},{"location":"concept/technology-stack/#on-premises","title":"On-Premises","text":"<ul> <li>Proxmox: VM-based deployment with dedicated resources</li> <li>Bare Metal: Direct Kubernetes installation</li> <li>Edge Computing: Lightweight K3s for edge locations</li> </ul>"},{"location":"concept/technology-stack/#performance-scalability","title":"Performance &amp; Scalability","text":""},{"location":"concept/technology-stack/#ai-powered-optimization","title":"AI-Powered Optimization","text":"<ul> <li>Intelligent Scaling: AI-driven resource optimization</li> <li>Predictive Scaling: Learn from workload patterns</li> <li>Cost Optimization: Automatic right-sizing recommendations</li> <li>Performance Insights: AI-generated optimization suggestions</li> </ul>"},{"location":"concept/technology-stack/#multi-tenancy-efficiency","title":"Multi-Tenancy Efficiency","text":"<ul> <li>vCluster Overhead: Minimal resource impact per workspace</li> <li>Shared Infrastructure: Efficient resource utilization</li> <li>Dedicated Nodes: Premium isolation for enterprise workloads</li> </ul>"},{"location":"concept/technology-stack/#development-workflow","title":"Development Workflow","text":""},{"location":"concept/technology-stack/#for-ai-developers","title":"For AI Developers","text":"<ol> <li>Create Workspace: Isolated environment for AI projects</li> <li>Deploy Functions: Serverless AI agent deployment</li> <li>CI/CD Integration: Automated testing and deployment</li> <li>Monitoring: Built-in observability for AI workloads</li> </ol>"},{"location":"concept/technology-stack/#development-tools","title":"Development Tools","text":"<ul> <li>kubectl: Direct Kubernetes access to workspaces</li> <li>HKS CLI: Hexabase.AI-specific operations</li> <li>Docker: Container building and testing</li> <li>VS Code Extensions: IDE integration for seamless development</li> </ul>"},{"location":"concept/technology-stack/#related-topics","title":"Related Topics","text":"<ul> <li>Multi-Tenancy - Understanding workspace and project isolation</li> <li>System Architecture - Detailed technical architecture</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"cronjobs/","title":"CronJobs","text":"<p>Master the deployment and management of scheduled tasks in Hexabase.AI using Kubernetes CronJobs.</p>"},{"location":"cronjobs/#overview","title":"Overview","text":"<p>CronJobs in Hexabase.AI provide a reliable way to run scheduled tasks in your Kubernetes environments. Whether you need to run periodic backups, data processing jobs, or maintenance tasks, our platform simplifies CronJob creation and management while adding enterprise features like monitoring, alerting, and job history tracking.</p>"},{"location":"cronjobs/#cronjob-documentation","title":"CronJob Documentation","text":"<ul> <li> Getting Started</li> </ul> <p>Learn the basics of creating and deploying CronJobs</p> <p> CronJob Basics</p> <ul> <li> Scheduling Patterns</li> </ul> <p>Master cron expressions and scheduling strategies</p> <p> Scheduling Guide</p> <ul> <li> Advanced Configuration</li> </ul> <p>Configure job policies, resources, and dependencies</p> <p> Advanced Config</p> <ul> <li> Monitoring &amp; Debugging</li> </ul> <p>Track job execution and troubleshoot failures</p> <p> Monitoring Guide</p>"},{"location":"cronjobs/#key-features","title":"Key Features","text":""},{"location":"cronjobs/#1-enhanced-scheduling","title":"1. Enhanced Scheduling","text":"<ul> <li>Visual Cron Builder: Create cron expressions with our intuitive UI</li> <li>Timezone Support: Schedule jobs in any timezone</li> <li>Schedule Validation: Prevent invalid cron expressions</li> <li>Next Run Preview: See when your job will run next</li> </ul>"},{"location":"cronjobs/#2-job-management","title":"2. Job Management","text":"<ul> <li>Job History: Track all executions with logs and metrics</li> <li>Manual Triggering: Run jobs on-demand for testing</li> <li>Pause/Resume: Temporarily disable jobs without deletion</li> <li>Batch Operations: Manage multiple CronJobs at once</li> </ul>"},{"location":"cronjobs/#3-enterprise-features","title":"3. Enterprise Features","text":"<ul> <li>Failure Notifications: Get alerted when jobs fail</li> <li>Success Tracking: Monitor job completion rates</li> <li>Resource Limits: Prevent runaway jobs</li> <li>Dependency Management: Chain jobs together</li> </ul>"},{"location":"cronjobs/#4-integration-capabilities","title":"4. Integration Capabilities","text":"<ul> <li>Secret Management: Securely inject credentials</li> <li>ConfigMap Support: Dynamic configuration</li> <li>Volume Mounts: Access persistent data</li> <li>Service Connections: Interact with other services</li> </ul>"},{"location":"cronjobs/#common-use-cases","title":"Common Use Cases","text":""},{"location":"cronjobs/#data-processing","title":"Data Processing","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-etl\nspec:\n  schedule: \"0 2 * * *\" # 2 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: etl-processor\n              image: myapp/etl:latest\n              command: [\"python\", \"etl.py\"]\n</code></pre>"},{"location":"cronjobs/#backup-operations","title":"Backup Operations","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: database-backup\nspec:\n  schedule: \"0 */6 * * *\" # Every 6 hours\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: backup\n              image: postgres:14\n              command: [\"pg_dump\"]\n              env:\n                - name: PGPASSWORD\n                  valueFrom:\n                    secretKeyRef:\n                      name: db-secret\n                      key: password\n</code></pre>"},{"location":"cronjobs/#maintenance-tasks","title":"Maintenance Tasks","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cleanup-old-data\nspec:\n  schedule: \"30 3 * * 0\" # 3:30 AM every Sunday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: cleanup\n              image: myapp/maintenance:latest\n              command: [\"./cleanup.sh\"]\n</code></pre>"},{"location":"cronjobs/#cronjob-lifecycle","title":"CronJob Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Created   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Scheduled  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Running   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502                     \u2502\n                           \u25bc                     \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Paused    \u2502     \u2502  Completed  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                               \u2502\n                                               \u25bc\n                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                        \u2502   History   \u2502\n                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"cronjobs/#best-practices","title":"Best Practices","text":""},{"location":"cronjobs/#1-idempotent-jobs","title":"1. Idempotent Jobs","text":"<p>Design jobs that can be safely re-run without side effects</p>"},{"location":"cronjobs/#2-appropriate-timeouts","title":"2. Appropriate Timeouts","text":"<p>Set realistic deadlines to prevent hanging jobs</p>"},{"location":"cronjobs/#3-resource-limits","title":"3. Resource Limits","text":"<p>Define CPU and memory limits to protect cluster stability</p>"},{"location":"cronjobs/#4-error-handling","title":"4. Error Handling","text":"<p>Implement proper error handling and retry logic</p>"},{"location":"cronjobs/#5-monitoring","title":"5. Monitoring","text":"<p>Set up alerts for job failures and performance issues</p>"},{"location":"cronjobs/#quick-examples","title":"Quick Examples","text":""},{"location":"cronjobs/#simple-hourly-job","title":"Simple Hourly Job","text":"<pre><code>hb cronjob create hourly-report \\\n  --schedule \"0 * * * *\" \\\n  --image myapp/reporter:latest \\\n  --command \"python report.py\"\n</code></pre>"},{"location":"cronjobs/#job-with-environment-variables","title":"Job with Environment Variables","text":"<pre><code>hb cronjob create data-sync \\\n  --schedule \"*/15 * * * *\" \\\n  --image myapp/sync:latest \\\n  --env DATABASE_URL=postgresql://... \\\n  --env API_KEY_FROM_SECRET=api-secret:key\n</code></pre>"},{"location":"cronjobs/#view-job-history","title":"View Job History","text":"<pre><code>hb cronjob history daily-backup --last 10\n</code></pre>"},{"location":"cronjobs/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"cronjobs/#common-issues","title":"Common Issues","text":"<ol> <li> <p>Job Not Running</p> </li> <li> <p>Check cron schedule syntax</p> </li> <li>Verify timezone settings</li> <li> <p>Ensure job is not paused</p> </li> <li> <p>Job Failing</p> </li> <li> <p>Review job logs</p> </li> <li>Check resource limits</li> <li> <p>Verify image availability</p> </li> <li> <p>Performance Issues</p> </li> <li>Monitor resource usage</li> <li>Check for concurrent job limits</li> <li>Review job duration trends</li> </ol>"},{"location":"cronjobs/#next-steps","title":"Next Steps","text":"<ul> <li>New to CronJobs? Start with Getting Started</li> <li>Need scheduling help? Check Scheduling Patterns</li> <li>Advanced usage? Explore Configuration Options</li> <li>Having issues? See Monitoring &amp; Debugging</li> </ul>"},{"location":"cronjobs/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kubernetes Jobs Documentation</li> <li>Functions for event-driven tasks</li> <li>Observability for monitoring</li> <li>API Reference for programmatic access</li> </ul>"},{"location":"cronjobs/examples/","title":"CronJob Examples","text":"<p>This page provides a collection of practical, copy-paste-ready examples for common CronJob use cases in Hexabase.AI.</p>"},{"location":"cronjobs/examples/#example-1-basic-hello-world","title":"Example 1: Basic \"Hello World\"","text":"<p>This is the simplest possible CronJob, which runs every minute and prints the current date. It's useful for verifying that the CronJob scheduler is working correctly.</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello-world\nspec:\n  # Run every minute\n  schedule: \"* * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: hello\n              image: busybox:1.28\n              args:\n                - /bin/sh\n                - -c\n                - date; echo \"Hello, World!\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"cronjobs/examples/#example-2-database-backup","title":"Example 2: Database Backup","text":"<p>This example runs <code>pg_dump</code> to back up a PostgreSQL database and uploads the dump to an S3-compatible object store using the <code>mc</code> (MinIO Client) tool.</p> <ul> <li>Prerequisites:</li> <li>A <code>Secret</code> named <code>db-backup-secrets</code> containing the database password (<code>DB_PASSWORD</code>) and S3 access keys (<code>S3_ACCESS_KEY</code>, <code>S3_SECRET_KEY</code>).</li> <li>Container Image: A custom image that contains both the <code>psql</code> and <code>mc</code> command-line tools.</li> </ul> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-db-backup\nspec:\n  # Run daily at 1:00 AM\n  schedule: \"0 1 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: db-backup\n              image: my-registry/backup-tools:latest\n              command: [\"/bin/sh\", \"-c\"]\n              args:\n                - |\n                  set -e\n                  echo \"Starting database backup...\"\n                  export PGPASSWORD=$DB_PASSWORD\n                  pg_dump -h db.my-app.svc -U admin my_database &gt; /tmp/backup.sql\n\n                  echo \"Uploading backup to S3...\"\n                  mc alias set s3 https://s3.example.com $S3_ACCESS_KEY $S3_SECRET_KEY\n                  mc cp /tmp/backup.sql s3/my-backups/db-$(date +%Y-%m-%d).sql\n\n                  echo \"Backup complete.\"\n              env:\n                - name: DB_PASSWORD\n                  valueFrom:\n                    secretKeyRef:\n                      name: db-backup-secrets\n                      key: DB_PASSWORD\n                - name: S3_ACCESS_KEY\n                  valueFrom:\n                    secretKeyRef:\n                      name: db-backup-secrets\n                      key: S3_ACCESS_KEY\n                - name: S3_SECRET_KEY\n                  valueFrom:\n                    secretKeyRef:\n                      name: db-backup-secrets\n                      key: S3_SECRET_KEY\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"cronjobs/examples/#example-3-application-health-check","title":"Example 3: Application Health Check","text":"<p>This CronJob runs a simple <code>curl</code> command to periodically check the health endpoint of a web service and reports a failure if it doesn't get a <code>200 OK</code> response.</p> <ul> <li>Use Case: A simple, external health check for a critical service.</li> <li>Note: HKS has built-in, more sophisticated health checking, but this is a good example of a simple monitoring task.</li> </ul> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: check-app-health\nspec:\n  # Run every 5 minutes\n  schedule: \"*/5 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: health-checker\n              image: curlimages/curl:latest\n              # The `-f` flag causes curl to exit with an error (non-zero)\n              # if the HTTP status code is not in the 2xx range.\n              # The CronJob will be marked as 'Failed' if the check fails.\n              args: [\"-f\", \"http://my-web-app.production.svc/health\"]\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"cronjobs/examples/#example-4-data-cleanup","title":"Example 4: Data Cleanup","text":"<p>This job runs weekly to clean up old, temporary files from a shared storage volume.</p> <ul> <li>Prerequisites: A <code>PersistentVolumeClaim</code> named <code>shared-temp-storage</code> that is also mounted by your application.</li> </ul> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: weekly-data-cleanup\nspec:\n  # Run every Sunday at 4:00 AM\n  schedule: \"0 4 * * 0\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: cleaner\n              image: busybox:1.28\n              command: [\"/bin/sh\", \"-c\"]\n              # Deletes files older than 7 days from the /data directory\n              args:\n                - \"find /data -type f -mtime +7 -delete\"\n              volumeMounts:\n                - name: temp-data\n                  mountPath: /data\n          volumes:\n            - name: temp-data\n              persistentVolumeClaim:\n                claimName: shared-temp-storage\n          restartPolicy: OnFailure\n</code></pre> <p>These examples can be adapted to a wide variety of scheduled tasks. The key is to find or build a container image with the necessary tools and then orchestrate its execution with a <code>CronJob</code> resource.</p>"},{"location":"cronjobs/integration-patterns/","title":"CronJob Integration Patterns","text":"<p>CronJobs in Hexabase.AI are powerful tools for scheduling tasks, but their true value is unlocked when they are integrated with other services. This guide explores common patterns for using CronJobs to build robust, automated workflows.</p>"},{"location":"cronjobs/integration-patterns/#pattern-1-data-processing-pipeline","title":"Pattern 1: Data Processing Pipeline","text":"<p>Use a sequence of CronJobs to create a scheduled data extraction, transformation, and loading (ETL) pipeline.</p> <p>Scenario: Every night, you need to export data from a production database, anonymize it, and load it into a data warehouse for analytics.</p> <pre><code>graph TD\n    A[CronJob 1: Export&lt;br&gt;1:00 AM] --&gt;|Data written to S3| B(S3 Bucket: Raw Data);\n    B --&gt; C[CronJob 2: Transform&lt;br&gt;2:00 AM];\n    C --&gt;|Anonymized data to S3| D(S3 Bucket: Processed Data);\n    D --&gt; E[CronJob 3: Load&lt;br&gt;3:00 AM];\n    E --&gt; F(Data Warehouse);</code></pre> <ul> <li>Job 1: Export: Runs a container with <code>pg_dump</code> or a custom script to export data from the production PostgreSQL database and upload the raw dump to an S3 bucket.</li> <li>Job 2: Transform: Runs a Python or Spark job that reads the raw data from S3, applies anonymization and transformation logic, and writes the processed data back to a different S3 bucket.</li> <li>Job 3: Load: Runs a script that uses the data warehouse's bulk loading utility (e.g., Snowflake's <code>COPY INTO</code>) to load the processed data from S3.</li> </ul> <p>Key Configuration:</p> <ul> <li>Scheduling: The jobs are scheduled sequentially with enough buffer time in between.</li> <li>Data Transfer: S3 or another object store acts as the intermediary storage layer.</li> <li>Secrets Management: Each job securely mounts the necessary database or S3 credentials from HKS <code>Secrets</code>.</li> </ul>"},{"location":"cronjobs/integration-patterns/#pattern-2-interacting-with-hks-functions","title":"Pattern 2: Interacting with HKS Functions","text":"<p>Combine CronJobs with serverless Functions for lightweight, event-driven tasks.</p> <p>Scenario: You want to send a daily summary email to all users of your application.</p> <ol> <li> <p>The CronJob:</p> <ul> <li>A simple CronJob is scheduled to run once a day.</li> <li>Its only task is to make an HTTP request to the HKS Function Gateway to trigger a specific function.</li> <li>It can pass a payload, such as a security token, in the request.</li> </ul> <pre><code># cronjob-to-trigger-function.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-email-trigger\nspec:\n  schedule: \"0 8 * * *\" # 8 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: trigger\n              image: curlimages/curl:latest\n              args:\n                - \"-X\"\n                - \"POST\"\n                - \"-H\"\n                - \"Authorization: Bearer $(FUNCTION_API_KEY)\"\n                - \"https://my-workspace.hks.gateway/send-summary-email\"\n          restartPolicy: OnFailure\n</code></pre> </li> <li> <p>The HKS Function:</p> <ul> <li>A serverless function written in Node.js or Python.</li> <li>It contains the business logic to query the user database and send emails via a third-party service like SendGrid or AWS SES.</li> <li>This pattern is highly efficient because the complex logic resides in a function that is only loaded and executed on demand, while the CronJob itself is extremely lightweight.</li> </ul> </li> </ol>"},{"location":"cronjobs/integration-patterns/#pattern-3-database-maintenance","title":"Pattern 3: Database Maintenance","text":"<p>Schedule regular maintenance tasks for your stateful applications.</p> <p>Scenario: You need to run a vacuum and analyze operation on a PostgreSQL database every weekend.</p> <ul> <li> <p>The CronJob:</p> </li> <li> <p>Schedules a job to run every Saturday at midnight.</p> </li> <li>The container image is the official <code>postgres</code> image, which includes the <code>psql</code> client tools.</li> <li>The database connection string and password are securely passed from an HKS <code>Secret</code>.</li> </ul> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgres-vacuum\nspec:\n  schedule: \"0 0 * * 6\" # Midnight on Saturday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: db-maintenance\n              image: postgres:14\n              command: [\"psql\"]\n              args: [\"$(PGO_CONNECT_STRING)\", \"-c\", \"VACUUM ANALYZE;\"]\n              env:\n                - name: PGO_CONNECT_STRING\n                  valueFrom:\n                    secretKeyRef:\n                      name: my-db-connection-secret\n                      key: dsn\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"cronjobs/integration-patterns/#pattern-4-aiops-driven-job-scheduling","title":"Pattern 4: AIOps-Driven Job Scheduling","text":"<p>Use HKS webhooks and the AIOps engine to trigger jobs based on system events rather than a fixed schedule.</p> <p>Scenario: You want to automatically run a diagnostic data collection job whenever the AIOps engine detects a \"high error rate\" alert for a specific service.</p> <ol> <li>The Job: A regular Kubernetes <code>Job</code> (not a CronJob) is defined. It contains a script that collects detailed logs, metrics, and memory dumps from the failing application.</li> <li>The Alert Rule: An <code>AlertRule</code> is configured to monitor the error rate.</li> <li>The Webhook: The <code>notification</code> channel for the alert is a generic webhook that points to the HKS API endpoint for creating a new job from the pre-defined job template.</li> </ol> <pre><code># alert-to-trigger-job.yaml\napiVersion: hks.io/v1\nkind: AlertRule\nmetadata:\n  name: high-error-rate-remediation\nspec:\n  condition:\n    # ... alert condition ...\n  notification:\n    channel: \"trigger-diagnostic-job-webhook\"\n---\napiVersion: hks.io/v1\nkind: NotificationChannel\nmetadata:\n  name: trigger-diagnostic-job-webhook\nspec:\n  type: webhook\n  config:\n    # This HKS API endpoint creates a Job from a template\n    url: \"https://api.hks.io/v1/jobs/createFromTemplate\"\n    # The body of the webhook POST contains the template name\n    body: '{\"template\": \"collect-diagnostics-job\"}'\n</code></pre> <p>This pattern creates a powerful, event-driven automation system where the AIOps engine can trigger remediation or diagnostic jobs automatically in response to system health issues.</p>"},{"location":"cronjobs/management/","title":"CronJob Management","text":"<p>This feature allows users to easily create and manage scheduled, recurring tasks within their projects using a standard, robust Kubernetes-native approach.</p>"},{"location":"cronjobs/management/#user-experience-and-workflow","title":"User Experience and Workflow","text":""},{"location":"cronjobs/management/#1-new-application-type","title":"1. New \"Application\" Type","text":"<p>In the UI, when creating a new application, users can select a new type: \"CronJob\".</p>"},{"location":"cronjobs/management/#2-configuration-ui","title":"2. Configuration UI","text":""},{"location":"cronjobs/management/#task-definition-template-based","title":"Task Definition (Template-based)","text":"<ul> <li>Instead of manually entering image details, users can select an existing \"Stateless\" Application from the same Project via a dropdown</li> <li>This action populates the CronJob template with the selected application's container image, environment variables, and resource requests</li> <li>Provides an intuitive \"run a task from this app\" experience</li> </ul>"},{"location":"cronjobs/management/#command-override","title":"Command Override","text":"<p>Users can override the container's default command/arguments specifically for this job.</p>"},{"location":"cronjobs/management/#schedule-configuration","title":"Schedule Configuration","text":"<ul> <li>A user-friendly UI is provided for setting the schedule (e.g., presets for \"hourly,\" \"daily,\" \"weekly\") which translates to a standard cron expression</li> <li>An advanced input field is also available for users to enter a raw <code>cron</code> expression directly</li> </ul>"},{"location":"cronjobs/management/#3-management-features","title":"3. Management Features","text":"<p>Users can: - View a list of their CronJobs - See the last execution time and result - View logs from past runs - Trigger a manual run</p>"},{"location":"cronjobs/management/#backend-implementation","title":"Backend Implementation","text":"<p>The implementation follows a Kubernetes-native approach:</p> <ol> <li> <p>The HKS API server receives the user's configuration and translates it into a standard Kubernetes <code>batch/v1.CronJob</code> resource manifest</p> </li> <li> <p>This manifest is applied to the tenant's vCluster</p> </li> <li> <p>The <code>spec.jobTemplate</code> contains the full pod specification derived from the selected application template and user overrides</p> </li> <li> <p>The entire lifecycle (scheduling, job creation, pod execution, cleanup) is handled by the native Kubernetes CronJob controller within the vCluster, ensuring stability and reliability</p> </li> </ol>"},{"location":"cronjobs/management/#integration-with-functions","title":"Integration with Functions","text":"<p>CronJobs can be used to trigger serverless functions on a schedule: - Configure a CronJob to run a container with <code>curl</code> or similar HTTP client - Set the command to invoke the function's HTTP endpoint - This provides scheduled execution for serverless functions without additional infrastructure</p>"},{"location":"cronjobs/ui-configuration/","title":"UI Configuration for CronJobs","text":"<p>While CronJobs can be managed via YAML manifests and the <code>hks</code> CLI, the Hexabase.AI web UI provides a user-friendly interface for creating, managing, and monitoring your scheduled jobs.</p>"},{"location":"cronjobs/ui-configuration/#creating-a-cronjob-in-the-ui","title":"Creating a CronJob in the UI","text":"<ol> <li>Navigate to your Workspace: Select the workspace where you want the CronJob to run.</li> <li>Go to the CronJobs Section: From the side navigation, click on \"CronJobs\".</li> <li>Click \"Create CronJob\": This will open a step-by-step wizard.</li> </ol>"},{"location":"cronjobs/ui-configuration/#step-1-basic-information","title":"Step 1: Basic Information","text":"<ul> <li>Name: A unique name for your CronJob (e.g., <code>daily-report-generator</code>).</li> <li>Description: An optional description of what the job does.</li> </ul>"},{"location":"cronjobs/ui-configuration/#step-2-job-container","title":"Step 2: Job Container","text":"<p>This section defines the container that will execute your job's logic.</p> <ul> <li>Container Image: The Docker image to run (e.g., <code>my-registry/my-reporting-tool:latest</code>).</li> <li>Command &amp; Arguments: Optionally override the container's default <code>CMD</code> or <code>ENTRYPOINT</code>. You can specify a command and its arguments.</li> <li>Example Command: <code>python</code></li> <li>Example Arguments: <code>-c \"import app; app.run_daily_report()\"</code></li> <li>Image Pull Policy: Set to <code>Always</code> to ensure you are running the latest image, or <code>IfNotPresent</code> for testing.</li> </ul>"},{"location":"cronjobs/ui-configuration/#step-3-schedule","title":"Step 3: Schedule","text":"<p>Define when the job should run using a standard cron schedule string.</p> <ul> <li>Schedule: Enter a cron expression. The UI provides helpful presets and a text explainer.</li> <li>Example for \"every day at 3:00 AM\": <code>0 3 * * *</code></li> <li>Example for \"every 15 minutes\": <code>*/15 * * * *</code></li> <li>Timezone: Select the timezone in which the schedule should be interpreted.</li> </ul>"},{"location":"cronjobs/ui-configuration/#step-4-advanced-settings","title":"Step 4: Advanced Settings","text":"<ul> <li>Restart Policy: What to do if the job's pod fails.</li> <li><code>OnFailure</code>: (Default) Restart the pod if it exits with an error.</li> <li><code>Never</code>: Do not restart the pod.</li> <li>Concurrency Policy: How to handle overlapping job runs.</li> <li><code>Allow</code>: (Default) Allow multiple instances of the job to run concurrently.</li> <li><code>Forbid</code>: Skip the new job run if the previous one is still running.</li> <li><code>Replace</code>: Cancel the currently running job and start the new one.</li> <li>Active Deadline: A timeout for the job. If it runs longer than this, the system will terminate it. (e.g., <code>30m</code>, <code>1h</code>).</li> <li>History Limits:</li> <li>Successful Jobs History Limit: How many completed job pods to keep.</li> <li>Failed Jobs History Limit: How many failed job pods to keep. This is useful for debugging.</li> </ul>"},{"location":"cronjobs/ui-configuration/#step-5-resources-environment","title":"Step 5: Resources &amp; Environment","text":"<ul> <li>Resource Requests &amp; Limits: Specify the CPU and Memory resources for the job's container, just like a regular deployment.</li> <li>Environment Variables: Add environment variables, either as key-value pairs or by importing them from <code>ConfigMaps</code> and <code>Secrets</code>. This is the secure way to pass database credentials or API keys to your job.</li> </ul> <p>After reviewing all the settings, click Create. The CronJob will be created and will trigger its first run at the next scheduled time.</p>"},{"location":"cronjobs/ui-configuration/#monitoring-cronjobs-in-the-ui","title":"Monitoring CronJobs in the UI","text":"<p>The CronJobs section of the UI provides a comprehensive overview of your scheduled tasks.</p> <ul> <li>CronJob List: Shows all configured CronJobs, their schedules, and the status of their last run (<code>Success</code>, <code>Failed</code>, <code>Running</code>).</li> <li>Job History: Click on a CronJob to see a detailed history of all its past runs (jobs).</li> <li>Viewing Logs: For any specific job run, you can view its complete logs with a single click. This is essential for debugging failed jobs.</li> <li>Manual Trigger: You can manually trigger a new run of a CronJob at any time, which is useful for testing.</li> </ul>"},{"location":"functions/","title":"Functions","text":"<p>Deploy and manage serverless functions on Kubernetes with Hexabase.AI's Functions feature.</p>"},{"location":"functions/#overview","title":"Overview","text":"<p>Hexabase.AI Functions brings serverless computing to your Kubernetes infrastructure, allowing you to run code without managing servers or containers. Built on industry-standard frameworks, our Functions feature provides automatic scaling, event-driven execution, and seamless integration with your existing Kubernetes workloads.</p>"},{"location":"functions/#functions-documentation","title":"Functions Documentation","text":"<ul> <li> Quick Start</li> </ul> <p>Deploy your first function in minutes</p> <p> Get Started</p> <ul> <li> Function Types</li> </ul> <p>HTTP endpoints, event handlers, and scheduled functions</p> <p> Function Types</p> <ul> <li> Development Guide</li> </ul> <p>Writing, testing, and debugging functions</p> <p> Development Guide</p> <ul> <li> Deployment</li> </ul> <p>Deploy and manage your functions with ease</p> <p> Deployment Guide</p>"},{"location":"functions/#key-features","title":"Key Features","text":""},{"location":"functions/#1-multi-language-support","title":"1. Multi-Language Support","text":"<ul> <li>Python: Data processing and ML workloads</li> <li>Node.js: API endpoints and webhooks</li> <li>Go: High-performance services</li> <li>Java: Enterprise integrations</li> <li>Custom Runtimes: Bring your own runtime</li> </ul>"},{"location":"functions/#2-event-sources","title":"2. Event Sources","text":"<ul> <li>HTTP Triggers: RESTful APIs and webhooks</li> <li>Message Queues: Kafka, RabbitMQ, NATS</li> <li>Storage Events: S3-compatible object storage</li> <li>Scheduled Events: Cron-based triggers</li> <li>Custom Events: Application-specific triggers</li> </ul>"},{"location":"functions/#3-automatic-scaling","title":"3. Automatic Scaling","text":"<ul> <li>Scale to Zero: Save resources when idle</li> <li>Instant Scale-Up: Handle traffic spikes</li> <li>Concurrent Execution: Process multiple requests</li> <li>Custom Metrics: Scale based on your metrics</li> </ul>"},{"location":"functions/#4-developer-experience","title":"4. Developer Experience","text":"<ul> <li>Local Development: Test functions locally</li> <li>Hot Reload: Instant updates during development</li> <li>Integrated Logging: Centralized function logs</li> <li>Distributed Tracing: Track request flow</li> </ul>"},{"location":"functions/#use-cases","title":"Use Cases","text":""},{"location":"functions/#api-endpoints","title":"API Endpoints","text":"<pre><code># function.py\ndef handle(request):\n    name = request.get('name', 'World')\n    return {\n        'statusCode': 200,\n        'body': f'Hello, {name}!'\n    }\n</code></pre>"},{"location":"functions/#data-processing","title":"Data Processing","text":"<pre><code># process_image.py\nimport base64\nfrom PIL import Image\n\ndef handle(event):\n    # Process uploaded image\n    image_data = base64.b64decode(event['data'])\n    img = Image.open(io.BytesIO(image_data))\n\n    # Resize image\n    thumbnail = img.resize((128, 128))\n\n    # Return processed image\n    output = io.BytesIO()\n    thumbnail.save(output, format='JPEG')\n\n    return {\n        'statusCode': 200,\n        'body': base64.b64encode(output.getvalue()),\n        'headers': {'Content-Type': 'image/jpeg'}\n    }\n</code></pre>"},{"location":"functions/#event-processing","title":"Event Processing","text":"<pre><code>// handle_order.js\nmodule.exports.handle = async (event) =&gt; {\n  const order = JSON.parse(event.data);\n\n  // Process order\n  await validateOrder(order);\n  await chargePayment(order);\n  await sendConfirmation(order);\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      orderId: order.id,\n      status: \"processed\",\n    }),\n  };\n};\n</code></pre>"},{"location":"functions/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Event Source  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Function Router \u2502\u2500\u2500\u2500\u2500\u25b6\u2502 Function Runtime \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502                          \u2502\n                               \u25bc                          \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502    Autoscaler   \u2502     \u2502   Your Function  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"functions/#function-lifecycle","title":"Function Lifecycle","text":"<ol> <li>Development: Write and test locally</li> <li>Packaging: Bundle code and dependencies</li> <li>Deployment: Push to Hexabase.AI</li> <li>Invocation: Triggered by events</li> <li>Scaling: Automatic based on load</li> <li>Monitoring: Track performance and errors</li> </ol>"},{"location":"functions/#quick-examples","title":"Quick Examples","text":""},{"location":"functions/#deploy-a-function","title":"Deploy a Function","text":"<pre><code># Deploy from current directory\nhb function deploy hello-world \\\n  --runtime python3.9 \\\n  --handler function.handle \\\n  --trigger http\n\n# Deploy from Git repository\nhb function deploy data-processor \\\n  --git-url https://github.com/myorg/functions \\\n  --git-path processors/etl \\\n  --trigger cron --schedule \"0 * * * *\"\n</code></pre>"},{"location":"functions/#invoke-a-function","title":"Invoke a Function","text":"<pre><code># HTTP trigger\ncurl https://api.hexabase.ai/functions/hello-world \\\n  -d '{\"name\": \"Alice\"}'\n\n# Direct invocation\nhb function invoke data-processor \\\n  --data '{\"file\": \"s3://bucket/data.csv\"}'\n</code></pre>"},{"location":"functions/#view-function-logs","title":"View Function Logs","text":"<pre><code>hb function logs hello-world --follow\n</code></pre>"},{"location":"functions/#best-practices","title":"Best Practices","text":""},{"location":"functions/#1-stateless-design","title":"1. Stateless Design","text":"<p>Functions should not maintain state between invocations</p>"},{"location":"functions/#2-fast-cold-starts","title":"2. Fast Cold Starts","text":"<p>Minimize dependencies and initialization time</p>"},{"location":"functions/#3-error-handling","title":"3. Error Handling","text":"<p>Implement proper error handling and retries</p>"},{"location":"functions/#4-resource-limits","title":"4. Resource Limits","text":"<p>Set appropriate memory and timeout limits</p>"},{"location":"functions/#5-security","title":"5. Security","text":"<p>Use secrets management for sensitive data</p>"},{"location":"functions/#comparison-with-cronjobs","title":"Comparison with CronJobs","text":"Feature Functions CronJobs Trigger Events, HTTP, Schedule Schedule only Scaling Automatic (0 to N) Fixed replicas Duration Short-lived (seconds-minutes) Long-running possible Use Case API endpoints, webhooks Batch processing, backups"},{"location":"functions/#next-steps","title":"Next Steps","text":"<ul> <li>Get Started: Deploy your first function with our Quick Start</li> <li>Learn More: Explore different Function Types</li> <li>Build: Follow our Development Guide</li> <li>Deploy: Master Deployment</li> </ul>"},{"location":"functions/#related-documentation","title":"Related Documentation","text":"<ul> <li>CronJobs for scheduled batch jobs</li> <li>API Reference for function API</li> <li>Observability for monitoring</li> <li>Security Best Practices</li> </ul>"},{"location":"functions/ai-agent-functions/","title":"AI Agent Functions","text":"<p>A unique and powerful feature of the Hexabase.AI platform is the ability to create AI Agent Functions. These are specialized HKS Functions that are designed to be invoked by the AIOps engine or to act as autonomous agents within your environment.</p>"},{"location":"functions/ai-agent-functions/#what-is-an-ai-agent-function","title":"What is an AI Agent Function?","text":"<p>An AI Agent Function is a serverless function that can:</p> <ul> <li>Be triggered by system events, alerts, or other AIOps signals.</li> <li>Interact with the HKS and Kubernetes APIs to observe and act upon the environment.</li> <li>Leverage a secure sandbox with built-in access to Large Language Models (LLMs).</li> <li>Execute complex, multi-step logic to perform autonomous tasks.</li> </ul> <p>This enables you to create powerful, custom automations and \"self-healing\" workflows that go far beyond simple webhooks.</p>"},{"location":"functions/ai-agent-functions/#use-cases","title":"Use Cases","text":"<ul> <li>Automated Diagnostics: When an alert fires, an agent function can automatically run a series of diagnostic commands (<code>describe pod</code>, fetch logs, check metrics) and post a rich summary to Slack.</li> <li>Cost-Optimization Agent: A scheduled agent function can run daily, scan for under-utilized resources (like idle deployments or oversized PVCs), and suggest cost-saving actions.</li> <li>Security Response Agent: When a security vulnerability is detected, an agent can automatically check if the affected image is running in production, create a Jira ticket, and notify the relevant team.</li> <li>Custom ChatOps Bot: Create a chatbot that listens for commands in Slack (e.g., <code>@hks-bot deploy my-app to staging</code>) and uses an agent function to safely execute the requested action after performing validation checks.</li> </ul>"},{"location":"functions/ai-agent-functions/#developing-an-agent-function","title":"Developing an Agent Function","text":"<p>Developing an agent function is similar to developing a standard HKS Function, but with a few key differences.</p>"},{"location":"functions/ai-agent-functions/#1-the-hks-sdk","title":"1. The HKS SDK","text":"<p>The primary difference is the use of the HKS SDK, which is automatically available in the agent runtime. This SDK provides pre-authenticated clients for interacting with platform services.</p> <p>Python Agent Example:</p> <pre><code># main.py\nfrom hks_sdk import hks, llm\n\ndef handler(event, context):\n    \"\"\"\n    This agent is triggered by an 'HighLatency' alert.\n    The event payload contains details about the alert.\n    \"\"\"\n\n    # --- 1. Observe ---\n    # Get details from the alert payload\n    app_name = event[\"alert\"][\"labels\"][\"app\"]\n    workspace = event[\"alert\"][\"labels\"][\"workspace\"]\n\n    # Use the SDK to get the pods for the affected application\n    pods = hks.apps.pods.list(workspace=workspace, selector=f\"app={app_name}\")\n\n    if not pods:\n        return {\"status\": \"noop\", \"reason\": \"No pods found for app.\"}\n\n    # --- 2. Orient &amp; Decide ---\n    # Use the LLM to summarize the pod logs and suggest a cause\n    pod_logs = hks.apps.pods.logs(workspace=workspace, name=pods[0].name, tail=100)\n\n    prompt = f\"\"\"\n    The following logs are from a pod experiencing high latency.\n    Summarize the potential root cause in one sentence.\n    Logs: {pod_logs}\n    \"\"\"\n\n    summary = llm.invoke(prompt) # Secure, sandboxed call to an LLM\n\n    # --- 3. Act ---\n    # Post the findings to a Slack channel\n    message = f\"*[High Latency Alert for {app_name}]*\\n\" \\\n              f\"*AI Summary:* {summary}\\n\" \\\n              f\"Found {len(pods)} pods. Check dashboard for full logs.\"\n\n    hks.notifications.slack.post(channel=\"#ops-alerts\", text=message)\n\n    return {\"status\": \"complete\", \"action_taken\": \"posted_summary_to_slack\"}\n</code></pre>"},{"location":"functions/ai-agent-functions/#2-the-trigger","title":"2. The Trigger","text":"<p>Instead of a standard HTTP trigger, an agent function is typically triggered by an <code>AIOpsTrigger</code>.</p> <pre><code># function.yaml for an AI Agent\napiVersion: hks.io/v1\nkind: Function\nmetadata:\n  name: high-latency-diagnostics-agent\nspec:\n  runtime:\n    name: python-agent # Use the special 'agent' runtime\n    version: \"3.9\"\n  handler: main.handler\n\n  # Trigger the function when a specific alert fires\n  trigger:\n    type: aiops\n    filter:\n      # Corresponds to the name of an AlertRule\n      alertName: \"HighAPILatency\"\n\n  # Grant the function permission to read pods and logs\n  permissions:\n    - resources: [\"pods\", \"pods/log\"]\n      verbs: [\"get\", \"list\"]\n    - resources: [\"notifications\"]\n      verbs: [\"create\"]\n</code></pre> <p>When the <code>HighAPILatency</code> alert fires, the AIOps engine will invoke this function and pass the full alert object as the <code>event</code> payload.</p>"},{"location":"functions/ai-agent-functions/#3-permissions-rbac-for-functions","title":"3. Permissions (RBAC for Functions)","text":"<p>Because agent functions can interact with the HKS API, they are subject to RBAC. The <code>permissions</code> section in the <code>function.yaml</code> grants the function a specific, short-lived set of permissions that it can use during its execution. This ensures that even if a function has a bug, its potential impact is limited to its stated permissions (Principle of Least Privilege).</p>"},{"location":"functions/ai-agent-functions/#secure-llm-integration","title":"Secure LLM Integration","text":"<p>A key feature of the agent runtime is the sandboxed LLM client (<code>hks_sdk.llm</code>).</p> <ul> <li>No API Keys Needed: You do not need to manage or embed your own OpenAI or other LLM provider keys.</li> <li>Data Sanitization: The HKS platform acts as a proxy, automatically sanitizing data sent to the LLM to remove sensitive information like PII, credentials, and internal hostnames.</li> <li>Model Choice: You can configure which underlying model the agent uses (e.g., GPT-4, Claude 3, or a fine-tuned model) at the workspace level.</li> </ul> <p>This provides a secure and easy way to add powerful AI reasoning capabilities to your automated workflows.</p>"},{"location":"functions/architecture/","title":"Function Service Architecture","text":""},{"location":"functions/architecture/#overview","title":"Overview","text":"<p>The Function Service in Hexabase AI provides a serverless compute platform for running user-defined functions in response to events or HTTP requests. Built on top of Knative, it offers automatic scaling, multi-language support, and seamless integration with other Hexabase AI services.</p>"},{"location":"functions/architecture/#architecture-components","title":"Architecture Components","text":""},{"location":"functions/architecture/#1-core-components","title":"1. Core Components","text":"<pre><code>graph TB\n    subgraph \"Control Plane\"\n        API[Function API]\n        Controller[Function Controller]\n        Registry[Function Registry]\n        Builder[Function Builder]\n    end\n\n    subgraph \"Host K3s Cluster\"\n        Knative[Knative Serving]\n        Kourier[Kourier Gateway]\n        EventBus[Event Bus]\n        Storage[Function Storage]\n    end\n\n    subgraph \"Tenant vCluster\"\n        Function[User Function]\n        Trigger[Event Trigger]\n        Binding[Service Binding]\n    end\n\n    API --&gt; Controller\n    Controller --&gt; Knative\n    Controller --&gt; Registry\n    Builder --&gt; Storage\n    Knative --&gt; Function\n    EventBus --&gt; Trigger\n    Trigger --&gt; Function\n    Function --&gt; Binding\n    Kourier --&gt; Function</code></pre>"},{"location":"functions/architecture/#2-key-components","title":"2. Key Components","text":""},{"location":"functions/architecture/#function-api","title":"Function API","text":"<ul> <li>RESTful API for function management</li> <li>Handles CRUD operations for functions</li> <li>Manages function deployments and versions</li> <li>Provides execution endpoints</li> </ul>"},{"location":"functions/architecture/#function-controller","title":"Function Controller","text":"<ul> <li>Orchestrates function lifecycle</li> <li>Manages Knative resources</li> <li>Handles scaling and resource allocation</li> <li>Monitors function health</li> </ul>"},{"location":"functions/architecture/#function-registry","title":"Function Registry","text":"<ul> <li>Stores function metadata</li> <li>Manages function versions</li> <li>Tracks deployment history</li> <li>Handles function discovery</li> </ul>"},{"location":"functions/architecture/#function-builder","title":"Function Builder","text":"<ul> <li>Builds container images from source code</li> <li>Supports multiple language runtimes</li> <li>Handles dependency management</li> <li>Pushes images to registry</li> </ul>"},{"location":"functions/architecture/#function-types","title":"Function Types","text":""},{"location":"functions/architecture/#1-http-functions","title":"1. HTTP Functions","text":"<ul> <li>Triggered by HTTP requests</li> <li>Synchronous execution</li> <li>Request/response pattern</li> <li>Auto-scaling based on traffic</li> </ul>"},{"location":"functions/architecture/#2-event-functions","title":"2. Event Functions","text":"<ul> <li>Triggered by events (CloudEvents)</li> <li>Asynchronous execution</li> <li>Event-driven pattern</li> <li>Auto-scaling based on queue depth</li> </ul>"},{"location":"functions/architecture/#3-scheduled-functions","title":"3. Scheduled Functions","text":"<ul> <li>Triggered by cron schedules</li> <li>Periodic execution</li> <li>Integrated with CronJob service</li> <li>Time-based scaling</li> </ul>"},{"location":"functions/architecture/#4-stream-functions","title":"4. Stream Functions","text":"<ul> <li>Process streaming data</li> <li>Continuous execution</li> <li>Integrated with event streams</li> <li>Throughput-based scaling</li> </ul>"},{"location":"functions/architecture/#supported-runtimes","title":"Supported Runtimes","text":""},{"location":"functions/architecture/#language-runtimes","title":"Language Runtimes","text":"<ol> <li>Node.js (14, 16, 18, 20)</li> <li>Python (3.8, 3.9, 3.10, 3.11)</li> <li>Go (1.19, 1.20, 1.21)</li> <li>Java (11, 17, 21)</li> <li>.NET (6.0, 7.0, 8.0)</li> <li>Ruby (3.0, 3.1, 3.2)</li> <li>PHP (8.0, 8.1, 8.2)</li> <li>Rust (latest stable)</li> </ol>"},{"location":"functions/architecture/#custom-runtimes","title":"Custom Runtimes","text":"<ul> <li>Bring Your Own Runtime (BYOR)</li> <li>Container-based functions</li> <li>WebAssembly support (experimental)</li> </ul>"},{"location":"functions/architecture/#function-lifecycle","title":"Function Lifecycle","text":""},{"location":"functions/architecture/#1-development","title":"1. Development","text":"<pre><code># Using hks-func CLI\nhks-func init --runtime python\nhks-func develop\nhks-func test\n</code></pre>"},{"location":"functions/architecture/#2-deployment","title":"2. Deployment","text":"<pre><code># Deploy function\nhks-func deploy --name my-function --runtime python\n\n# Update function\nhks-func update --name my-function --env KEY=value\n\n# Version management\nhks-func deploy --name my-function --tag v2\nhks-func rollback --name my-function --version v1\n</code></pre>"},{"location":"functions/architecture/#3-execution","title":"3. Execution","text":"<ul> <li>Cold start optimization</li> <li>Warm instance pooling</li> <li>Concurrent request handling</li> <li>Automatic retry on failure</li> </ul>"},{"location":"functions/architecture/#4-monitoring","title":"4. Monitoring","text":"<ul> <li>Execution metrics</li> <li>Performance tracking</li> <li>Error logging</li> <li>Cost analytics</li> </ul>"},{"location":"functions/architecture/#scaling-configuration","title":"Scaling Configuration","text":""},{"location":"functions/architecture/#autoscaling-metrics","title":"Autoscaling Metrics","text":"<ol> <li>Concurrency - Number of simultaneous requests</li> <li>RPS - Requests per second</li> <li>CPU - CPU utilization</li> <li>Memory - Memory usage</li> <li>Custom - User-defined metrics</li> </ol>"},{"location":"functions/architecture/#scaling-profiles","title":"Scaling Profiles","text":""},{"location":"functions/architecture/#default-profile","title":"Default Profile","text":"<pre><code>minScale: 0\nmaxScale: 100\ntarget: 100\nmetric: concurrency\nscaleDownDelay: 30s\n</code></pre>"},{"location":"functions/architecture/#high-performance-profile","title":"High-Performance Profile","text":"<pre><code>minScale: 1\nmaxScale: 500\ntarget: 50\nmetric: rps\nscaleDownDelay: 60s\n</code></pre>"},{"location":"functions/architecture/#mlai-profile","title":"ML/AI Profile","text":"<pre><code>minScale: 1\nmaxScale: 50\ntarget: 80\nmetric: cpu\nscaleDownDelay: 300s\n</code></pre>"},{"location":"functions/architecture/#security","title":"Security","text":""},{"location":"functions/architecture/#1-authentication","title":"1. Authentication","text":"<ul> <li>JWT token validation</li> <li>API key authentication</li> <li>OAuth 2.0 support</li> <li>Service account integration</li> </ul>"},{"location":"functions/architecture/#2-authorization","title":"2. Authorization","text":"<ul> <li>Role-based access control (RBAC)</li> <li>Function-level permissions</li> <li>Namespace isolation</li> <li>Resource quotas</li> </ul>"},{"location":"functions/architecture/#3-network-security","title":"3. Network Security","text":"<ul> <li>TLS encryption</li> <li>Network policies</li> <li>Ingress filtering</li> <li>DDoS protection</li> </ul>"},{"location":"functions/architecture/#4-runtime-security","title":"4. Runtime Security","text":"<ul> <li>Sandboxed execution</li> <li>Resource limits</li> <li>Security scanning</li> <li>Vulnerability detection</li> </ul>"},{"location":"functions/architecture/#integration-points","title":"Integration Points","text":""},{"location":"functions/architecture/#1-event-sources","title":"1. Event Sources","text":"<ul> <li>HTTP/HTTPS endpoints</li> <li>Message queues (NATS, Kafka)</li> <li>Database triggers</li> <li>Storage events</li> <li>Custom event sources</li> </ul>"},{"location":"functions/architecture/#2-service-bindings","title":"2. Service Bindings","text":"<ul> <li>Database connections</li> <li>Cache services</li> <li>Storage buckets</li> <li>External APIs</li> <li>Secrets management</li> </ul>"},{"location":"functions/architecture/#3-observability","title":"3. Observability","text":"<ul> <li>Prometheus metrics</li> <li>Distributed tracing</li> <li>Structured logging</li> <li>Custom dashboards</li> </ul>"},{"location":"functions/architecture/#performance-optimization","title":"Performance Optimization","text":""},{"location":"functions/architecture/#1-cold-start-reduction","title":"1. Cold Start Reduction","text":"<ul> <li>Pre-warmed instances</li> <li>Lightweight base images</li> <li>Lazy loading</li> <li>Connection pooling</li> </ul>"},{"location":"functions/architecture/#2-resource-optimization","title":"2. Resource Optimization","text":"<ul> <li>Right-sizing containers</li> <li>Memory caching</li> <li>CPU profiling</li> <li>Network optimization</li> </ul>"},{"location":"functions/architecture/#3-cost-optimization","title":"3. Cost Optimization","text":"<ul> <li>Scale-to-zero</li> <li>Spot instance usage</li> <li>Resource sharing</li> <li>Execution batching</li> </ul>"},{"location":"functions/architecture/#best-practices","title":"Best Practices","text":""},{"location":"functions/architecture/#1-function-design","title":"1. Function Design","text":"<ul> <li>Keep functions small and focused</li> <li>Minimize dependencies</li> <li>Use async/await patterns</li> <li>Handle errors gracefully</li> </ul>"},{"location":"functions/architecture/#2-configuration","title":"2. Configuration","text":"<ul> <li>Use environment variables</li> <li>Externalize configuration</li> <li>Version your functions</li> <li>Document dependencies</li> </ul>"},{"location":"functions/architecture/#3-testing","title":"3. Testing","text":"<ul> <li>Unit test functions</li> <li>Integration testing</li> <li>Load testing</li> <li>Chaos testing</li> </ul>"},{"location":"functions/architecture/#4-deployment","title":"4. Deployment","text":"<ul> <li>Use CI/CD pipelines</li> <li>Blue-green deployments</li> <li>Canary releases</li> <li>Automated rollbacks</li> </ul>"},{"location":"functions/architecture/#troubleshooting","title":"Troubleshooting","text":""},{"location":"functions/architecture/#common-issues","title":"Common Issues","text":"<ol> <li>Cold Start Latency</li> <li>Solution: Increase min instances</li> <li>Use lighter runtimes</li> <li> <p>Optimize initialization</p> </li> <li> <p>Memory Errors</p> </li> <li>Solution: Increase memory limits</li> <li>Check for memory leaks</li> <li> <p>Optimize data structures</p> </li> <li> <p>Timeout Errors</p> </li> <li>Solution: Increase timeout</li> <li>Optimize function logic</li> <li> <p>Use async processing</p> </li> <li> <p>Scaling Issues</p> </li> <li>Solution: Adjust scaling metrics</li> <li>Review resource limits</li> <li>Check cluster capacity</li> </ol>"},{"location":"functions/architecture/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>GPU Support - For ML/AI workloads</li> <li>Edge Functions - Deploy to edge locations</li> <li>Function Composition - Chain functions together</li> <li>State Management - Durable function execution</li> <li>WebAssembly - Full WASM support</li> <li>Polyglot Functions - Multiple languages in one function</li> </ol>"},{"location":"functions/deployment/","title":"Function Deployment","text":"<p>Once you have developed and tested your function locally, the next step is to deploy it to the Hexabase.AI platform. Deployment packages your code and dependencies, and makes your function available via a secure HTTP endpoint.</p>"},{"location":"functions/deployment/#deployment-methods","title":"Deployment Methods","text":"<p>You can deploy functions using two primary methods:</p> <ol> <li>Using the HKS CLI: The recommended method for automated, CI/CD-driven deployments.</li> <li>Using the HKS UI: A user-friendly, wizard-based approach for manual deployments.</li> </ol>"},{"location":"functions/deployment/#the-functionyaml-manifest","title":"The <code>function.yaml</code> Manifest","text":"<p>The deployment of a function and its configuration are defined in a <code>function.yaml</code> manifest file. This file should be stored alongside your function code in version control.</p> <pre><code># function.yaml\napiVersion: hks.io/v1\nkind: Function\nmetadata:\n  name: my-hello-world-function\n  # This function will be deployed to the 'development' workspace\n  workspace: development\nspec:\n  # The function's source code details\n  source:\n    # Path to the directory containing your code and dependencies\n    path: ./src\n\n  # The runtime environment for the function\n  runtime:\n    name: python\n    version: \"3.9\"\n\n  # The entry point for the function\n  handler: main.handler # (file.function_name)\n\n  # Configuration for the HTTP endpoint\n  trigger:\n    type: http\n    # The path where the function will be exposed\n    path: /api/hello\n    method: GET\n    auth:\n      # 'public' makes the endpoint available without authentication\n      # 'token' would require a valid HKS JWT\n      type: public\n\n  # Resource allocation for the function\n  resources:\n    memory: 128Mi\n    cpu: \"100m\"\n    timeout: 30s # Function will time out after 30 seconds\n\n  # Environment variables and secrets\n  environment:\n    variables:\n      LOG_LEVEL: \"debug\"\n    secrets:\n      - name: MY_API_KEY\n        secretName: external-service-key\n        secretKey: api-key\n</code></pre>"},{"location":"functions/deployment/#deployment-with-the-hks-cli","title":"Deployment with the HKS CLI","text":"<p>The <code>hb function deploy</code> command reads your <code>function.yaml</code>, packages the source code directory, and deploys it to your workspace.</p> <pre><code># Deploy the function defined in the current directory's function.yaml\nhb function deploy\n</code></pre> <p>What happens during deployment:</p> <ol> <li>The CLI archives the source directory specified in <code>function.yaml</code>.</li> <li>It uploads the archive to the HKS build service.</li> <li>The build service creates a container image for your function:<ul> <li>It uses the specified runtime base image.</li> <li>It installs any dependencies from <code>requirements.txt</code> or <code>package.json</code>.</li> <li>It adds your function code to the image.</li> </ul> </li> <li>The new function image is pushed to the secure, internal HKS container registry.</li> <li>The HKS FaaS (Function-as-a-Service) controller updates the function's configuration, pointing it to the new image.</li> <li>The HTTP endpoint is created or updated in the Function Gateway.</li> </ol> <p>Subsequent deployments will create a new version of the function, and you can easily roll back to a previous version if needed.</p> <pre><code># Roll back to the previous version of a function\nhb function rollback my-hello-world-function\n</code></pre>"},{"location":"functions/deployment/#cicd-integration","title":"CI/CD Integration","text":"<p>For a robust workflow, integrate function deployment into your CI/CD pipeline.</p> <p>Example GitLab CI Job:</p> <pre><code>deploy_function:\n  stage: deploy\n  image: hexabase/hks-cli:latest\n  script:\n    - echo \"Deploying my-hello-world-function...\"\n    # The HKS_API_KEY for a service account should be stored as a secure CI/CD variable\n    - hb function deploy --api-key $HKS_API_KEY\n  rules:\n    # Only run when changes are made in the function's source directory\n    - changes:\n        - functions/my-hello-world/**/*\n</code></pre>"},{"location":"functions/deployment/#viewing-deployment-status","title":"Viewing Deployment Status","text":"<p>You can check the status and details of your deployed functions at any time.</p> <pre><code># List all functions in your current workspace\nhb function list\n\n# Get detailed information about a specific function, including its endpoint URL\nhb function get my-hello-world-function\n\n# View the real-time logs for a function\nhb function logs -f my-hello-world-function\n</code></pre> <p>The HKS UI also provides a complete overview of all your deployed functions, their versions, invocation metrics, and logs.</p>"},{"location":"functions/development/","title":"Function Development","text":"<p>Developing serverless functions in Hexabase.AI is designed to be a straightforward and familiar experience for developers. You can write functions in your preferred language, manage dependencies, and test locally before deploying.</p>"},{"location":"functions/development/#supported-runtimes","title":"Supported Runtimes","text":"<p>Hexabase.AI provides managed, secure runtimes for several popular languages:</p> <ul> <li>Node.js (v18, v20)</li> <li>Python (v3.9, v3.11)</li> <li>Go (v1.21)</li> </ul> <p>These runtimes are optimized for fast cold starts and include common libraries.</p>"},{"location":"functions/development/#function-structure","title":"Function Structure","text":"<p>A function is essentially a single file with a specific handler signature.</p>"},{"location":"functions/development/#python-example","title":"Python Example","text":"<p>Your file (<code>main.py</code>) must contain a function named <code>handler</code>.</p> <pre><code># main.py\nimport json\n\ndef handler(event, context):\n    \"\"\"\n    The main entry point for the function.\n\n    :param event: A dictionary containing the request payload and headers.\n    :param context: A dictionary containing runtime information (e.g., request ID).\n    :return: A dictionary that will be serialized as the HTTP response.\n    \"\"\"\n\n    # Get name from query parameter or request body\n    name = \"World\"\n    if event.get(\"queryStringParameters\") and \"name\" in event[\"queryStringParameters\"]:\n        name = event[\"queryStringParameters\"][\"name\"]\n    elif event.get(\"body\"):\n        try:\n            body = json.loads(event[\"body\"])\n            if \"name\" in body:\n                name = body[\"name\"]\n        except json.JSONDecodeError:\n            pass\n\n    response_body = {\n        \"message\": f\"Hello, {name}!\"\n    }\n\n    return {\n        \"statusCode\": 200,\n        \"headers\": {\n            \"Content-Type\": \"application/json\"\n        },\n        \"body\": json.dumps(response_body)\n    }\n</code></pre> <ul> <li><code>event</code>: Contains all the information about the HTTP request that triggered the function, including <code>httpMethod</code>, <code>path</code>, <code>headers</code>, <code>queryStringParameters</code>, and <code>body</code>.</li> <li><code>context</code>: Provides information about the invocation, function, and execution environment.</li> <li>Return Value: The dictionary returned by the handler is transformed into an HTTP response. You must specify <code>statusCode</code>, <code>headers</code>, and a stringified <code>body</code>.</li> </ul>"},{"location":"functions/development/#nodejs-example","title":"Node.js Example","text":"<p>Your file (<code>index.js</code>) must export an <code>async</code> function named <code>handler</code>.</p> <pre><code>// index.js\nexports.handler = async (event, context) =&gt; {\n  let name = \"World\";\n\n  if (event.queryStringParameters &amp;&amp; event.queryStringParameters.name) {\n    name = event.queryStringParameters.name;\n  } else if (event.body) {\n    try {\n      const body = JSON.parse(event.body);\n      if (body.name) {\n        name = body.name;\n      }\n    } catch (e) {\n      // Ignore JSON parsing errors\n    }\n  }\n\n  const responseBody = {\n    message: `Hello, ${name}!`,\n  };\n\n  const response = {\n    statusCode: 200,\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify(responseBody),\n  };\n\n  return response;\n};\n</code></pre>"},{"location":"functions/development/#managing-dependencies","title":"Managing Dependencies","text":""},{"location":"functions/development/#python-requirementstxt","title":"Python (<code>requirements.txt</code>)","text":"<p>For Python functions, you can specify third-party libraries by including a <code>requirements.txt</code> file in your function's directory.</p> <pre><code># requirements.txt\nrequests==2.28.1\npyjwt&gt;=2.0.0\n</code></pre> <p>When you deploy the function, HKS will automatically install these dependencies into the function's environment.</p>"},{"location":"functions/development/#nodejs-packagejson","title":"Node.js (<code>package.json</code>)","text":"<p>For Node.js functions, include a <code>package.json</code> file.</p> <pre><code>{\n  \"name\": \"my-hks-function\",\n  \"version\": \"1.0.0\",\n  \"dependencies\": {\n    \"axios\": \"^1.4.0\",\n    \"lodash\": \"^4.17.21\"\n  }\n}\n</code></pre> <p>The HKS build process will run <code>npm install</code> to bundle the dependencies with your function.</p>"},{"location":"functions/development/#local-development-and-testing","title":"Local Development and Testing","text":"<p>You can develop and test your functions locally without needing to deploy them first. The HKS CLI provides a local invocation tool.</p> <ol> <li>Write your function (<code>main.py</code> or <code>index.js</code>) and its dependency file.</li> <li> <p>Run the local invoke command:</p> <pre><code># For a Python function\nhb function invoke-local main.py --event sample-event.json\n\n# For a Node.js function\nhb function invoke-local index.js --event sample-event.json\n</code></pre> </li> <li> <p>Create a sample event file (<code>sample-event.json</code>) to simulate an HTTP request:     <pre><code>{\n  \"httpMethod\": \"POST\",\n  \"path\": \"/hello\",\n  \"queryStringParameters\": {\n    \"source\": \"local\"\n  },\n  \"body\": \"{\\\"name\\\": \\\"developer\\\"}\"\n}\n</code></pre></p> </li> </ol> <p>The <code>invoke-local</code> command runs your function in a local container that closely mimics the production HKS runtime environment, providing an accurate testing experience.</p>"},{"location":"functions/development/#accessing-secrets-and-environment-variables","title":"Accessing Secrets and Environment Variables","text":"<p>Never hard-code sensitive information in your function code.</p> <ul> <li>Environment Variables: You can configure environment variables when you deploy your function.</li> <li>Secrets: For sensitive data like API keys or database passwords, mount them as environment variables from HKS Secrets.</li> </ul> <p>When you deploy a function, you can specify environment variables and secret references in the UI or in your <code>function.yaml</code> file. These will be securely injected into the function's runtime environment.</p> <pre><code># In your function.yaml\n---\nspec:\n  environment:\n    variables:\n      LOG_LEVEL: \"info\"\n    secrets:\n      - name: STRIPE_API_KEY\n        secretName: payment-gateway-secret\n        secretKey: api-key\n</code></pre> <p>Inside your function code, you can then access these as standard environment variables: <code>os.environ.get(\"LOG_LEVEL\")</code> or <code>process.env.STRIPE_API_KEY</code>.</p>"},{"location":"functions/overview/","title":"HKS Functions (Serverless Platform)","text":"<p>HKS Functions provides a managed Function-as-a-Service (FaaS) experience, enabling developers to deploy and run event-driven code without managing underlying infrastructure. This feature is built on top of Knative.</p>"},{"location":"functions/overview/#core-architecture","title":"Core Architecture","text":""},{"location":"functions/overview/#platform-level-knative","title":"Platform-Level Knative","text":"<ul> <li>Knative Serving and Knative Functions (<code>kn func</code>) components are installed by platform administrators once on the Host K3s Cluster</li> <li>This forms the serverless backbone for all tenants</li> </ul>"},{"location":"functions/overview/#developer-centric-experience-devex","title":"Developer-Centric Experience (DevEx)","text":"<p>The primary interface for developers is a dedicated CLI tool:</p> <ul> <li><code>hks-func</code> CLI: A wrapper around the standard <code>kn func</code> CLI</li> <li>Automates HKS authentication and context configuration</li> <li>Fetches the correct Kubeconfig for the target project</li> </ul> <p>Sample Workflow: <pre><code>$ hb login\n$ hb project select my-serverless-project\n$ hks-func create -l node my-function\n# ... edit function code ...\n$ hks-func deploy\n</code></pre></p>"},{"location":"functions/overview/#ui-for-management","title":"UI for Management","text":"<p>The HKS UI serves as a management and observability dashboard for deployed functions: - View a list of all functions within a project - See function status, invocation endpoints (URLs), and resource consumption - Access real-time logs and performance metrics</p>"},{"location":"functions/overview/#function-invocation-patterns","title":"Function Invocation Patterns","text":""},{"location":"functions/overview/#http-trigger","title":"HTTP Trigger","text":"<ul> <li>Knative automatically provides a public URL for every deployed function</li> <li>This is the primary way to invoke functions</li> </ul>"},{"location":"functions/overview/#scheduled-trigger","title":"Scheduled Trigger","text":"<ul> <li>Functions can be invoked on a schedule using the CronJob feature</li> <li>The CronJob runs a container with <code>curl</code> or similar tool to hit the function's HTTP endpoint at the scheduled time</li> </ul>"},{"location":"functions/overview/#ai-powered-dynamic-function-execution-advanced","title":"AI-Powered Dynamic Function Execution (Advanced)","text":"<p>This powerful capability allows AI agents to generate, deploy, and execute code on-the-fly in a secure sandbox.</p>"},{"location":"functions/overview/#execution-flow-and-security-model","title":"Execution Flow and Security Model","text":"<ol> <li> <p>Code Generation: An AIOps agent generates a piece of code to perform a specific task</p> </li> <li> <p>Dynamic Deploy Request: The agent calls a secure Internal Operations API on the HKS Control Plane (e.g., <code>POST /internal/v1/operations/deploy-function</code>), passing the code and the short-lived internal JWT</p> </li> <li> <p>Secure Build &amp; Deploy:</p> </li> <li>The HKS backend receives the request and uses a secure, isolated in-cluster builder (e.g., Kaniko) to build a temporary container image from the provided code</li> <li>It then deploys this image as a new Knative Function to the user's vCluster</li> <li> <p>The function runs with a highly restricted, single-purpose Service Account</p> </li> <li> <p>Scoped Invocation: The backend returns the function's internal URL to the agent. The agent invokes the function to get the result</p> </li> <li> <p>Automatic Cleanup: After execution (or a timeout), the agent (or a garbage collector) calls another internal API (<code>delete-function</code>) to remove the temporary function and its associated resources</p> </li> </ol>"},{"location":"functions/overview/#developer-tooling","title":"Developer Tooling","text":"<ul> <li>HKS Internal SDK (Python): Abstracts the entire flow</li> <li>AI agents can simply call methods like <code>hks_sdk.functions.execute(code=\"...\")</code></li> <li>The SDK handles the entire secure deploy-invoke-cleanup lifecycle</li> <li>Detailed documentation outlines capabilities and limitations (e.g., available libraries, resource quotas)</li> </ul>"},{"location":"functions/runtime/","title":"Function Runtime Environment","text":"<p>When you deploy a function to Hexabase.AI, it runs in a managed, secure, and isolated environment. Understanding this runtime environment is key to developing reliable and performant functions.</p>"},{"location":"functions/runtime/#the-execution-environment","title":"The Execution Environment","text":"<p>Each function runs inside a lightweight, isolated container based on gVisor, which provides a secure sandbox with a private filesystem and network stack. This \"sandbox\" approach ensures that one function cannot interfere with another, even if they are running on the same underlying node.</p> <p>The base OS for the runtime container is a minimal, hardened Linux distribution.</p>"},{"location":"functions/runtime/#lifecycle-of-a-function-invocation","title":"Lifecycle of a Function Invocation","text":"<ol> <li>Request: An HTTP request arrives at the Function Gateway for a specific function endpoint.</li> <li>Cold Start (if necessary): If there are no idle instances of your function's container available, the FaaS system performs a \"cold start\":<ul> <li>A new sandboxed container is created.</li> <li>Your function's code and its dependencies are loaded into memory.</li> <li>Your function's initialization code (any code outside the main <code>handler</code>) is run.</li> </ul> </li> <li>Warm Start: If an idle \"warm\" container is available from a previous invocation, it is immediately used, skipping the cold start steps.</li> <li>Invocation: The FaaS system invokes your <code>handler</code> function, passing it the <code>event</code> and <code>context</code> objects.</li> <li>Response: Your function returns a response dictionary.</li> <li>Shutdown: The FaaS system serializes your response and sends it back to the client. The container is then either frozen (to keep it warm for a subsequent request) or terminated.</li> </ol> <p>Note: Cold starts typically take a few hundred milliseconds, while warm starts are near-instantaneous. The system is optimized to keep frequently used functions warm.</p>"},{"location":"functions/runtime/#resource-limits","title":"Resource Limits","text":"<p>The runtime environment imposes the following limits, which can be configured in your <code>function.yaml</code>:</p> <ul> <li>Memory: The maximum amount of memory your function can use. If it exceeds this limit, its process will be terminated.</li> <li>Default: <code>128Mi</code></li> <li>Max: <code>2Gi</code></li> <li>Timeout: The maximum execution time for your function. If it runs longer than this, the invocation will be terminated, and a <code>504 Gateway Timeout</code> error will be returned.</li> <li>Default: <code>30s</code></li> <li>Max: <code>900s</code> (15 minutes)</li> <li>CPU: CPU is not a hard limit but is allocated proportionally to the memory setting. A function with more memory will receive more CPU time.</li> </ul>"},{"location":"functions/runtime/#filesystem-access","title":"Filesystem Access","text":"<ul> <li>Read-Only Code: Your function's code and its dependencies are mounted into the container in a read-only directory. You cannot modify your code at runtime.</li> <li>Temporary Writable Directory: Each function container has access to a writable <code>/tmp</code> directory with a limited size (e.g., 512 MB). This directory is non-persistent; its contents are lost after the function invocation ends. It should only be used for temporary, intermediate file storage during a single execution.</li> </ul>"},{"location":"functions/runtime/#environment-variables","title":"Environment Variables","text":"<p>The runtime environment exposes several standard environment variables.</p>"},{"location":"functions/runtime/#standard-variables","title":"Standard Variables","text":"Variable Description <code>AWS_REGION</code> The AWS region where the function is executing. <code>AWS_EXECUTION_ENV</code> Identifies the runtime, e.g., <code>AWS_Lambda_python3.9</code>. <code>_HANDLER</code> The name of your handler function (e.g., <code>main.handler</code>)."},{"location":"functions/runtime/#hks-specific-variables","title":"HKS-Specific Variables","text":"Variable Description <code>HKS_FUNCTION_NAME</code> The name of your function. <code>HKS_FUNCTION_VERSION</code> The deployed version of your function. <code>HKS_WORKSPACE_NAME</code> The name of the workspace the function belongs to. <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> The endpoint for the OpenTelemetry collector, used for manual tracing instrumentation. <p>Additionally, any environment variables or secrets you define in your <code>function.yaml</code> will be available to your function's process.</p>"},{"location":"functions/runtime/#networking","title":"Networking","text":"<ul> <li>Outbound Connectivity: By default, functions have access to the public internet. You can use this to make API calls to third-party services.</li> <li>Private Networking (Enterprise Plan): For functions that need to access resources in a private VPC (like a database), you can configure them to attach to a specific VPC. This will route their outbound traffic through that VPC, but it may increase cold start times.</li> <li>No Inbound Connectivity: Functions cannot receive inbound traffic on arbitrary ports. All communication must come through the main HTTP invocation.</li> </ul>"},{"location":"ja/","title":"Hexabase.AI \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3078\u3088\u3046\u3053\u305d","text":"<p>AI\u6307\u5411Kubernetes as a Service - AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u77e5\u80fd\u7684\u306a\u81ea\u52d5\u5316\u3067\u30c7\u30d7\u30ed\u30a4\u3001\u30b9\u30b1\u30fc\u30eb\u3001\u7ba1\u7406</p>"},{"location":"ja/#_1","title":"\u306f\u3058\u3081\u306b","text":"<ul> <li> AI \u958b\u767a\u8005</li> </ul> <p>AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u672c\u756a\u5bfe\u5fdc\u306e Kubernetes \u306b\u9ad8\u901f\u30c7\u30d7\u30ed\u30a4</p> <p> \u958b\u767a\u3092\u59cb\u3081\u308b</p> <ul> <li> \u30c1\u30fc\u30e0</li> </ul> <p>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5206\u96e2\u3067\u5c02\u7528\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u4e0a\u3067\u306e AI \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306e\u5354\u696d\u3068\u30b9\u30b1\u30fc\u30eb</p> <p> \u30c1\u30fc\u30e0\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7</p> <ul> <li> \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba</li> </ul> <p>\u5b8c\u5168\u306a\u5236\u5fa1\u3068\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u306b\u3088\u308b\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30fb\u30aa\u30f3\u30d7\u30ec\u30df\u30b9 AI \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u306e\u30c7\u30d7\u30ed\u30a4</p> <p> \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30ac\u30a4\u30c9</p> <ul> <li> \u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8</li> </ul> <p>\u30ac\u30a4\u30c9\u4ed8\u304d\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3067\u6570\u5206\u3067\u6700\u521d\u306e AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c</p> <p> \u30af\u30a4\u30c3\u30af\u30c7\u30d7\u30ed\u30a4</p>"},{"location":"ja/#_2","title":"\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u6a5f\u80fd","text":"<ul> <li> \u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> </ul> <p>Hexabase.AI \u306e\u57fa\u672c\u6982\u5ff5\u3092\u7406\u89e3\u3057\u307e\u3059</p> <p> \u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u5b66\u3076 (\u65e5\u672c\u8a9e)</p> <ul> <li> \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9</li> </ul> <p>\u7d44\u7e54\u304c Hexabase.AI \u3092\u3069\u306e\u3088\u3046\u306b\u4f7f\u7528\u3057\u3066\u3044\u308b\u304b\u3092\u63a2\u308a\u307e\u3059</p> <p> \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u898b\u308b (English)</p> <ul> <li> \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> </ul> <p>\u6280\u8853\u7684\u306a\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u6df1\u304f\u6398\u308a\u4e0b\u3052\u307e\u3059</p> <p> \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8 (English)</p> <ul> <li> RBAC</li> </ul> <p>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u306e\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3</p> <p> RBAC \u30ac\u30a4\u30c9 (English)</p>"},{"location":"ja/#_3","title":"\u9ad8\u5ea6\u306a\u6a5f\u80fd","text":"<ul> <li> CronJobs</li> </ul> <p>\u5b9a\u671f\u7684\u306a\u30bf\u30b9\u30af\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u304a\u3088\u3073\u7ba1\u7406\u3057\u307e\u3059</p> <p> CronJobs \u30ac\u30a4\u30c9 (English)</p> <ul> <li> Functions</li> </ul> <p>Kubernetes \u4e0a\u3067\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059</p> <p> Functions \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8 (English)</p> <ul> <li> \u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3</li> </ul> <p>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u76e3\u8996\u3001\u30ed\u30b0\u8a18\u9332\u3001\u30c8\u30ec\u30fc\u30b9\u3092\u884c\u3044\u307e\u3059</p> <p> \u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0 (English)</p> <ul> <li> AIOps</li> </ul> <p>AI \u3092\u6d3b\u7528\u3057\u305f\u904b\u7528\u3068\u81ea\u52d5\u5316</p> <p> AIOps \u6a5f\u80fd (English)</p>"},{"location":"ja/#_4","title":"\u958b\u767a\u8005\u5411\u3051\u30ea\u30bd\u30fc\u30b9","text":"<ul> <li> \u8a00\u8a9e\u5207\u308a\u66ff\u3048</li> </ul> <p>\u82f1\u8a9e\u7248\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5207\u308a\u66ff\u3048\u308b</p> <p> English Documentation</p> <ul> <li> API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</li> </ul> <p>\u81ea\u52d5\u751f\u6210API \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\uff08\u6e96\u5099\u4e2d\uff09</p> <p> API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</p>"},{"location":"ja/#hexabaseai_1","title":"Hexabase.AI \u3068\u306f\uff1f","text":"<p>Hexabase.AI (HKS) \u306f\u3001AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\u958b\u767a\u8005\u5411\u3051\u306b\u7279\u5225\u306b\u8a2d\u8a08\u3055\u308c\u305f **AI\u6307\u5411Kubernetes as a Service \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0**\u3067\u3059\u3002CNCF \u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u6a19\u6e96\u306b\u57fa\u3065\u3044\u3066\u69cb\u7bc9\u3055\u308c\u3001AI \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30d1\u30bf\u30fc\u30f3\u3092\u7406\u89e3\u3059\u308b\u77e5\u80fd\u7684\u306a\u81ea\u52d5\u5316\u3001\u76e3\u8996\u3001\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/#hexabaseai_2","title":"\u306a\u305c Hexabase.AI \u3092\u9078\u3076\u306e\u304b\uff1f","text":"<ul> <li>AI \u30d5\u30a1\u30fc\u30b9\u30c8\u30c7\u30b6\u30a4\u30f3: AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3001\u6a5f\u68b0\u5b66\u7fd2\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306b\u6700\u9069\u5316</li> <li>\u5373\u5ea7\u306e\u672c\u756a\u74b0\u5883: AI \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u6570\u9031\u9593\u3067\u306f\u306a\u304f\u6570\u5206\u3067\u672c\u756a\u74b0\u5883\u306b\u30c7\u30d7\u30ed\u30a4</li> <li>\u30b9\u30de\u30fc\u30c8\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0: \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30d1\u30bf\u30fc\u30f3\u304b\u3089\u5b66\u7fd2\u3059\u308b AI \u99c6\u52d5\u306e\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316</li> <li>\u30c1\u30fc\u30e0\u5354\u696d: \u304d\u3081\u7d30\u304b\u3044\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3092\u5099\u3048\u305f\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9</li> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u5bfe\u5fdc: \u5b8c\u5168\u306a\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u3068\u5236\u5fa1\u3092\u5099\u3048\u305f\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30fb\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u30c7\u30d7\u30ed\u30a4</li> <li>\u30aa\u30fc\u30d7\u30f3\u6a19\u6e96: CNCF OSS \u306b\u57fa\u3065\u304f\u69cb\u7bc9 - \u30d9\u30f3\u30c0\u30fc\u30ed\u30c3\u30af\u30a4\u30f3\u306a\u3057\u3001\u99b4\u67d3\u307f\u306e\u3042\u308b\u30c4\u30fc\u30eb\u3092\u4f7f\u7528</li> </ul>"},{"location":"ja/#_5","title":"\u6700\u9069\u306a\u5bfe\u8c61\u8005","text":"<ul> <li>LLM\u3001ML \u30e2\u30c7\u30eb\u3001AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f7f\u7528\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b AI \u958b\u767a\u8005</li> <li>DevOps \u306e\u30aa\u30fc\u30d0\u30fc\u30d8\u30c3\u30c9\u306a\u3057\u306b\u8fc5\u901f\u3067\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u306a AI \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u304c\u5fc5\u8981\u306a \u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7</li> <li>\u7570\u306a\u308b AI \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3068\u5b9f\u9a13\u306e\u305f\u3081\u306e\u5206\u96e2\u3055\u308c\u305f\u74b0\u5883\u304c\u5fc5\u8981\u306a \u30c1\u30fc\u30e0</li> <li>\u30ac\u30d0\u30ca\u30f3\u30b9\u3068\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u3092\u5099\u3048\u305f\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8 AI \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u304c\u5fc5\u8981\u306a \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba</li> </ul>"},{"location":"ja/#_6","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3068\u6280\u8853","text":"<p>Hexabase.AI \u306f\u5b9f\u7e3e\u306e\u3042\u308b CNCF \u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u6280\u8853\u306b\u57fa\u3065\u3044\u3066\u69cb\u7bc9\u3055\u308c\u3066\u304a\u308a\u3001\u4fe1\u983c\u6027\u3001\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001\u30d9\u30f3\u30c0\u30fc\u72ec\u7acb\u6027\u3092\u4fdd\u8a3c\u3057\u307e\u3059\uff1a</p> <ul> <li>Kubernetes: \u30b3\u30f3\u30c6\u30ca\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u57fa\u76e4</li> <li>Prometheus &amp; Grafana: \u76e3\u8996\u3068\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u30b9\u30bf\u30c3\u30af</li> <li>OpenTelemetry: \u5206\u6563\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u53ce\u96c6</li> <li>Proxmox: \u5c02\u7528\u30ce\u30fc\u30c9\u7ba1\u7406\u306e\u305f\u3081\u306e\u4eee\u60f3\u5316</li> <li>AI \u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3: Python \u30d9\u30fc\u30b9\u306e\u77e5\u80fd\u7684\u81ea\u52d5\u5316\u30a8\u30f3\u30b8\u30f3</li> </ul>"},{"location":"ja/#_7","title":"\u30af\u30a4\u30c3\u30af\u30ea\u30f3\u30af","text":"<ul> <li>\u958b\u767a</li> </ul> <ul> <li>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9\uff08\u81ea\u52d5\u751f\u6210\uff09</li> <li> <p>CLI \u30c4\u30fc\u30eb\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8</p> </li> <li> <p>\u30ea\u30bd\u30fc\u30b9</p> </li> </ul> <ul> <li>GitHub \u30ea\u30dd\u30b8\u30c8\u30ea</li> <li>\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u30b5\u30dd\u30fc\u30c8</li> <li>\u30ea\u30ea\u30fc\u30b9\u30ce\u30fc\u30c8</li> </ul>"},{"location":"ja/#_8","title":"\u30b5\u30dd\u30fc\u30c8","text":"<p>\u304a\u56f0\u308a\u3067\u3059\u304b\uff1f\u3053\u3061\u3089\u3092\u3054\u78ba\u8a8d\u304f\u3060\u3055\u3044\uff1a</p> <ul> <li>\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u30d5\u30a9\u30fc\u30e9\u30e0</li> <li>\u8ab2\u984c\u30c8\u30e9\u30c3\u30ab\u30fc</li> <li>\u30b5\u30dd\u30fc\u30c8\u3078\u306e\u304a\u554f\u3044\u5408\u308f\u305b</li> </ul>"},{"location":"ja/service-scope/","title":"Hexabase KaaS\u30b5\u30fc\u30d3\u30b9 \u30b5\u30fc\u30d3\u30b9\u63d0\u4f9b\u7bc4\u56f2\u3068\u8cac\u4efb\u5206\u754c\u70b9","text":"<p>Hexabase KaaS\uff08Kubernetes as a Service\uff09\u306f\u3001Kubernetes\u3068\u5b8c\u5168\u4e92\u63db\u6027\u3092\u6301\u3061\u306a\u304c\u3089\u3001\u5c02\u9580\u77e5\u8b58\u304c\u306a\u3044\u65b9\u3067\u3082\u76f4\u611f\u7684\u306b\u64cd\u4f5c\u3067\u304d\u308bUI\u3068\u88dc\u52a9\u6a5f\u80fd\u306b\u3088\u308a\u3001\u30b3\u30f3\u30c6\u30ca\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u904b\u7528\u3092\u5bb9\u6613\u306b\u3059\u308b\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u3059\u3002 \u672c\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001Hexabase KaaS\u3092\u3054\u5229\u7528\u3044\u305f\u3060\u304f\u4e0a\u3067\u306e\u3001\u5f0a\u793e\uff08Hexabase\uff09\u3068\u304a\u5ba2\u69d8\u3068\u306e\u9593\u306e\u30b5\u30fc\u30d3\u30b9\u63d0\u4f9b\u7bc4\u56f2\u3068\u8cac\u4efb\u5206\u754c\u70b9\u3092\u660e\u78ba\u306b\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u307e\u3059\u3002</p>"},{"location":"ja/service-scope/#1","title":"1. \u8cac\u4efb\u5206\u754c\u70b9\u306e\u6982\u8981","text":"<p>Hexabase KaaS\u306b\u304a\u3051\u308b\u8cac\u4efb\u7bc4\u56f2\u306f\u3001\u4e00\u822c\u7684\u306a\u30af\u30e9\u30a6\u30c9\u30b5\u30fc\u30d3\u30b9\u306e\u8cac\u4efb\u5171\u6709\u30e2\u30c7\u30eb\u306b\u6e96\u3058\u307e\u3059\u3002\u4ee5\u4e0b\u306e\u8868\u306f\u3001\u30b5\u30fc\u30d3\u30b9\u63d0\u4f9b\u5f62\u614b\u3054\u3068\u306e\u8cac\u4efb\u306e\u6240\u5728\u3092\u307e\u3068\u3081\u305f\u3082\u306e\u3067\u3059\u3002</p> \u30ec\u30a4\u30e4\u30fc \u5185\u5bb9 KaaS\u7248 \u4ed6\u793e\u30af\u30e9\u30a6\u30c9\u7248 \u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u7248 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u672c\u4f53\u3001\u30c7\u30fc\u30bf\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5bfe\u7b56\u3001\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u7ba1\u7406 \u304a\u5ba2\u69d8 \u304a\u5ba2\u69d8 \u304a\u5ba2\u69d8 Kubernetes\u57fa\u76e4 \u30b3\u30f3\u30c6\u30ca\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3001\u76e3\u8996\u30fb\u30ed\u30b0\u6a5f\u80fd\u3001\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u3001\u30a2\u30af\u30bb\u30b9\u5236\u5fa1 Hexabase Hexabase Hexabase \u4eee\u60f3\u30a4\u30f3\u30d5\u30e9 \u4eee\u60f3\u30de\u30b7\u30f3\u3001\u4eee\u60f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3001\u4eee\u60f3\u30b9\u30c8\u30ec\u30fc\u30b8 Hexabase \u304a\u5ba2\u69d8 (\u203b1) \u304a\u5ba2\u69d8 (\u203b1) \u7269\u7406\u30a4\u30f3\u30d5\u30e9 \u7269\u7406\u30b5\u30fc\u30d0\u30fc\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u6a5f\u5668\u3001\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc Hexabase \u304a\u5ba2\u69d8 (\u203b1) \u304a\u5ba2\u69d8 (\u203b1) <p>(\u203b1) \u4ed6\u793e\u30af\u30e9\u30a6\u30c9\u7248\u30fb\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u7248\u306e\u30a4\u30f3\u30d5\u30e9\u306b\u3064\u3044\u3066</p> <ul> <li>\u4ed6\u793e\u30af\u30e9\u30a6\u30c9\u7248: \u304a\u5ba2\u69d8\u304c\u3054\u5951\u7d04\u306e\u30af\u30e9\u30a6\u30c9\u30b5\u30fc\u30d3\u30b9\uff08AWS, Azure, GCP\u306a\u3069\uff09\u306e\u30a2\u30ab\u30a6\u30f3\u30c8\u3001\u304a\u3088\u3073\u305d\u306e\u4e0a\u3067\u52d5\u4f5c\u3059\u308bKubernetes\uff08EKS, AKS, GKE\u306a\u3069\uff09\u306e\u7ba1\u7406\u8cac\u4efb\u306f\u304a\u5ba2\u69d8\u306b\u3042\u308a\u307e\u3059\u3002</li> <li>\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u7248: \u304a\u5ba2\u69d8\u304c\u4fdd\u6709\u3059\u308b\u7269\u7406\u30b5\u30fc\u30d0\u30fc\u3084\u4eee\u60f3\u5316\u57fa\u76e4\uff08Proxmox\u306a\u3069\uff09\u306e\u7ba1\u7406\u8cac\u4efb\u306f\u304a\u5ba2\u69d8\u306b\u3042\u308a\u307e\u3059\u3002</li> </ul> <p>\u3010\u69cb\u7bc9\u30fb\u904b\u7528\u652f\u63f4\u3011 \u4e0a\u8a18(\u203b1)\u306e\u7bc4\u56f2\u306b\u3064\u3044\u3066\u3001Hexabase\u793e\u306b\u3088\u308b**\u521d\u671f\u69cb\u7bc9\u30b5\u30fc\u30d3\u30b9**\u3084**\u30de\u30cd\u30fc\u30b8\u30c9\u30fb\u30b5\u30fc\u30d3\u30b9**\u3092\u5225\u9014\u3054\u5951\u7d04\u3044\u305f\u3060\u304f\u3053\u3068\u3067\u3001Hexabase\u793e\u304c\u69cb\u7bc9\u3084\u904b\u7528\u3092\u4ee3\u884c\u3059\u308b\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u500b\u5225\u306b\u3054\u76f8\u8ac7\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/service-scope/#2","title":"2. \u5404\u30ec\u30a4\u30e4\u30fc\u306b\u304a\u3051\u308b\u8cac\u4efb\u5206\u754c\u70b9\u306e\u8a73\u7d30","text":""},{"location":"ja/service-scope/#21","title":"2.1. \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ec\u30a4\u30e4\u30fc\uff08\u304a\u5ba2\u69d8\u306e\u8cac\u4efb\u7bc4\u56f2\uff09","text":"<p>Hexabase\u306f\u3001\u304a\u5ba2\u69d8\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u52d5\u4f5c\u3055\u305b\u308b\u305f\u3081\u306e\u5f37\u529b\u306a\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u304c\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u305d\u306e\u3082\u306e\u306e\u7ba1\u7406\u8cac\u4efb\u306f\u8ca0\u3044\u307e\u305b\u3093\u3002</p> \u9805\u76ee \u304a\u5ba2\u69d8\u306e\u8cac\u4efb\u7bc4\u56f2 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u52d5\u4f5c\u4fdd\u8a3c \u304a\u5ba2\u69d8\u304c\u958b\u767a\u30fb\u30c7\u30d7\u30ed\u30a4\u3057\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u6b63\u5e38\u306a\u52d5\u4f5c\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3001\u54c1\u8cea\u306e\u62c5\u4fdd\u3002 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9\u306e\u8106\u5f31\u6027\u5bfe\u7b56\u3001\u9069\u5207\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u4f7f\u7528\u3001\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3\u3068\u5bfe\u7b56\u3002 \u30c7\u30fc\u30bf\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3068\u5fa9\u65e7 \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u3084\u30d5\u30a1\u30a4\u30eb\u306a\u3069\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u5229\u7528\u3059\u308b\u6c38\u7d9a\u30c7\u30fc\u30bf\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a08\u753b\u306e\u7b56\u5b9a\u3001\u5b9a\u671f\u7684\u306a\u5b9f\u884c\u3001\u304a\u3088\u3073\u969c\u5bb3\u767a\u751f\u6642\u306e\u304a\u5ba2\u69d8\u81ea\u8eab\u306b\u3088\u308b\u30c7\u30fc\u30bf\u5fa9\u65e7\u4f5c\u696d\u3002 \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8 \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u6a5f\u80fd\u8ffd\u52a0\u3084\u30d0\u30b0\u4fee\u6b63\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d1\u30c3\u30c1\u304c\u9069\u7528\u3055\u308c\u305f\u65b0\u3057\u3044\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u304a\u5ba2\u69d8\u81ea\u8eab\u3067\u6e96\u5099\u3057\u3001\u30c7\u30d7\u30ed\u30a4\uff08\u6700\u65b0\u5316\uff09\u3059\u308b\u3053\u3068\u3002"},{"location":"ja/service-scope/#22-kuberneteshexabase","title":"2.2. Kubernetes\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30ec\u30a4\u30e4\u30fc\uff08Hexabase\u306e\u8cac\u4efb\u7bc4\u56f2\uff09","text":"<p>Hexabase\u306f\u3001\u304a\u5ba2\u69d8\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u904b\u7528\u306b\u96c6\u4e2d\u3067\u304d\u308b\u3088\u3046\u3001\u8907\u96d1\u306aKubernetes\u74b0\u5883\u306e\u7ba1\u7406\u30fb\u904b\u7528\u3092\u8cac\u4efb\u3092\u6301\u3063\u3066\u884c\u3044\u307e\u3059\u3002</p> \u9805\u76ee Hexabase\u306e\u63d0\u4f9b\u7bc4\u56f2 \u30b3\u30f3\u30c6\u30ca\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3 \u30b3\u30f3\u30c6\u30ca\u306e\u81ea\u52d5\u30c7\u30d7\u30ed\u30a4\u3001\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3001\u304a\u3088\u3073\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u7ba1\u7406\u6a5f\u80fd\u306e\u63d0\u4f9b\u3002 \u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u3068\u6700\u9069\u5316 \u30b3\u30f3\u30c6\u30ca\u304c\u5fc5\u8981\u3068\u3059\u308bCPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u7b49\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u52b9\u7387\u7684\u306b\u7ba1\u7406\u30fb\u6700\u9069\u5316\u3059\u308b\u6a5f\u80fd\u306e\u63d0\u4f9b\u3002 \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u76e3\u8996\u3068\u30ed\u30ae\u30f3\u30b0 Kubernetes\u30af\u30e9\u30b9\u30bf\u304a\u3088\u3073\u30b3\u30f3\u30c6\u30ca\u306e\u7a3c\u50cd\u72b6\u6cc1\u3084\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u76e3\u8996\u3057\u3001\u30ed\u30b0\u3092\u53ce\u96c6\u30fb\u5206\u6790\u3059\u308b\u305f\u3081\u306e\u7d71\u5408\u7684\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3002 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3068\u30b9\u30c8\u30ec\u30fc\u30b8\u7ba1\u7406 \u30b3\u30f3\u30c6\u30ca\u9593\u306e\u5b89\u5168\u306a\u901a\u4fe1\u3092\u5b9f\u73fe\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u6a5f\u80fd\u3084\u3001\u30c7\u30fc\u30bf\u306e\u6c38\u7d9a\u5316\u3092\u884c\u3046\u30b9\u30c8\u30ec\u30fc\u30b8\u6a5f\u80fd\u306e\u63d0\u4f9b\u3002 \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9 Kubernetes\u30af\u30e9\u30b9\u30bf\u81ea\u4f53\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u7dad\u6301\u3001\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u3001\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u74b0\u5883\u306b\u304a\u3051\u308b\u30ea\u30bd\u30fc\u30b9\u5206\u96e2\u6a5f\u80fd\u306e\u63d0\u4f9b\u3002 \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8 Kubernetes\u672c\u4f53\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u30a2\u30c3\u30d7\u3084\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d1\u30c3\u30c1\u306e\u9069\u7528\u3068\u3044\u3063\u305f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u3002 VM/\u30b3\u30f3\u30c6\u30ca\u7d71\u5408\u7ba1\u7406 Kubernetes\u4e0a\u3067\u4eee\u60f3\u30de\u30b7\u30f3\uff08VM\uff09\u3068\u30b3\u30f3\u30c6\u30ca\u3092\u4e00\u5143\u7684\u306b\u7ba1\u7406\u3067\u304d\u308b\u6a5f\u80fd\u306e\u63d0\u4f9b\u3002 \u30b5\u30dd\u30fc\u30c8\u3068\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8 \u304a\u5ba2\u69d8\u304c\u30b5\u30fc\u30d3\u30b9\u3092\u5186\u6ed1\u306b\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u6280\u8853\u30b5\u30dd\u30fc\u30c8\u3001\u304a\u3088\u3073\u5404\u7a2e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u63d0\u4f9b\u3002"},{"location":"ja/service-scope/#23","title":"2.3. \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30fc\u30ec\u30a4\u30e4\u30fc\uff08\u63d0\u4f9b\u5f62\u614b\u306b\u3088\u308a\u5206\u62c5\uff09","text":"<p>\u30a4\u30f3\u30d5\u30e9\u5c64\u306e\u8cac\u4efb\u5206\u754c\u70b9\u306f\u3001\u304a\u5ba2\u69d8\u304c\u9078\u629e\u3059\u308b\u63d0\u4f9b\u5f62\u614b\u306b\u3088\u3063\u3066\u7570\u306a\u308a\u307e\u3059\u3002</p>"},{"location":"ja/service-scope/#kaashexabase","title":"KaaS\u7248\u3092\u3054\u5229\u7528\u306e\u5834\u5408\uff08Hexabase\u306e\u8cac\u4efb\u7bc4\u56f2\uff09","text":"<p>\u7269\u7406\u30b5\u30fc\u30d0\u30fc\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u3001\u304a\u3088\u3073\u305d\u308c\u3089\u3092\u4eee\u60f3\u5316\u3059\u308b\u57fa\u76e4\u306e\u5168\u3066\u3092\u3001Hexabase\u304c\u30d5\u30eb\u30de\u30cd\u30fc\u30b8\u30c9\u3067\u63d0\u4f9b\u3057\u307e\u3059\u3002\u304a\u5ba2\u69d8\u306f\u30a4\u30f3\u30d5\u30e9\u306e\u5b58\u5728\u3092\u610f\u8b58\u3059\u308b\u3053\u3068\u306a\u304f\u3001\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u611f\u899a\u3067\u30b5\u30fc\u30d3\u30b9\u3092\u3054\u5229\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p>"},{"location":"ja/service-scope/#_1","title":"\u4ed6\u793e\u30af\u30e9\u30a6\u30c9\u7248\u30fb\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u7248\u3092\u3054\u5229\u7528\u306e\u5834\u5408\uff08\u304a\u5ba2\u69d8\u306e\u8cac\u4efb\u7bc4\u56f2\uff09","text":"<p>\u524d\u8ff0\u306e\u901a\u308a\u3001\u57fa\u76e4\u3068\u306a\u308b\u30af\u30e9\u30a6\u30c9\u74b0\u5883\u3084\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u306e\u7269\u7406/\u4eee\u60f3\u74b0\u5883\u306e\u69cb\u7bc9\u30fb\u7ba1\u7406\u30fb\u904b\u7528\u306f\u304a\u5ba2\u69d8\u306e\u8cac\u4efb\u7bc4\u56f2\u3068\u306a\u308a\u307e\u3059\u3002Hexabase KaaS\u306f\u3001\u305d\u306e\u4e0a\u3067\u52d5\u4f5c\u3059\u308b\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u3057\u3066\u30b5\u30fc\u30d3\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/aiops/","title":"AI \u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3 (AIOps)","text":"<p>Hexabase.AI \u306e\u4e3b\u8981\u6a5f\u80fd\u306e\u4e00\u3064\u3067\u3042\u308b AIOps \u306f\u3001\u30b3\u30f3\u30c6\u30ca\u30b5\u30fc\u30d3\u30b9\u306e\u904b\u7528\u3092\u81ea\u52d5\u5316\u3057\u3001\u30c1\u30e3\u30c3\u30c8\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u901a\u3058\u3066\u76f4\u63a5\u7684\u306a\u904b\u7528\u5236\u5fa1\u3092\u63d0\u4f9b\u3059\u308b\u3001Kubernetes \u904b\u7528\u306b\u7279\u5316\u3057\u305f\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8 AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3067\u3059\u3002</p>"},{"location":"ja/aiops/#_1","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306e AIOps \u306f\u5305\u62ec\u7684\u306a\u81ea\u52d5\u5316\u6a5f\u80fd\u3092\u4e2d\u5fc3\u306b\u69cb\u7bc9\u3055\u308c\u3066\u304a\u308a\u3001K8S \u904b\u7528\u306b\u7279\u5316\u3057\u305f AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u3001Hexabase \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u304b\u3089\u69d8\u3005\u306a\u30ed\u30b0\u60c5\u5831\u3084\u904b\u7528\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057\u3066\u30e6\u30fc\u30b6\u30fc\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\u3002AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u3001\u30ed\u30b0\u30a4\u30f3\u3057\u305f\u30e6\u30fc\u30b6\u30fc\u3068\u307e\u3063\u305f\u304f\u540c\u3058\u6a29\u9650\u7bc4\u56f2\u5185\u3067\u306e\u307f\u52d5\u4f5c\u3057\u3001\u5b89\u5168\u3067\u9069\u5207\u306a\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002</p> <p>\u3053\u306e\u9769\u65b0\u7684\u306a\u30a2\u30d7\u30ed\u30fc\u30c1\u306b\u3088\u308a\u3001\u81ea\u7136\u8a00\u8a9e\u3067\u306e\u3084\u308a\u53d6\u308a\u3092\u901a\u3058\u3066\u65e2\u5b58\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3068\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u7d71\u5408\u3057\u306a\u304c\u3089\u3001\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u81ea\u52d5\u5316\u3001\u30d7\u30ed\u30a2\u30af\u30c6\u30a3\u30d6\u306a\u76e3\u8996\u3001\u305d\u3057\u3066 Kubernetes \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u306e\u7ba1\u7406\u65b9\u6cd5\u3092\u5909\u9769\u3057\u307e\u3059\u3002</p>"},{"location":"ja/aiops/#aiops","title":"\u30b3\u30a2 AIOps \u6a5f\u80fd","text":"<ul> <li> \u30c1\u30e3\u30c3\u30c8\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u904b\u7528</li> </ul> <p>\u81ea\u7136\u8a00\u8a9e\u30c1\u30e3\u30c3\u30c8\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u901a\u3058\u305f\u76f4\u63a5\u7684\u306a\u904b\u7528\u5236\u5fa1</p> <p> \u30c1\u30e3\u30c3\u30c8\u904b\u7528\u30ac\u30a4\u30c9</p> <ul> <li> \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u76e3\u8996</li> </ul> <p>\u30d7\u30ed\u30a2\u30af\u30c6\u30a3\u30d6\u30a2\u30e9\u30fc\u30c8\u4ed8\u304d\u306e\u30ea\u30bd\u30fc\u30b9\u3068\u30ed\u30b0\u76e3\u8996</p> <p> \u76e3\u8996\u6a5f\u80fd</p> <ul> <li> \u81ea\u52d5\u904b\u7528</li> </ul> <p>\u81ea\u5df1\u4fee\u5fa9\u30b7\u30b9\u30c6\u30e0\u3068\u81ea\u52d5\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b5\u30dd\u30fc\u30c8</p> <p> \u81ea\u52d5\u5316\u30ac\u30a4\u30c9</p> <ul> <li> AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u7d71\u5408</li> </ul> <p>\u4efb\u610f\u306e\u30c1\u30e3\u30c3\u30c8\u30c4\u30fc\u30eb\u3068\u306e\u30dc\u30c3\u30c8\u3068\u3057\u3066\u306e\u30b7\u30fc\u30e0\u30ec\u30b9\u306a\u7d71\u5408</p> <p> \u30dc\u30c3\u30c8\u7d71\u5408</p>"},{"location":"ja/aiops/#_2","title":"\u5229\u7528\u53ef\u80fd\u306a\u6a5f\u80fd","text":"<p>Hexabase.AI AIOps \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u4ee5\u4e0b\u306e\u5305\u62ec\u7684\u306a\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p>"},{"location":"ja/aiops/#_3","title":"\ud83c\udf05 \u65e5\u6b21\u904b\u7528","text":"<ul> <li>\u671d\u306e\u6328\u62f6: \u6bce\u671d\u306e\u81ea\u52d5\u7684\u306a\u30b7\u30b9\u30c6\u30e0\u30b9\u30c6\u30fc\u30bf\u30b9\u30ec\u30dd\u30fc\u30c8</li> <li>\u30b7\u30b9\u30c6\u30e0\u30d8\u30eb\u30b9\u30b5\u30de\u30ea\u30fc: \u30af\u30e9\u30b9\u30bf\u30fc\u30b9\u30c6\u30fc\u30bf\u30b9\u3001\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u3001\u591c\u9593\u306e\u554f\u984c\u306e\u6982\u8981</li> </ul>"},{"location":"ja/aiops/#_4","title":"\ud83d\udcca \u76e3\u8996\u30fb\u30a2\u30e9\u30fc\u30c8","text":"<ul> <li>\u30ea\u30bd\u30fc\u30b9\u76e3\u8996: CPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30ea\u30bd\u30fc\u30b9\u306e\u7d99\u7d9a\u7684\u306a\u76e3\u8996</li> <li>\u30ed\u30b0\u76e3\u8996: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30b7\u30b9\u30c6\u30e0\u30ed\u30b0\u306e\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u5206\u6790</li> <li>\u30d7\u30ed\u30a2\u30af\u30c6\u30a3\u30d6\u30a2\u30e9\u30fc\u30c8: \u30ce\u30a4\u30ba\u3092\u524a\u6e1b\u3057\u3001\u5b9f\u884c\u53ef\u80fd\u306a\u554f\u984c\u306b\u7126\u70b9\u3092\u5f53\u3066\u305f\u30b9\u30de\u30fc\u30c8\u30a2\u30e9\u30fc\u30c8\u30b7\u30b9\u30c6\u30e0</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30e1\u30c8\u30ea\u30af\u30b9: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6307\u6a19\u306e\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u8ffd\u8de1</li> </ul>"},{"location":"ja/aiops/#_5","title":"\ud83d\udd27 \u8ab2\u984c\u7ba1\u7406","text":"<ul> <li>\u8ab2\u984c\u691c\u51fa: \u30a2\u30e9\u30fc\u30c8\u3068\u76e3\u8996\u30c7\u30fc\u30bf\u304b\u3089\u306e\u554f\u984c\u306e\u81ea\u52d5\u8b58\u5225</li> <li>\u8ab2\u984c\u63d0\u8d77: \u6307\u5b9a\u3055\u308c\u305f\u8ab2\u984c\u7ba1\u7406\u30b7\u30b9\u30c6\u30e0\u3068\u306e\u76f4\u63a5\u7d71\u5408</li> <li>\u521d\u671f\u8abf\u67fb: AI \u3092\u6d3b\u7528\u3057\u305f\u6839\u672c\u539f\u56e0\u5206\u6790\u3068\u554f\u984c\u8abf\u67fb</li> <li>\u4fee\u6b63\u63d0\u6848: \u7279\u5b9a\u3055\u308c\u305f\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u306e\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u63d0\u6848</li> <li>PR/MR \u4f5c\u6210: \u63d0\u6848\u3055\u308c\u305f\u4fee\u6b63\u306e\u305f\u3081\u306e\u30d7\u30eb\u30ea\u30af\u30a8\u30b9\u30c8\u307e\u305f\u306f\u30de\u30fc\u30b8\u30ea\u30af\u30a8\u30b9\u30c8\u306e\u81ea\u52d5\u4f5c\u6210</li> </ul>"},{"location":"ja/aiops/#_6","title":"\ud83d\udcac \u30c1\u30e3\u30c3\u30c8\u7d71\u5408","text":"<ul> <li>\u30de\u30eb\u30c1\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30b5\u30dd\u30fc\u30c8: \u4efb\u610f\u306e\u30c1\u30e3\u30c3\u30c8\u30c4\u30fc\u30eb\uff08Slack\u3001Teams\u3001Discord \u306a\u3069\uff09\u306b\u30dc\u30c3\u30c8\u3068\u3057\u3066\u767b\u9332\u53ef\u80fd</li> <li>\u81ea\u7136\u8a00\u8a9e\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9: \u5e73\u6613\u306a\u65e5\u672c\u8a9e\u3092\u4f7f\u7528\u3057\u3066\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3068\u3084\u308a\u53d6\u308a</li> <li>\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u30ec\u30b9\u30dd\u30f3\u30b9: AI \u304c\u3042\u306a\u305f\u306e\u7279\u5b9a\u306e\u74b0\u5883\u3092\u7406\u89e3\u3057\u3001\u95a2\u9023\u3059\u308b\u60c5\u5831\u3092\u63d0\u4f9b</li> <li>\u5b89\u5168\u306a\u30a2\u30af\u30bb\u30b9: \u30ed\u30b0\u30a4\u30f3\u3057\u305f\u30e6\u30fc\u30b6\u30fc\u3068\u307e\u3063\u305f\u304f\u540c\u3058\u6a29\u9650\u5185\u3067\u52d5\u4f5c</li> </ul>"},{"location":"ja/aiops/#_7","title":"\ud83d\ude80 \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30fb\u30c6\u30b9\u30c8","text":"<ul> <li>\u81ea\u52d5\u30c6\u30b9\u30c8: \u5c02\u7528\u30c6\u30b9\u30c8\u74b0\u5883\u3067\u306e\u7d99\u7d9a\u7684\u306a\u30c6\u30b9\u30c8</li> <li>\u30c6\u30b9\u30c8\u7d50\u679c\u76e3\u8996: \u30c6\u30b9\u30c8\u7d50\u679c\u3068\u54c1\u8cea\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u8ffd\u8de1</li> <li>\u65b0\u30b7\u30b9\u30c6\u30e0\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b5\u30dd\u30fc\u30c8: AI \u30a2\u30b7\u30b9\u30c8\u4ed8\u304d\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u8a08\u753b\u3068\u5b9f\u884c</li> <li>AI \u751f\u6210\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8: \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u8a2d\u5b9a\u306e\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u4f5c\u6210</li> <li>\u8a2d\u5b9a\u53cd\u6620: \u6700\u9069\u5316\u3055\u308c\u305f\u8a2d\u5b9a\u3068\u69cb\u6210\u306e\u81ea\u52d5\u9069\u7528</li> </ul>"},{"location":"ja/aiops/#_8","title":"\u2699\ufe0f \u30ea\u30bd\u30fc\u30b9\u7ba1\u7406","text":"<ul> <li>\u30ea\u30bd\u30fc\u30b9\u8ffd\u52a0: \u65b0\u3057\u3044\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30ea\u30bd\u30fc\u30b9\u306e AI \u30ac\u30a4\u30c9\u4ed8\u304d\u8ffd\u52a0</li> <li>\u30ea\u30bd\u30fc\u30b9\u5909\u66f4: \u65e2\u5b58\u30ea\u30bd\u30fc\u30b9\u306e\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u66f4\u65b0\u3068\u6700\u9069\u5316</li> <li>\u30ea\u30bd\u30fc\u30b9\u524a\u9664: \u672a\u4f7f\u7528\u307e\u305f\u306f\u5ec3\u6b62\u3055\u308c\u305f\u30ea\u30bd\u30fc\u30b9\u306e\u5b89\u5168\u306a\u524a\u9664</li> <li>\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u30d7\u30e9\u30f3\u30cb\u30f3\u30b0: \u4f7f\u7528\u30d1\u30bf\u30fc\u30f3\u306b\u57fa\u3065\u304f\u4e88\u6e2c\u7684\u30ea\u30bd\u30fc\u30b9\u8a08\u753b</li> </ul>"},{"location":"ja/aiops/#_9","title":"\ud83d\udcdd \u6d3b\u52d5\u30ed\u30b0","text":"<ul> <li>\u52d5\u4f5c\u30ed\u30b0: \u3059\u3079\u3066\u306e AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u6d3b\u52d5\u306e\u5305\u62ec\u7684\u306a\u30ed\u30b0\u8a18\u9332</li> <li>\u76e3\u67fb\u8a3c\u8de1: AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u5b9f\u884c\u3057\u305f\u30a2\u30af\u30b7\u30e7\u30f3\u306e\u5b8c\u5168\u306a\u5c65\u6b74</li> <li>\u610f\u601d\u6c7a\u5b9a\u306e\u900f\u660e\u6027: \u7279\u5b9a\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u304c\u63a8\u5968\u307e\u305f\u306f\u5b9f\u884c\u3055\u308c\u305f\u7406\u7531\u306e\u660e\u78ba\u306a\u8aac\u660e</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30b5\u30dd\u30fc\u30c8: \u898f\u5236\u304a\u3088\u3073\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u8981\u4ef6\u306e\u305f\u3081\u306e\u8a73\u7d30\u306a\u30ed\u30b0</li> </ul>"},{"location":"ja/aiops/#_10","title":"\u30c1\u30e3\u30c3\u30c8\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u904b\u7528","text":"<p>AIOps \u30c1\u30e3\u30c3\u30c8\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306b\u3088\u308a\u3001\u81ea\u7136\u8a00\u8a9e\u30b3\u30de\u30f3\u30c9\u3092\u901a\u3058\u3066 Kubernetes \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3092\u7ba1\u7406\u3067\u304d\u307e\u3059\uff1a</p>"},{"location":"ja/aiops/#_11","title":"\u30c1\u30e3\u30c3\u30c8\u3067\u306e\u3084\u308a\u53d6\u308a\u4f8b","text":"<pre><code>\ud83d\udc64 \u30e6\u30fc\u30b6\u30fc: \"\u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059\u3002\u30b7\u30b9\u30c6\u30e0\u306e\u8abf\u5b50\u306f\u3069\u3046\u3067\u3059\u304b\uff1f\"\n\ud83e\udd16 AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8: \"\u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059\uff01\u30b7\u30b9\u30c6\u30e0\u30b9\u30c6\u30fc\u30bf\u30b9: \u3059\u3079\u3066\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u304c\u6b63\u5e38\u3067\u3059\u3002\n              CPU\u4f7f\u7528\u7387: 65%\uff08\u6b63\u5e38\uff09\u3001\u30e1\u30e2\u30ea: 72%\uff08\u6b63\u5e38\uff09\u3002\n              \u904e\u53bb24\u6642\u9593\u3067\u30a2\u30e9\u30fc\u30c8\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n              \u5348\u524d10:00\u306buser-service v2.1.0\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u304c\u4e88\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002\"\n\n\ud83d\udc64 \u30e6\u30fc\u30b6\u30fc: \"\u6c7a\u6e08\u30b5\u30fc\u30d3\u30b9\u306e\u30ed\u30b0\u3092\u898b\u305b\u3066\u304f\u3060\u3055\u3044\"\n\ud83e\udd16 AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8: \"\u904e\u53bb1\u6642\u9593\u306epayment-service\u30ed\u30b0\u3092\u53d6\u5f97\u4e2d...\n              [\u30ed\u30b0\u5206\u6790] \u30a8\u30e9\u30fc\u306f\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3067\u3057\u305f\u30021,247\u4ef6\u306e\u6210\u529f\u3057\u305f\u53d6\u5f15\u3002\n              \u5e73\u5747\u5fdc\u7b54\u6642\u9593: 145ms\uff08SLA\u5185\uff09\u3002\"\n\n\ud83d\udc64 \u30e6\u30fc\u30b6\u30fc: \"\u30c1\u30a7\u30c3\u30af\u30a2\u30a6\u30c8API\u304c\u9045\u3044\u3088\u3046\u3067\u3059\u304c\u3001\u8abf\u67fb\u3057\u3066\u3082\u3089\u3048\u307e\u3059\u304b\uff1f\"\n\ud83e\udd16 AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8: \"\u30c1\u30a7\u30c3\u30af\u30a2\u30a6\u30c8API\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u8abf\u67fb\u4e2d...\n              [\u5206\u6790] \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a\u30d7\u30fc\u30eb\u304c95%\u306e\u5bb9\u91cf\u306b\u9054\u3057\u3066\u3044\u307e\u3059\u3002\n              [\u63a8\u5968] \u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a\u309220\u304b\u308930\u306b\u30b9\u30b1\u30fc\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n              [\u30a2\u30af\u30b7\u30e7\u30f3] \u63a5\u7d9a\u30d7\u30fc\u30eb\u8a2d\u5b9a\u3092\u66f4\u65b0\u3059\u308bPR\u3092\u4f5c\u6210\u4e2d\u3002\n              PR #154\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f: '\u30c1\u30a7\u30c3\u30af\u30a2\u30a6\u30c8API\u7528\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u63a5\u7d9a\u30d7\u30fc\u30eb\u306e\u30b9\u30b1\u30fc\u30eb'\"\n</code></pre>"},{"location":"ja/aiops/#_12","title":"\u30b5\u30dd\u30fc\u30c8\u5bfe\u8c61\u30c1\u30e3\u30c3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0","text":"<ul> <li>Slack: \u30ea\u30c3\u30c1\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u4ed8\u304d\u306e\u30cd\u30a4\u30c6\u30a3\u30d6\u30dc\u30c3\u30c8\u7d71\u5408</li> <li>Microsoft Teams: \u30ab\u30fc\u30c9\u30a4\u30f3\u30bf\u30e9\u30af\u30b7\u30e7\u30f3\u4ed8\u304d\u306e\u30d5\u30eb\u6a5f\u80fd\u30dc\u30c3\u30c8</li> <li>Discord: \u7d75\u6587\u5b57\u30ea\u30a2\u30af\u30b7\u30e7\u30f3\u4ed8\u304d\u306e\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u30d5\u30ec\u30f3\u30c9\u30ea\u30fc\u30dc\u30c3\u30c8</li> <li>Telegram: \u30a4\u30f3\u30e9\u30a4\u30f3\u30ad\u30fc\u30dc\u30fc\u30c9\u4ed8\u304d\u306e\u5b89\u5168\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0</li> <li>\u30ab\u30b9\u30bf\u30e0Webhook: API\u7d4c\u7531\u3067\u306e\u4efb\u610f\u306e\u30c1\u30e3\u30c3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u306e\u7d71\u5408</li> </ul>"},{"location":"ja/aiops/#_13","title":"\u65e5\u6b21\u904b\u7528\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":""},{"location":"ja/aiops/#_14","title":"\u671d\u306e\u30b7\u30b9\u30c6\u30e0\u30ec\u30dd\u30fc\u30c8","text":"<p>AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u6bce\u671d\u81ea\u52d5\u7684\u306b\u4ee5\u4e0b\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p> <pre><code>\ud83c\udf05 \u65e5\u6b21\u30b7\u30b9\u30c6\u30e0\u30ec\u30dd\u30fc\u30c8 - 2024\u5e743\u670815\u65e5\n\n\ud83d\udcca \u30af\u30e9\u30b9\u30bf\u30fc\u30d8\u30eb\u30b9:\n   \u2705 \u672c\u756a\u74b0\u5883: \u6b63\u5e38 (12/12 \u30ce\u30fc\u30c9)\n   \u2705 \u30b9\u30c6\u30fc\u30b8\u30f3\u30b0: \u6b63\u5e38 (4/4 \u30ce\u30fc\u30c9)\n   \u26a0\ufe0f  \u958b\u767a\u74b0\u5883: 1\u30ce\u30fc\u30c9\u304c\u518d\u8d77\u52d5\u4e2d\n\n\ud83d\udcc8 \u30ea\u30bd\u30fc\u30b9\u30b9\u30c6\u30fc\u30bf\u30b9:\n   \u2022 CPU\u4f7f\u7528\u7387: 68% (\u6628\u65e5\u304b\u3089\u21975%)\n   \u2022 \u30e1\u30e2\u30ea\u4f7f\u7528\u7387: 74% (\u5b89\u5b9a)\n   \u2022 \u30b9\u30c8\u30ec\u30fc\u30b8: 45% (\u6628\u65e5\u304b\u3089\u21982%)\n\n\ud83d\udd14 \u591c\u9593\u306e\u6d3b\u52d5:\n   \u2022 3\u4ef6\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u304c\u6b63\u5e38\u306b\u5b8c\u4e86\n   \u2022 2\u4ef6\u306e\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u30a4\u30d9\u30f3\u30c8 (user-service, api-gateway)\n   \u2022 0\u4ef6\u306e\u91cd\u8981\u30a2\u30e9\u30fc\u30c8\n\n\ud83d\udccb \u4eca\u65e5\u306e\u4e88\u5b9a:\n   \u2022 10:00 AM: notification-service v1.2.3\u306e\u30c7\u30d7\u30ed\u30a4\n   \u2022 2:00 PM: \u672c\u756a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u5b9a\u671f\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\n   \u2022 4:00 PM: \u9031\u6b21\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30f3\n\n\ud83d\udca1 \u63a8\u5968\u4e8b\u9805:\n   \u2022 \u958b\u767a\u30af\u30e9\u30b9\u30bf\u30fc\u30ce\u30fc\u30c9\u306e\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3092\u691c\u8a0e\n   \u2022 \u30b9\u30c8\u30ec\u30fc\u30b8\u4f7f\u7528\u91cf\u304c\u5897\u52a0\u50be\u5411\u3001\u4fdd\u6301\u30dd\u30ea\u30b7\u30fc\u306e\u78ba\u8a8d\n</code></pre>"},{"location":"ja/aiops/#aiops_1","title":"AIOps \u306e\u958b\u59cb","text":""},{"location":"ja/aiops/#1-aiops","title":"\u30d5\u30a7\u30fc\u30ba1: AIOps \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u6709\u52b9\u5316","text":"<pre><code># \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7528\u306eAIOps\u3092\u6709\u52b9\u5316\nhb aiops enable --workspace production\n\n# \u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u8a2d\u5b9a\nhb aiops chat-bot setup \\\n  --platform slack \\\n  --webhook-url $SLACK_WEBHOOK_URL \\\n  --channel \"#ops-alerts\"\n\n# \u76e3\u8996\u8a2d\u5b9a\u306e\u69cb\u6210\nhb aiops monitoring configure \\\n  --daily-reports true \\\n  --alert-threshold medium \\\n  --auto-investigation true\n</code></pre>"},{"location":"ja/aiops/#2","title":"\u30d5\u30a7\u30fc\u30ba2: \u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u767b\u9332","text":""},{"location":"ja/aiops/#slack","title":"Slack \u7d71\u5408","text":"<pre><code># Slack\u3067AIOps\u30dc\u30c3\u30c8\u3092\u767b\u9332\nhb aiops chat-bot register slack \\\n  --app-token $SLACK_APP_TOKEN \\\n  --bot-token $SLACK_BOT_TOKEN \\\n  --signing-secret $SLACK_SIGNING_SECRET\n</code></pre>"},{"location":"ja/aiops/#microsoft-teams","title":"Microsoft Teams \u7d71\u5408","text":"<pre><code># Teams\u3067AIOps\u30dc\u30c3\u30c8\u3092\u767b\u9332\nhb aiops chat-bot register teams \\\n  --app-id $TEAMS_APP_ID \\\n  --app-password $TEAMS_APP_PASSWORD \\\n  --tenant-id $TEAMS_TENANT_ID\n</code></pre>"},{"location":"ja/aiops/#3","title":"\u30d5\u30a7\u30fc\u30ba3: \u81ea\u52d5\u5316\u306e\u8a2d\u5b9a","text":"<pre><code># \u81ea\u52d5\u8ab2\u984c\u7ba1\u7406\u306e\u8a2d\u5b9a\nhb aiops issues configure \\\n  --system jira \\\n  --project-key \"OPS\" \\\n  --auto-create true \\\n  --severity-mapping critical:P1,high:P2,medium:P3\n\n# \u81ea\u52d5PR\u4f5c\u6210\u306e\u6709\u52b9\u5316\nhb aiops automation enable pr-creation \\\n  --repository github.com/myorg/infrastructure \\\n  --branch-prefix \"aiops/fix-\" \\\n  --auto-assign-reviewers ops-team\n\n# \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b5\u30dd\u30fc\u30c8\u306e\u8a2d\u5b9a\nhb aiops deployment configure \\\n  --auto-generate-configs true \\\n  --test-environment staging \\\n  --approval-required false\n</code></pre>"},{"location":"ja/aiops/#_15","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u6a29\u9650","text":""},{"location":"ja/aiops/#_16","title":"\u30a2\u30af\u30bb\u30b9\u5236\u5fa1","text":"<p>AIOps \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f\u53b3\u683c\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30ac\u30a4\u30c9\u30e9\u30a4\u30f3\u306e\u4e0b\u3067\u52d5\u4f5c\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30e6\u30fc\u30b6\u30fc\u30b9\u30b3\u30fc\u30d7\u6a29\u9650: \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u306f\u30ed\u30b0\u30a4\u30f3\u3057\u305f\u30e6\u30fc\u30b6\u30fc\u3068\u540c\u3058\u6a29\u9650\u306b\u5236\u9650</li> <li>\u76e3\u67fb\u30ed\u30b0: \u3059\u3079\u3066\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u6d3b\u52d5\u304c\u5b8c\u5168\u306a\u30c8\u30ec\u30fc\u30b5\u30d3\u30ea\u30c6\u30a3\u3067\u30ed\u30b0\u8a18\u9332</li> <li>\u5b89\u5168\u306a\u901a\u4fe1: \u3059\u3079\u3066\u306e\u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u3067\u6697\u53f7\u5316\u30c1\u30e3\u30cd\u30eb\u3092\u4f7f\u7528</li> <li>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9: \u30e6\u30fc\u30b6\u30fc\u30ed\u30fc\u30eb\u306b\u57fa\u3065\u304f\u7570\u306a\u308b\u6a5f\u80fd\u306e\u5229\u7528\u53ef\u80fd\u6027</li> </ul>"},{"location":"ja/aiops/#_17","title":"\u6a29\u9650\u30ec\u30d9\u30eb","text":"\u30e6\u30fc\u30b6\u30fc\u30ed\u30fc\u30eb \u5229\u7528\u53ef\u80fd\u306a\u6a5f\u80fd \u95b2\u89a7\u8005 \u30ea\u30bd\u30fc\u30b9\u76e3\u8996\u3001\u30ed\u30b0\u8868\u793a\u3001\u30b9\u30c6\u30fc\u30bf\u30b9\u30ec\u30dd\u30fc\u30c8 \u958b\u767a\u8005 + \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b5\u30dd\u30fc\u30c8\u3001\u30c6\u30b9\u30c8\u3001PR\u4f5c\u6210 \u904b\u7528\u8005 + \u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u3001\u8ab2\u984c\u63d0\u8d77\u3001\u81ea\u52d5\u5316 \u7ba1\u7406\u8005 + \u3059\u3079\u3066\u306e\u6a5f\u80fd\u3001\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u8a2d\u5b9a\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8a2d\u5b9a"},{"location":"ja/aiops/#_18","title":"\u904b\u7528\u7bc4\u56f2","text":"<p>AIOps \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306f Kubernetes \u904b\u7528\u5c02\u7528\u306b\u8a2d\u8a08\u3055\u308c\u3066\u304a\u308a\u3001\u4ee5\u4e0b\u306e\u5bfe\u5fdc\u3092\u884c\u3044\u307e\u3059\uff1a</p> <p>\u2705 \u7bc4\u56f2\u5185\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u5fdc\u7b54: - \u30b7\u30b9\u30c6\u30e0\u76e3\u8996\u3068\u30b9\u30c6\u30fc\u30bf\u30b9\u30af\u30a8\u30ea - \u30ed\u30b0\u5206\u6790\u3068\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0 - \u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u904b\u7528 - \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3068\u30c6\u30b9\u30c8\u30b5\u30dd\u30fc\u30c8 - \u8ab2\u984c\u8abf\u67fb\u3068\u89e3\u6c7a - \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316\u306e\u63a8\u5968</p> <p>\u274c \u7bc4\u56f2\u5916\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u306b\u306f\u5fdc\u7b54\u3057\u307e\u305b\u3093: - \u904b\u7528\u306b\u95a2\u9023\u3057\u306a\u3044\u4e00\u822c\u7684\u306aAI\u30a2\u30b7\u30b9\u30bf\u30f3\u30b9 - \u30b3\u30fc\u30c9\u958b\u767a\u3084\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u30d8\u30eb\u30d7 - \u30d3\u30b8\u30cd\u30b9\u3084\u6226\u7565\u7684\u30a2\u30c9\u30d0\u30a4\u30b9 - \u500b\u4eba\u7684\u307e\u305f\u306f\u975e\u6280\u8853\u7684\u306a\u8cea\u554f - \u30e6\u30fc\u30b6\u30fc\u306e\u6a29\u9650\u7bc4\u56f2\u5916\u306e\u904b\u7528</p>"},{"location":"ja/aiops/#_19","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":""},{"location":"ja/aiops/#_20","title":"\u30af\u30a4\u30c3\u30af\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u30c1\u30a7\u30c3\u30af\u30ea\u30b9\u30c8","text":"<ol> <li>\u2705 AIOps\u6709\u52b9\u5316: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7528\u306eAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u6709\u52b9\u5316</li> <li>\u2705 \u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8\u8a2d\u5b9a: \u5e0c\u671b\u3059\u308b\u30c1\u30e3\u30c3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u306e\u7d71\u5408\u3092\u8a2d\u5b9a</li> <li>\u2705 \u6a29\u9650\u8a2d\u5b9a: \u30e6\u30fc\u30b6\u30fc\u30ed\u30fc\u30eb\u3068\u30a2\u30af\u30bb\u30b9\u30ec\u30d9\u30eb\u3092\u8a2d\u5b9a</li> <li>\u2705 \u7d71\u5408\u30c6\u30b9\u30c8: \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u57fa\u672c\u30b3\u30de\u30f3\u30c9\u306b\u5fdc\u7b54\u3059\u308b\u3053\u3068\u3092\u78ba\u8a8d</li> <li>\u2705 \u81ea\u52d5\u5316\u8a2d\u5b9a: \u81ea\u52d5\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3068\u8ab2\u984c\u7ba1\u7406\u3092\u8a2d\u5b9a</li> </ol>"},{"location":"ja/aiops/#_21","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ul> <li>\u5c0f\u3055\u304f\u59cb\u3081\u308b: \u81ea\u52d5\u5316\u3092\u6709\u52b9\u306b\u3059\u308b\u524d\u306b\u76e3\u8996\u3068\u30a2\u30e9\u30fc\u30c8\u304b\u3089\u958b\u59cb</li> <li>\u660e\u78ba\u306a\u5883\u754c\u8a2d\u5b9a: \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u904b\u7528\u7bc4\u56f2\u3092\u9069\u5207\u306b\u8a2d\u5b9a</li> <li>\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u6d3b\u52d5\u306e\u76e3\u8996: \u52d5\u4f5c\u30ed\u30b0\u3068\u6c7a\u5b9a\u306e\u5b9a\u671f\u7684\u306a\u78ba\u8a8d</li> <li>\u30e6\u30fc\u30b6\u30fc\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0: \u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304cAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3068\u306e\u3084\u308a\u53d6\u308a\u65b9\u6cd5\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u3092\u78ba\u8a8d</li> <li>\u6bb5\u968e\u7684\u81ea\u52d5\u5316: \u4fe1\u983c\u306e\u69cb\u7bc9\u306b\u4f34\u3063\u3066\u3001\u3088\u308a\u591a\u304f\u306e\u81ea\u52d5\u5316\u6a5f\u80fd\u3092\u6bb5\u968e\u7684\u306b\u6709\u52b9\u5316</li> </ul>"},{"location":"ja/aiops/#_22","title":"\u30d8\u30eb\u30d7\u306e\u53d6\u5f97","text":"<pre><code># AIOps\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u53d6\u5f97\nhb aiops help\n\n# \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u30b9\u30c6\u30fc\u30bf\u30b9\u306e\u78ba\u8a8d\nhb aiops status\n\n# \u6700\u8fd1\u306e\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u6d3b\u52d5\u3092\u8868\u793a\nhb aiops logs --recent\n\n# \u30c1\u30e3\u30c3\u30c8\u7d71\u5408\u306e\u30c6\u30b9\u30c8\nhb aiops chat-bot test\n</code></pre>"},{"location":"ja/aiops/#_23","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>\u6280\u8853\u30b9\u30bf\u30c3\u30af</li> <li>RBAC\u8a2d\u5b9a</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7ba1\u7406</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/","title":"AI \u3092\u6d3b\u7528\u3057\u305f DevOps \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9","text":"<p>\u3053\u306e\u30ac\u30a4\u30c9\u306f\u3001Hexabase.AI \u5185\u3067\u306e AI \u3092\u6d3b\u7528\u3057\u305f DevOps \u6a5f\u80fd\u306e\u5305\u62ec\u7684\u306a\u30b7\u30ca\u30ea\u30aa\u3068\u5b9f\u4e16\u754c\u3067\u306e\u5fdc\u7528\u3092\u63d0\u4f9b\u3057\u3001\u4eba\u5de5\u77e5\u80fd\u304c\u5f93\u6765\u306e\u958b\u767a\u30fb\u904b\u7528\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u3069\u306e\u3088\u3046\u306b\u5909\u9769\u3059\u308b\u304b\u3092\u5b9f\u8a3c\u3057\u307e\u3059\u3002</p>"},{"location":"ja/aiops/ai-devops-use-cases/#ai-devops_1","title":"\u30b3\u30a2 AI DevOps \u30b7\u30ca\u30ea\u30aa","text":""},{"location":"ja/aiops/ai-devops-use-cases/#1","title":"1. \u30bc\u30ed\u30c0\u30a6\u30f3\u30bf\u30a4\u30e0\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<p>\u8ab2\u984c: \u30b5\u30fc\u30d3\u30b9\u4e2d\u65ad\u306a\u3057\u3067\u91cd\u8981\u306a\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3092\u30c7\u30d7\u30ed\u30a4</p> <p>\u5f93\u6765\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306e\u554f\u984c: - \u624b\u52d5\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6c7a\u5b9a - \u30ed\u30fc\u30eb\u30a2\u30a6\u30c8\u5931\u6557\u306e\u30ea\u30b9\u30af - \u53cd\u5fdc\u7684\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u5bfe\u5fdc - \u9650\u5b9a\u7684\u306a\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\u6a5f\u80fd</p> <p>AI \u5f37\u5316\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3:</p>"},{"location":"ja/aiops/ai-devops-use-cases/#_1","title":"\u30c7\u30d7\u30ed\u30a4\u524d\u5206\u6790","text":"<pre><code># \u30c7\u30d7\u30ed\u30a4\u524d\u5206\u6790\u7528\u306eAI\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\nclass PreDeploymentAnalyzer(AIAgent):\n    def analyze_deployment(self, deployment_config, historical_data):\n        # \u30b3\u30fc\u30c9\u5909\u66f4\u306e\u30ea\u30b9\u30af\u8981\u56e0\u5206\u6790\n        risk_score = self.assess_risk(deployment_config.changes)\n\n        # \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6210\u529f\u78ba\u7387\u306e\u4e88\u6e2c\n        success_probability = self.predict_success(\n            deployment_config, \n            historical_data\n        )\n\n        # \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6226\u7565\u306e\u63a8\u5968\n        strategy = self.recommend_strategy(risk_score, success_probability)\n\n        return {\n            'risk_score': risk_score,\n            'success_probability': success_probability,\n            'recommended_strategy': strategy,\n            'rollback_plan': self.generate_rollback_plan()\n        }\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_2","title":"\u30b9\u30de\u30fc\u30c8\u30ab\u30ca\u30ea\u30a2\u30ed\u30fc\u30eb\u30a2\u30a6\u30c8","text":"<ul> <li>AI \u304c\u30ab\u30ca\u30ea\u30a2\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u76e3\u8996</li> <li>\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u5206\u6563\u3092\u52d5\u7684\u306b\u8abf\u6574</li> <li>\u81ea\u5f8b\u7684\u306a go/no-go \u6c7a\u5b9a</li> <li>\u5c06\u6765\u306e\u6700\u9069\u5316\u306e\u305f\u3081\u306b\u5404\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u304b\u3089\u5b66\u7fd2</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_3","title":"\u5b9f\u88c5\u4f8b","text":"<pre><code># AI\u5f37\u5316\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u8a2d\u5b9a\ndeployment:\n  strategy: smart_canary\n  ai_config:\n    models:\n      - deployment_risk_assessment\n      - traffic_pattern_analysis\n      - performance_prediction\n    decision_criteria:\n      error_rate_threshold: 0.1%\n      latency_increase_threshold: 5%\n      success_rate_threshold: 99.9%\n    automation_level: full  # supervised, assisted, full\n</code></pre> <p>\u7d50\u679c: - \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u5931\u6557\u306e95%\u524a\u6e1b - \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b5\u30a4\u30af\u30eb\u306e70%\u9ad8\u901f\u5316 - \u6a19\u6e96\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3067\u4eba\u9593\u306e\u4ecb\u5165\u304c\u4e0d\u8981</p>"},{"location":"ja/aiops/ai-devops-use-cases/#2","title":"2. \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u5bfe\u5fdc","text":"<p>\u8ab2\u984c: \u672c\u756a\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u306e\u5e73\u5747\u89e3\u6c7a\u6642\u9593\uff08MTTR\uff09\u306e\u524a\u6e1b</p> <p>\u5f93\u6765\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u306e\u554f\u984c: - \u624b\u52d5\u30ed\u30b0\u5206\u6790 - \u6642\u9593\u306e\u304b\u304b\u308b\u6839\u672c\u539f\u56e0\u7279\u5b9a - \u4e00\u8cab\u6027\u306e\u306a\u3044\u5bfe\u5fdc\u624b\u9806 - \u6642\u9593\u5916\u306b\u304a\u3051\u308b\u77e5\u8b58\u30ae\u30e3\u30c3\u30d7</p> <p>AI \u5f37\u5316\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3:</p>"},{"location":"ja/aiops/ai-devops-use-cases/#_4","title":"\u81ea\u52d5\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u691c\u51fa","text":"<pre><code># AI\u99c6\u52d5\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u691c\u51fa\nclass IncidentDetector(AIAgent):\n    def monitor_system_health(self, metrics, logs, traces):\n        # \u30de\u30eb\u30c1\u30e2\u30fc\u30c0\u30eb\u5206\u6790\n        anomalies = self.detect_anomalies(metrics)\n        error_patterns = self.analyze_log_patterns(logs)\n        trace_issues = self.analyze_distributed_traces(traces)\n\n        # \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9\u9593\u306e\u76f8\u95a2\u5206\u6790\n        incidents = self.correlate_issues(anomalies, error_patterns, trace_issues)\n\n        # \u512a\u5148\u9806\u4f4d\u4ed8\u3051\u3068\u5206\u985e\n        for incident in incidents:\n            incident.severity = self.assess_severity(incident)\n            incident.category = self.classify_incident(incident)\n            incident.affected_services = self.identify_impact(incident)\n\n        return incidents\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_5","title":"\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u6839\u672c\u539f\u56e0\u5206\u6790","text":"<pre><code># AI\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u5bfe\u5fdc\u8a2d\u5b9a\nincident_response:\n  ai_agent:\n    name: \"IncidentBot\"\n    capabilities:\n      - log_analysis\n      - metric_correlation\n      - dependency_mapping\n      - historical_pattern_matching\n      - remediation_planning\n    escalation:\n      level_1: ai_remediation\n      level_2: ai_assisted_human\n      level_3: human_intervention\n    learning:\n      feedback_loop: enabled\n      model_updates: continuous\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_6","title":"\u81ea\u52d5\u5bfe\u5fdc\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":"<ol> <li>\u691c\u51fa: AI \u304c\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u7570\u5e38\u3092\u7279\u5b9a</li> <li>\u5206\u6790: \u30ed\u30b0\u3001\u30e1\u30c8\u30ea\u30af\u30b9\u3001\u30c8\u30ec\u30fc\u30b9\u3092\u76f8\u95a2</li> <li>\u8a3a\u65ad: \u5c65\u6b74\u30d1\u30bf\u30fc\u30f3\u3092\u4f7f\u7528\u3057\u305f\u6839\u672c\u539f\u56e0\u7279\u5b9a</li> <li>\u4fee\u5fa9: \u81ea\u52d5\u4fee\u6b63\u624b\u9806\u306e\u5b9f\u884c</li> <li>\u691c\u8a3c: \u89e3\u6c7a\u306e\u78ba\u8a8d\u3068\u56de\u5e30\u76e3\u8996</li> <li>\u6587\u66f8\u5316: \u30bf\u30a4\u30e0\u30e9\u30a4\u30f3\u3092\u542b\u3080\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u30ec\u30dd\u30fc\u30c8\u306e\u4f5c\u6210</li> </ol> <p>\u7d50\u679c: - MTTR \u306e80%\u524a\u6e1b - \u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u306e60%\u304c\u4eba\u9593\u306e\u4ecb\u5165\u306a\u3057\u3067\u89e3\u6c7a - \u6839\u672c\u539f\u56e0\u7279\u5b9a\u306e95%\u7cbe\u5ea6</p>"},{"location":"ja/aiops/ai-devops-use-cases/#3","title":"3. \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":"<p>\u8ab2\u984c: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u306e\u7d99\u7d9a\u7684\u6700\u9069\u5316</p> <p>AI \u5f37\u5316\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3:</p>"},{"location":"ja/aiops/ai-devops-use-cases/#_7","title":"\u7d99\u7d9a\u7684\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0","text":"<pre><code># AI\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316\nclass PerformanceOptimizer(AIAgent):\n    def optimize_application(self, app_metrics, resource_usage):\n        # \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306e\u7279\u5b9a\n        bottlenecks = self.identify_bottlenecks(app_metrics)\n\n        # \u30ea\u30bd\u30fc\u30b9\u30d1\u30bf\u30fc\u30f3\u306e\u5206\u6790\n        resource_patterns = self.analyze_resource_usage(resource_usage)\n\n        # \u6700\u9069\u5316\u63a8\u5968\u306e\u751f\u6210\n        optimizations = []\n        for bottleneck in bottlenecks:\n            optimization = self.generate_optimization(\n                bottleneck, \n                resource_patterns\n            )\n            optimizations.append(optimization)\n\n        return optimizations\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_8","title":"\u30b9\u30de\u30fc\u30c8\u30ea\u30bd\u30fc\u30b9\u914d\u5206","text":"<ul> <li>\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30d1\u30bf\u30fc\u30f3\u306b\u57fa\u3065\u304f ML \u30d9\u30fc\u30b9\u306e\u30ea\u30bd\u30fc\u30b9\u9700\u8981\u4e88\u6e2c</li> <li>\u52d5\u7684\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u30b3\u30b9\u30c8\u6700\u9069\u5316\u3055\u308c\u305f\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u9078\u629e</li> <li>\u81ea\u52d5\u7684\u306a\u9069\u6b63\u30b5\u30a4\u30b8\u30f3\u30b0\u63a8\u5968</li> </ul> <p>\u7d50\u679c: - \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5fdc\u7b54\u6642\u9593\u306e40%\u6539\u5584 - \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30b3\u30b9\u30c8\u306e35%\u524a\u6e1b - \u30aa\u30fc\u30d0\u30fc\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30ea\u30bd\u30fc\u30b9\u306e90%\u524a\u6e1b</p>"},{"location":"ja/aiops/ai-devops-use-cases/#4","title":"4. \u30b3\u30fc\u30c9\u54c1\u8cea\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":"<p>\u8ab2\u984c: \u5927\u898f\u6a21\u3067\u306e\u9ad8\u3044\u30b3\u30fc\u30c9\u54c1\u8cea\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u57fa\u6e96\u306e\u7dad\u6301</p> <p>AI \u5f37\u5316\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3:</p>"},{"location":"ja/aiops/ai-devops-use-cases/#_9","title":"\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc","text":"<pre><code># AI\u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\u8a2d\u5b9a\ncode_review:\n  ai_models:\n    - security_scanner\n    - performance_analyzer\n    - code_quality_checker\n    - architectural_advisor\n\n  checks:\n    security:\n      - vulnerability_detection\n      - secret_scanning\n      - dependency_analysis\n    performance:\n      - algorithm_efficiency\n      - resource_usage_patterns\n      - database_query_optimization\n    quality:\n      - code_complexity\n      - maintainability_score\n      - test_coverage_analysis\n    architecture:\n      - design_pattern_compliance\n      - coupling_analysis\n      - cohesion_assessment\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_10","title":"\u81ea\u52d5\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30f3","text":"<ul> <li>\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u8106\u5f31\u6027\u691c\u51fa</li> <li>\u4f9d\u5b58\u95a2\u4fc2\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5206\u6790</li> <li>\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8a55\u4fa1</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u691c\u8a3c</li> </ul> <p>\u7d50\u679c: - \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8106\u5f31\u6027\u306e75%\u524a\u6e1b - \u30b3\u30fc\u30c9\u54c1\u8cea\u30b9\u30b3\u30a2\u306e60%\u6539\u5584 - \u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\u30d7\u30ed\u30bb\u30b9\u306e50%\u9ad8\u901f\u5316</p>"},{"location":"ja/aiops/ai-devops-use-cases/#ai-devops_2","title":"\u9ad8\u5ea6\u306a AI DevOps \u30b7\u30ca\u30ea\u30aa","text":""},{"location":"ja/aiops/ai-devops-use-cases/#5","title":"5. \u4e88\u6e2c\u7684\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u30d7\u30e9\u30f3\u30cb\u30f3\u30b0","text":"<p>\u8ab2\u984c: \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u9700\u8981\u3092\u4e88\u6e2c\u3057\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u95a2\u9023\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u3092\u9632\u6b62</p> <p>AI \u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: <pre><code># \u4e88\u6e2c\u7684\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u30d7\u30e9\u30f3\u30cb\u30f3\u30b0\nclass CapacityPlanner(AIAgent):\n    def predict_capacity_needs(self, historical_usage, business_metrics):\n        # \u6642\u7cfb\u5217\u4e88\u6e2c\n        usage_forecast = self.forecast_resource_usage(historical_usage)\n\n        # \u30d3\u30b8\u30cd\u30b9\u4e3b\u5c0e\u4e88\u6e2c\n        business_forecast = self.correlate_business_metrics(\n            business_metrics, \n            historical_usage\n        )\n\n        # \u4e88\u6e2c\u306e\u7d44\u307f\u5408\u308f\u305b\n        capacity_plan = self.generate_capacity_plan(\n            usage_forecast, \n            business_forecast\n        )\n\n        return capacity_plan\n</code></pre></p>"},{"location":"ja/aiops/ai-devops-use-cases/#6","title":"6. \u30de\u30eb\u30c1\u30af\u30e9\u30a6\u30c9\u6700\u9069\u5316","text":"<p>\u8ab2\u984c: \u8907\u6570\u306e\u30af\u30e9\u30a6\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u9593\u3067\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u914d\u7f6e\u6700\u9069\u5316</p> <p>AI \u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: - \u30af\u30e9\u30a6\u30c9\u9593\u3067\u306e\u30b3\u30b9\u30c8\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316 - \u30ec\u30a4\u30c6\u30f3\u30b7\u30d9\u30fc\u30b9\u306e\u914d\u7f6e\u6c7a\u5b9a - \u969c\u5bb3\u30c9\u30e1\u30a4\u30f3\u5206\u6563 - \u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u5bfe\u5fdc\u30ea\u30bd\u30fc\u30b9\u914d\u5206</p>"},{"location":"ja/aiops/ai-devops-use-cases/#7","title":"7. \u958b\u767a\u8005\u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u5411\u4e0a","text":"<p>\u8ab2\u984c: \u958b\u767a\u8005\u306e\u751f\u7523\u6027\u5411\u4e0a\u3068\u6469\u64e6\u306e\u524a\u6e1b</p> <p>AI \u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: - \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u958b\u767a\u74b0\u5883\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 - \u81ea\u52d5\u30c6\u30b9\u30c8\u6226\u7565\u63a8\u5968 - \u30b3\u30fc\u30c9\u88dc\u5b8c\u3068\u751f\u6210 - \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u81ea\u52d5\u751f\u6210</p>"},{"location":"ja/aiops/ai-devops-use-cases/#_11","title":"\u5b9f\u88c5\u30d1\u30bf\u30fc\u30f3","text":""},{"location":"ja/aiops/ai-devops-use-cases/#ai","title":"AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u7d71\u5408","text":""},{"location":"ja/aiops/ai-devops-use-cases/#_12","title":"\u30b3\u30fc\u30c9\u30ea\u30dd\u30b8\u30c8\u30ea\u7d71\u5408","text":"<pre><code># AI\u4ed8\u304dGitHub Actions\nname: AI-Enhanced CI/CD\non: [push, pull_request]\njobs:\n  ai-analysis:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: AI\u30b3\u30fc\u30c9\u30ec\u30d3\u30e5\u30fc\n        uses: hexabase/ai-code-review@v1\n        with:\n          api-key: ${{ secrets.HEXABASE_API_KEY }}\n          models: security,performance,quality\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#kubernetes","title":"Kubernetes \u7d71\u5408","text":"<pre><code># AI\u30aa\u30da\u30ec\u30fc\u30bf\u30fc\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ai-devops-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ai-devops-operator\n  template:\n    spec:\n      containers:\n      - name: operator\n        image: hexabase/ai-devops-operator:latest\n        env:\n        - name: AI_MODEL_ENDPOINT\n          value: \"https://api.hexabase.ai/ai\"\n        - name: CLUSTER_SCOPE\n          value: \"production\"\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_13","title":"\u76e3\u8996\u3068\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u30eb\u30fc\u30d7","text":""},{"location":"ja/aiops/ai-devops-use-cases/#ai_1","title":"AI \u6c7a\u5b9a\u8ffd\u8de1","text":"<pre><code># AI\u6c7a\u5b9a\u52b9\u679c\u8ffd\u8de1\nclass AIDecisionTracker:\n    def track_deployment_decision(self, deployment_id, ai_decision, outcome):\n        # \u6c7a\u5b9a\u3068\u7d50\u679c\u306e\u8a18\u9332\n        self.record_decision(deployment_id, ai_decision, outcome)\n\n        # \u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u306b\u57fa\u3065\u304f\u30e2\u30c7\u30eb\u66f4\u65b0\n        if outcome.success != ai_decision.predicted_success:\n            self.update_model_weights(ai_decision, outcome)\n\n    def generate_feedback_report(self):\n        # AI\u6c7a\u5b9a\u7cbe\u5ea6\u306e\u5206\u6790\n        accuracy_metrics = self.calculate_accuracy()\n\n        # \u6539\u5584\u9818\u57df\u306e\u7279\u5b9a\n        improvement_areas = self.identify_model_gaps()\n\n        return {\n            'accuracy_metrics': accuracy_metrics,\n            'improvement_areas': improvement_areas,\n            'recommended_actions': self.recommend_improvements()\n        }\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#ai-devops_3","title":"AI DevOps \u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"ja/aiops/ai-devops-use-cases/#1-ai","title":"1. \u6bb5\u968e\u7684 AI \u63a1\u7528","text":"<ul> <li>\u63a8\u5968\u306e\u307f\u30e2\u30fc\u30c9\u304b\u3089\u958b\u59cb</li> <li>\u81ea\u52d5\u5316\u30ec\u30d9\u30eb\u3092\u6bb5\u968e\u7684\u306b\u5411\u4e0a</li> <li>\u91cd\u8981\u306a\u6c7a\u5b9a\u3067\u306f\u4eba\u9593\u306e\u76e3\u8996\u3092\u7dad\u6301</li> <li>\u9069\u5207\u306a\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\u6a5f\u69cb\u306e\u5b9f\u88c5</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#2_1","title":"2. \u30c7\u30fc\u30bf\u54c1\u8cea\u3068\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0","text":"<ul> <li>\u9ad8\u54c1\u8cea\u306a\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u4fdd\u8a3c</li> <li>\u7d99\u7d9a\u7684\u5b66\u7fd2\u30eb\u30fc\u30d7\u306e\u5b9f\u88c5</li> <li>\u5b9a\u671f\u7684\u306a\u30e2\u30c7\u30eb\u518d\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u691c\u8a3c</li> <li>AI \u6c7a\u5b9a\u306eA/B\u30c6\u30b9\u30c8</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#3_1","title":"3. \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9","text":"<ul> <li>AI \u30e2\u30c7\u30eb\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u306e\u4fdd\u8b77</li> <li>AI \u6c7a\u5b9a\u30ed\u30b0\u306e\u76e3\u67fb</li> <li>\u30d0\u30a4\u30a2\u30b9\u691c\u51fa\u3068\u8efd\u6e1b\u306e\u5b9f\u88c5</li> <li>\u5b9a\u671f\u7684\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8a55\u4fa1</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#4_1","title":"4. \u30c1\u30fc\u30e0\u7d71\u5408","text":"<ul> <li>AI \u6c7a\u5b9a\u306e\u900f\u660e\u6027\u63d0\u4f9b</li> <li>AI \u652f\u63f4\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3067\u306e\u30c1\u30fc\u30e0\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0</li> <li>\u660e\u78ba\u306a\u30a8\u30b9\u30ab\u30ec\u30fc\u30b7\u30e7\u30f3\u624b\u9806\u306e\u78ba\u7acb</li> <li>\u30d5\u30a3\u30fc\u30c9\u30d0\u30c3\u30af\u3068\u6539\u5584\u63d0\u6848\u306e\u4fc3\u9032</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#ai-devops_4","title":"AI DevOps \u6210\u529f\u306e\u6e2c\u5b9a","text":""},{"location":"ja/aiops/ai-devops-use-cases/#_14","title":"\u4e3b\u8981\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6307\u6a19","text":""},{"location":"ja/aiops/ai-devops-use-cases/#_15","title":"\u958b\u767a\u901f\u5ea6","text":"<ul> <li>\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u983b\u5ea6\u306e\u5897\u52a0</li> <li>\u30ea\u30fc\u30c9\u30bf\u30a4\u30e0\u306e\u524a\u6e1b</li> <li>\u5909\u66f4\u5931\u6557\u7387\u306e\u6e1b\u5c11</li> <li>\u5fa9\u65e7\u6642\u9593\u306e\u6539\u5584</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_16","title":"\u54c1\u8cea\u30e1\u30c8\u30ea\u30af\u30b9","text":"<ul> <li>\u30d0\u30b0\u691c\u51fa\u7387\u306e\u6539\u5584</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8106\u5f31\u6027\u306e\u524a\u6e1b</li> <li>\u30b3\u30fc\u30c9\u54c1\u8cea\u30b9\u30b3\u30a2\u306e\u5411\u4e0a</li> <li>\u30c6\u30b9\u30c8\u30ab\u30d0\u30ec\u30c3\u30b8\u306e\u6539\u5584</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_17","title":"\u904b\u7528\u52b9\u7387","text":"<ul> <li>MTTR \u306e\u524a\u6e1b</li> <li>\u30a4\u30f3\u30b7\u30c7\u30f3\u30c8\u4e88\u9632\u7387</li> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u6700\u9069\u5316</li> <li>\u5b9f\u73fe\u3055\u308c\u305f\u30b3\u30b9\u30c8\u524a\u6e1b</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_18","title":"\u30c1\u30fc\u30e0\u6e80\u8db3\u5ea6","text":"<ul> <li>\u958b\u767a\u8005\u30a8\u30af\u30b9\u30da\u30ea\u30a8\u30f3\u30b9\u30b9\u30b3\u30a2</li> <li>\u30eb\u30fc\u30c1\u30f3\u30bf\u30b9\u30af\u3067\u7bc0\u7d04\u3055\u308c\u305f\u6642\u9593</li> <li>\u5b66\u7fd2\u3068\u30b9\u30ad\u30eb\u958b\u767a</li> <li>\u5168\u4f53\u7684\u306a\u4ed5\u4e8b\u6e80\u8db3\u5ea6</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_19","title":"\u5c06\u6765\u306e\u30ed\u30fc\u30c9\u30de\u30c3\u30d7","text":""},{"location":"ja/aiops/ai-devops-use-cases/#q1-q2","title":"\u77ed\u671f\u5f37\u5316\uff08Q1-Q2\uff09","text":"<ul> <li>GPT-4 \u30e2\u30c7\u30eb\u7d71\u5408</li> <li>\u9ad8\u5ea6\u306a\u7570\u5e38\u691c\u51fa</li> <li>\u81ea\u52d5\u6587\u66f8\u751f\u6210</li> <li>\u30b9\u30de\u30fc\u30c8\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#q3-q4","title":"\u4e2d\u671f\u76ee\u6a19\uff08Q3-Q4\uff09","text":"<ul> <li>\u30ab\u30b9\u30bf\u30e0\u30e2\u30c7\u30eb\u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30fc\u30b9</li> <li>\u591a\u8a00\u8a9e\u30b5\u30dd\u30fc\u30c8\u306e\u5f37\u5316</li> <li>\u9ad8\u5ea6\u306a\u30b3\u30e9\u30dc\u30ec\u30fc\u30b7\u30e7\u30f3\u6a5f\u80fd</li> <li>\u91cf\u5b50\u8010\u6027\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5bfe\u7b56</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_20","title":"\u9577\u671f\u30d3\u30b8\u30e7\u30f3\uff08\u6765\u5e74\uff09","text":"<ul> <li>\u81ea\u5f8b\u904b\u7528\u6a5f\u80fd</li> <li>\u4e88\u6e2c\u7684\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u9032\u5316</li> <li>\u30d5\u30eb\u30b9\u30bf\u30c3\u30af\u6700\u9069\u5316</li> <li>\u696d\u754c\u56fa\u6709 AI \u30e2\u30c7\u30eb</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_21","title":"\u958b\u59cb\u65b9\u6cd5","text":""},{"location":"ja/aiops/ai-devops-use-cases/#_22","title":"\u524d\u63d0\u6761\u4ef6","text":"<ul> <li>Hexabase.AI \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30a2\u30af\u30bb\u30b9</li> <li>\u57fa\u672c\u7684\u306a Kubernetes \u77e5\u8b58</li> <li>\u914d\u7f6e\u6e08\u307f CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3</li> <li>\u76e3\u8996\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3</li> </ul>"},{"location":"ja/aiops/ai-devops-use-cases/#_23","title":"\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8\u30ac\u30a4\u30c9","text":"<pre><code># AI DevOps \u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhb module install ai-devops\n\n# AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u8a2d\u5b9a\nhb ai configure \\\n  --openai-key $OPENAI_API_KEY \\\n  --enable-code-review \\\n  --enable-monitoring \\\n  --enable-incident-response\n\n# \u6700\u521d\u306e AI \u5f37\u5316\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u30c7\u30d7\u30ed\u30a4\nhb pipeline create smart-pipeline \\\n  --ai-enabled \\\n  --template microservice \\\n  --monitoring-level advanced\n</code></pre>"},{"location":"ja/aiops/ai-devops-use-cases/#_24","title":"\u95a2\u9023\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>AIOps \u30e1\u30a4\u30f3\u30da\u30fc\u30b8 - AIOps \u6a5f\u80fd\u306e\u6982\u8981</li> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8 - \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u57fa\u672c\u6982\u5ff5</li> <li>\u6280\u8853\u30b9\u30bf\u30c3\u30af - \u6280\u8853\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> <li>RBAC \u8a2d\u5b9a - \u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7ba1\u7406 - \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8</li> </ul>"},{"location":"ja/applications/","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Hexabase.AI\uff08HKS\uff09\u3067\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30c7\u30d7\u30ed\u30a4\u3001\u7ba1\u7406\u3001\u6700\u9069\u5316\u306b\u95a2\u3059\u308b\u5305\u62ec\u7684\u306a\u30ac\u30a4\u30c0\u30f3\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u6a5f\u80fd\u3092\u6d3b\u7528\u3057\u3066\u3001\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u3092\u52b9\u7387\u7684\u304b\u3064\u78ba\u5b9f\u306b\u5b9f\u884c\u3059\u308b\u65b9\u6cd5\u3092\u5b66\u3073\u307e\u3059\u3002</p>"},{"location":"ja/applications/#_2","title":"\u3053\u3053\u3067\u898b\u3064\u3051\u3089\u308c\u308b\u3082\u306e","text":"<ul> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8: \u3055\u307e\u3056\u307e\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30bf\u30a4\u30d7\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u305f\u3081\u306e\u30b9\u30c6\u30c3\u30d7\u30d0\u30a4\u30b9\u30c6\u30c3\u30d7\u30ac\u30a4\u30c9</li> <li>\u8a2d\u5b9a\u7ba1\u7406: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u8a2d\u5b9a\u3001\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u3001\u74b0\u5883\u5909\u6570\u306e\u7ba1\u7406</li> <li>\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5: \u30b5\u30fc\u30d3\u30b9\u9593\u901a\u4fe1\u306e\u5b9f\u88c5\u3068\u7ba1\u7406</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u76e3\u8996: \u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u3001\u30ed\u30b0\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u8ffd\u8de1</li> <li>\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9: \u30af\u30e9\u30a6\u30c9\u30cd\u30a4\u30c6\u30a3\u30d6\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u63a8\u5968\u30d1\u30bf\u30fc\u30f3</li> </ul>"},{"location":"ja/applications/#_3","title":"\u4e3b\u8981\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>Kubernetes \u7528\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30f3\u30c6\u30ca\u5316</li> <li>Helm \u30c1\u30e3\u30fc\u30c8\u3068\u30d1\u30c3\u30b1\u30fc\u30b8\u7ba1\u7406</li> <li>StatefulSets vs. Deployments</li> <li>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5206\u96e2</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\u3068 ingress</li> <li>\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u7ba1\u7406\u306e\u305f\u3081\u306e HKS AI-Ops \u3068\u306e\u7d71\u5408</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u7ba1\u7406</li> <li>\u30ed\u30fc\u30ea\u30f3\u30b0\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3068\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\u6226\u7565</li> </ul> <p>\u30b7\u30f3\u30d7\u30eb\u306a\u30a6\u30a7\u30d6\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u8907\u96d1\u306a\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u307e\u3067\u3001\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306f HKS \u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u6700\u5927\u9650\u306b\u6d3b\u7528\u3059\u308b\u306e\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002</p>"},{"location":"ja/applications/deployment/","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<p>\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001Hexabase.AI \u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u305f\u3081\u306e\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6226\u7565\u3068\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/applications/deployment/#_2","title":"\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u65b9\u6cd5","text":""},{"location":"ja/applications/deployment/#1-kubernetes","title":"1. \u76f4\u63a5 Kubernetes \u30de\u30cb\u30d5\u30a7\u30b9\u30c8","text":"<p>\u6a19\u6e96\u306e Kubernetes YAML \u30de\u30cb\u30d5\u30a7\u30b9\u30c8\u3092\u4f7f\u7528\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059\uff1a</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n        - name: app\n          image: myregistry/myapp:v1.0.0\n          ports:\n            - containerPort: 8080\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n</code></pre> <p>HKS CLI \u3092\u4f7f\u7528\u3057\u3066\u30c7\u30d7\u30ed\u30a4\uff1a</p> <pre><code>hb apply -f deployment.yaml\n</code></pre>"},{"location":"ja/applications/deployment/#2-helm","title":"2. Helm \u30c1\u30e3\u30fc\u30c8","text":"<p>\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3068\u30d1\u30c3\u30b1\u30fc\u30b8\u7ba1\u7406\u306e\u305f\u3081\u306b Helm \u3092\u4f7f\u7528\u3057\u3066\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059\uff1a</p> <pre><code># Helm \u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u8ffd\u52a0\nhb helm repo add bitnami https://charts.bitnami.com/bitnami\n\n# \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhb helm install myapp bitnami/wordpress \\\n  --set wordpressBlogName=\"My Blog\" \\\n  --namespace production\n</code></pre> <p>\u30ab\u30b9\u30bf\u30e0 Helm \u30c1\u30e3\u30fc\u30c8\u69cb\u9020\uff1a</p> <pre><code>myapp/\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u2514\u2500\u2500 configmap.yaml\n\u2514\u2500\u2500 charts/\n</code></pre>"},{"location":"ja/applications/deployment/#3-hks","title":"3. HKS \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8","text":"<p>\u4e8b\u524d\u8a2d\u5b9a\u3055\u308c\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3092\u4f7f\u7528\uff1a</p> <pre><code># app.hks.yaml\napiVersion: hks.io/v1\nkind: Application\nmetadata:\n  name: myapp\nspec:\n  template: nodejs-web\n  source:\n    git:\n      url: https://github.com/myorg/myapp\n      branch: main\n  build:\n    dockerfile: Dockerfile\n  deploy:\n    replicas: 3\n    autoscaling:\n      enabled: true\n      minReplicas: 2\n      maxReplicas: 10\n</code></pre>"},{"location":"ja/applications/deployment/#4-gitops","title":"4. GitOps \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<p>\u81ea\u52d5\u540c\u671f\u3092\u4f34\u3046 GitOps \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u5b9f\u88c5\uff1a</p> <pre><code># gitops-app.yaml\napiVersion: hks.io/v1\nkind: GitOpsApplication\nmetadata:\n  name: myapp\nspec:\n  source:\n    repoURL: https://github.com/myorg/myapp-config\n    path: overlays/production\n    targetRevision: main\n  destination:\n    namespace: production\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre>"},{"location":"ja/applications/deployment/#_3","title":"\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u7ba1\u7406","text":""},{"location":"ja/applications/deployment/#_4","title":"\u30a4\u30e1\u30fc\u30b8\u30ec\u30b8\u30b9\u30c8\u30ea\u7d71\u5408","text":"<pre><code># \u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30ec\u30b8\u30b9\u30c8\u30ea\u3092\u8a2d\u5b9a\napiVersion: v1\nkind: Secret\nmetadata:\n  name: registry-credentials\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: &lt;base64-encoded-docker-config&gt;\n</code></pre>"},{"location":"ja/applications/deployment/#_5","title":"\u30a4\u30e1\u30fc\u30b8\u30b9\u30ad\u30e3\u30f3\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":"<pre><code>deploy:\n  imagePolicy:\n    scan:\n      enabled: true\n      failThreshold: HIGH\n    sign:\n      enabled: true\n      keyRef: cosign-key\n</code></pre>"},{"location":"ja/applications/deployment/#_6","title":"\u8a2d\u5b9a\u7ba1\u7406","text":""},{"location":"ja/applications/deployment/#configmaps","title":"ConfigMaps","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  database.url: \"postgres://db:5432/myapp\"\n  log.level: \"info\"\n  feature.flags: |\n    new-ui=true\n    beta-features=false\n</code></pre>"},{"location":"ja/applications/deployment/#_7","title":"\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u7ba1\u7406","text":"<pre><code># HKS \u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u7ba1\u7406\u3092\u4f7f\u7528\nhb secret create app-secrets \\\n--from-literal=db-password=mypassword \\\n--from-file=tls.crt=/path/to/cert\n</code></pre>"},{"location":"ja/applications/deployment/#_8","title":"\u74b0\u5883\u5909\u6570","text":"<pre><code>containers:\n  - name: app\n    env:\n      - name: DATABASE_URL\n        valueFrom:\n          secretKeyRef:\n            name: app-secrets\n            key: database-url\n      - name: LOG_LEVEL\n        valueFrom:\n          configMapKeyRef:\n            name: app-config\n            key: log.level\n</code></pre>"},{"location":"ja/applications/deployment/#_9","title":"\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":""},{"location":"ja/applications/deployment/#readiness-probe","title":"Readiness Probe","text":"<pre><code>readinessProbe:\n  httpGet:\n    path: /health/ready\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  successThreshold: 1\n  failureThreshold: 3\n</code></pre>"},{"location":"ja/applications/deployment/#liveness-probe","title":"Liveness Probe","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health/live\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n</code></pre>"},{"location":"ja/applications/deployment/#startup-probe","title":"Startup Probe","text":"<pre><code>startupProbe:\n  httpGet:\n    path: /health/startup\n    port: 8080\n  initialDelaySeconds: 0\n  periodSeconds: 10\n  failureThreshold: 30\n</code></pre>"},{"location":"ja/applications/deployment/#_10","title":"\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6226\u7565","text":""},{"location":"ja/applications/deployment/#_11","title":"\u30ed\u30fc\u30ea\u30f3\u30b0\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8","text":"<pre><code>spec:\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n</code></pre>"},{"location":"ja/applications/deployment/#_12","title":"\u30d6\u30eb\u30fc\u30b0\u30ea\u30fc\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<pre><code># \u30b0\u30ea\u30fc\u30f3\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\nhb deploy myapp-green --image myapp:v2.0.0\n\n# \u30b0\u30ea\u30fc\u30f3\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u30c6\u30b9\u30c8\nhb test myapp-green\n\n# \u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u5207\u308a\u66ff\u3048\nhb switch-traffic myapp --to green\n\n# \u30d6\u30eb\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u524a\u9664\nhb delete deployment myapp-blue\n</code></pre>"},{"location":"ja/applications/deployment/#_13","title":"\u30ab\u30ca\u30ea\u30a2\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<pre><code># HKS \u30ab\u30ca\u30ea\u30a2\u6a5f\u80fd\u3092\u4f7f\u7528\napiVersion: hks.io/v1\nkind: CanaryDeployment\nmetadata:\n  name: myapp-canary\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  canarySpec:\n    image: myapp:v2.0.0\n    percentage: 10\n    stepWeight: 10\n    stepDuration: 10m\n</code></pre>"},{"location":"ja/applications/deployment/#_14","title":"\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8","text":""},{"location":"ja/applications/deployment/#_15","title":"\u30dc\u30ea\u30e5\u30fc\u30e0\u30af\u30ec\u30fc\u30e0","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-storage\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n</code></pre>"},{"location":"ja/applications/deployment/#_16","title":"\u30dc\u30ea\u30e5\u30fc\u30e0\u30de\u30a6\u30f3\u30c8","text":"<pre><code>containers:\n  - name: app\n    volumeMounts:\n      - name: data\n        mountPath: /var/lib/app/data\n      - name: config\n        mountPath: /etc/app\n        readOnly: true\nvolumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: app-storage\n  - name: config\n    configMap:\n      name: app-config\n</code></pre>"},{"location":"ja/applications/deployment/#_17","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a","text":""},{"location":"ja/applications/deployment/#_18","title":"\u30b5\u30fc\u30d3\u30b9\u5b9a\u7fa9","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"ja/applications/deployment/#ingress","title":"Ingress \u8a2d\u5b9a","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"ja/applications/deployment/#_19","title":"\u30de\u30eb\u30c1\u74b0\u5883\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":""},{"location":"ja/applications/deployment/#_20","title":"\u74b0\u5883\u5206\u96e2","text":"<pre><code># base/kustomization.yaml\nresources:\n  - deployment.yaml\n  - service.yaml\n\n# overlays/dev/kustomization.yaml\nbases:\n  - ../../base\npatchesStrategicMerge:\n  - deployment-patch.yaml\nconfigMapGenerator:\n  - name: app-config\n    literals:\n      - environment=development\n\n# overlays/prod/kustomization.yaml\nbases:\n  - ../../base\nreplicas:\n  - name: myapp\n    count: 5\n</code></pre>"},{"location":"ja/applications/deployment/#namespace","title":"Namespace \u5206\u96e2","text":"<pre><code># \u74b0\u5883\u3092\u4f5c\u6210\nhb namespace create dev\nhb namespace create staging\nhb namespace create production\n\n# \u7279\u5b9a\u306e\u74b0\u5883\u306b\u30c7\u30d7\u30ed\u30a4\nhb deploy --namespace production\n</code></pre>"},{"location":"ja/applications/deployment/#_21","title":"\u76e3\u8996\u3068\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3","text":""},{"location":"ja/applications/deployment/#prometheus","title":"Prometheus \u30e1\u30c8\u30ea\u30af\u30b9","text":"<pre><code>metadata:\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\n    prometheus.io/path: \"/metrics\"\n</code></pre>"},{"location":"ja/applications/deployment/#_22","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30b0","text":"<pre><code># \u30ed\u30b0\u96c6\u7d04\u3092\u8a2d\u5b9a\nspec:\n  containers:\n    - name: app\n      env:\n        - name: LOG_FORMAT\n          value: \"json\"\n        - name: LOG_OUTPUT\n          value: \"stdout\"\n</code></pre>"},{"location":"ja/applications/deployment/#_23","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li> <p>\u30b3\u30f3\u30c6\u30ca\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</p> </li> <li> <p>\u6700\u5c0f\u9650\u306e\u30d9\u30fc\u30b9\u30a4\u30e1\u30fc\u30b8\u3092\u4f7f\u7528</p> </li> <li>\u975e\u30eb\u30fc\u30c8\u30e6\u30fc\u30b6\u30fc\u3068\u3057\u3066\u5b9f\u884c</li> <li>\u30b3\u30f3\u30c6\u30ca\u3042\u305f\u308a1\u3064\u306e\u30d7\u30ed\u30bb\u30b9</li> <li> <p>\u30b7\u30b0\u30ca\u30eb\u3092\u9069\u5207\u306b\u51e6\u7406</p> </li> <li> <p>\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406</p> </li> <li> <p>\u5e38\u306b\u30ea\u30bd\u30fc\u30b9\u30ea\u30af\u30a8\u30b9\u30c8\u3068\u5236\u9650\u3092\u8a2d\u5b9a</p> </li> <li>\u6c34\u5e73\u30dd\u30c3\u30c9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3092\u4f7f\u7528</li> <li> <p>\u9069\u5207\u306a\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\u3092\u5b9f\u88c5</p> </li> <li> <p>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3</p> </li> <li> <p>\u8106\u5f31\u6027\u306b\u3064\u3044\u3066\u30a4\u30e1\u30fc\u30b8\u3092\u30b9\u30ad\u30e3\u30f3</p> </li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u3092\u4f7f\u7528</li> <li>RBAC \u3092\u5b9f\u88c5</li> <li> <p>\u4fdd\u5b58\u6642\u306b\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u3092\u6697\u53f7\u5316</p> </li> <li> <p>\u9ad8\u53ef\u7528\u6027</p> </li> <li> <p>\u8907\u6570\u306e\u30be\u30fc\u30f3\u306b\u30c7\u30d7\u30ed\u30a4</p> </li> <li>\u30dd\u30c3\u30c9\u4e2d\u65ad\u4e88\u7b97\u3092\u4f7f\u7528</li> <li>\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc\u3092\u5b9f\u88c5</li> <li> <p>\u969c\u5bb3\u3092\u60f3\u5b9a\u3057\u305f\u8a2d\u8a08</p> </li> <li> <p>\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u885b\u751f</p> </li> <li>\u5ba3\u8a00\u7684\u8a2d\u5b9a\u3092\u4f7f\u7528</li> <li>\u3059\u3079\u3066\u3092\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406</li> <li>\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u81ea\u52d5\u5316</li> <li>\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u76e3\u8996</li> </ol>"},{"location":"ja/applications/deployment/#_24","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/applications/deployment/#_25","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":"<pre><code># \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u72b6\u614b\u3092\u30c1\u30a7\u30c3\u30af\nhb get deployments -n production\n\n# \u30dd\u30c3\u30c9\u30ed\u30b0\u3092\u8868\u793a\nhb logs -f deployment/myapp\n\n# \u30a4\u30d9\u30f3\u30c8\u306e\u305f\u3081\u306b\u30dd\u30c3\u30c9\u3092\u8a18\u8ff0\nhb describe pod myapp-xyz\n\n# \u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u30c1\u30a7\u30c3\u30af\nhb top pods -n production\n\n# \u5b9f\u884c\u4e2d\u306e\u30b3\u30f3\u30c6\u30ca\u3092\u30c7\u30d0\u30c3\u30b0\nhb exec -it myapp-xyz -- /bin/sh\n</code></pre>"},{"location":"ja/applications/deployment/#_26","title":"\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\u624b\u9806","text":"<pre><code># \u30ed\u30fc\u30eb\u30a2\u30a6\u30c8\u5c65\u6b74\u3092\u8868\u793a\nhb rollout history deployment/myapp\n\n# \u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\nhb rollout undo deployment/myapp\n\n# \u7279\u5b9a\u306e\u30ea\u30d3\u30b8\u30e7\u30f3\u306b\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\nhb rollout undo deployment/myapp --to-revision=2\n</code></pre>"},{"location":"ja/applications/load-balancing/","title":"\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":"<p>\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u306f\u3001Hexabase.AI \u3067\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u8907\u6570\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u9593\u3067\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u5206\u6563\u3059\u308b\u305f\u3081\u306b\u91cd\u8981\u3067\u3059\u3002\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001\u3055\u307e\u3056\u307e\u306a\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u6226\u7565\u3068\u8a2d\u5b9a\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/applications/load-balancing/#_2","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u8907\u6570\u30ec\u30d9\u30eb\u306e\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30b5\u30fc\u30d3\u30b9\u30ec\u30d9\u30eb\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\uff08\u30ec\u30a4\u30e4\u30fc4\uff09</li> <li>Ingress \u30ec\u30d9\u30eb\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\uff08\u30ec\u30a4\u30e4\u30fc7\uff09</li> <li>\u30b0\u30ed\u30fc\u30d0\u30eb\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\uff08\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\uff09</li> <li>\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\uff08\u9ad8\u5ea6\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u7ba1\u7406\uff09</li> </ul>"},{"location":"ja/applications/load-balancing/#_3","title":"\u30b5\u30fc\u30d3\u30b9\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":""},{"location":"ja/applications/load-balancing/#clusterip","title":"ClusterIP \u30b5\u30fc\u30d3\u30b9","text":"<p>\u30af\u30e9\u30b9\u30bf\u30fc\u5185\u3067\u306e\u57fa\u672c\u7684\u306a\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  type: ClusterIP\n  sessionAffinity: None # \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u30e9\u30a6\u30f3\u30c9\u30ed\u30d3\u30f3\n</code></pre>"},{"location":"ja/applications/load-balancing/#_4","title":"\u30bb\u30c3\u30b7\u30e7\u30f3\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3","text":"<p>\u30b9\u30c6\u30a3\u30c3\u30ad\u30fc\u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7dad\u6301\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 3600 # 1\u6642\u9593\n</code></pre>"},{"location":"ja/applications/load-balancing/#_5","title":"\u30d8\u30c3\u30c9\u30ec\u30b9\u30b5\u30fc\u30d3\u30b9","text":"<p>\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b5\u30a4\u30c9\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u7528\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-headless\nspec:\n  clusterIP: None\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre>"},{"location":"ja/applications/load-balancing/#ingress","title":"Ingress \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":""},{"location":"ja/applications/load-balancing/#nginx-ingress","title":"NGINX Ingress","text":"<p>NGINX \u30d9\u30fc\u30b9\u306e\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u3092\u8a2d\u5b9a\uff1a</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/load-balance: \"round_robin\"\n    nginx.ingress.kubernetes.io/upstream-hash-by: \"$request_uri\"\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"ja/applications/load-balancing/#_6","title":"\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0","text":"<p>NGINX \u3067\u5229\u7528\u53ef\u80fd\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\uff1a</p> <pre><code>annotations:\n  # \u30e9\u30a6\u30f3\u30c9\u30ed\u30d3\u30f3\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09\n  nginx.ingress.kubernetes.io/load-balance: \"round_robin\"\n\n  # \u6700\u5c0f\u63a5\u7d9a\u6570\n  nginx.ingress.kubernetes.io/load-balance: \"least_conn\"\n\n  # IP \u30cf\u30c3\u30b7\u30e5\n  nginx.ingress.kubernetes.io/load-balance: \"ip_hash\"\n\n  # \u4e00\u8cab\u6027\u30cf\u30c3\u30b7\u30e5\n  nginx.ingress.kubernetes.io/upstream-hash-by: \"$request_uri\"\n</code></pre>"},{"location":"ja/applications/load-balancing/#nginx","title":"\u9ad8\u5ea6\u306a NGINX \u8a2d\u5b9a","text":"<pre><code>annotations:\n  # \u63a5\u7d9a\u5236\u9650\n  nginx.ingress.kubernetes.io/limit-connections: \"10\"\n  nginx.ingress.kubernetes.io/limit-rps: \"100\"\n\n  # \u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\n  nginx.ingress.kubernetes.io/proxy-connect-timeout: \"5\"\n  nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n  nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n\n  # \u30ea\u30c8\u30e9\u30a4\n  nginx.ingress.kubernetes.io/proxy-next-upstream: \"error timeout\"\n  nginx.ingress.kubernetes.io/proxy-next-upstream-tries: \"3\"\n</code></pre>"},{"location":"ja/applications/load-balancing/#_7","title":"\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":""},{"location":"ja/applications/load-balancing/#istio","title":"Istio \u8a2d\u5b9a","text":"<p>Istio \u3092\u4f7f\u7528\u3057\u305f\u9ad8\u5ea6\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u7ba1\u7406\uff1a</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: myapp-destination\nspec:\n  host: myapp-service\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 50\n        http2MaxRequests: 100\n        maxRequestsPerConnection: 2\n    loadBalancer:\n      simple: LEAST_REQUEST # \u307e\u305f\u306f ROUND_ROBIN, RANDOM, PASSTHROUGH\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n</code></pre>"},{"location":"ja/applications/load-balancing/#_8","title":"\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc","text":"<p>\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc\u3092\u5b9f\u88c5\uff1a</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: myapp-circuit-breaker\nspec:\n  host: myapp-service\n  trafficPolicy:\n    outlierDetection:\n      consecutive5xxErrors: 5\n      consecutiveGatewayErrors: 5\n      interval: 10s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n      minHealthPercent: 30\n      splitExternalLocalOriginErrors: true\n</code></pre>"},{"location":"ja/applications/load-balancing/#_9","title":"\u30ea\u30c8\u30e9\u30a4\u8a2d\u5b9a","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-retry\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - timeout: 30s\n      retries:\n        attempts: 3\n        perTryTimeout: 10s\n        retryOn: gateway-error,connect-failure,refused-stream\n        retryRemoteLocalities: true\n</code></pre>"},{"location":"ja/applications/load-balancing/#_10","title":"\u30b0\u30ed\u30fc\u30d0\u30eb\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":""},{"location":"ja/applications/load-balancing/#_11","title":"\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: global-ingress\n  annotations:\n    external-dns.alpha.kubernetes.io/hostname: myapp.global.example.com\n    external-dns.alpha.kubernetes.io/ttl: \"60\"\nspec:\n  rules:\n    - host: myapp.global.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"ja/applications/load-balancing/#_12","title":"\u5730\u7406\u7684\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":"<p>HKS \u30b0\u30ed\u30fc\u30d0\u30eb\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u3092\u4f7f\u7528\uff1a</p> <pre><code>apiVersion: hks.io/v1\nkind: GlobalLoadBalancer\nmetadata:\n  name: myapp-global\nspec:\n  selector:\n    app: myapp\n  regions:\n    - name: us-east-1\n      weight: 40\n      healthCheck:\n        path: /health\n        interval: 10s\n    - name: eu-west-1\n      weight: 30\n    - name: ap-southeast-1\n      weight: 30\n  routing:\n    policy: geographic # \u307e\u305f\u306f weighted, latency, failover\n    stickyRegion: true\n</code></pre>"},{"location":"ja/applications/load-balancing/#_13","title":"\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":""},{"location":"ja/applications/load-balancing/#_14","title":"\u30b5\u30fc\u30d3\u30b9\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n  healthCheckNodePort: 30000\n</code></pre>"},{"location":"ja/applications/load-balancing/#ingress_1","title":"Ingress \u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":"<pre><code>annotations:\n  nginx.ingress.kubernetes.io/health-check-path: \"/health\"\n  nginx.ingress.kubernetes.io/health-check-interval: \"10\"\n  nginx.ingress.kubernetes.io/health-check-timeout: \"5\"\n  nginx.ingress.kubernetes.io/health-check-max-fails: \"3\"\n</code></pre>"},{"location":"ja/applications/load-balancing/#_15","title":"\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u30bf\u30a4\u30d7","text":""},{"location":"ja/applications/load-balancing/#4","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\uff08\u30ec\u30a4\u30e4\u30fc4\uff09","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-nlb\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: myapp\n  ports:\n    - port: 80\n      targetPort: 8080\n</code></pre>"},{"location":"ja/applications/load-balancing/#7","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\uff08\u30ec\u30a4\u30e4\u30fc7\uff09","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-alb\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"ja/applications/load-balancing/#_16","title":"\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u914d\u4fe1","text":""},{"location":"ja/applications/load-balancing/#_17","title":"\u91cd\u307f\u4ed8\u304d\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-weighted\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - match:\n        - headers:\n            version:\n              exact: v2\n      route:\n        - destination:\n            host: myapp-service\n            subset: v2\n          weight: 20\n        - destination:\n            host: myapp-service\n            subset: v1\n          weight: 80\n</code></pre>"},{"location":"ja/applications/load-balancing/#ab","title":"A/B \u30c6\u30b9\u30c8","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: myapp-ab-test\nspec:\n  hosts:\n    - myapp-service\n  http:\n    - match:\n        - headers:\n            user-group:\n              exact: beta\n      route:\n        - destination:\n            host: myapp-service\n            subset: v2\n    - route:\n        - destination:\n            host: myapp-service\n            subset: v1\n</code></pre>"},{"location":"ja/applications/load-balancing/#_18","title":"\u30ab\u30ca\u30ea\u30a2\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<pre><code>apiVersion: flagger.app/v1beta1\nkind: Canary\nmetadata:\n  name: myapp-canary\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  service:\n    port: 80\n    targetPort: 8080\n  analysis:\n    interval: 1m\n    threshold: 10\n    maxWeight: 50\n    stepWeight: 10\n    metrics:\n      - name: request-success-rate\n        thresholdRange:\n          min: 99\n        interval: 1m\n</code></pre>"},{"location":"ja/applications/load-balancing/#_19","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":""},{"location":"ja/applications/load-balancing/#_20","title":"\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u30d7\u30fc\u30ea\u30f3\u30b0","text":"<pre><code>trafficPolicy:\n  connectionPool:\n    tcp:\n      maxConnections: 100\n      connectTimeout: 30s\n      tcpKeepalive:\n        time: 7200\n        interval: 75\n        probes: 10\n    http:\n      http1MaxPendingRequests: 100\n      http2MaxRequests: 100\n      maxRequestsPerConnection: 2\n      h2UpgradePolicy: UPGRADE\n</code></pre>"},{"location":"ja/applications/load-balancing/#keep-alive","title":"Keep-Alive \u8a2d\u5b9a","text":"<pre><code>annotations:\n  nginx.ingress.kubernetes.io/upstream-keepalive-connections: \"32\"\n  nginx.ingress.kubernetes.io/upstream-keepalive-timeout: \"60\"\n  nginx.ingress.kubernetes.io/upstream-keepalive-requests: \"100\"\n</code></pre>"},{"location":"ja/applications/load-balancing/#_21","title":"\u76e3\u8996\u3068\u30e1\u30c8\u30ea\u30af\u30b9","text":""},{"location":"ja/applications/load-balancing/#prometheus","title":"Prometheus \u30e1\u30c8\u30ea\u30af\u30b9","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/path: \"/metrics\"\n    prometheus.io/port: \"9090\"\nspec:\n  selector:\n    app: myapp\n  ports:\n    - name: http\n      port: 80\n      targetPort: 8080\n    - name: metrics\n      port: 9090\n      targetPort: 9090\n</code></pre>"},{"location":"ja/applications/load-balancing/#_22","title":"\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u30e1\u30c8\u30ea\u30af\u30b9","text":"<p>\u4e3b\u8981\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u76e3\u8996\uff1a</p> <ul> <li>\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3042\u305f\u308a\u306e\u30ea\u30af\u30a8\u30b9\u30c8\u7387</li> <li>\u30ec\u30b9\u30dd\u30f3\u30b9\u6642\u9593\u5206\u5e03</li> <li>\u30a8\u30e9\u30fc\u7387</li> <li>\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u30d7\u30fc\u30eb\u4f7f\u7528\u7387</li> <li>\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc\u30b9\u30c6\u30fc\u30bf\u30b9</li> </ul> <pre><code># \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u30c1\u30a7\u30c3\u30af\nhb lb status myapp-service\n\n# \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u30d8\u30eb\u30b9\u3092\u8868\u793a\nhb lb backends myapp-service\n\n# \u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u914d\u4fe1\u3092\u76e3\u8996\nhb lb traffic myapp-service --watch\n</code></pre>"},{"location":"ja/applications/load-balancing/#_23","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/applications/load-balancing/#_24","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":"<ol> <li>\u4e0d\u5747\u7b49\u306a\u8ca0\u8377\u5206\u6563</li> </ol> <pre><code># \u30dd\u30c3\u30c9\u5206\u6563\u3092\u30c1\u30a7\u30c3\u30af\nhb get pods -o wide\n\n# \u30b5\u30fc\u30d3\u30b9\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u78ba\u8a8d\nhb get endpoints myapp-service\n</code></pre> <ol> <li>\u30bb\u30c3\u30b7\u30e7\u30f3\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u304c\u6a5f\u80fd\u3057\u306a\u3044</li> </ol> <pre><code># \u30bb\u30c3\u30b7\u30e7\u30f3\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u3092\u30c6\u30b9\u30c8\nfor i in {1..10}; do\n  curl -b cookies.txt -c cookies.txt http://myapp.example.com\ndone\n</code></pre> <ol> <li>\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\u5931\u6557</li> </ol> <pre><code># \u30d8\u30eb\u30b9\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u30c1\u30a7\u30c3\u30af\nhb exec -it myapp-pod -- curl localhost:8080/health\n\n# ingress \u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc\u30ed\u30b0\u3092\u8868\u793a\nhb logs -n ingress-nginx deployment/ingress-nginx-controller\n</code></pre>"},{"location":"ja/applications/load-balancing/#_25","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li> <p>\u9069\u5207\u306a\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc\u306e\u9078\u629e</p> </li> <li> <p>\u5185\u90e8\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306b\u306f Service \u3092\u4f7f\u7528</p> </li> <li>HTTP/HTTPS \u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306b\u306f Ingress \u3092\u4f7f\u7528</li> <li> <p>\u9ad8\u5ea6\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u7ba1\u7406\u306b\u306f Service Mesh \u3092\u4f7f\u7528</p> </li> <li> <p>\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af</p> </li> <li> <p>\u5305\u62ec\u7684\u306a\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\u3092\u5b9f\u88c5</p> </li> <li>\u9069\u5207\u306a\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u3068\u95be\u5024\u3092\u4f7f\u7528</li> <li> <p>\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u76e3\u8996</p> </li> <li> <p>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9</p> </li> <li> <p>\u30b3\u30cd\u30af\u30b7\u30e7\u30f3\u30d7\u30fc\u30ea\u30f3\u30b0\u3092\u6709\u52b9\u5316</p> </li> <li>\u9069\u5207\u306a\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u3092\u8a2d\u5b9a</li> <li> <p>\u53ef\u80fd\u306a\u5834\u5408\u306f HTTP/2 \u3092\u4f7f\u7528</p> </li> <li> <p>\u4fe1\u983c\u6027</p> </li> <li> <p>\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc\u3092\u5b9f\u88c5</p> </li> <li>\u30ea\u30c8\u30e9\u30a4\u3092\u9069\u5207\u306b\u8a2d\u5b9a</li> <li> <p>\u5916\u308c\u5024\u691c\u51fa\u3092\u4f7f\u7528</p> </li> <li> <p>\u76e3\u8996</p> </li> <li>\u8ca0\u8377\u5206\u6563\u3092\u8ffd\u8de1</li> <li>\u30a8\u30e9\u30fc\u7387\u3092\u76e3\u8996</li> <li>\u7570\u5e38\u306b\u30a2\u30e9\u30fc\u30c8</li> </ol>"},{"location":"ja/applications/resource-management/","title":"\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406","text":"<p>\u52b9\u679c\u7684\u306a\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u306f\u3001Hexabase.AI \u3067\u306e\u6700\u9069\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30af\u30e9\u30b9\u30bf\u30fc\u52b9\u7387\u306b\u3068\u3063\u3066\u91cd\u8981\u3067\u3059\u3002\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001CPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u3001\u305d\u306e\u4ed6\u306e\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u6226\u7565\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/applications/resource-management/#_2","title":"\u30ea\u30bd\u30fc\u30b9\u30bf\u30a4\u30d7","text":""},{"location":"ja/applications/resource-management/#cpu","title":"CPU \u30ea\u30bd\u30fc\u30b9","text":"<p>CPU \u30ea\u30bd\u30fc\u30b9\u306f CPU \u5358\u4f4d\u3067\u6e2c\u5b9a\u3055\u308c\u307e\u3059\uff1a</p> <ul> <li><code>1</code> = 1 vCPU/\u30b3\u30a2</li> <li><code>1000m</code> = 1 CPU\uff08m = \u30df\u30eaCPU\uff09</li> <li><code>100m</code> = 0.1 CPU</li> </ul> <pre><code>resources:\n  requests:\n    cpu: \"100m\" # \u4fdd\u8a3c\u3055\u308c\u308b\u6700\u5c0f\u5024\n  limits:\n    cpu: \"500m\" # \u8a31\u53ef\u3055\u308c\u308b\u6700\u5927\u5024\n</code></pre>"},{"location":"ja/applications/resource-management/#_3","title":"\u30e1\u30e2\u30ea\u30ea\u30bd\u30fc\u30b9","text":"<p>\u30e1\u30e2\u30ea\u306f\u5358\u4f4d\u63a5\u5c3e\u8f9e\u4ed8\u304d\u306e\u30d0\u30a4\u30c8\u3067\u6e2c\u5b9a\u3055\u308c\u307e\u3059\uff1a</p> <ul> <li><code>Ki</code> = \u30ad\u30d3\u30d0\u30a4\u30c8\uff081024\u30d0\u30a4\u30c8\uff09</li> <li><code>Mi</code> = \u30e1\u30d3\u30d0\u30a4\u30c8\uff081024 Ki\uff09</li> <li><code>Gi</code> = \u30ae\u30d3\u30d0\u30a4\u30c8\uff081024 Mi\uff09</li> </ul> <pre><code>resources:\n  requests:\n    memory: \"256Mi\" # \u4fdd\u8a3c\u3055\u308c\u308b\u6700\u5c0f\u5024\n  limits:\n    memory: \"512Mi\" # \u8a31\u53ef\u3055\u308c\u308b\u6700\u5927\u5024\n</code></pre>"},{"location":"ja/applications/resource-management/#_4","title":"\u30ea\u30bd\u30fc\u30b9\u30ea\u30af\u30a8\u30b9\u30c8\u3068\u5236\u9650","text":""},{"location":"ja/applications/resource-management/#_5","title":"\u57fa\u672c\u8a2d\u5b9a","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  template:\n    spec:\n      containers:\n        - name: app\n          image: myapp:latest\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"250m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n</code></pre>"},{"location":"ja/applications/resource-management/#vs","title":"\u30ea\u30af\u30a8\u30b9\u30c8 vs \u5236\u9650\u306e\u7406\u89e3","text":"<ul> <li>\u30ea\u30af\u30a8\u30b9\u30c8: \u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u306e\u305f\u3081\u306e\u4fdd\u8a3c\u30ea\u30bd\u30fc\u30b9</li> <li>\u5236\u9650: \u30b3\u30f3\u30c6\u30ca\u304c\u4f7f\u7528\u3067\u304d\u308b\u6700\u5927\u30ea\u30bd\u30fc\u30b9</li> </ul> <pre><code># Burstable QoS \u30af\u30e9\u30b9\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n\n# Guaranteed QoS \u30af\u30e9\u30b9\uff08\u30ea\u30af\u30a8\u30b9\u30c8 = \u5236\u9650\uff09\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n</code></pre>"},{"location":"ja/applications/resource-management/#qos","title":"\u30b5\u30fc\u30d3\u30b9\u54c1\u8cea\uff08QoS\uff09\u30af\u30e9\u30b9","text":""},{"location":"ja/applications/resource-management/#1-guaranteed","title":"1. Guaranteed","text":"<p>\u6700\u9ad8\u512a\u5148\u5ea6\u3001\u5236\u9650\u3092\u8d85\u3048\u306a\u3044\u9650\u308a\u7d42\u4e86\u3055\u308c\u307e\u305b\u3093\uff1a</p> <pre><code>containers:\n  - name: critical-app\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"1\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"1\"\n</code></pre>"},{"location":"ja/applications/resource-management/#2-burstable","title":"2. Burstable","text":"<p>\u4e2d\u512a\u5148\u5ea6\u3001\u30ea\u30af\u30a8\u30b9\u30c8\u4ee5\u4e0a\u306b\u30d0\u30fc\u30b9\u30c8\u3067\u304d\u307e\u3059\uff1a</p> <pre><code>containers:\n  - name: web-app\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n</code></pre>"},{"location":"ja/applications/resource-management/#3-besteffort","title":"3. BestEffort","text":"<p>\u6700\u4f4e\u512a\u5148\u5ea6\u3001\u6700\u521d\u306b\u9000\u907f\u3055\u308c\u307e\u3059\uff1a</p> <pre><code>containers:\n  - name: batch-job\n    # \u30ea\u30bd\u30fc\u30b9\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u307e\u305b\u3093\n</code></pre>"},{"location":"ja/applications/resource-management/#_6","title":"\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf","text":""},{"location":"ja/applications/resource-management/#namespace","title":"Namespace \u30ea\u30bd\u30fc\u30b9\u5236\u9650","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-resources\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: \"200Gi\"\n    limits.cpu: \"200\"\n    limits.memory: \"400Gi\"\n    persistentvolumeclaims: \"10\"\n    services.loadbalancers: \"2\"\n</code></pre>"},{"location":"ja/applications/resource-management/#_7","title":"\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6570\u30af\u30a9\u30fc\u30bf","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: object-counts\n  namespace: production\nspec:\n  hard:\n    pods: \"50\"\n    services: \"10\"\n    replicationcontrollers: \"20\"\n    secrets: \"100\"\n    configmaps: \"100\"\n</code></pre>"},{"location":"ja/applications/resource-management/#_8","title":"\u5236\u9650\u7bc4\u56f2","text":""},{"location":"ja/applications/resource-management/#_9","title":"\u30c7\u30d5\u30a9\u30eb\u30c8\u30b3\u30f3\u30c6\u30ca\u5236\u9650","text":"<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: default-limits\n  namespace: production\nspec:\n  limits:\n    - default:\n        cpu: \"500m\"\n        memory: \"512Mi\"\n      defaultRequest:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      max:\n        cpu: \"2\"\n        memory: \"2Gi\"\n      min:\n        cpu: \"50m\"\n        memory: \"64Mi\"\n      type: Container\n</code></pre>"},{"location":"ja/applications/resource-management/#_10","title":"\u30dd\u30c3\u30c9\u30ec\u30d9\u30eb\u5236\u9650","text":"<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: pod-limits\nspec:\n  limits:\n    - max:\n        cpu: \"4\"\n        memory: \"8Gi\"\n      min:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      type: Pod\n</code></pre>"},{"location":"ja/applications/resource-management/#hpa","title":"\u6c34\u5e73\u30dd\u30c3\u30c9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\uff08HPA\uff09","text":""},{"location":"ja/applications/resource-management/#cpu_1","title":"CPU \u30d9\u30fc\u30b9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n</code></pre>"},{"location":"ja/applications/resource-management/#_11","title":"\u30e1\u30e2\u30ea\u30d9\u30fc\u30b9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-memory-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 80\n</code></pre>"},{"location":"ja/applications/resource-management/#_12","title":"\u30ab\u30b9\u30bf\u30e0\u30e1\u30c8\u30ea\u30af\u30b9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-custom-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 2\n  maxReplicas: 20\n  metrics:\n    - type: Pods\n      pods:\n        metric:\n          name: requests_per_second\n        target:\n          type: AverageValue\n          averageValue: \"100\"\n    - type: Object\n      object:\n        metric:\n          name: queue_length\n        describedObject:\n          apiVersion: v1\n          kind: Service\n          name: myapp-queue\n        target:\n          type: Value\n          value: \"30\"\n</code></pre>"},{"location":"ja/applications/resource-management/#vpa","title":"\u5782\u76f4\u30dd\u30c3\u30c9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\uff08VPA\uff09","text":""},{"location":"ja/applications/resource-management/#vpa_1","title":"VPA \u8a2d\u5b9a","text":"<pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: myapp-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  updatePolicy:\n    updateMode: \"Auto\" # \u307e\u305f\u306f \"Off\", \"Initial\"\n  resourcePolicy:\n    containerPolicies:\n      - containerName: app\n        minAllowed:\n          cpu: 100m\n          memory: 128Mi\n        maxAllowed:\n          cpu: 2\n          memory: 2Gi\n        controlledResources: [\"cpu\", \"memory\"]\n</code></pre>"},{"location":"ja/applications/resource-management/#_13","title":"\u30b9\u30c8\u30ec\u30fc\u30b8\u30ea\u30bd\u30fc\u30b9","text":""},{"location":"ja/applications/resource-management/#_14","title":"\u6c38\u7d9a\u30dc\u30ea\u30e5\u30fc\u30e0\u30af\u30ec\u30fc\u30e0","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: myapp-storage\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n</code></pre>"},{"location":"ja/applications/resource-management/#_15","title":"\u30b9\u30c8\u30ec\u30fc\u30b8\u30af\u30e9\u30b9","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\nallowVolumeExpansion: true\n</code></pre>"},{"location":"ja/applications/resource-management/#_16","title":"\u30dc\u30ea\u30e5\u30fc\u30e0\u30ea\u30bd\u30fc\u30b9\u5236\u9650","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: storage-quota\nspec:\n  hard:\n    requests.storage: \"100Gi\"\n    persistentvolumeclaims: \"10\"\n    fast-ssd.storageclass.storage.k8s.io/requests.storage: \"50Gi\"\n    fast-ssd.storageclass.storage.k8s.io/persistentvolumeclaims: \"5\"\n</code></pre>"},{"location":"ja/applications/resource-management/#_17","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30ea\u30bd\u30fc\u30b9","text":""},{"location":"ja/applications/resource-management/#_18","title":"\u5e2f\u57df\u5e45\u5236\u9650","text":"<pre><code>metadata:\n  annotations:\n    kubernetes.io/ingress-bandwidth: \"10M\"\n    kubernetes.io/egress-bandwidth: \"10M\"\n</code></pre>"},{"location":"ja/applications/resource-management/#_19","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: myapp-network-policy\nspec:\n  podSelector:\n    matchLabels:\n      app: myapp\n  policyTypes:\n    - Ingress\n    - Egress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              role: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"ja/applications/resource-management/#gpu","title":"GPU \u30ea\u30bd\u30fc\u30b9","text":""},{"location":"ja/applications/resource-management/#gpu_1","title":"GPU \u914d\u5206","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-pod\nspec:\n  containers:\n    - name: cuda-container\n      image: nvidia/cuda:11.0-base\n      resources:\n        limits:\n          nvidia.com/gpu: 1 # 1\u3064\u306e GPU \u3092\u30ea\u30af\u30a8\u30b9\u30c8\n</code></pre>"},{"location":"ja/applications/resource-management/#gpu_2","title":"GPU \u5171\u6709","text":"<pre><code># NVIDIA MIG \u3092\u4f7f\u7528\u3057\u305f\u5206\u6570 GPU\nresources:\n  limits:\n    nvidia.com/mig-3g.20gb: 1\n</code></pre>"},{"location":"ja/applications/resource-management/#_20","title":"\u30ea\u30bd\u30fc\u30b9\u76e3\u8996","text":""},{"location":"ja/applications/resource-management/#_21","title":"\u30e1\u30c8\u30ea\u30af\u30b9\u53ce\u96c6","text":"<pre><code># \u30ea\u30bd\u30fc\u30b9\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u6709\u52b9\u5316\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: metrics-config\ndata:\n  metrics.yaml: |\n    collection_interval: 30s\n    resources:\n      - cpu\n      - memory\n      - disk\n      - network\n</code></pre>"},{"location":"ja/applications/resource-management/#_22","title":"\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u30b3\u30de\u30f3\u30c9","text":"<pre><code># \u30ce\u30fc\u30c9\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u8868\u793a\nhb top nodes\n\n# \u30dd\u30c3\u30c9\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u8868\u793a\nhb top pods -n production\n\n# \u30b3\u30f3\u30c6\u30ca\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u8868\u793a\nhb top pod myapp-pod --containers\n\n# \u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u72b6\u614b\u3092\u53d6\u5f97\nhb get resourcequota -n production\n\n# \u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u8a73\u8ff0\nhb describe node worker-1\n</code></pre>"},{"location":"ja/applications/resource-management/#_23","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"ja/applications/resource-management/#1","title":"1. \u9069\u6b63\u30b5\u30a4\u30b8\u30f3\u30b0","text":"<pre><code># \u76e3\u8996\u304b\u3089\u958b\u59cb\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"200m\"\n\n# \u5206\u6790\u5f8c\u3001\u5b9f\u969b\u306e\u4f7f\u7528\u91cf\u306b\u8abf\u6574\nresources:\n  requests:\n    memory: \"384Mi\"  # P95 \u4f7f\u7528\u91cf\n    cpu: \"150m\"      # P95 \u4f7f\u7528\u91cf\n  limits:\n    memory: \"512Mi\"  # P99 \u4f7f\u7528\u91cf + \u30d0\u30c3\u30d5\u30a1\n    cpu: \"300m\"      # P99 \u4f7f\u7528\u91cf + \u30d0\u30c3\u30d5\u30a1\n</code></pre>"},{"location":"ja/applications/resource-management/#2","title":"2. \u30ea\u30bd\u30fc\u30b9\u6bd4\u7387","text":"<pre><code># \u826f\u3044\u5b9f\u8df5: 2:1 \u306e\u5236\u9650\u5bfe\u30ea\u30af\u30a8\u30b9\u30c8\u6bd4\u7387\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"1Gi\" # \u30ea\u30af\u30a8\u30b9\u30c8\u306e2\u500d\n    cpu: \"1000m\" # \u30ea\u30af\u30a8\u30b9\u30c8\u306e2\u500d\n</code></pre>"},{"location":"ja/applications/resource-management/#3-namespace","title":"3. Namespace \u69cb\u6210","text":"<pre><code># \u30ea\u30bd\u30fc\u30b9\u5206\u96e2\u3055\u308c\u305f namespace \u3092\u4f5c\u6210\nhb create namespace dev --quota small\nhb create namespace staging --quota medium\nhb create namespace production --quota large\n</code></pre>"},{"location":"ja/applications/resource-management/#4","title":"4. \u30ea\u30bd\u30fc\u30b9\u8a08\u753b","text":"<pre><code># \u30ea\u30bd\u30fc\u30b9\u914d\u5206\u6226\u7565\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: resource-tiers\ndata:\n  small: |\n    cpu: 100m-500m\n    memory: 128Mi-512Mi\n  medium: |\n    cpu: 500m-2000m\n    memory: 512Mi-2Gi\n  large: |\n    cpu: 2000m-8000m\n    memory: 2Gi-8Gi\n</code></pre>"},{"location":"ja/applications/resource-management/#_24","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/applications/resource-management/#_25","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":"<ol> <li>OOMKilled \u30dd\u30c3\u30c9</li> </ol> <pre><code># OOM \u5f37\u5236\u7d42\u4e86\u3092\u30c1\u30a7\u30c3\u30af\nhb describe pod myapp-pod | grep -i oom\n\n# \u30e1\u30e2\u30ea\u5236\u9650\u3092\u5897\u52a0\nhb set resources deployment myapp --limits=memory=1Gi\n</code></pre> <ol> <li>CPU \u30b9\u30ed\u30c3\u30c8\u30ea\u30f3\u30b0</li> </ol> <pre><code># CPU \u30b9\u30ed\u30c3\u30c8\u30ea\u30f3\u30b0\u3092\u30c1\u30a7\u30c3\u30af\nhb exec myapp-pod -- cat /sys/fs/cgroup/cpu/cpu.stat\n\n# CPU \u5236\u9650\u3092\u8abf\u6574\nhb set resources deployment myapp --limits=cpu=1000m\n</code></pre> <ol> <li>\u4fdd\u7559\u4e2d\u306e\u30dd\u30c3\u30c9</li> </ol> <pre><code># \u30dd\u30c3\u30c9\u304c\u4fdd\u7559\u4e2d\u306e\u7406\u7531\u3092\u30c1\u30a7\u30c3\u30af\nhb describe pod myapp-pod\n\n# \u30ce\u30fc\u30c9\u30ea\u30bd\u30fc\u30b9\u3092\u8868\u793a\nhb describe nodes | grep -A 5 \"Allocated resources\"\n</code></pre>"},{"location":"ja/applications/resource-management/#_26","title":"\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316","text":"<pre><code># VPA \u304b\u3089\u63a8\u5968\u4e8b\u9805\u3092\u53d6\u5f97\nhb get vpa myapp-vpa -o yaml\n\n# \u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u30d1\u30bf\u30fc\u30f3\u3092\u5206\u6790\nhb top pods --sort-by=cpu\nhb top pods --sort-by=memory\n\n# \u5206\u6790\u7528\u306b\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\nhb get --raw /metrics | grep container_\n</code></pre>"},{"location":"ja/applications/resource-management/#hks","title":"HKS \u56fa\u6709\u306e\u6a5f\u80fd","text":""},{"location":"ja/applications/resource-management/#ai","title":"AI \u4e3b\u5c0e\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316","text":"<pre><code>apiVersion: hks.io/v1\nkind: ResourceOptimizer\nmetadata:\n  name: ai-optimizer\nspec:\n  target:\n    kind: Deployment\n    name: myapp\n  optimization:\n    mode: aggressive # \u307e\u305f\u306f conservative, balanced\n    metrics:\n      - cpu\n      - memory\n    constraints:\n      minReplicas: 2\n      maxCost: 100 # \u6708\u3042\u305f\u308a USD\n</code></pre>"},{"location":"ja/applications/resource-management/#_27","title":"\u30b3\u30b9\u30c8\u30d9\u30fc\u30b9\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0","text":"<pre><code>apiVersion: hks.io/v1\nkind: CostAwareHPA\nmetadata:\n  name: cost-aware-scaler\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  costConstraints:\n    maxMonthlyCost: 500\n    preferSpotInstances: true\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n</code></pre>"},{"location":"ja/applications/service-discovery/","title":"\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<p>\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u306f\u3001Hexabase.AI \u3067\u306e\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u901a\u4fe1\u306b\u4e0d\u53ef\u6b20\u3067\u3059\u3002\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001DNS \u30d9\u30fc\u30b9\u306e\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u3001\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u7d71\u5408\u3001\u9ad8\u5ea6\u306a\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30d1\u30bf\u30fc\u30f3\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/applications/service-discovery/#_2","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u8907\u6570\u306e\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30e1\u30ab\u30cb\u30ba\u30e0\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p> <ul> <li>Kubernetes DNS\uff08CoreDNS\uff09</li> <li>\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\uff08Istio/Linkerd\uff09</li> <li>\u5916\u90e8\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\uff08Consul\u3001etcd\uff09</li> <li>\u30d8\u30c3\u30c9\u30ec\u30b9\u30b5\u30fc\u30d3\u30b9 \u76f4\u63a5\u30dd\u30c3\u30c9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u7528</li> </ul>"},{"location":"ja/applications/service-discovery/#kubernetes-dns","title":"Kubernetes DNS \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":""},{"location":"ja/applications/service-discovery/#_3","title":"\u57fa\u672c\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<p>\u3059\u3079\u3066\u306e\u30b5\u30fc\u30d3\u30b9\u304c DNS \u30a8\u30f3\u30c8\u30ea\u3092\u53d6\u5f97\u3057\u307e\u3059\uff1a</p> <pre><code>&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local\n</code></pre> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: backend-api\n  namespace: production\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 8080\n      targetPort: 8080\n</code></pre> <p>\u30a2\u30af\u30bb\u30b9\u30d1\u30bf\u30fc\u30f3\uff1a</p> <pre><code># \u540c\u3058 namespace \u304b\u3089\ncurl http://backend-api:8080\n\n# \u7570\u306a\u308b namespace \u304b\u3089\ncurl http://backend-api.production:8080\n\n# \u5b8c\u5168\u4fee\u98fe\ncurl http://backend-api.production.svc.cluster.local:8080\n</code></pre>"},{"location":"ja/applications/service-discovery/#dns","title":"DNS \u30dd\u30ea\u30b7\u30fc","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  dnsPolicy: ClusterFirst # \u30c7\u30d5\u30a9\u30eb\u30c8\n  # \u305d\u306e\u4ed6\u306e\u30aa\u30d7\u30b7\u30e7\u30f3: Default, None, ClusterFirstWithHostNet\n  dnsConfig:\n    nameservers:\n      - 1.1.1.1\n    searches:\n      - production.svc.cluster.local\n      - svc.cluster.local\n    options:\n      - name: ndots\n        value: \"5\"\n</code></pre>"},{"location":"ja/applications/service-discovery/#_4","title":"\u30d8\u30c3\u30c9\u30ec\u30b9\u30b5\u30fc\u30d3\u30b9","text":""},{"location":"ja/applications/service-discovery/#_5","title":"\u76f4\u63a5\u30dd\u30c3\u30c9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: database-cluster\nspec:\n  clusterIP: None # \u30d8\u30c3\u30c9\u30ec\u30b9\u30b5\u30fc\u30d3\u30b9\n  selector:\n    app: postgres\n  ports:\n    - port: 5432\n</code></pre> <p>DNS \u306f\u3059\u3079\u3066\u306e\u30dd\u30c3\u30c9 IP \u3092\u8fd4\u3057\u307e\u3059\uff1a</p> <pre><code># \u3059\u3079\u3066\u306e\u30dd\u30c3\u30c9\u306e A \u30ec\u30b3\u30fc\u30c9\u3092\u8fd4\u3059\nnslookup database-cluster.default.svc.cluster.local\n\n# \u500b\u5225\u306e\u30dd\u30c3\u30c9 DNS\n&lt;pod-name&gt;.&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local\n</code></pre>"},{"location":"ja/applications/service-discovery/#statefulset","title":"StatefulSet \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-headless\nspec:\n  clusterIP: None\n  selector:\n    app: postgres\n  ports:\n    - port: 5432\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\nspec:\n  serviceName: postgres-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n        - name: postgres\n          image: postgres:14\n</code></pre> <p>\u4e88\u6e2c\u53ef\u80fd\u306a\u30dd\u30c3\u30c9\u540d\uff1a</p> <pre><code># \u7279\u5b9a\u306e\u30ec\u30d7\u30ea\u30ab\u306b\u30a2\u30af\u30bb\u30b9\npostgres-0.postgres-headless.default.svc.cluster.local\npostgres-1.postgres-headless.default.svc.cluster.local\npostgres-2.postgres-headless.default.svc.cluster.local\n</code></pre>"},{"location":"ja/applications/service-discovery/#_6","title":"\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":""},{"location":"ja/applications/service-discovery/#istio","title":"Istio \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: ServiceEntry\nmetadata:\n  name: external-api\nspec:\n  hosts:\n    - api.external.com\n  ports:\n    - number: 443\n      name: https\n      protocol: HTTPS\n  location: MESH_EXTERNAL\n  resolution: DNS\n</code></pre>"},{"location":"ja/applications/service-discovery/#_7","title":"\u4eee\u60f3\u30b5\u30fc\u30d3\u30b9","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews-route\nspec:\n  hosts:\n    - reviews\n  http:\n    - match:\n        - headers:\n            version:\n              exact: v2\n      route:\n        - destination:\n            host: reviews\n            subset: v2\n    - route:\n        - destination:\n            host: reviews\n            subset: v1\n</code></pre>"},{"location":"ja/applications/service-discovery/#_8","title":"\u30c7\u30b9\u30c6\u30a3\u30cd\u30fc\u30b7\u30e7\u30f3\u30eb\u30fc\u30eb","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: reviews-destination\nspec:\n  host: reviews\n  subsets:\n    - name: v1\n      labels:\n        version: v1\n    - name: v2\n      labels:\n        version: v2\n</code></pre>"},{"location":"ja/applications/service-discovery/#endpointslices","title":"EndpointSlices","text":""},{"location":"ja/applications/service-discovery/#_9","title":"\u30e2\u30c0\u30f3\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u7ba1\u7406","text":"<pre><code>apiVersion: discovery.k8s.io/v1\nkind: EndpointSlice\nmetadata:\n  name: myapp-endpoints\n  labels:\n    kubernetes.io/service-name: myapp\naddressType: IPv4\nendpoints:\n  - addresses:\n      - \"10.1.2.3\"\n    conditions:\n      ready: true\n      serving: true\n      terminating: false\nports:\n  - port: 8080\n    protocol: TCP\n</code></pre>"},{"location":"ja/applications/service-discovery/#_10","title":"\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30d1\u30bf\u30fc\u30f3","text":""},{"location":"ja/applications/service-discovery/#_11","title":"\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b5\u30a4\u30c9\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0","text":"<pre><code>// \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b5\u30a4\u30c9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u3092\u4f7f\u7528\u3057\u305f Go \u306e\u4f8b\npackage main\n\nimport (\n    \"fmt\"\n    \"net\"\n    \"math/rand\"\n)\n\nfunc discoverService(service string) ([]string, error) {\n    _, addrs, err := net.LookupSRV(\"\", \"\", service)\n    if err != nil {\n        return nil, err\n    }\n\n    var endpoints []string\n    for _, addr := range addrs {\n        endpoints = append(endpoints, fmt.Sprintf(\"%s:%d\", addr.Target, addr.Port))\n    }\n    return endpoints, nil\n}\n\nfunc getRandomEndpoint(service string) (string, error) {\n    endpoints, err := discoverService(service)\n    if err != nil {\n        return \"\", err\n    }\n    return endpoints[rand.Intn(len(endpoints))], nil\n}\n</code></pre>"},{"location":"ja/applications/service-discovery/#_12","title":"\u30d8\u30eb\u30b9\u5bfe\u5fdc\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  annotations:\n    service.alpha.kubernetes.io/tolerate-unready-endpoints: \"false\"\nspec:\n  selector:\n    app: api\n  ports:\n    - port: 80\n  publishNotReadyAddresses: false # \u6e96\u5099\u5b8c\u4e86\u30dd\u30c3\u30c9\u306e\u307f\u3092\u767a\u898b\n</code></pre>"},{"location":"ja/applications/service-discovery/#_13","title":"\u5916\u90e8\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":""},{"location":"ja/applications/service-discovery/#consul","title":"Consul \u7d71\u5408","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: consul-config\ndata:\n  consul.json: |\n    {\n      \"datacenter\": \"dc1\",\n      \"services\": [\n        {\n          \"name\": \"web-app\",\n          \"tags\": [\"production\", \"v1\"],\n          \"port\": 8080,\n          \"check\": {\n            \"http\": \"http://localhost:8080/health\",\n            \"interval\": \"10s\"\n          }\n        }\n      ]\n    }\n</code></pre>"},{"location":"ja/applications/service-discovery/#dns_1","title":"\u5916\u90e8 DNS","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp\n  annotations:\n    external-dns.alpha.kubernetes.io/hostname: myapp.example.com\n    external-dns.alpha.kubernetes.io/ttl: \"60\"\nspec:\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: myapp\n                port:\n                  number: 80\n</code></pre>"},{"location":"ja/applications/service-discovery/#_14","title":"\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30bf\u30fc\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":""},{"location":"ja/applications/service-discovery/#_15","title":"\u30af\u30ed\u30b9\u30af\u30e9\u30b9\u30bf\u30fc\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: ServiceEntry\nmetadata:\n  name: cross-cluster-service\nspec:\n  hosts:\n    - remote-service.remote-cluster.local\n  location: MESH_EXTERNAL\n  ports:\n    - number: 8080\n      name: http\n      protocol: HTTP\n  resolution: DNS\n  endpoints:\n    - address: cluster-2-gateway.example.com\n      ports:\n        http: 15443\n</code></pre>"},{"location":"ja/applications/service-discovery/#dns_2","title":"\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30bf\u30fc DNS","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns-custom\n  namespace: kube-system\ndata:\n  remote.server: |\n    remote-cluster.local:53 {\n        forward . 10.0.0.100:53\n    }\n</code></pre>"},{"location":"ja/applications/service-discovery/#_16","title":"\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":""},{"location":"ja/applications/service-discovery/#_17","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-discovery-policy\nspec:\n  podSelector:\n    matchLabels:\n      app: api\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: production\n        - podSelector:\n            matchLabels:\n              role: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"ja/applications/service-discovery/#mtls","title":"\u30b5\u30fc\u30d3\u30b9\u901a\u4fe1\u7528 mTLS","text":"<pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\nspec:\n  mtls:\n    mode: STRICT\n</code></pre>"},{"location":"ja/applications/service-discovery/#_18","title":"\u9ad8\u5ea6\u306a\u30d1\u30bf\u30fc\u30f3","text":""},{"location":"ja/applications/service-discovery/#_19","title":"\u30b5\u30fc\u30d3\u30b9\u30ec\u30b8\u30b9\u30c8\u30ea\u30d1\u30bf\u30fc\u30f3","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: service-registry\ndata:\n  services.yaml: |\n    services:\n      - name: user-service\n        endpoints:\n          - host: user-service.production\n            port: 8080\n            weight: 100\n      - name: order-service\n        endpoints:\n          - host: order-service-v1.production\n            port: 8080\n            weight: 80\n          - host: order-service-v2.production\n            port: 8080\n            weight: 20\n</code></pre>"},{"location":"ja/applications/service-discovery/#_20","title":"\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u4ed8\u304d\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: circuit-breaker\nspec:\n  host: backend-service\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n      minHealthPercent: 30\n</code></pre>"},{"location":"ja/applications/service-discovery/#_21","title":"\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u76e3\u8996","text":""},{"location":"ja/applications/service-discovery/#_22","title":"\u30e1\u30c8\u30ea\u30af\u30b9","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  annotations:\n    prometheus.io/scrape: \"true\"\n    prometheus.io/path: \"/metrics\"\nspec:\n  selector:\n    app: myapp\n  ports:\n    - name: web\n      port: 80\n    - name: metrics\n      port: 9090\n</code></pre>"},{"location":"ja/applications/service-discovery/#_23","title":"\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":"<pre><code># DNS \u89e3\u6c7a\u3092\u30c1\u30a7\u30c3\u30af\nhb exec -it debug-pod -- nslookup myservice\n\n# \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u30c1\u30a7\u30c3\u30af\nhb get endpoints myservice\n\n# \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u30b9\u30e9\u30a4\u30b9\u3092\u30c1\u30a7\u30c3\u30af\nhb get endpointslices -l kubernetes.io/service-name=myservice\n\n# \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u3092\u30c6\u30b9\u30c8\nhb run test --rm -it --image=busybox -- wget -O- http://myservice\n</code></pre>"},{"location":"ja/applications/service-discovery/#_24","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/applications/service-discovery/#_25","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":"<ol> <li>DNS \u89e3\u6c7a\u5931\u6557</li> </ol> <pre><code># CoreDNS \u30ed\u30b0\u3092\u30c1\u30a7\u30c3\u30af\nhb logs -n kube-system -l k8s-app=kube-dns\n\n# \u30dd\u30c3\u30c9\u304b\u3089 DNS \u3092\u30c6\u30b9\u30c8\nhb exec -it myapp -- nslookup kubernetes.default\n</code></pre> <ol> <li>\u30b5\u30fc\u30d3\u30b9\u304c\u898b\u3064\u304b\u3089\u306a\u3044</li> </ol> <pre><code># \u30b5\u30fc\u30d3\u30b9\u304c\u5b58\u5728\u3059\u308b\u3053\u3068\u3092\u78ba\u8a8d\nhb get svc myservice\n\n# \u30b5\u30fc\u30d3\u30b9\u30bb\u30ec\u30af\u30bf\u30fc\u3092\u30c1\u30a7\u30c3\u30af\nhb describe svc myservice\n\n# \u4e00\u81f4\u3059\u308b\u30dd\u30c3\u30c9\u3092\u78ba\u8a8d\nhb get pods -l app=myapp\n</code></pre> <ol> <li>\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u304c\u6e96\u5099\u3067\u304d\u3066\u3044\u306a\u3044</li> </ol> <pre><code># \u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u72b6\u614b\u3092\u30c1\u30a7\u30c3\u30af\nhb get endpoints myservice\n\n# \u30dd\u30c3\u30c9\u6e96\u5099\u72b6\u614b\u3092\u30c1\u30a7\u30c3\u30af\nhb get pods -l app=myapp -o wide\n</code></pre>"},{"location":"ja/applications/service-discovery/#_26","title":"\u30c7\u30d0\u30c3\u30b0\u30c4\u30fc\u30eb","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: network-debug\nspec:\n  containers:\n    - name: debug\n      image: nicolaka/netshoot\n      command: [\"/bin/bash\"]\n      args: [\"-c\", \"sleep 3600\"]\n</code></pre> <p>\u30c7\u30d0\u30c3\u30b0\u30b3\u30de\u30f3\u30c9\uff1a</p> <pre><code># DNS \u30c7\u30d0\u30c3\u30b0\ndig @10.96.0.10 myservice.default.svc.cluster.local\n\n# \u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30c6\u30b9\u30c8\ncurl -v http://myservice.default.svc.cluster.local\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30b9\u3092\u30c8\u30ec\u30fc\u30b9\ntraceroute myservice.default.svc.cluster.local\n</code></pre>"},{"location":"ja/applications/service-discovery/#_27","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li> <p>\u9069\u5207\u306a\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u65b9\u6cd5\u3092\u4f7f\u7528</p> </li> <li> <p>\u30b7\u30f3\u30d7\u30eb\u306a\u30b5\u30fc\u30d3\u30b9\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u306b\u306f DNS</p> </li> <li>\u30b9\u30c6\u30fc\u30c8\u30d5\u30eb\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306b\u306f\u30d8\u30c3\u30c9\u30ec\u30b9\u30b5\u30fc\u30d3\u30b9</li> <li> <p>\u9ad8\u5ea6\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u7ba1\u7406\u306b\u306f\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5</p> </li> <li> <p>\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af\u3092\u5b9f\u88c5</p> </li> <li> <p>\u5e38\u306b readiness probe \u3092\u5b9a\u7fa9</p> </li> <li>\u81ea\u5df1\u4fee\u5fa9\u306e\u305f\u3081 liveness probe \u3092\u4f7f\u7528</li> <li> <p>\u9069\u5207\u306a\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u3092\u8a2d\u5b9a</p> </li> <li> <p>\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u7d50\u679c\u3092\u30ad\u30e3\u30c3\u30b7\u30e5</p> </li> <li> <p>\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30b5\u30a4\u30c9\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3092\u5b9f\u88c5</p> </li> <li>TTL \u3092\u9069\u5207\u306b\u4f7f\u7528</li> <li> <p>\u30ad\u30e3\u30c3\u30b7\u30e5\u7121\u52b9\u5316\u3092\u51e6\u7406</p> </li> <li> <p>\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u30d8\u30eb\u30b9\u3092\u76e3\u8996</p> </li> <li> <p>DNS \u30af\u30a8\u30ea\u30ec\u30a4\u30c6\u30f3\u30b7\u3092\u8ffd\u8de1</p> </li> <li>\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u5909\u66f4\u3092\u76e3\u8996</li> <li> <p>\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc\u5931\u6557\u306b\u30a2\u30e9\u30fc\u30c8</p> </li> <li> <p>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8003\u616e\u4e8b\u9805</p> </li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u3092\u4f7f\u7528</li> <li>\u53ef\u80fd\u306a\u5834\u5408\u306f mTLS \u3092\u5b9f\u88c5</li> <li>\u30b5\u30fc\u30d3\u30b9\u516c\u958b\u3092\u5236\u9650</li> </ol>"},{"location":"ja/applications/service-discovery/#hks","title":"HKS \u56fa\u6709\u306e\u6a5f\u80fd","text":""},{"location":"ja/applications/service-discovery/#ai","title":"AI \u5f37\u5316\u30c7\u30a3\u30b9\u30ab\u30d0\u30ea\u30fc","text":"<pre><code>apiVersion: hks.io/v1\nkind: SmartDiscovery\nmetadata:\n  name: intelligent-routing\nspec:\n  service: myapp\n  optimization:\n    - latency\n    - cost\n    - reliability\n  learning:\n    enabled: true\n    window: 7d\n</code></pre>"},{"location":"ja/applications/service-discovery/#_28","title":"\u30b0\u30ed\u30fc\u30d0\u30eb\u30b5\u30fc\u30d3\u30b9\u30ab\u30bf\u30ed\u30b0","text":"<pre><code># \u30af\u30e9\u30b9\u30bf\u30fc\u5168\u4f53\u306e\u3059\u3079\u3066\u306e\u30b5\u30fc\u30d3\u30b9\u3092\u30ea\u30b9\u30c8\nhb catalog list --global\n\n# \u6a5f\u80fd\u3067\u30b5\u30fc\u30d3\u30b9\u3092\u691c\u7d22\nhb catalog search --tag \"user-auth\"\n\n# \u30b5\u30fc\u30d3\u30b9\u8a73\u7d30\u3092\u53d6\u5f97\nhb catalog describe user-service --detailed\n</code></pre>"},{"location":"ja/concept/","title":"\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8","text":"<p>Hexabase.AI \u306e\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8\u30bb\u30af\u30b7\u30e7\u30f3\u3078\u3088\u3046\u3053\u305d\u3002\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001Hexabase.AI \u3092\u4f7f\u7528\u3059\u308b\u969b\u306b\u7406\u89e3\u3057\u3066\u304a\u304f\u5fc5\u8981\u304c\u3042\u308b\u57fa\u672c\u7684\u306a\u6982\u5ff5\u3068\u7528\u8a9e\u3092\u7d39\u4ecb\u3057\u307e\u3059\u3002</p> <p>\u30ea\u30f3\u30af\u5148\u306b\u3064\u3044\u3066</p> <p>\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u306f\u82f1\u8a9e\u7248\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u63a5\u7d9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/concept/#_2","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u3001\u5f37\u529b\u306a\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u306e Kubernetes as a Service \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u305f\u3081\u306b\u9023\u643a\u3059\u308b\u3001\u3044\u304f\u3064\u304b\u306e\u91cd\u8981\u306a\u6982\u5ff5\u306b\u57fa\u3065\u3044\u3066\u69cb\u7bc9\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u6982\u5ff5\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u52b9\u679c\u7684\u306b\u4f7f\u7528\u304a\u3088\u3073\u7ba1\u7406\u3059\u308b\u305f\u3081\u306b\u4e0d\u53ef\u6b20\u3067\u3059\u3002</p>"},{"location":"ja/concept/#_3","title":"\u4e3b\u306a\u6982\u5ff5","text":"<ul> <li> \u7d44\u7e54 (Organizations)</li> </ul> <p>Hexabase.AI \u3092\u4f7f\u7528\u3059\u308b\u4f01\u696d\u3084\u30c1\u30fc\u30e0\u3092\u8868\u3059\u30c8\u30c3\u30d7\u30ec\u30d9\u30eb\u306e\u30a8\u30f3\u30c6\u30a3\u30c6\u30a3</p> <p> \u7d44\u7e54\u306b\u3064\u3044\u3066\u5b66\u3076 (English)</p> <ul> <li> \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 (Workspaces)</li> </ul> <p>\u7d44\u7e54\u5185\u3067\u3001\u7570\u306a\u308b\u30c1\u30fc\u30e0\u3084\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u305f\u3081\u306b\u5206\u96e2\u3055\u308c\u305f\u74b0\u5883</p> <p> \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u3064\u3044\u3066\u5b66\u3076 (English)</p> <ul> <li> \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 (Projects)</li> </ul> <p>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u69cb\u6210\u3092\u542b\u3080\u3001\u30c7\u30d7\u30ed\u30a4\u53ef\u80fd\u306a\u5358\u4f4d</p> <p> \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u3064\u3044\u3066\u5b66\u3076</p> <ul> <li> \u30af\u30e9\u30b9\u30bf\u30fc (Clusters)</li> </ul> <p>\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306b Hexabase.AI \u306b\u3088\u3063\u3066\u7ba1\u7406\u3055\u308c\u308b Kubernetes \u30af\u30e9\u30b9\u30bf\u30fc</p> <p> \u30af\u30e9\u30b9\u30bf\u30fc\u306b\u3064\u3044\u3066\u5b66\u3076 (English)</p>"},{"location":"ja/concept/#_4","title":"\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u30e2\u30c7\u30eb","text":"<p>Hexabase.AI \u306f\u968e\u5c64\u7684\u306a\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u30e2\u30c7\u30eb\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>\u7d44\u7e54\n\u2514\u2500\u2500 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\n    \u2514\u2500\u2500 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\n        \u2514\u2500\u2500 \u30ea\u30bd\u30fc\u30b9 (Deployments, Services, etc.)\n</code></pre> <p>\u3053\u306e\u69cb\u9020\u306f\u4ee5\u4e0b\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p> <ul> <li>\u5206\u96e2: \u7570\u306a\u308b\u7d44\u7e54\u9593\u306e\u5b8c\u5168\u306a\u5206\u96e2</li> <li>\u67d4\u8edf\u6027: \u7570\u306a\u308b\u30c1\u30fc\u30e0\u3084\u74b0\u5883\u306e\u305f\u3081\u306e\u8907\u6570\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3: \u5404\u30ec\u30d9\u30eb\u3067\u306e\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u306e\u30a2\u30af\u30bb\u30b9\u5236\u5fa1</li> <li>\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3054\u3068\u306e\u30af\u30a9\u30fc\u30bf\u3068\u5236\u9650</li> </ul>"},{"location":"ja/concept/#_5","title":"\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8","text":""},{"location":"ja/concept/#_6","title":"\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3","text":"<ul> <li>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5168\u4f53\u306e\u904b\u7528\u3092\u7ba1\u7406</li> <li>\u8a8d\u8a3c\u3068\u8a8d\u53ef\u3092\u51e6\u7406</li> <li>\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3068\u7ba1\u7406\u3092\u8abf\u6574</li> </ul>"},{"location":"ja/concept/#_7","title":"\u30c7\u30fc\u30bf\u30d7\u30ec\u30fc\u30f3","text":"<ul> <li>Kubernetes \u30af\u30e9\u30b9\u30bf\u30fc\u3067\u5b9f\u969b\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u3092\u5b9f\u884c</li> <li>\u30b3\u30f3\u30d4\u30e5\u30fc\u30c8\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\u30ea\u30bd\u30fc\u30b9\u3092\u63d0\u4f9b</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u3068\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u5b9f\u88c5</li> </ul>"},{"location":"ja/concept/#aiops","title":"AIOps \u30a8\u30f3\u30b8\u30f3","text":"<ul> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u3068\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u76e3\u8996</li> <li>\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u63a8\u5968\u4e8b\u9805\u3092\u63d0\u4f9b</li> <li>\u6700\u9069\u5316\u3068\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u306e\u6c7a\u5b9a\u3092\u81ea\u52d5\u5316</li> </ul>"},{"location":"ja/concept/#_8","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>Hexabase.AI \u306f\u521d\u3081\u3066\u3067\u3059\u304b\uff1f \u30c8\u30c3\u30d7\u30ec\u30d9\u30eb\u306e\u69cb\u9020\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306b \u7d44\u7e54 (English) \u304b\u3089\u59cb\u3081\u307e\u3057\u3087\u3046</li> <li>\u30c1\u30fc\u30e0\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u304b\uff1f \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 (English) \u306b\u3064\u3044\u3066\u5b66\u3073\u3001\u74b0\u5883\u3092\u6574\u7406\u3059\u308b\u65b9\u6cd5\u3092\u5b66\u3073\u307e\u3057\u3087\u3046</li> <li>\u30c7\u30d7\u30ed\u30a4\u306e\u6e96\u5099\u306f\u3067\u304d\u307e\u3057\u305f\u304b\uff1f \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 \u3092\u7406\u89e3\u3057\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30d1\u30c3\u30b1\u30fc\u30b8\u5316\u3059\u308b\u65b9\u6cd5\u3092\u5b66\u3073\u307e\u3057\u3087\u3046</li> <li>\u30a4\u30f3\u30d5\u30e9\u3092\u7ba1\u7406\u3057\u307e\u3059\u304b\uff1f \u30af\u30e9\u30b9\u30bf\u30fc (English) \u3068\u305d\u306e\u6a5f\u80fd\u3092\u63a2\u308a\u307e\u3057\u3087\u3046</li> </ul>"},{"location":"ja/concept/#_9","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u6982\u8981 (English)</li> <li>\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u6982\u8981 (English)</li> <li>API \u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 (English)</li> </ul>"},{"location":"ja/concept/core-concepts/","title":"Hexabase AI: \u30b3\u30f3\u30bb\u30d7\u30c8\u3068\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"ja/concept/core-concepts/#1","title":"1. \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u6982\u8981","text":""},{"location":"ja/concept/core-concepts/#_1","title":"\u30d3\u30b8\u30e7\u30f3","text":"<p>Hexabase AI \u306f\u3001K3s \u3068 vCluster \u3092\u57fa\u76e4\u3068\u3059\u308b\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8 Kubernetes as a Service \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u3042\u308a\u3001\u3042\u3089\u3086\u308b\u30b9\u30ad\u30eb\u30ec\u30d9\u30eb\u306e\u958b\u767a\u8005\u304c Kubernetes \u3092\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/concept/core-concepts/#_2","title":"\u30b3\u30a2\u30d0\u30ea\u30e5\u30fc","text":"<ul> <li>\u5c0e\u5165\u306e\u5bb9\u6613\u3055: \u8efd\u91cf\u306a K3s \u30d9\u30fc\u30b9\u3068 vCluster \u4eee\u60f3\u5316\u306b\u3088\u308b\u8fc5\u901f\u306a\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8</li> <li>\u76f4\u611f\u7684\u306a UX: \u7d44\u7e54\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u901a\u3058\u3066 Kubernetes \u306e\u8907\u96d1\u3055\u3092\u62bd\u8c61\u5316</li> <li>\u5f37\u529b\u306a\u30c6\u30ca\u30f3\u30c8\u5206\u96e2: vCluster \u304c\u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306b\u5c02\u7528 API \u30b5\u30fc\u30d0\u30fc\u3068\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u3092\u63d0\u4f9b</li> <li>\u30af\u30e9\u30a6\u30c9\u30cd\u30a4\u30c6\u30a3\u30d6\u904b\u7528: Prometheus\u3001Grafana\u3001Loki \u76e3\u8996\u5185\u8535\uff1bFlux GitOps\uff1bKyverno \u30dd\u30ea\u30b7\u30fc</li> <li>\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u900f\u660e\u6027: \u5b8c\u5168\u306a\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u516c\u958b\u306b\u3088\u308b\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u4e3b\u5c0e\u306e\u958b\u767a</li> </ul>"},{"location":"ja/concept/core-concepts/#_3","title":"\u65e2\u5b58\u306e\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9","text":"<ul> <li>UI (Next.js): https://github.com/b-eee/hxb-next-webui</li> <li>API (Go): https://github.com/b-eee/apicore</li> </ul> <p>\u4e21\u30ea\u30dd\u30b8\u30c8\u30ea\u3068\u3082\u3001\u3053\u306e\u4ed5\u69d8\u306b\u57fa\u3065\u304f\u5927\u5e45\u306a\u518d\u5b9f\u88c5\u304c\u5fc5\u8981\u3067\u3059\u3002</p>"},{"location":"ja/concept/core-concepts/#2","title":"2. \u30b7\u30b9\u30c6\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"ja/concept/core-concepts/#_4","title":"\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u6982\u8981","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Hexabase UI    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Hexabase API    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Host K3s       \u2502\n\u2502  (Next.js)      \u2502     \u2502  (Control Plane) \u2502     \u2502  Cluster        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502                        \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n                        \u2502                 \u2502          \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510    \u2502  vClusters  \u2502\n                  \u2502PostgreSQL \u2502     \u2502   Redis   \u2502    \u2502  (Tenants)  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                          \u2502\n                                    \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n                                    \u2502   NATS    \u2502\n                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/concept/core-concepts/#_5","title":"\u30c7\u30fc\u30bf\u30d5\u30ed\u30fc","text":"<ol> <li>\u30e6\u30fc\u30b6\u30fc\u64cd\u4f5c: \u30d6\u30e9\u30a6\u30b6 \u2192 UI \u2192 \u8a8d\u8a3c\u30c8\u30fc\u30af\u30f3\u4ed8\u304d API \u30ea\u30af\u30a8\u30b9\u30c8</li> <li>API \u51e6\u7406: \u8a8d\u8a3c\u691c\u8a3c \u2192 \u30d3\u30b8\u30cd\u30b9\u30ed\u30b8\u30c3\u30af \u2192 DB \u66f4\u65b0 \u2192 \u975e\u540c\u671f\u30bf\u30b9\u30af</li> <li>vCluster \u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3: API \u2192 client-go \u2192 Host K3s \u2192 vCluster \u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb</li> <li>\u975e\u540c\u671f\u51e6\u7406: API \u2192 NATS \u2192 \u30ef\u30fc\u30ab\u30fc \u2192 \u9577\u6642\u9593\u5b9f\u884c\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3</li> <li>\u72b6\u614b\u6c38\u7d9a\u5316: \u3059\u3079\u3066\u306e\u30a8\u30f3\u30c6\u30a3\u30c6\u30a3\u306b PostgreSQL\u3001\u30ad\u30e3\u30c3\u30b7\u30e5\u306b Redis</li> <li>\u76e3\u8996: Prometheus \u30e1\u30c8\u30ea\u30af\u30b9 \u2192 Loki \u30ed\u30b0 \u2192 Grafana \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9</li> <li>GitOps \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8: Git \u2192 Flux \u2192 Host K3s \u2192 \u81ea\u52d5\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8</li> <li>\u30dd\u30ea\u30b7\u30fc\u9069\u7528: Kyverno admission controller \u2192 \u30dd\u30ea\u30b7\u30fc\u691c\u8a3c</li> </ol>"},{"location":"ja/concept/core-concepts/#3","title":"3. \u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8","text":"Hexabase \u30b3\u30f3\u30bb\u30d7\u30c8 Kubernetes \u540c\u7b49\u7269 \u30b9\u30b3\u30fc\u30d7 \u8aac\u660e \u7d44\u7e54 N/A Hexabase \u8acb\u6c42\u3068\u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u5358\u4f4d \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 vCluster Host K3s \u5206\u96e2\u3055\u308c\u305f Kubernetes \u74b0\u5883 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30d7\u30e9\u30f3 ResourceQuota/Nodes vCluster \u30ea\u30bd\u30fc\u30b9\u5236\u9650\u3068\u30ce\u30fc\u30c9\u914d\u5206 \u7d44\u7e54\u30e6\u30fc\u30b6\u30fc N/A Hexabase \u8acb\u6c42/\u7ba1\u7406\u62c5\u5f53\u8005 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30e1\u30f3\u30d0\u30fc OIDC Subject vCluster kubectl \u30a2\u30af\u30bb\u30b9\u6a29\u3092\u6301\u3064\u6280\u8853\u30e6\u30fc\u30b6\u30fc \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30b0\u30eb\u30fc\u30d7 OIDC Claim vCluster \u6a29\u9650\u5272\u308a\u5f53\u3066\u5358\u4f4d\uff08\u968e\u5c64\u7684\uff09 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 ClusterRole ClusterRole vCluster \u30d7\u30ea\u30bb\u30c3\u30c8\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5168\u4f53\u6a29\u9650 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 Namespace vCluster \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e\u30ea\u30bd\u30fc\u30b9\u5206\u96e2 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ed\u30fc\u30eb Role Namespace \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5185\u306e\u30ab\u30b9\u30bf\u30e0\u6a29\u9650"},{"location":"ja/concept/core-concepts/#4","title":"4. \u30e6\u30fc\u30b6\u30fc\u30d5\u30ed\u30fc","text":""},{"location":"ja/concept/core-concepts/#41","title":"4.1 \u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u3068\u7d44\u7e54\u7ba1\u7406","text":"<ul> <li>\u8a8d\u8a3c: OIDC \u306b\u3088\u308b\u5916\u90e8 IdP\uff08Google/GitHub\uff09</li> <li>\u81ea\u52d5\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0: \u521d\u56de\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u6642\u306b\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u7d44\u7e54\u3092\u4f5c\u6210</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005: \u8acb\u6c42\uff08Stripe\uff09\u3068\u30e6\u30fc\u30b6\u30fc\u62db\u5f85\u3092\u7ba1\u7406</li> </ul>"},{"location":"ja/concept/core-concepts/#42-vcluster","title":"4.2 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08vCluster\uff09\u7ba1\u7406","text":"<ul> <li>\u4f5c\u6210: \u30d7\u30e9\u30f3\u9078\u629e \u2192 vCluster \u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0 \u2192 OIDC \u8a2d\u5b9a</li> <li>\u521d\u671f\u8a2d\u5b9a:</li> <li>ClusterRoles \u81ea\u52d5\u4f5c\u6210: <code>hexabase:workspace-admin</code>, <code>hexabase:workspace-viewer</code></li> <li>\u30c7\u30d5\u30a9\u30eb\u30c8\u30b0\u30eb\u30fc\u30d7\u4f5c\u6210: <code>WorkspaceMembers</code> \u2192 <code>WSAdmins</code>, <code>WSUsers</code></li> <li>\u4f5c\u6210\u8005\u3092 <code>WSAdmins</code> \u30b0\u30eb\u30fc\u30d7\u306b\u5272\u308a\u5f53\u3066</li> </ul>"},{"location":"ja/concept/core-concepts/#43-namespace","title":"4.3 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\uff08Namespace\uff09\u7ba1\u7406","text":"<ul> <li>\u4f5c\u6210: UI \u30ea\u30af\u30a8\u30b9\u30c8 \u2192 vCluster \u5185\u3067 namespace \u4f5c\u6210</li> <li>ResourceQuota: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30d7\u30e9\u30f3\u306b\u57fa\u3065\u304f\u81ea\u52d5\u9069\u7528</li> <li>\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb: UI \u3092\u901a\u3058\u3066\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30b9\u30b3\u30fc\u30d7\u30ed\u30fc\u30eb\u3092\u4f5c\u6210</li> </ul>"},{"location":"ja/concept/core-concepts/#44","title":"4.4 \u6a29\u9650\u7ba1\u7406","text":"<ul> <li>\u5272\u308a\u5f53\u3066: UI \u3092\u901a\u3058\u3066\u30b0\u30eb\u30fc\u30d7 \u2192 \u30ed\u30fc\u30eb/ClusterRoles</li> <li>\u7d99\u627f: \u518d\u5e30\u7684\u306a\u30b0\u30eb\u30fc\u30d7\u30e1\u30f3\u30d0\u30fc\u30b7\u30c3\u30d7\u89e3\u6c7a</li> <li>OIDC \u7d71\u5408: \u30c8\u30fc\u30af\u30f3\u30af\u30ec\u30fc\u30e0\u5185\u306e\u5e73\u5766\u5316\u3055\u308c\u305f\u30b0\u30eb\u30fc\u30d7</li> </ul>"},{"location":"ja/concept/core-concepts/#5","title":"5. \u6280\u8853\u30b9\u30bf\u30c3\u30af","text":""},{"location":"ja/concept/core-concepts/#_6","title":"\u30b3\u30a2\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8","text":"<ul> <li>\u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9: Next.js</li> <li>\u30d0\u30c3\u30af\u30a8\u30f3\u30c9: Go (Golang)</li> <li>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9: PostgreSQL\uff08\u30d7\u30e9\u30a4\u30de\u30ea\uff09\u3001Redis\uff08\u30ad\u30e3\u30c3\u30b7\u30e5\uff09</li> <li>\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0: NATS</li> <li>\u30b3\u30f3\u30c6\u30ca\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0: K3s + vCluster</li> </ul>"},{"location":"ja/concept/core-concepts/#cicd","title":"CI/CD &amp; \u904b\u7528","text":"<ul> <li>CI \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3: Tekton\uff08Kubernetes \u30cd\u30a4\u30c6\u30a3\u30d6\uff09</li> <li>GitOps: ArgoCD \u307e\u305f\u306f Flux</li> <li>\u30b3\u30f3\u30c6\u30ca\u30b9\u30ad\u30e3\u30f3: Trivy</li> <li>\u30e9\u30f3\u30bf\u30a4\u30e0\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3: Falco</li> <li>\u30dd\u30ea\u30b7\u30fc\u30a8\u30f3\u30b8\u30f3: Kyverno</li> </ul>"},{"location":"ja/concept/core-concepts/#6-iac","title":"6. \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08IaC\uff09","text":""},{"location":"ja/concept/core-concepts/#helm","title":"Helm \u30a2\u30f3\u30d6\u30ec\u30e9\u30c1\u30e3\u30fc\u30c8","text":"<pre><code>apiVersion: v2\nname: hexabase-ai\ndependencies:\n  - name: postgresql\n    repository: https://charts.bitnami.com/bitnami\n  - name: redis\n    repository: https://charts.bitnami.com/bitnami\n  - name: nats\n    repository: https://nats-io.github.io/k8s/helm/charts/\n</code></pre>"},{"location":"ja/concept/core-concepts/#_7","title":"\u30af\u30a4\u30c3\u30af\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>helm repo add hexabase https://hexabase.ai/charts\nhelm install hexabase-ai hexabase/hexabase-ai -f values.yaml\n</code></pre>"},{"location":"ja/concept/core-concepts/#7","title":"7. \u4e3b\u8981\u6a5f\u80fd","text":""},{"location":"ja/concept/core-concepts/#_8","title":"\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc","text":"<ul> <li>vCluster \u306b\u3088\u308b\u5b8c\u5168\u306a API \u30b5\u30fc\u30d0\u30fc\u5206\u96e2</li> <li>\u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306e\u5c02\u7528\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8</li> <li>\u30d7\u30ec\u30df\u30a2\u30e0\u30d7\u30e9\u30f3\u5411\u3051\u30aa\u30d7\u30b7\u30e7\u30f3\u5c02\u7528\u30ce\u30fc\u30c9</li> </ul>"},{"location":"ja/concept/core-concepts/#_9","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":"<ul> <li>\u5916\u90e8 IdP \u8a8d\u8a3c\u306e\u307f</li> <li>Hexabase \u304c vCluster \u306e OIDC \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u3057\u3066\u6a5f\u80fd</li> <li>Kyverno \u30dd\u30ea\u30b7\u30fc\u9069\u7528</li> <li>\u30c6\u30ca\u30f3\u30c8\u9593\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u96e2</li> </ul>"},{"location":"ja/concept/core-concepts/#_10","title":"\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3","text":"<ul> <li>\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306e\u6c34\u5e73\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u30ad\u30e5\u30fc\u30d9\u30fc\u30b9\u306e\u975e\u540c\u671f\u51e6\u7406</li> <li>\u30b9\u30c6\u30fc\u30c8\u30ec\u30b9 API \u8a2d\u8a08</li> <li>Redis \u30ad\u30e3\u30c3\u30b7\u30e5\u30ec\u30a4\u30e4\u30fc</li> </ul>"},{"location":"ja/concept/core-concepts/#_11","title":"\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3","text":"<ul> <li>Prometheus \u30e1\u30c8\u30ea\u30af\u30b9\u53ce\u96c6</li> <li>Loki \u306b\u3088\u308b\u96c6\u4e2d\u30ed\u30b0</li> <li>\u4e8b\u524d\u69cb\u7bc9\u6e08\u307f Grafana \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9</li> <li>\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u8ffd\u8de1</li> </ul>"},{"location":"ja/concept/core-concepts/#8","title":"8. \u307e\u3068\u3081","text":"<p>Hexabase AI \u306f\u3001\u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u62bd\u8c61\u5316\u3001\u5f37\u529b\u306a\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u306e\u904b\u7528\u30c4\u30fc\u30eb\u3092\u901a\u3058\u3066 Kubernetes \u30a2\u30af\u30bb\u30b9\u3092\u6c11\u4e3b\u5316\u3057\u307e\u3059\u3002K3s \u3068 vCluster \u3092\u6d3b\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u500b\u4eba\u958b\u767a\u8005\u304b\u3089\u5927\u898f\u6a21\u7d44\u7e54\u307e\u3067\u5bfe\u5fdc\u3059\u308b\u672c\u756a\u74b0\u5883\u5bfe\u5fdc\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3057\u3001\u30cd\u30a4\u30c6\u30a3\u30d6 Kubernetes \u306e\u67d4\u8edf\u6027\u3068\u30d1\u30ef\u30fc\u3092\u7dad\u6301\u3057\u307e\u3059\u3002</p> <p>\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306e\u6027\u8cea\u306b\u3088\u308a\u3001\u900f\u660e\u6027\u3001\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u4e3b\u5c0e\u306e\u30a4\u30ce\u30d9\u30fc\u30b7\u30e7\u30f3\u3001\u7279\u5b9a\u8981\u4ef6\u306b\u5bfe\u3059\u308b\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u80fd\u529b\u304c\u4fdd\u8a3c\u3055\u308c\u307e\u3059\u3002\u30b7\u30f3\u30d7\u30eb\u306a Helm \u30d9\u30fc\u30b9\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3068\u5305\u62ec\u7684\u306a\u76e3\u8996\u306b\u3088\u308a\u3001Hexabase AI \u306f\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306a Kubernetes \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u65b0\u3057\u3044\u6a19\u6e96\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/concept/multi-tenancy/","title":"\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc","text":""},{"location":"ja/concept/multi-tenancy/#_2","title":"\u6982\u8981","text":"<p>HXB \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306f\u3001\u7d44\u7e54\u304c\u7570\u306a\u308b\u30c1\u30fc\u30e0\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3001\u307e\u305f\u306f\u9867\u5ba2\u9593\u3067\u53b3\u683c\u306a\u5206\u96e2\u3092\u7dad\u6301\u3057\u306a\u304c\u3089\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3092\u5b89\u5168\u306b\u5171\u6709\u3067\u304d\u308b\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u306e\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/concept/multi-tenancy/#_3","title":"\u4e3b\u8981\u6982\u5ff5","text":""},{"location":"ja/concept/multi-tenancy/#_4","title":"\u30c6\u30ca\u30f3\u30c8\u5206\u96e2","text":"<p>\u5404\u30c6\u30ca\u30f3\u30c8\u306f\u4ee5\u4e0b\u3092\u542b\u3080\u72ec\u81ea\u306e\u5206\u96e2\u3055\u308c\u305f\u74b0\u5883\u5185\u3067\u52d5\u4f5c\u3057\u307e\u3059\uff1a</p> <ul> <li>\u5c02\u7528 namespace</li> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3068\u5236\u9650</li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5883\u754c</li> <li>RBAC \u30dd\u30ea\u30b7\u30fc</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_5","title":"\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406","text":"<p>HXB \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u306b\u306f\u4ee5\u4e0b\u304c\u542b\u307e\u308c\u307e\u3059\uff1a</p> <ul> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf: \u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306e CPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u5236\u9650</li> <li>\u512a\u5148\u5ea6\u30af\u30e9\u30b9: \u516c\u5e73\u306a\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u306e\u4fdd\u8a3c</li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u96e2: \u30c6\u30ca\u30f3\u30c8\u56fa\u6709\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc</li> <li>\u30b9\u30c8\u30ec\u30fc\u30b8\u5206\u96e2: \u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306e\u5c02\u7528\u6c38\u7d9a\u30dc\u30ea\u30e5\u30fc\u30e0</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_6","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"ja/concept/multi-tenancy/#namespace","title":"Namespace \u30d9\u30fc\u30b9\u306e\u5206\u96e2","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: tenant-production\n  labels:\n    tenant: production\n    environment: prod\n</code></pre>"},{"location":"ja/concept/multi-tenancy/#_7","title":"\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: tenant-quota\nspec:\n  hard:\n    requests.cpu: \"100\"\n    requests.memory: \"200Gi\"\n    persistentvolumeclaims: \"10\"\n</code></pre>"},{"location":"ja/concept/multi-tenancy/#_8","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8003\u616e\u4e8b\u9805","text":""},{"location":"ja/concept/multi-tenancy/#rbac","title":"RBAC \u7d71\u5408","text":"<p>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u306f Kubernetes RBAC \u3092\u6d3b\u7528\u3057\u3066\u4ee5\u4e0b\u3092\u5b9f\u73fe\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30c6\u30ca\u30f3\u30c8\u56fa\u6709\u30ed\u30fc\u30eb\u306e\u5b9a\u7fa9</li> <li>\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u306e\u7ba1\u7406</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u306e\u9069\u7528</li> <li>\u30a2\u30af\u30bb\u30b9\u3068\u64cd\u4f5c\u306e\u76e3\u67fb</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_9","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: tenant-isolation\nspec:\n  podSelector:\n    matchLabels:\n      tenant: production\n  policyTypes:\n    - Ingress\n    - Egress\n</code></pre>"},{"location":"ja/concept/multi-tenancy/#_10","title":"\u5b9f\u88c5\u30ac\u30a4\u30c9","text":""},{"location":"ja/concept/multi-tenancy/#_11","title":"\u65b0\u3057\u3044\u30c6\u30ca\u30f3\u30c8\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ol> <li>Namespace \u306e\u4f5c\u6210</li> </ol> <pre><code>kubectl create namespace tenant-name\n</code></pre> <ol> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u306e\u9069\u7528</li> </ol> <pre><code>kubectl apply -f tenant-quota.yaml\n</code></pre> <ol> <li>RBAC \u306e\u8a2d\u5b9a</li> </ol> <pre><code>kubectl apply -f tenant-rbac.yaml\n</code></pre> <ol> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u306e\u8a2d\u5b9a <pre><code>kubectl apply -f tenant-network-policy.yaml\n</code></pre></li> </ol>"},{"location":"ja/concept/multi-tenancy/#_12","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"ja/concept/multi-tenancy/#_13","title":"\u30c6\u30ca\u30f3\u30c8\u30aa\u30f3\u30dc\u30fc\u30c7\u30a3\u30f3\u30b0","text":"<ul> <li>\u30c6\u30ca\u30f3\u30c8\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u306e\u81ea\u52d5\u5316</li> <li>\u4e00\u8cab\u6027\u306e\u305f\u3081\u306e\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u4f7f\u7528</li> <li>\u627f\u8a8d\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306e\u5b9f\u88c5</li> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u306e\u76e3\u8996</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_14","title":"\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406","text":"<ul> <li>\u9069\u5207\u306a\u30af\u30a9\u30fc\u30bf\u306e\u8a2d\u5b9a</li> <li>\u4f7f\u7528\u7387\u306e\u76e3\u8996</li> <li>\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u306e\u5b9f\u88c5</li> <li>\u5b9a\u671f\u7684\u306a\u5bb9\u91cf\u8a08\u753b</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_15","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":"<ul> <li>\u5b9a\u671f\u7684\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u76e3\u67fb</li> <li>\u6700\u5c0f\u6a29\u9650\u539f\u5247\u306e\u5b9f\u88c5</li> <li>\u7570\u5e38\u306e\u76e3\u8996</li> <li>\u30dd\u30ea\u30b7\u30fc\u306e\u6700\u65b0\u7dad\u6301</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_16","title":"\u76e3\u8996\u3068\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3","text":""},{"location":"ja/concept/multi-tenancy/#_17","title":"\u30c6\u30ca\u30f3\u30c8\u30e1\u30c8\u30ea\u30af\u30b9","text":"<p>\u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306e\u4e3b\u8981\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u76e3\u8996\uff1a</p> <ul> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387</li> <li>API \u30ea\u30af\u30a8\u30b9\u30c8\u7387</li> <li>\u30a8\u30e9\u30fc\u7387</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30e1\u30c8\u30ea\u30af\u30b9</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_18","title":"\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u3092\u8868\u793a\u3059\u308b\u30c6\u30ca\u30f3\u30c8\u56fa\u6709\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u3092\u4f5c\u6210\uff1a</p> <ul> <li>\u30ea\u30bd\u30fc\u30b9\u6d88\u8cbb</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5065\u5168\u6027</li> <li>\u30b3\u30b9\u30c8\u914d\u5206</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u72b6\u6cc1</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_19","title":"\u30b3\u30b9\u30c8\u7ba1\u7406","text":""},{"location":"ja/concept/multi-tenancy/#_20","title":"\u30ea\u30bd\u30fc\u30b9\u8ffd\u8de1","text":"<ul> <li>\u30c6\u30ca\u30f3\u30c8\u3054\u3068\u306e\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u8ffd\u8de1</li> <li>\u30c1\u30e3\u30fc\u30b8\u30d0\u30c3\u30af/\u30b7\u30e7\u30fc\u30d0\u30c3\u30af\u306e\u5b9f\u88c5</li> <li>\u4f7f\u7528\u91cf\u30ec\u30dd\u30fc\u30c8\u306e\u751f\u6210</li> <li>\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u306e\u6700\u9069\u5316</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_21","title":"\u30b3\u30b9\u30c8\u6700\u9069\u5316","text":"<ul> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u306e\u9069\u6b63\u30b5\u30a4\u30b8\u30f3\u30b0</li> <li>\u30ea\u30bd\u30fc\u30b9\u30dd\u30ea\u30b7\u30fc\u306e\u5b9f\u88c5</li> <li>\u9069\u5207\u306a\u5834\u6240\u3067\u306e\u30b9\u30dd\u30c3\u30c8\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u4f7f\u7528</li> <li>\u5b9a\u671f\u7684\u306a\u30b3\u30b9\u30c8\u30ec\u30d3\u30e5\u30fc</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_22","title":"\u9ad8\u5ea6\u306a\u6a5f\u80fd","text":""},{"location":"ja/concept/multi-tenancy/#_23","title":"\u52d5\u7684\u30c6\u30ca\u30f3\u30c8\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0","text":"<p>\u4ee5\u4e0b\u3092\u4f7f\u7528\u3057\u305f\u30c6\u30ca\u30f3\u30c8\u4f5c\u6210\u306e\u81ea\u52d5\u5316\uff1a</p> <ul> <li>GitOps \u30ef\u30fc\u30af\u30d5\u30ed\u30fc</li> <li>API \u99c6\u52d5\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0</li> <li>\u30bb\u30eb\u30d5\u30b5\u30fc\u30d3\u30b9\u30dd\u30fc\u30bf\u30eb</li> <li>ID \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u306e\u7d71\u5408</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_24","title":"\u30c6\u30ca\u30f3\u30c8\u9593\u901a\u4fe1","text":"<p>\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u5236\u5fa1\u3055\u308c\u305f\u901a\u4fe1\u3092\u6709\u52b9\u5316\uff1a</p> <ul> <li>\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5\u7d71\u5408</li> <li>API \u30b2\u30fc\u30c8\u30a6\u30a7\u30a4</li> <li>\u5171\u6709\u30b5\u30fc\u30d3\u30b9</li> <li>\u76e3\u67fb\u8a3c\u8de1</li> </ul>"},{"location":"ja/concept/multi-tenancy/#_25","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/concept/multi-tenancy/#_26","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":"<ol> <li> <p>\u30ea\u30bd\u30fc\u30b9\u67af\u6e07</p> </li> <li> <p>\u30af\u30a9\u30fc\u30bf\u5236\u9650\u306e\u78ba\u8a8d</p> </li> <li>\u30ea\u30bd\u30fc\u30b9\u30ea\u30af\u30a8\u30b9\u30c8\u306e\u30ec\u30d3\u30e5\u30fc</li> <li> <p>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u6700\u9069\u5316</p> </li> <li> <p>\u30a2\u30af\u30bb\u30b9\u62d2\u5426</p> </li> <li> <p>RBAC \u30dd\u30ea\u30b7\u30fc\u306e\u691c\u8a3c</p> </li> <li>\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u306e\u78ba\u8a8d</li> <li> <p>\u76e3\u67fb\u30ed\u30b0\u306e\u30ec\u30d3\u30e5\u30fc</p> </li> <li> <p>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u63a5\u7d9a</p> </li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u306e\u691c\u8a3c</li> <li>DNS \u89e3\u6c7a\u306e\u78ba\u8a8d</li> <li>\u30b5\u30fc\u30d3\u30b9\u691c\u51fa\u306e\u691c\u8a3c</li> </ol>"},{"location":"ja/concept/multi-tenancy/#_27","title":"\u95a2\u9023\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>\u6280\u8853\u30b9\u30bf\u30c3\u30af</li> <li>RBAC: \u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u306f\u72ec\u81ea\u306e\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u304c\u3042\u308a\u3001\u304d\u3081\u7d30\u304b\u3044\u6a29\u9650\u8a2d\u5b9a\u304c\u53ef\u80fd\u3067\u3059\u3002\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001Kubernetes RBAC \u6982\u8981 \u304a\u3088\u3073 \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u5236\u9650\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf: \u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u306f\u72ec\u81ea\u306e\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u3042\u308a\u30011\u3064\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u304c\u4ed6\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u3053\u3068\u3092\u9632\u304e\u307e\u3059\u3002</li> </ul>"},{"location":"ja/concept/overview/","title":"Hexabase AI \u6982\u8981","text":"<p>Hexabase AI \u3078\u3088\u3046\u3053\u305d - AI \u6a5f\u80fd\u3092\u5185\u8535\u3057\u305f\u6b21\u4e16\u4ee3\u306e Kubernetes-as-a-Service \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u3059\u3002</p>"},{"location":"ja/concept/overview/#hexabase-ai_1","title":"Hexabase AI \u3068\u306f\uff1f","text":"<p>Hexabase AI \u306f\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30c7\u30d7\u30ed\u30a4\u3068\u7ba1\u7406\u3092\u7c21\u7d20\u5316\u3057\u306a\u304c\u3089\u3001\u5f37\u529b\u306a AI \u99c6\u52d5\u306e\u81ea\u52d5\u5316\u6a5f\u80fd\u3092\u63d0\u4f9b\u3059\u308b\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8 Kubernetes \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3067\u3059\u3002K3s \u3068 vCluster \u6280\u8853\u306b\u57fa\u3065\u3044\u3066\u69cb\u7bc9\u3055\u308c\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3092\u5099\u3048\u305f\u5206\u96e2\u3055\u308c\u305f Kubernetes \u74b0\u5883\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/concept/overview/#_1","title":"\u4e3b\u306a\u6a5f\u80fd","text":""},{"location":"ja/concept/overview/#kubernetes","title":"\ud83d\ude80 \u5373\u5ea7\u306b\u5229\u7528\u53ef\u80fd\u306a Kubernetes \u74b0\u5883","text":"<ul> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9: \u6570\u79d2\u3067\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u308b\u5206\u96e2\u3055\u308c\u305f vCluster \u74b0\u5883</li> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8: \u30cd\u30fc\u30e0\u30b9\u30da\u30fc\u30b9\u30d9\u30fc\u30b9\u306e\u30ea\u30bd\u30fc\u30b9\u7d44\u7e54\u5316</li> <li>\u30aa\u30fc\u30c8\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0: \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u306a\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406</li> </ul>"},{"location":"ja/concept/overview/#ai","title":"\ud83e\udd16 AI \u3092\u6d3b\u7528\u3057\u305f\u904b\u7528","text":"<ul> <li>\u30b9\u30de\u30fc\u30c8\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0: AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u304c\u554f\u984c\u3092\u5206\u6790\u3057\u3066\u4fee\u6b63</li> <li>\u30b3\u30fc\u30c9\u751f\u6210: Kubernetes \u30de\u30cb\u30d5\u30a7\u30b9\u30c8\u3068\u8a2d\u5b9a\u3092\u751f\u6210</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316: AI \u99c6\u52d5\u306e\u30ea\u30bd\u30fc\u30b9\u63a8\u5968</li> </ul>"},{"location":"ja/concept/overview/#_2","title":"\ud83d\udd27 \u958b\u767a\u8005\u30d5\u30ec\u30f3\u30c9\u30ea\u30fc","text":"<ul> <li>\u30b7\u30f3\u30d7\u30eb\u306a CLI: \u76f4\u611f\u7684\u306a\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</li> <li>Web \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9: \u30d3\u30b8\u30e5\u30a2\u30eb\u7ba1\u7406\u306e\u305f\u3081\u306e\u30e2\u30c0\u30f3\u306a UI</li> <li>API \u30d5\u30a1\u30fc\u30b9\u30c8: \u5b8c\u5168\u306a REST \u304a\u3088\u3073 WebSocket API</li> </ul>"},{"location":"ja/concept/overview/#_3","title":"\ud83c\udfd7\ufe0f \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u5bfe\u5fdc","text":"<ul> <li>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u306e\u5b8c\u5168\u306a\u5206\u96e2</li> <li>RBAC: \u304d\u3081\u7d30\u304b\u3044\u30a2\u30af\u30bb\u30b9\u5236\u5fa1</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9: SOC2\u3001HIPAA\u3001GDPR \u5bfe\u5fdc</li> <li>\u9ad8\u53ef\u7528\u6027: \u7d44\u307f\u8fbc\u307f\u306e\u5197\u9577\u6027\u3068\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc</li> </ul>"},{"location":"ja/concept/overview/#_4","title":"\ud83d\udcbc \u7d44\u307f\u8fbc\u307f\u30b5\u30fc\u30d3\u30b9","text":"<ul> <li>CronJobs: \u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3055\u308c\u305f\u30bf\u30b9\u30af\u7ba1\u7406</li> <li>\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570: Knative \u306b\u3088\u308b\u30a4\u30d9\u30f3\u30c8\u99c6\u52d5\u578b\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\uff06\u30ea\u30b9\u30c8\u30a2: \u81ea\u52d5\u30c7\u30fc\u30bf\u4fdd\u8b77</li> <li>\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0: \u7d71\u5408\u3055\u308c\u305f Prometheus \u3068 Grafana</li> </ul>"},{"location":"ja/concept/overview/#_5","title":"\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9","text":""},{"location":"ja/concept/overview/#_6","title":"\u958b\u767a\u30c1\u30fc\u30e0","text":"<ul> <li>\u5206\u96e2\u3055\u308c\u305f\u958b\u767a\u74b0\u5883\u3092\u30b9\u30d4\u30f3\u30a2\u30c3\u30d7</li> <li>\u672c\u756a\u74b0\u5883\u306b\u8fd1\u3044\u8a2d\u5b9a\u3067\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c6\u30b9\u30c8</li> <li>\u7d44\u307f\u8fbc\u307f\u306e\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3067\u5171\u540c\u4f5c\u696d</li> </ul>"},{"location":"ja/concept/overview/#devops","title":"DevOps \u30a8\u30f3\u30b8\u30cb\u30a2","text":"<ul> <li>\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u81ea\u52d5\u5316</li> <li>\u8907\u6570\u306e\u74b0\u5883\u3092\u4e00\u7b87\u6240\u304b\u3089\u7ba1\u7406</li> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3092\u76e3\u8996\u3057\u3066\u6700\u9069\u5316</li> </ul>"},{"location":"ja/concept/overview/#_7","title":"\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba","text":"<ul> <li>\u30c1\u30fc\u30e0\u306b\u30bb\u30eb\u30d5\u30b5\u30fc\u30d3\u30b9 Kubernetes \u3092\u63d0\u4f9b</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u57fa\u6e96\u3092\u7dad\u6301</li> <li>\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30b3\u30b9\u30c8\u3092\u524a\u6e1b</li> </ul>"},{"location":"ja/concept/overview/#aiml","title":"AI/ML \u30a8\u30f3\u30b8\u30cb\u30a2","text":"<ul> <li>ML \u30e2\u30c7\u30eb\u3092\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570\u3068\u3057\u3066\u30c7\u30d7\u30ed\u30a4</li> <li>CronJobs \u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b8\u30e7\u30d6\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb</li> <li>\u81ea\u52d5\u904b\u7528\u306e\u305f\u3081\u306b AI \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u3092\u4f7f\u7528</li> </ul>"},{"location":"ja/concept/overview/#_8","title":"\u4ed5\u7d44\u307f","text":"<ol> <li>\u7d44\u7e54\u306e\u4f5c\u6210: \u8acb\u6c42\u3068\u30c1\u30fc\u30e0\u30e6\u30cb\u30c3\u30c8\u3092\u8a2d\u5b9a</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0: \u5206\u96e2\u3055\u308c\u305f Kubernetes \u74b0\u5883\u3092\u53d6\u5f97</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30c7\u30d7\u30ed\u30a4: kubectl\u3001UI\u3001\u307e\u305f\u306f API \u3092\u4f7f\u7528</li> <li>\u76e3\u8996\u3068\u30b9\u30b1\u30fc\u30eb: \u7d44\u307f\u8fbc\u307f\u306e\u53ef\u89b3\u6e2c\u6027\u3068\u30aa\u30fc\u30c8\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u5171\u540c\u4f5c\u696d: \u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u306e\u30a2\u30af\u30bb\u30b9\u3067\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3092\u62db\u5f85</li> </ol>"},{"location":"ja/concept/overview/#_9","title":"\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \u30e6\u30fc\u30b6\u30fc\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9    \u2502\n\u2502  (Web UI / CLI)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Hexabase API      \u2502\n\u2502  (\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \u30db\u30b9\u30c8 K3s \u30af\u30e9\u30b9\u30bf\u30fc  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  vCluster       \u2502\n\u2502                     \u2502     \u2502  (\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3    \u2502\n\u2502 (\u30b9\u30c8\u30ec\u30fc\u30b8\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/concept/overview/#_10","title":"\u6599\u91d1\u30d7\u30e9\u30f3","text":""},{"location":"ja/concept/overview/#_11","title":"\u30b9\u30bf\u30fc\u30bf\u30fc","text":"<ul> <li>1 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9</li> <li>2 CPU\u30014GB RAM</li> <li>\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u30b5\u30dd\u30fc\u30c8</li> <li>\u500b\u4eba\u306b\u6700\u9069</li> </ul>"},{"location":"ja/concept/overview/#_12","title":"\u30d7\u30ed","text":"<ul> <li>5 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9</li> <li>8 CPU\u300132GB RAM</li> <li>\u30e1\u30fc\u30eb\u30b5\u30dd\u30fc\u30c8</li> <li>\u5c0f\u898f\u6a21\u30c1\u30fc\u30e0\u306b\u6700\u9069</li> </ul>"},{"location":"ja/concept/overview/#_13","title":"\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba","text":"<ul> <li>\u7121\u5236\u9650\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9</li> <li>\u30ab\u30b9\u30bf\u30e0\u30ea\u30bd\u30fc\u30b9</li> <li>24/7 \u30b5\u30dd\u30fc\u30c8</li> <li>SLA \u4fdd\u8a3c</li> </ul>"},{"location":"ja/concept/overview/#_14","title":"\u4ed6\u306e\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3068\u306e\u6bd4\u8f03","text":"\u6a5f\u80fd Hexabase AI \u5f93\u6765\u306e K8s \u305d\u306e\u4ed6\u306e KaaS \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u9593 &lt; 1 \u5206 \u6570\u6642\u9593/\u6570\u65e5 10-30 \u5206 \u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc \u7d44\u307f\u8fbc\u307f \u8907\u96d1\u306a\u8a2d\u5b9a \u5236\u9650\u3042\u308a AI \u904b\u7528 \u2705 \u274c \u274c \u30b3\u30b9\u30c8 \u7121\u6599\u301c \u9ad8\u3044\u56fa\u5b9a\u8cbb \u5909\u52d5 \u5b66\u7fd2\u66f2\u7dda \u4f4e\u3044 \u9ad8\u3044 \u4e2d\u7a0b\u5ea6"},{"location":"ja/concept/overview/#_15","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>\u30b7\u30b9\u30c6\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> <li>AIOps \u30a8\u30f3\u30b8\u30f3</li> <li>\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u53c2\u52a0</li> </ul>"},{"location":"ja/concept/overview/#_16","title":"\u3054\u8cea\u554f\u306f\uff1f","text":"<ul> <li>\u55b6\u696d: sales@hexabase.com</li> <li>\u30b5\u30dd\u30fc\u30c8: support@hexabase.com</li> <li>\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8: docs.hexabase.ai</li> <li>\u30b9\u30c6\u30fc\u30bf\u30b9: status.hexabase.ai</li> </ul> <p>Hexabase AI - AI \u306b\u3088\u3063\u3066\u5f37\u5316\u3055\u308c\u305f\u3001\u30b7\u30f3\u30d7\u30eb\u306a Kubernetes \ud83d\ude80</p>"},{"location":"ja/concept/technology-stack/","title":"\u6280\u8853\u30b9\u30bf\u30c3\u30af","text":""},{"location":"ja/concept/technology-stack/#_2","title":"\u6982\u8981","text":"<p>HXB \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306f\u3001\u30af\u30e9\u30b9\u6700\u9ad8\u306e\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u30c6\u30af\u30ce\u30ed\u30b8\u30fc\u3068\u9769\u65b0\u7684\u306a\u30ab\u30b9\u30bf\u30e0\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u3001AI \u3092\u6d3b\u7528\u3057\u305f\u904b\u7528\u3068\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u7ba1\u7406\u306e\u305f\u3081\u306e\u5305\u62ec\u7684\u306a\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u3001\u73fe\u4ee3\u7684\u3067\u30af\u30e9\u30a6\u30c9\u30cd\u30a4\u30c6\u30a3\u30d6\u306a\u6280\u8853\u30b9\u30bf\u30c3\u30af\u4e0a\u306b\u69cb\u7bc9\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/concept/technology-stack/#_3","title":"\u30b3\u30a2\u6280\u8853","text":""},{"location":"ja/concept/technology-stack/#_4","title":"\u30b3\u30f3\u30c6\u30ca\u30aa\u30fc\u30b1\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3","text":""},{"location":"ja/concept/technology-stack/#kubernetes","title":"Kubernetes","text":"<ul> <li>\u30d0\u30fc\u30b8\u30e7\u30f3: 1.28+</li> <li>\u30c7\u30a3\u30b9\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3: EKS\u3001GKE\u3001AKS\u3001\u30d0\u30cb\u30e9 Kubernetes \u3068\u4e92\u63db</li> <li>\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8:</li> <li>\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\uff08API \u30b5\u30fc\u30d0\u30fc\u3001\u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u3001\u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\uff09</li> <li>\u30c7\u30fc\u30bf\u30d7\u30ec\u30fc\u30f3\uff08kubelet\u3001kube-proxy\uff09</li> <li>\u5206\u6563\u72b6\u614b\u7ba1\u7406\u306e\u305f\u3081\u306e etcd</li> </ul>"},{"location":"ja/concept/technology-stack/#_5","title":"\u30b3\u30f3\u30c6\u30ca\u30e9\u30f3\u30bf\u30a4\u30e0","text":""},{"location":"ja/concept/technology-stack/#containerd","title":"containerd","text":"<ul> <li>\u9ad8\u6027\u80fd\u30b3\u30f3\u30c6\u30ca\u30e9\u30f3\u30bf\u30a4\u30e0</li> <li>OCI \u6e96\u62e0</li> <li>Kubernetes CRI \u3068\u306e\u7d71\u5408</li> </ul>"},{"location":"ja/concept/technology-stack/#docker","title":"Docker","text":"<ul> <li>\u958b\u767a\u74b0\u5883\u30b5\u30dd\u30fc\u30c8</li> <li>\u30a4\u30e1\u30fc\u30b8\u30d3\u30eb\u30c9\u3068\u7ba1\u7406</li> <li>\u30ec\u30b8\u30b9\u30c8\u30ea\u7d71\u5408</li> </ul>"},{"location":"ja/concept/technology-stack/#_6","title":"\u30b5\u30fc\u30d3\u30b9\u30e1\u30c3\u30b7\u30e5","text":""},{"location":"ja/concept/technology-stack/#istio","title":"Istio","text":"<ul> <li>\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u7ba1\u7406</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc</li> <li>\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3</li> <li>\u30b5\u30fc\u30ad\u30c3\u30c8\u30d6\u30ec\u30fc\u30ab\u30fc\u3068\u30ea\u30c8\u30e9\u30a4\u30ed\u30b8\u30c3\u30af</li> </ul>"},{"location":"ja/concept/technology-stack/#ingress","title":"Ingress \u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc","text":""},{"location":"ja/concept/technology-stack/#nginx-ingress-controller","title":"NGINX Ingress Controller","text":"<ul> <li>HTTP/HTTPS \u30eb\u30fc\u30c6\u30a3\u30f3\u30b0</li> <li>SSL/TLS \u7d42\u7aef</li> <li>\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0</li> <li>WebSocket \u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/concept/technology-stack/#traefik","title":"Traefik","text":"<ul> <li>\u52d5\u7684\u8a2d\u5b9a</li> <li>Let's Encrypt \u7d71\u5408</li> <li>\u30df\u30c9\u30eb\u30a6\u30a7\u30a2\u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/concept/technology-stack/#_7","title":"\u30b9\u30c8\u30ec\u30fc\u30b8","text":""},{"location":"ja/concept/technology-stack/#_8","title":"\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8","text":"<ul> <li>CSI \u30c9\u30e9\u30a4\u30d0\u30fc: \u4e3b\u8981\u30af\u30e9\u30a6\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u30b5\u30dd\u30fc\u30c8</li> <li>Rook/Ceph: \u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u5206\u6563\u30b9\u30c8\u30ec\u30fc\u30b8</li> <li>MinIO: S3 \u4e92\u63db\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30b9\u30c8\u30ec\u30fc\u30b8</li> </ul>"},{"location":"ja/concept/technology-stack/#_9","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9","text":"<ul> <li>PostgreSQL: \u30d7\u30e9\u30a4\u30de\u30ea\u30ea\u30ec\u30fc\u30b7\u30e7\u30ca\u30eb\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9</li> <li>Redis: \u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3068\u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406</li> <li>ClickHouse: \u30a2\u30ca\u30ea\u30c6\u30a3\u30af\u30b9\u3068\u6642\u7cfb\u5217\u30c7\u30fc\u30bf</li> </ul>"},{"location":"ja/concept/technology-stack/#_10","title":"\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u30b9\u30bf\u30c3\u30af","text":""},{"location":"ja/concept/technology-stack/#_11","title":"\u30e1\u30c8\u30ea\u30af\u30b9","text":"<ul> <li>Prometheus: \u30e1\u30c8\u30ea\u30af\u30b9\u53ce\u96c6\u3068\u4fdd\u5b58</li> <li>Grafana: \u53ef\u8996\u5316\u3068\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9</li> <li>AlertManager: \u30a2\u30e9\u30fc\u30c8\u30eb\u30fc\u30c6\u30a3\u30f3\u30b0\u3068\u7ba1\u7406</li> </ul>"},{"location":"ja/concept/technology-stack/#_12","title":"\u30ed\u30b0","text":"<ul> <li>Fluentd/Fluent Bit: \u30ed\u30b0\u53ce\u96c6\u3068\u8ee2\u9001</li> <li>Elasticsearch: \u30ed\u30b0\u4fdd\u5b58\u3068\u691c\u7d22</li> <li>Kibana: \u30ed\u30b0\u53ef\u8996\u5316\u3068\u5206\u6790</li> </ul>"},{"location":"ja/concept/technology-stack/#_13","title":"\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0","text":"<ul> <li>OpenTelemetry: \u5206\u6563\u30c8\u30ec\u30fc\u30b7\u30f3\u30b0</li> <li>Jaeger: \u30c8\u30ec\u30fc\u30b9\u4fdd\u5b58\u3068\u53ef\u8996\u5316</li> </ul>"},{"location":"ja/concept/technology-stack/#cicd-gitops","title":"CI/CD \u3068 GitOps","text":""},{"location":"ja/concept/technology-stack/#argocd","title":"ArgoCD","text":"<ul> <li>GitOps \u7d99\u7d9a\u7684\u30c7\u30ea\u30d0\u30ea\u30fc</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u540c\u671f</li> <li>\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30bf\u30fc\u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/concept/technology-stack/#tekton","title":"Tekton","text":"<ul> <li>\u30af\u30e9\u30a6\u30c9\u30cd\u30a4\u30c6\u30a3\u30d6 CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3</li> <li>Kubernetes \u30cd\u30a4\u30c6\u30a3\u30d6\u30ef\u30fc\u30af\u30d5\u30ed\u30fc</li> <li>\u62e1\u5f35\u53ef\u80fd\u306a\u30bf\u30b9\u30af\u30e9\u30a4\u30d6\u30e9\u30ea</li> </ul>"},{"location":"ja/concept/technology-stack/#_14","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3","text":""},{"location":"ja/concept/technology-stack/#_15","title":"\u30dd\u30ea\u30b7\u30fc\u7ba1\u7406","text":"<ul> <li>Open Policy Agent (OPA): \u30dd\u30ea\u30b7\u30fc\u30a2\u30ba\u30b3\u30fc\u30c9</li> <li>Gatekeeper: Kubernetes admission controller</li> <li>Falco: \u30e9\u30f3\u30bf\u30a4\u30e0\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u76e3\u8996</li> </ul>"},{"location":"ja/concept/technology-stack/#_16","title":"\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u7ba1\u7406","text":"<ul> <li>Kubernetes Secrets: \u30cd\u30a4\u30c6\u30a3\u30d6\u30b7\u30fc\u30af\u30ec\u30c3\u30c8\u4fdd\u5b58</li> <li>Sealed Secrets: Git \u5185\u306e\u6697\u53f7\u5316\u30b7\u30fc\u30af\u30ec\u30c3\u30c8</li> <li>External Secrets Operator: \u5916\u90e8 vault \u3068\u306e\u7d71\u5408</li> </ul>"},{"location":"ja/concept/technology-stack/#aiml","title":"AI/ML \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3","text":""},{"location":"ja/concept/technology-stack/#_17","title":"\u30e2\u30c7\u30eb\u30b5\u30fc\u30d3\u30f3\u30b0","text":"<ul> <li>KServe: \u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u63a8\u8ad6</li> <li>Seldon Core: ML \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0</li> <li>NVIDIA Triton: \u9ad8\u6027\u80fd\u63a8\u8ad6</li> </ul>"},{"location":"ja/concept/technology-stack/#llm","title":"LLM \u7d71\u5408","text":"<ul> <li>LangChain: LLM \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af</li> <li>\u30d9\u30af\u30bf\u30fc\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9: Chroma\u3001Pinecone\u3001Weaviate</li> <li>\u30e2\u30c7\u30eb\u30ec\u30b8\u30b9\u30c8\u30ea: MLflow\u3001Kubeflow</li> </ul>"},{"location":"ja/concept/technology-stack/#_18","title":"\u958b\u767a\u30c4\u30fc\u30eb","text":""},{"location":"ja/concept/technology-stack/#_19","title":"\u8a00\u8a9e\u3068\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af","text":"<ul> <li>Go: \u30b3\u30a2\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8</li> <li>Python: AI/ML \u30b5\u30fc\u30d3\u30b9\u3068\u30b9\u30af\u30ea\u30d7\u30c8</li> <li>TypeScript/React: Web UI</li> <li>Rust: \u9ad8\u6027\u80fd\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8</li> </ul>"},{"location":"ja/concept/technology-stack/#api","title":"API","text":"<ul> <li>gRPC: \u5185\u90e8\u30b5\u30fc\u30d3\u30b9\u901a\u4fe1</li> <li>GraphQL: \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9 API \u30b2\u30fc\u30c8\u30a6\u30a7\u30a4</li> <li>REST: \u5916\u90e8\u7d71\u5408</li> </ul>"},{"location":"ja/concept/technology-stack/#_20","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u5c64","text":""},{"location":"ja/concept/technology-stack/#_21","title":"\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u5c64","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Cloud Providers             \u2502\n\u2502    (AWS, GCP, Azure, On-Prem)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Kubernetes Clusters         \u2502\n\u2502    (Multi-region, Multi-cloud)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/concept/technology-stack/#_22","title":"\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5c64","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Service Mesh (Istio)          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Observability    \u2502    Security    \u2502\n\u2502 (Prometheus, ELK)  \u2502  (OPA, Falco)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     CI/CD &amp; GitOps (ArgoCD)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/concept/technology-stack/#_23","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c64","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        HXB Platform Services        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  AI Agents  \u2502  Functions  \u2502  APIs  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Workload Management &amp; Scaling    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/concept/technology-stack/#_24","title":"\u7d71\u5408\u30dd\u30a4\u30f3\u30c8","text":""},{"location":"ja/concept/technology-stack/#_25","title":"\u5916\u90e8\u30b5\u30fc\u30d3\u30b9","text":"<ul> <li>\u30af\u30e9\u30a6\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc API: AWS\u3001GCP\u3001Azure</li> <li>\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406: GitHub\u3001GitLab\u3001Bitbucket</li> <li>\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea: Docker Hub\u3001ECR\u3001GCR</li> <li>ID \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc: OIDC\u3001SAML\u3001LDAP</li> </ul>"},{"location":"ja/concept/technology-stack/#_26","title":"\u901a\u4fe1\u30d7\u30ed\u30c8\u30b3\u30eb","text":"<ul> <li>HTTP/HTTPS: \u5916\u90e8 API</li> <li>gRPC: \u5185\u90e8\u30b5\u30fc\u30d3\u30b9</li> <li>WebSocket: \u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u66f4\u65b0</li> <li>AMQP/Kafka: \u30a4\u30d9\u30f3\u30c8\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0</li> </ul>"},{"location":"ja/concept/technology-stack/#_27","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u7279\u6027","text":""},{"location":"ja/concept/technology-stack/#_28","title":"\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3","text":"<ul> <li>\u6c34\u5e73\u30dd\u30c3\u30c9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u5782\u76f4\u30dd\u30c3\u30c9\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u30af\u30e9\u30b9\u30bf\u30fc\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8</li> </ul>"},{"location":"ja/concept/technology-stack/#_29","title":"\u9ad8\u53ef\u7528\u6027","text":"<ul> <li>\u30de\u30eb\u30c1\u30de\u30b9\u30bf\u30fc\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3</li> <li>\u30af\u30ed\u30b9\u30be\u30fc\u30f3\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3</li> <li>\u81ea\u52d5\u30d5\u30a7\u30a4\u30eb\u30aa\u30fc\u30d0\u30fc</li> <li>\u707d\u5bb3\u5fa9\u65e7</li> </ul>"},{"location":"ja/concept/technology-stack/#_30","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":"<ul> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3068\u5236\u9650</li> <li>\u30dd\u30c3\u30c9\u512a\u5148\u5ea6\u3068\u30d7\u30ea\u30a8\u30f3\u30d7\u30b7\u30e7\u30f3</li> <li>\u30ce\u30fc\u30c9\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u3068\u30a2\u30f3\u30c1\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3</li> <li>\u30c8\u30dd\u30ed\u30b8\u30fc\u5bfe\u5fdc\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0</li> </ul>"},{"location":"ja/concept/technology-stack/#_31","title":"\u958b\u767a\u30ef\u30fc\u30af\u30d5\u30ed\u30fc","text":""},{"location":"ja/concept/technology-stack/#_32","title":"\u30ed\u30fc\u30ab\u30eb\u958b\u767a","text":"<pre><code># \u958b\u767a\u30c4\u30fc\u30eb\n- kubectl\n- Helm\n- Skaffold\n- Tilt\n</code></pre>"},{"location":"ja/concept/technology-stack/#_33","title":"\u30c6\u30b9\u30c8","text":"<ul> <li>\u30e6\u30cb\u30c3\u30c8\u30c6\u30b9\u30c8\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af</li> <li>\u7d71\u5408\u30c6\u30b9\u30c8</li> <li>\u30a8\u30f3\u30c9\u30c4\u30fc\u30a8\u30f3\u30c9\u30c6\u30b9\u30c8</li> <li>\u30ab\u30aa\u30b9\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0</li> </ul>"},{"location":"ja/concept/technology-stack/#_34","title":"\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8","text":"<ul> <li>\u30d6\u30eb\u30fc\u30b0\u30ea\u30fc\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8</li> <li>\u30ab\u30ca\u30ea\u30a2\u30ea\u30ea\u30fc\u30b9</li> <li>\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u30d5\u30e9\u30b0</li> <li>\u30d7\u30ed\u30b0\u30ec\u30c3\u30b7\u30d6\u30c7\u30ea\u30d0\u30ea\u30fc</li> </ul>"},{"location":"ja/concept/technology-stack/#_35","title":"\u30ed\u30fc\u30c9\u30de\u30c3\u30d7","text":""},{"location":"ja/concept/technology-stack/#_36","title":"\u4eca\u5f8c\u306e\u6280\u8853","text":"<ul> <li>WebAssembly: WASM \u30d9\u30fc\u30b9\u95a2\u6570</li> <li>eBPF: \u9ad8\u5ea6\u306a\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\u3068\u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3</li> <li>Crossplane: Infrastructure as Code</li> <li>Dapr: \u5206\u6563\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e9\u30f3\u30bf\u30a4\u30e0</li> </ul>"},{"location":"ja/concept/technology-stack/#_37","title":"\u95a2\u9023\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc: \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u8a2d\u8a08\u306e\u8a73\u7d30\u3002</li> <li>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc: HKS \u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u5206\u96e2\u3059\u308b\u65b9\u6cd5\u3092\u5b66\u7fd2\u3002</li> <li>\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u53c2\u52a0: \u30d8\u30eb\u30d7\u3092\u53d7\u3051\u3001\u4ed6\u306e\u30e6\u30fc\u30b6\u30fc\u3068\u3064\u306a\u304c\u308b\u3002</li> </ul>"},{"location":"ja/nodes/","title":"\u30ce\u30fc\u30c9","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Hexabase.AI\uff08HKS\uff09\u3067\u306e\u30ce\u30fc\u30c9\u7ba1\u7406\u306b\u95a2\u3059\u308b\u3059\u3079\u3066\u3092\u8aac\u660e\u3057\u307e\u3059\u3002\u30ce\u30fc\u30c9\u306f Kubernetes \u30af\u30e9\u30b9\u30bf\u30fc\u306e\u57fa\u672c\u7684\u306a\u30b3\u30f3\u30d4\u30e5\u30fc\u30c8\u5358\u4f4d\u3067\u3042\u308a\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u52d5\u4f5c\u3059\u308b\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/nodes/#_2","title":"\u3053\u3053\u3067\u898b\u3064\u3051\u3089\u308c\u308b\u3082\u306e","text":"<ul> <li>\u30ce\u30fc\u30c9\u30bf\u30a4\u30d7: \u7570\u306a\u308b\u30ce\u30fc\u30c9\u8a2d\u5b9a\u3068\u305d\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u7406\u89e3</li> <li>\u30ce\u30fc\u30c9\u7ba1\u7406: \u30af\u30e9\u30b9\u30bf\u30fc\u5185\u3067\u306e\u30ce\u30fc\u30c9\u306e\u8ffd\u52a0\u3001\u524a\u9664\u3001\u4fdd\u5b88</li> <li>\u30ce\u30fc\u30c9\u76e3\u8996: \u30ce\u30fc\u30c9\u30d8\u30eb\u30b9\u3001\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30e1\u30c8\u30ea\u30af\u30b9\u3001\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u306e\u8ffd\u8de1</li> <li>\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0: \u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u30dd\u30ea\u30b7\u30fc\u3068\u624b\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u624b\u9806</li> <li>\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0: \u4e00\u822c\u7684\u306a\u30ce\u30fc\u30c9\u554f\u984c\u3068\u305d\u306e\u89e3\u6c7a\u7b56</li> </ul>"},{"location":"ja/nodes/#_3","title":"\u4e3b\u8981\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9 vs \u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9</li> <li>\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3068\u30ce\u30fc\u30c9\u30b0\u30eb\u30fc\u30d7</li> <li>\u30ce\u30fc\u30c9\u30e9\u30d9\u30eb\u3068\u30c6\u30a4\u30f3\u30c8</li> <li>\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u3068\u5236\u9650</li> <li>\u30ce\u30fc\u30c9\u4fdd\u5b88\u3068\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9</li> <li>\u4e88\u6e2c\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u306e\u305f\u3081\u306e AI-Ops \u3068\u306e\u7d71\u5408</li> </ul> <p>\u5c0f\u898f\u6a21\u306a\u958b\u767a\u30af\u30e9\u30b9\u30bf\u30fc\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u5834\u5408\u3067\u3082\u3001\u5927\u898f\u6a21\u306a\u672c\u756a\u74b0\u5883\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u5834\u5408\u3067\u3082\u3001\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u306f HKS \u3067\u306e\u52b9\u679c\u7684\u306a\u30ce\u30fc\u30c9\u7ba1\u7406\u6226\u7565\u3092\u30ac\u30a4\u30c9\u3057\u307e\u3059\u3002</p>"},{"location":"ja/nodes/configuration/","title":"\u30ce\u30fc\u30c9\u8a2d\u5b9a","text":"<p>\u3053\u306e\u30ac\u30a4\u30c9\u3067\u306f\u3001Hexabase.AI \u3067\u306e\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u9ad8\u5ea6\u306a\u8a2d\u5b9a\u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u8a2d\u5b9a\u306f\u4e00\u822c\u7684\u306a\u4f7f\u7528\u306b\u6700\u9069\u5316\u3055\u308c\u3066\u3044\u307e\u3059\u304c\u3001\u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306b\u5bfe\u3057\u3066\u30ce\u30fc\u30c9\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002</p>"},{"location":"ja/nodes/configuration/#_2","title":"\u30ce\u30fc\u30c9\u30e9\u30d9\u30eb\u3068\u30c6\u30a4\u30f3\u30c8","text":"<p>\u30e9\u30d9\u30eb\u3068\u30c6\u30a4\u30f3\u30c8\u306f\u3001\u30dd\u30c3\u30c9\u304c\u30ce\u30fc\u30c9\u306b\u3069\u306e\u3088\u3046\u306b\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3055\u308c\u308b\u304b\u3092\u5236\u5fa1\u3059\u308b\u4e3b\u8981\u306a\u30e1\u30ab\u30cb\u30ba\u30e0\u3067\u3059\u3002</p> <ul> <li>\u30e9\u30d9\u30eb: <code>nodeSelector</code> \u3068 <code>nodeAffinity</code> \u3067\u4f7f\u7528\u3055\u308c\u3001\u30dd\u30c3\u30c9\u3092\u30ce\u30fc\u30c9\u306b\u5f15\u304d\u4ed8\u3051\u307e\u3059\u3002</li> <li>\u30c6\u30a4\u30f3\u30c8: \u4e00\u81f4\u3059\u308b <code>toleration</code> \u3092\u6301\u305f\u306a\u3044\u9650\u308a\u3001\u30dd\u30c3\u30c9\u3092\u30ce\u30fc\u30c9\u304b\u3089\u9060\u3056\u3051\u308b\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002</li> </ul>"},{"location":"ja/nodes/configuration/#_3","title":"\u4e00\u822c\u7684\u306a\u30e9\u30d9\u30eb\u4ed8\u3051\u30b9\u30ad\u30fc\u30e0","text":"<ul> <li>\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30bf\u30a4\u30d7\u5225: <code>workload-type=database</code>, <code>workload-type=frontend</code>, <code>workload-type=ml</code></li> <li>\u74b0\u5883\u5225: <code>environment=production</code>, <code>environment=staging</code></li> <li>\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u5225: <code>gpu=nvidia-a10g</code>, <code>disk=fast-ssd</code></li> <li>\u30c1\u30fc\u30e0\u5225: <code>team=backend</code>, <code>team=data-science</code></li> </ul>"},{"location":"ja/nodes/configuration/#_4","title":"\u4e00\u822c\u7684\u306a\u30c6\u30a4\u30f3\u30c8","text":"<ul> <li>\u5c02\u7528\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2: GPU \u30ce\u30fc\u30c9\u306b\u30c6\u30a4\u30f3\u30c8\uff08<code>gpu=true:NoSchedule</code>\uff09\u3092\u9069\u7528\u3059\u308b\u3053\u3068\u3067\u3001GPU \u3092\u7279\u5225\u306b\u8981\u6c42\u3059\u308b\u30dd\u30c3\u30c9\u306e\u307f\u304c\u305d\u3053\u306b\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3055\u308c\u308b\u3053\u3068\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002</li> <li>\u30ce\u30fc\u30c9\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9: \u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u3092\u5b9f\u884c\u3059\u308b\u524d\u306b\u3001<code>maintenance=true:NoExecute</code> \u3067\u624b\u52d5\u3067\u30ce\u30fc\u30c9\u306b\u30c6\u30a4\u30f3\u30c8\u3092\u9069\u7528\u3067\u304d\u307e\u3059\u3002<code>NoExecute</code> \u52b9\u679c\u306f\u3001\u30c6\u30a4\u30f3\u30c8\u3092\u8a31\u5bb9\u3057\u306a\u3044\u5b9f\u884c\u4e2d\u306e\u30dd\u30c3\u30c9\u3092\u9000\u907f\u3055\u305b\u307e\u3059\u3002</li> </ul>"},{"location":"ja/nodes/configuration/#_5","title":"\u30e9\u30d9\u30eb\u3068\u30c6\u30a4\u30f3\u30c8\u306e\u66f4\u65b0","text":"<p>HKS UI \u307e\u305f\u306f CLI \u3092\u901a\u3058\u3066\u3001\u3044\u3064\u3067\u3082\u30ce\u30fc\u30c9\u304b\u3089\u30e9\u30d9\u30eb\u3068\u30c6\u30a4\u30f3\u30c8\u3092\u8ffd\u52a0\u307e\u305f\u306f\u524a\u9664\u3067\u304d\u307e\u3059\u3002</p> <pre><code># \u30ce\u30fc\u30c9\u306b\u65b0\u3057\u3044\u30e9\u30d9\u30eb\u3092\u8ffd\u52a0\nhb node label my-node-01 owner=sre-team\n\n# \u30ce\u30fc\u30c9\u306b\u65b0\u3057\u3044\u30c6\u30a4\u30f3\u30c8\u3092\u8ffd\u52a0\nhb node taint my-node-01 sensitive=true:NoSchedule\n\n# \u30ce\u30fc\u30c9\u304b\u3089\u30c6\u30a4\u30f3\u30c8\u3092\u524a\u9664\nhb node taint my-node-01 sensitive:NoSchedule-\n</code></pre>"},{"location":"ja/nodes/configuration/#_6","title":"\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb","text":"<p>\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306f\u3001\u540c\u3058\u8a2d\u5b9a\uff08\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u30bf\u30a4\u30d7\u3001\u30c7\u30a3\u30b9\u30af\u30b5\u30a4\u30ba\u3001\u30e9\u30d9\u30eb\u3001\u30c6\u30a4\u30f3\u30c8\uff09\u3092\u5171\u6709\u3059\u308b\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u30b0\u30eb\u30fc\u30d7\u3067\u3059\u3002\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u540c\u3058\u30bf\u30a4\u30d7\u306e\u8907\u6570\u306e\u30ce\u30fc\u30c9\u304c\u5fc5\u8981\u306a\u5834\u5408\u306e\u7ba1\u7406\u304c\u7c21\u7d20\u5316\u3055\u308c\u307e\u3059\u3002</p> <pre><code># 3\u3064\u306e\u540c\u4e00\u30ce\u30fc\u30c9\u3067\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3092\u4f5c\u6210\nhb nodepool create production-workers \\\n  --node-type c5.xlarge \\\n  --node-count 3 \\\n  --labels \"pool=production-workers\" \\\n  --enable-autoscaling --min-nodes 2 --max-nodes 10\n</code></pre>"},{"location":"ja/nodes/configuration/#_7","title":"\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306e\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0","text":"<p>\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3067\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b\u5834\u5408\u3001Hexabase.AI \u306f\u30ea\u30bd\u30fc\u30b9\u9700\u8981\u306b\u57fa\u3065\u3044\u3066\u30ce\u30fc\u30c9\u3092\u81ea\u52d5\u7684\u306b\u8ffd\u52a0\u307e\u305f\u306f\u524a\u9664\u3057\u307e\u3059\u3002</p> <ul> <li>\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7: \u30d7\u30fc\u30eb\u5185\u306e\u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\u306b\u3088\u308a\uc2a4\u30b1\u30b8\u30e5\u30fc\u30eb\u3067\u304d\u306a\u3044\u4fdd\u7559\u4e2d\u306e\u30dd\u30c3\u30c9\u304c\u3042\u308b\u5834\u5408\u3001\u65b0\u3057\u3044\u30ce\u30fc\u30c9\u304c\u8ffd\u52a0\u3055\u308c\u307e\u3059\uff08<code>max-nodes</code> \u307e\u3067\uff09\u3002</li> <li>\u30b9\u30b1\u30fc\u30eb\u30c0\u30a6\u30f3: \u30d7\u30fc\u30eb\u5185\u306e\u30ce\u30fc\u30c9\u304c\u6307\u5b9a\u671f\u9593\u4e2d\u306b\u4f7f\u7528\u7387\u304c\u4f4e\u304f\u3001\u305d\u306e\u30dd\u30c3\u30c9\u304c\u4ed6\u306e\u5834\u6240\u306b\u5b89\u5168\u306b\u518d\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3067\u304d\u308b\u5834\u5408\u3001\u305d\u306e\u30ce\u30fc\u30c9\u306f\u30c9\u30ec\u30a4\u30f3\u51e6\u7406\u3055\u308c\u7d42\u4e86\u3055\u308c\u307e\u3059\uff08<code>min-nodes</code> \u307e\u3067\uff09\u3002</li> </ul>"},{"location":"ja/nodes/configuration/#_8","title":"\u30ab\u30b9\u30bf\u30e0\u30ce\u30fc\u30c9\u8a2d\u5b9a\uff08\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\uff09","text":"<p>\u9ad8\u5ea6\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3067\u306f\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u306e\u304a\u5ba2\u69d8\u306f <code>NodeConfig</code> \u30ea\u30bd\u30fc\u30b9\u3092\u4f7f\u7528\u3057\u3066\u30ce\u30fc\u30c9\u306b\u30ab\u30b9\u30bf\u30e0\u8a2d\u5b9a\u3092\u9069\u7528\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/nodes/configuration/#_9","title":"\u30ab\u30b9\u30bf\u30e0\u30ab\u30fc\u30cd\u30eb\u30d1\u30e9\u30e1\u30fc\u30bf","text":"<p>\u9ad8\u6027\u80fd\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\u3084\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306a\u3069\u3001\u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u7528\u306b <code>sysctl</code> \u30ab\u30fc\u30cd\u30eb\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u3067\u304d\u307e\u3059\u3002</p> <pre><code>apiVersion: hks.io/v1\nkind: NodeConfig\nmetadata:\n  name: high-performance-net\nspec:\n  # \u3053\u306e\u30e9\u30d9\u30eb\u3092\u6301\u3064\u30ce\u30fc\u30c9\u306b\u3053\u306e\u8a2d\u5b9a\u3092\u9069\u7528\n  nodeSelector:\n    workload-type: \"real-time-bidding\"\n\n  # \u9069\u7528\u3059\u308b\u30ab\u30fc\u30cd\u30eb\u8a2d\u5b9a\n  kernel:\n    sysctl:\n      net.core.somaxconn: \"65535\"\n      net.ipv4.tcp_max_syn_backlog: \"16384\"\n      vm.max_map_count: \"262144\"\n</code></pre>"},{"location":"ja/nodes/configuration/#_10","title":"\u30ab\u30b9\u30bf\u30e0\u8d77\u52d5\u30b9\u30af\u30ea\u30d7\u30c8","text":"<p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306b\u3001\u30ce\u30fc\u30c9\u8d77\u52d5\u6642\u306b\u30ab\u30b9\u30bf\u30e0\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30b5\u30fc\u30c9\u30d1\u30fc\u30c6\u30a3\u306e\u76e3\u8996\u3084\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb</li> <li>\u5927\u5bb9\u91cf\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3068\u30ad\u30e3\u30c3\u30b7\u30e5</li> <li>\u30ab\u30b9\u30bf\u30e0\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u8a2d\u5b9a\u306e\u5b9f\u884c</li> </ul> <pre><code>apiVersion: hks.io/v1\nkind: NodeConfig\nmetadata:\n  name: install-custom-agent\nspec:\n  nodeSelector:\n    team: \"security\"\n\n  startupScript: |\n    #!/bin/bash\n    set -e\n    echo \"Installing custom security agent...\"\n    curl -sSL https://my-agent.com/install.sh | bash\n    systemctl enable --now my-custom-agent\n</code></pre> <p>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u6ce8\u610f: \u3059\u3079\u3066\u306e\u8d77\u52d5\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u30b5\u30f3\u30c9\u30dc\u30c3\u30af\u30b9\u74b0\u5883\u3067\u5b9f\u884c\u3055\u308c\u3001Hexabase.AI \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30c1\u30fc\u30e0\u306b\u3088\u308b\u30ec\u30d3\u30e5\u30fc\u306e\u5bfe\u8c61\u3068\u306a\u308a\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u304c\u8a31\u53ef\u3055\u308c\u308b\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002</p>"},{"location":"ja/nodes/configuration/#_11","title":"\u30ce\u30fc\u30c9\u30a4\u30e1\u30fc\u30b8\u306e\u7ba1\u7406","text":"<p>Hexabase.AI \u306f\u3001\u5c02\u7528\u30ce\u30fc\u30c9\u7528\u306b\u6700\u9069\u5316\u3055\u308c\u305f\u5f37\u5316\u3055\u308c\u305f OS \u30a4\u30e1\u30fc\u30b8\u306e\u30bb\u30c3\u30c8\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002\u3053\u308c\u3089\u306e\u30a4\u30e1\u30fc\u30b8\u306f\u3001\u4e00\u822c\u7684\u306a Linux \u30c7\u30a3\u30b9\u30c8\u30ea\u30d3\u30e5\u30fc\u30b7\u30e7\u30f3\uff08Ubuntu \u3084 Bottlerocket \u306a\u3069\uff09\u306b\u57fa\u3065\u3044\u3066\u304a\u308a\u3001<code>kubelet</code>\u3001\u30b3\u30f3\u30c6\u30ca\u30e9\u30f3\u30bf\u30a4\u30e0\u3001HKS \u30a8\u30fc\u30b8\u30a7\u30f3\u30c8\u306a\u3069\u306e\u5fc5\u8981\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3067\u4e8b\u524d\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <ul> <li>\u81ea\u52d5\u66f4\u65b0: HKS \u306f\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d1\u30c3\u30c1\u3068 OS \u66f4\u65b0\u3092\u9069\u7528\u3059\u308b\u305f\u3081\u306b\u3001\u7121\u505c\u6b62\u3067\u30ed\u30fc\u30ea\u30f3\u30b0\u65b9\u5f0f\u3067\u65b0\u3057\u3044\u30ce\u30fc\u30c9\u30a4\u30e1\u30fc\u30b8\u3092\u81ea\u52d5\u7684\u306b\u30ed\u30fc\u30eb\u30a2\u30a6\u30c8\u3057\u307e\u3059\u3002</li> <li>\u30ab\u30b9\u30bf\u30e0\u30a4\u30e1\u30fc\u30b8\uff08\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\uff09: \u72ec\u81ea\u306e\u300c\u30b4\u30fc\u30eb\u30c7\u30f3\u300dOS \u30a4\u30e1\u30fc\u30b8\u3092\u4f7f\u7528\u3059\u308b\u53b3\u683c\u306a\u8981\u4ef6\u3092\u6301\u3064\u7d44\u7e54\u5411\u3051\u306b\u3001HKS \u306f\u3001\u7279\u5b9a\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u4e92\u63db\u6027\u57fa\u6e96\u3092\u6e80\u305f\u3059\u3053\u3068\u3092\u6761\u4ef6\u3068\u3057\u3066\u3001\u30ab\u30b9\u30bf\u30e0\u30a4\u30e1\u30fc\u30b8\u3092\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306b\u7d71\u5408\u3059\u308b\u4f5c\u696d\u3092\u652f\u63f4\u3067\u304d\u307e\u3059\u3002</li> </ul>"},{"location":"ja/rbac/","title":"Kubernetes RBAC","text":"<p>\u30bb\u30ad\u30e5\u30a2\u306a\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8 Kubernetes \u904b\u7528\u306e\u305f\u3081\u306b\u3001Hexabase.AI \u304c\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09\u3092\u3069\u306e\u3088\u3046\u306b\u5b9f\u88c5\u30fb\u7ba1\u7406\u3059\u308b\u304b\u3092\u5b66\u3073\u307e\u3059\u3002</p>"},{"location":"ja/rbac/#_1","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u3001\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u3001\u7c21\u7d20\u5316\u3055\u308c\u305f\u7ba1\u7406\u3001\u5f37\u5316\u3055\u308c\u305f\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u305f\u3081\u306e\u8ffd\u52a0\u6a5f\u80fd\u3092\u5099\u3048\u305f Kubernetes \u30cd\u30a4\u30c6\u30a3\u30d6 RBAC \u3092\u62e1\u5f35\u3059\u308b\u6d17\u7df4\u3055\u308c\u305f RBAC \u30b7\u30b9\u30c6\u30e0\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u79c1\u305f\u3061\u306e RBAC \u5b9f\u88c5\u306b\u3088\u308a\u3001\u30e6\u30fc\u30b6\u30fc\u306f\u5fc5\u8981\u306a\u6a29\u9650\u306e\u307f\u3092\u53d6\u5f97\u3067\u304d\u307e\u3059\u2014\u591a\u3059\u304e\u305a\u3001\u5c11\u306a\u3059\u304e\u307e\u305b\u3093\u3002</p>"},{"location":"ja/rbac/#rbac","title":"RBAC \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8","text":"<ul> <li> \u30ed\u30fc\u30eb\u3068\u6a29\u9650</li> </ul> <p>\u4e8b\u524d\u5b9a\u7fa9\u3055\u308c\u305f\u30ed\u30fc\u30eb\u3068\u30ab\u30b9\u30bf\u30e0\u6a29\u9650\u30e2\u30c7\u30eb\u3092\u7406\u89e3</p> <p> \u30ed\u30fc\u30eb\u3092\u63a2\u7d22</p> <ul> <li> \u30e6\u30fc\u30b6\u30fc\u7ba1\u7406</li> </ul> <p>\u30e6\u30fc\u30b6\u30fc\u3001\u30b0\u30eb\u30fc\u30d7\u3001\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u306e\u7ba1\u7406</p> <p> \u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u30ac\u30a4\u30c9</p> <ul> <li> \u30dd\u30ea\u30b7\u30fc\u8a2d\u5b9a</li> </ul> <p>\u30a2\u30af\u30bb\u30b9\u30dd\u30ea\u30b7\u30fc\u306e\u8a2d\u5b9a\u3068\u30ab\u30b9\u30bf\u30de\u30a4\u30ba</p> <p> \u30dd\u30ea\u30b7\u30fc\u8a2d\u5b9a</p> <ul> <li> \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</li> </ul> <p>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3068\u4e00\u822c\u7684\u306a\u30d1\u30bf\u30fc\u30f3</p> <p> RBAC \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</p>"},{"location":"ja/rbac/#rbac_1","title":"RBAC \u30e2\u30c7\u30eb","text":"<p>Hexabase.AI \u306f\u3001\u304d\u3081\u7d30\u304b\u3044\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3092\u63d0\u4f9b\u3059\u308b\u968e\u5c64 RBAC \u30e2\u30c7\u30eb\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\uff1a</p> <pre><code>\u7d44\u7e54\n\u251c\u2500\u2500 \u7d44\u7e54\u30ed\u30fc\u30eb\uff08Admin\u3001Viewer\uff09\n\u2514\u2500\u2500 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\n    \u251c\u2500\u2500 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ed\u30fc\u30eb\uff08Owner\u3001Developer\u3001Viewer\uff09\n    \u2514\u2500\u2500 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\n        \u2514\u2500\u2500 Kubernetes RBAC\uff08\u30cd\u30a4\u30c6\u30a3\u30d6\u30ed\u30fc\u30eb\uff09\n</code></pre>"},{"location":"ja/rbac/#_2","title":"\u4e3b\u8981\u6a5f\u80fd","text":""},{"location":"ja/rbac/#1","title":"1. \u30de\u30eb\u30c1\u30ec\u30d9\u30eb\u6a29\u9650","text":"<ul> <li>\u7d44\u7e54\u30ec\u30d9\u30eb: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u4f5c\u6210\u3068\u8acb\u6c42\u7ba1\u7406\u306e\u5236\u5fa1</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30d9\u30eb: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3068\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u306e\u7ba1\u7406</li> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ec\u30d9\u30eb: \u304d\u3081\u7d30\u304b\u3044 Kubernetes \u6a29\u9650</li> </ul>"},{"location":"ja/rbac/#2","title":"2. \u4e8b\u524d\u5b9a\u7fa9\u30ed\u30fc\u30eb","text":"<ul> <li>\u7d44\u7e54\u7ba1\u7406\u8005: \u7d44\u7e54\u306e\u5b8c\u5168\u5236\u5fa1</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u6240\u6709\u8005: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7ba1\u7406\u3068\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30c7\u30d7\u30ed\u30a4</li> <li>\u958b\u767a\u8005: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30c7\u30d7\u30ed\u30a4\u3068\u7ba1\u7406</li> <li>\u95b2\u89a7\u8005: \u30ea\u30bd\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9</li> </ul>"},{"location":"ja/rbac/#3","title":"3. \u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb","text":"<ul> <li>\u7279\u5b9a\u6a29\u9650\u3092\u6301\u3064\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u306e\u4f5c\u6210</li> <li>\u8907\u96d1\u306a\u30b7\u30ca\u30ea\u30aa\u5411\u3051\u306e\u8907\u6570\u6a29\u9650\u306e\u7d44\u307f\u5408\u308f\u305b</li> <li>\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u30d9\u30fc\u30b9\u306e\u30ed\u30fc\u30eb\u4f5c\u6210</li> </ul>"},{"location":"ja/rbac/#4","title":"4. \u52d5\u7684\u6a29\u9650\u7d99\u627f","text":"<ul> <li>\u7d44\u7e54\u304b\u3089\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3078\u306e\u6a29\u9650\u306e\u30ab\u30b9\u30b1\u30fc\u30c9</li> <li>\u4e0b\u4f4d\u30ec\u30d9\u30eb\u3067\u306e\u7d99\u627f\u6a29\u9650\u306e\u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9</li> <li>\u81ea\u52d5\u6a29\u9650\u4f1d\u64ad</li> </ul>"},{"location":"ja/rbac/#rbac_2","title":"\u4e00\u822c\u7684\u306a RBAC \u30b7\u30ca\u30ea\u30aa","text":""},{"location":"ja/rbac/#1_1","title":"\u30b7\u30ca\u30ea\u30aa 1: \u958b\u767a\u30c1\u30fc\u30e0\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<pre><code>\u30c1\u30fc\u30e0\u69cb\u9020:\n  - \u30c1\u30fc\u30e0\u30ea\u30fc\u30c0\u30fc: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u6240\u6709\u8005\n  - \u958b\u767a\u8005: \u30c7\u30d7\u30ed\u30a4\u6a29\u9650\u3092\u6301\u3064\u958b\u767a\u8005\u30ed\u30fc\u30eb\n  - QA \u30a8\u30f3\u30b8\u30cb\u30a2: \u30ed\u30b0\u30a2\u30af\u30bb\u30b9\u3092\u6301\u3064\u95b2\u89a7\u8005\u30ed\u30fc\u30eb\n  - CI/CD \u30b5\u30fc\u30d3\u30b9: \u30c7\u30d7\u30ed\u30a4\u6a29\u9650\u3092\u6301\u3064\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\n</code></pre>"},{"location":"ja/rbac/#2_1","title":"\u30b7\u30ca\u30ea\u30aa 2: \u30de\u30eb\u30c1\u74b0\u5883\u30a2\u30af\u30bb\u30b9","text":"<pre><code>\u74b0\u5883\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7:\n  - \u672c\u756a: \u30b7\u30cb\u30a2\u958b\u767a\u8005\u3068 SRE \u306b\u9650\u5b9a\n  - \u30b9\u30c6\u30fc\u30b8\u30f3\u30b0: \u3059\u3079\u3066\u306e\u958b\u767a\u8005\u306b\u30aa\u30fc\u30d7\u30f3\n  - \u958b\u767a: \u3059\u3079\u3066\u306e\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u306e\u30bb\u30eb\u30d5\u30b5\u30fc\u30d3\u30b9\n</code></pre>"},{"location":"ja/rbac/#3_1","title":"\u30b7\u30ca\u30ea\u30aa 3: \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u30a2\u30af\u30bb\u30b9","text":"<pre><code>\u5916\u90e8\u30a2\u30af\u30bb\u30b9:\n  - \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u95a2\u4fc2\u8005: \u7279\u5b9a\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u95b2\u89a7\u8005\u30ed\u30fc\u30eb\n  - \u8acb\u8ca0\u696d\u8005: \u671f\u9593\u9650\u5b9a\u306e\u958b\u767a\u8005\u30a2\u30af\u30bb\u30b9\n  - \u76e3\u67fb\u62c5\u5f53\u8005: \u76e3\u67fb\u30ed\u30b0\u53ef\u8996\u6027\u3092\u6301\u3064\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9\n</code></pre>"},{"location":"ja/rbac/#_3","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8003\u616e\u4e8b\u9805","text":""},{"location":"ja/rbac/#_4","title":"\u6700\u5c0f\u6a29\u9650\u306e\u539f\u5247","text":"<ul> <li>\u30e6\u30fc\u30b6\u30fc\u306f\u5fc5\u8981\u6700\u5c0f\u9650\u306e\u6a29\u9650\u3092\u53d6\u5f97</li> <li>\u5b9a\u671f\u7684\u306a\u6a29\u9650\u76e3\u67fb</li> <li>\u81ea\u52d5\u6a29\u9650\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7</li> </ul>"},{"location":"ja/rbac/#_5","title":"\u8077\u52d9\u5206\u96e2","text":"<ul> <li>\u30c7\u30d7\u30ed\u30a4\u3068\u627f\u8a8d\u306e\u7570\u306a\u308b\u30ed\u30fc\u30eb</li> <li>\u72ec\u7acb\u3057\u305f\u672c\u756a\u30a2\u30af\u30bb\u30b9\u5236\u5fa1</li> <li>\u3059\u3079\u3066\u306e\u6a29\u9650\u5909\u66f4\u306e\u76e3\u67fb\u8a3c\u8de1</li> </ul>"},{"location":"ja/rbac/#_6","title":"\u591a\u5c64\u9632\u5fa1","text":"<ul> <li>\u8907\u6570\u306e\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u30ec\u30a4\u30e4\u30fc</li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u304c RBAC \u3092\u88dc\u5b8c</li> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u60aa\u7528\u3092\u9632\u6b62</li> </ul>"},{"location":"ja/rbac/#_7","title":"\u30af\u30a4\u30c3\u30af\u30b9\u30bf\u30fc\u30c8\u4f8b","text":""},{"location":"ja/rbac/#_8","title":"\u958b\u767a\u8005\u30a2\u30af\u30bb\u30b9\u306e\u4ed8\u4e0e","text":"<pre><code>hb rbac grant-role developer user@example.com --workspace my-workspace\n</code></pre>"},{"location":"ja/rbac/#_9","title":"\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u306e\u4f5c\u6210","text":"<pre><code>hb rbac create-role custom-deployer \\\n  --permissions deploy,view-logs,manage-secrets \\\n  --workspace my-workspace\n</code></pre>"},{"location":"ja/rbac/#_10","title":"\u30e6\u30fc\u30b6\u30fc\u6a29\u9650\u306e\u8868\u793a","text":"<pre><code>hb rbac list-permissions user@example.com\n</code></pre>"},{"location":"ja/rbac/#kubernetes","title":"Kubernetes \u3068\u306e\u7d71\u5408","text":"<p>Hexabase.AI RBAC \u306f\u30cd\u30a4\u30c6\u30a3\u30d6 Kubernetes RBAC \u3068\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u7d71\u5408\u3055\u308c\u307e\u3059\uff1a</p> <ol> <li>\u81ea\u52d5\u5909\u63db: \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30ed\u30fc\u30eb\u304c Kubernetes \u30ed\u30fc\u30eb\u306b\u30de\u30c3\u30d7</li> <li>\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u7ba1\u7406: \u81ea\u52d5\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u4f5c\u6210</li> <li>Namespace \u5206\u96e2: RBAC \u30dd\u30ea\u30b7\u30fc\u304c namespace \u5883\u754c\u3092\u5f37\u5236</li> <li>\u76e3\u67fb\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9: \u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u306e\u305f\u3081\u306b\u3059\u3079\u3066\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u30ed\u30b0</li> </ol>"},{"location":"ja/rbac/#_11","title":"\u6b21\u306e\u30b9\u30c6\u30c3\u30d7","text":"<ul> <li>RBAC \u304c\u521d\u3081\u3066\u3067\u3059\u304b\uff1f \u30ed\u30fc\u30eb\u3068\u6a29\u9650 \u304b\u3089\u59cb\u3081\u307e\u3057\u3087\u3046</li> <li>\u30e6\u30fc\u30b6\u30fc\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u307e\u3059\u304b\uff1f \u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u30ac\u30a4\u30c9 \u306b\u5f93\u3063\u3066\u304f\u3060\u3055\u3044</li> <li>\u30ab\u30b9\u30bf\u30e0\u30dd\u30ea\u30b7\u30fc\u304c\u5fc5\u8981\u3067\u3059\u304b\uff1f \u30dd\u30ea\u30b7\u30fc\u8a2d\u5b9a \u306b\u3064\u3044\u3066\u5b66\u7fd2\u3057\u3066\u304f\u3060\u3055\u3044</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u91cd\u8996\u3067\u3059\u304b\uff1f RBAC \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9 \u3092\u30ec\u30d3\u30e5\u30fc\u3057\u3066\u304f\u3060\u3055\u3044</li> </ul>"},{"location":"ja/rbac/#_12","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9</li> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>\u6a29\u9650\u30e2\u30c7\u30eb</li> </ul>"},{"location":"ja/rbac/best-practices/","title":"RBAC \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<p>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09\u3092\u9069\u5207\u306b\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u306f\u3001Hexabase.AI \u74b0\u5883\u3092\u4fdd\u8b77\u3059\u308b\u6700\u3082\u91cd\u8981\u306a\u5074\u9762\u306e1\u3064\u3067\u3059\u3002\u3053\u308c\u3089\u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u306b\u5f93\u3046\u3053\u3068\u3067\u3001\u5b89\u5168\u3067\u7ba1\u7406\u3057\u3084\u3059\u3044\u30b7\u30b9\u30c6\u30e0\u3092\u7dad\u6301\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/rbac/best-practices/#1-polp","title":"1. \u6700\u5c0f\u6a29\u9650\u306e\u539f\u5247\uff08PoLP\uff09\u3092\u9075\u5b88\u3059\u308b","text":"<p>\u3053\u308c\u306f\u3001\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u306e\u6700\u3082\u57fa\u672c\u7684\u306a\u539f\u5247\u3067\u3059\u3002</p> <ul> <li>\u5fc5\u8981\u306a\u3082\u306e\u306e\u307f\u3092\u4ed8\u4e0e: \u30e6\u30fc\u30b6\u30fc\u3068\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u306f\u3001\u8077\u52d9\u3092\u9042\u884c\u3059\u308b\u305f\u3081\u306b\u7d76\u5bfe\u306b\u5fc5\u8981\u306a\u6a29\u9650\u306e\u307f\u3092\u6301\u3064\u3079\u304d\u3067\u3059\u3002</li> <li>\u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9\u6a29\u9650\u3092\u907f\u3051\u308b: \u771f\u306b\u5fc5\u8981\u3067\u306a\u3044\u9650\u308a\u3001\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3067\u30ea\u30bd\u30fc\u30b9\u3084\u52d5\u8a5e\u306b <code>*</code> \u3092\u4f7f\u7528\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\u660e\u793a\u7684\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li><code>viewer</code> \u304b\u3089\u59cb\u3081\u308b: \u65b0\u3057\u3044\u30e6\u30fc\u30b6\u30fc\u304c\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u53c2\u52a0\u3057\u305f\u3089\u3001\u307e\u305a <code>viewer</code> \u30ed\u30fc\u30eb\u3092\u4ed8\u4e0e\u3057\u307e\u3059\u3002\u5909\u66f4\u3092\u958b\u59cb\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u5834\u5408\u306b\u306e\u307f\u3001\u6a29\u9650\u3092 <code>developer</code> \u306b\u6607\u683c\u3055\u305b\u307e\u3059\u3002</li> <li><code>workspace_admin</code> \u306f\u63a7\u3048\u3081\u306b\u4f7f\u7528: <code>workspace_admin</code> \u30ed\u30fc\u30eb\u306f\u9ad8\u3044\u7279\u6a29\u3092\u6301\u3061\u307e\u3059\u3002\u65e5\u5e38\u7684\u306a\u958b\u767a\u30bf\u30b9\u30af\u3067\u306f\u306a\u304f\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u81ea\u4f53\u306e\u7ba1\u7406\u306b\u8cac\u4efb\u3092\u6301\u3064\u30c1\u30fc\u30e0\u30ea\u30fc\u30c9\u307e\u305f\u306f\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7ba1\u7406\u8005\u306e\u305f\u3081\u306b\u4e88\u7d04\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> </ul>"},{"location":"ja/rbac/best-practices/#2","title":"2. \u30e6\u30fc\u30b6\u30fc\u3068\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u7ba1\u7406\u3092\u5206\u96e2\u3059\u308b","text":"<ul> <li>\u5171\u6709\u30a2\u30ab\u30a6\u30f3\u30c8\u306f\u4f7f\u7528\u3057\u306a\u3044: \u3059\u3079\u3066\u306e\u4eba\u9593\u30e6\u30fc\u30b6\u30fc\u306f\u72ec\u81ea\u306e\u540d\u524d\u4ed8\u304d\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u6301\u3064\u3079\u304d\u3067\u3059\u3002\u5171\u6709\u30a2\u30ab\u30a6\u30f3\u30c8\uff08\u4f8b\uff1a\u30c1\u30fc\u30e0\u5168\u4f53\u3067\u5358\u4e00\u306e <code>developer</code> \u30a2\u30ab\u30a6\u30f3\u30c8\uff09\u306f\u4f7f\u7528\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u76e3\u67fb\u30ed\u30b0\u3092\u901a\u3058\u3066\u8aac\u660e\u8cac\u4efb\u304c\u78ba\u4fdd\u3055\u308c\u307e\u3059\u3002</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5c02\u7528\u306e\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8: \u5404\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u307e\u305f\u306f CI/CD \u30b8\u30e7\u30d6\u306f\u72ec\u81ea\u306e\u5c02\u7528 <code>ServiceAccount</code> \u3092\u6301\u3064\u3079\u304d\u3067\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u6a29\u9650\u304c\u5206\u96e2\u3055\u308c\u30011\u3064\u306e\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u304c\u4fb5\u5bb3\u3055\u308c\u3066\u3082\u3001\u5f71\u97ff\u7bc4\u56f2\u304c\u9650\u5b9a\u3055\u308c\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001<code>ci-builder</code> \u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u306f <code>production-app</code> \u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u3068\u540c\u3058\u6a29\u9650\u3092\u6301\u3064\u3079\u304d\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002</li> </ul>"},{"location":"ja/rbac/best-practices/#3-2-rbac","title":"3. 2\u5c64 RBAC \u30b7\u30b9\u30c6\u30e0\u3092\u6d3b\u7528\u3059\u308b","text":"<ul> <li>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7ba1\u7406\u306b\u306f\u7d44\u7e54\u30ed\u30fc\u30eb\u3092\u4f7f\u7528: <code>organization_admin</code> \u3067\u7d44\u7e54\u30ec\u30d9\u30eb\u3067\u306e\u30e6\u30fc\u30b6\u30fc\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3001\u8acb\u6c42\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u958b\u767a\u306b\u306f\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ed\u30fc\u30eb\u3092\u4f7f\u7528: <code>workspace_admin</code>\u3001<code>developer</code>\u3001<code>viewer</code> \u3067\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30d9\u30eb\u3067\u306e Kubernetes \u30ea\u30bd\u30fc\u30b9\u3068\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002</li> <li>\u3059\u3079\u3066\u306e\u4eba\u306b <code>organization_admin</code> \u3092\u4e0e\u3048\u306a\u3044: \u3053\u306e\u30ed\u30fc\u30eb\u306f\u3001HKS \u74b0\u5883\u5168\u4f53\u306e\u30b9\u30fc\u30d1\u30fc\u30e6\u30fc\u30b6\u30fc\u306b\u306a\u308b\u3053\u3068\u3068\u540c\u7b49\u3067\u3059\u3002\u305d\u306e\u4f7f\u7528\u306f\u3001\u4fe1\u983c\u3067\u304d\u308b\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7ba1\u7406\u8005\u306e\u975e\u5e38\u306b\u5c11\u6570\u306b\u5236\u9650\u3059\u3079\u304d\u3067\u3059\u3002</li> </ul>"},{"location":"ja/rbac/best-practices/#4-rbac","title":"4. RBAC \u30dd\u30ea\u30b7\u30fc\u3068\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3092\u5b9a\u671f\u7684\u306b\u76e3\u67fb\u3059\u308b","text":"<ul> <li>\u5b9a\u671f\u7684\u306a\u30ec\u30d3\u30e5\u30fc\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb: \u5c11\u306a\u304f\u3068\u3082\u56db\u534a\u671f\u306b\u4e00\u5ea6\u3001<code>organization_admin</code> \u307e\u305f\u306f <code>workspace_admin</code> \u304c\u3059\u3079\u3066\u306e\u30ed\u30fc\u30eb\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3092\u30ec\u30d3\u30e5\u30fc\u3059\u3079\u304d\u3067\u3059\u3002</li> <li>\u53e4\u3044\u30a2\u30af\u30bb\u30b9\u3092\u63a2\u3059: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u95a2\u308f\u3089\u306a\u304f\u306a\u3063\u305f\u30e6\u30fc\u30b6\u30fc\u3092\u524a\u9664\u3057\u307e\u3059\u3002</li> <li>\u904e\u5ea6\u306b\u8a31\u53ef\u7684\u306a\u30ed\u30fc\u30eb\u3092\u7279\u5b9a: \u5fc5\u8981\u4ee5\u4e0a\u306e\u6a29\u9650\u3092\u6301\u3064\u30e6\u30fc\u30b6\u30fc\u304c\u3044\u306a\u3044\u304b\u30c1\u30a7\u30c3\u30af\u3057\u307e\u3059\u3002<code>workspace_admin</code> \u3092 <code>developer</code> \u306b\u3067\u304d\u306a\u3044\u3067\u3057\u3087\u3046\u304b\uff1f</li> <li>\u76e3\u67fb\u3092\u81ea\u52d5\u5316: <code>hks</code> CLI \u3092\u4f7f\u7528\u3057\u3066\u76e3\u67fb\u306e\u4e00\u90e8\u3092\u30b9\u30af\u30ea\u30d7\u30c8\u5316\u3057\u307e\u3059\u3002</li> </ul> <pre><code># \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e\u3059\u3079\u3066\u306e\u30e6\u30fc\u30b6\u30fc\u3068\u305d\u306e\u30ed\u30fc\u30eb\u3092\u30ea\u30b9\u30c8\nhb list-users --workspace my-prod-space\n\n# \u7279\u5b9a\u306e\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u306e\u6a29\u9650\u3092\u30c1\u30a7\u30c3\u30af\nhb get workspacerole custom-role -o yaml\n</code></pre>"},{"location":"ja/rbac/best-practices/#5","title":"5. \u304d\u3081\u7d30\u304b\u3044\u5236\u5fa1\u306b\u306f\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3092\u4f7f\u7528\u3059\u308b","text":"<ul> <li>\u30c7\u30d5\u30a9\u30eb\u30c8\u30ed\u30fc\u30eb\u3092\u7121\u7406\u306b\u4f7f\u308f\u306a\u3044: \u7d44\u307f\u8fbc\u307f\u306e <code>developer</code> \u30ed\u30fc\u30eb\u304c\u7279\u5b9a\u306e\u30bf\u30b9\u30af\u306b\u306f\u8a31\u53ef\u7684\u3059\u304e\u308b\u5834\u5408\u3001\u3068\u308a\u3042\u3048\u305a\u4ed8\u4e0e\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\u3002</li> <li>\u4f8b: <code>Pods</code> \u3068 <code>Jobs</code> \u306e\u307f\u3092\u4f5c\u6210\u3067\u304d\u3001<code>Deployments</code> \u3084 <code>Services</code> \u306f\u4f5c\u6210\u3067\u304d\u306a\u3044 <code>ci-runner</code> \u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</li> <li>\u4f8b: \u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u8868\u793a\u3057\u3001\u30c7\u30d0\u30c3\u30b0\u306e\u305f\u3081\u306b\u30dd\u30c3\u30c9\u306b <code>exec</code> \u3067\u304d\u308b\u304c\u3001<code>Secrets</code> \u306f\u8868\u793a\u3067\u304d\u306a\u3044 <code>support-staff</code> \u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/rbac/best-practices/#6-kubernetes-rbac","title":"6. \u57fa\u76e4\u3068\u306a\u308b Kubernetes RBAC \u3092\u4fdd\u8b77\u3059\u308b","text":"<ul> <li>\u624b\u52d5\u306e <code>kubectl</code> \u5909\u66f4\u3092\u907f\u3051\u308b: <code>kubectl</code> \u3092\u4f7f\u7528\u3057\u3066\u624b\u52d5\u3067 <code>Roles</code> \u3084 <code>RoleBindings</code> \u3092\u4f5c\u6210\u3057\u306a\u3044\u3067\u304f\u3060\u3055\u3044\u3002Hexabase.AI \u306b Kubernetes RBAC \u30ea\u30bd\u30fc\u30b9\u3092\u7ba1\u7406\u3055\u305b\u3066\u304f\u3060\u3055\u3044\u3002\u624b\u52d5\u3067\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3092\u4f5c\u6210\u3059\u308b\u3068\u3001HKS UI \u3068 Kubernetes \u72b6\u614b\u304c\u540c\u671f\u3057\u306a\u3044\u300c\u30b9\u30d7\u30ea\u30c3\u30c8\u30d6\u30ec\u30fc\u30f3\u300d\u30b7\u30ca\u30ea\u30aa\u306b\u9665\u308a\u3001\u6df7\u4e71\u3092\u62db\u304f\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</li> <li>\u76f4\u63a5\u306e <code>kubectl</code> \u30a2\u30af\u30bb\u30b9\u3092\u5236\u9650: \u307b\u3068\u3093\u3069\u306e\u30e6\u30fc\u30b6\u30fc\u306b\u3068\u3063\u3066\u3001\u3059\u3079\u3066\u306e\u5bfe\u8a71\u306f HKS \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\uff08UI\u3001CLI\u3001API\uff09\u3092\u901a\u3058\u3066\u884c\u3046\u3079\u304d\u3067\u3059\u3002\u76f4\u63a5\u306e <code>kubectl</code> \u30a2\u30af\u30bb\u30b9\u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7ba1\u7406\u8005\u307e\u305f\u306f\u7dca\u6025\u6642\u306e break-glass \u30b7\u30ca\u30ea\u30aa\u306b\u9650\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u3059\u3079\u3066\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u304c HKS \u76e3\u67fb\u30ed\u30b0\u3092\u901a\u904e\u3059\u308b\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u307e\u3059\u3002</li> </ul>"},{"location":"ja/rbac/hexabase-rbac/","title":"Hexabase RBAC","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Hexabase.AI \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u81ea\u4f53\u5185\u306e\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09\u5b9f\u88c5\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/hexabase-rbac/#_1","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u3001\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5168\u4f53\u3067\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3092\u7ba1\u7406\u3059\u308b\u305f\u3081\u306e\u5305\u62ec\u7684\u306a RBAC \u30b7\u30b9\u30c6\u30e0\u3092\u5b9f\u88c5\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u30b7\u30b9\u30c6\u30e0\u306f\u3001\u30e6\u30fc\u30b6\u30fc\u304c\u7570\u306a\u308b\u7d44\u7e54\u30ec\u30d9\u30eb\u3067\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u3069\u306e\u3088\u3046\u306b\u5bfe\u8a71\u3059\u308b\u304b\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/hexabase-rbac/#_2","title":"\u30ed\u30fc\u30eb\u968e\u5c64","text":""},{"location":"ja/rbac/hexabase-rbac/#_3","title":"\u7d44\u7e54\u30ec\u30d9\u30eb\u30ed\u30fc\u30eb","text":"<ul> <li>\u7d44\u7e54\u7ba1\u7406\u8005: \u7d44\u7e54\u306e\u5b8c\u5168\u5236\u5fa1</li> <li>\u7d44\u7e54\u95b2\u89a7\u8005: \u7d44\u7e54\u30ea\u30bd\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9</li> </ul>"},{"location":"ja/rbac/hexabase-rbac/#_4","title":"\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30d9\u30eb\u30ed\u30fc\u30eb","text":"<ul> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7ba1\u7406\u8005: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ea\u30bd\u30fc\u30b9\u306e\u5b8c\u5168\u5236\u5fa1</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u958b\u767a\u8005: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u4f5c\u6210\u3068\u7ba1\u7406\u304c\u53ef\u80fd</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u95b2\u89a7\u8005: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ea\u30bd\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9</li> </ul>"},{"location":"ja/rbac/hexabase-rbac/#_5","title":"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ec\u30d9\u30eb\u30ed\u30fc\u30eb","text":"<ul> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u6240\u6709\u8005: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ea\u30bd\u30fc\u30b9\u306e\u5b8c\u5168\u5236\u5fa1</li> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5354\u529b\u8005: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ea\u30bd\u30fc\u30b9\u306e\u5909\u66f4\u304c\u53ef\u80fd</li> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u95b2\u89a7\u8005: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30ea\u30bd\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9</li> </ul>"},{"location":"ja/rbac/hexabase-rbac/#_6","title":"\u6a29\u9650\u30e2\u30c7\u30eb","text":"<p>Hexabase RBAC \u30b7\u30b9\u30c6\u30e0\u306f\u4ee5\u4e0b\u306e\u539f\u5247\u306b\u5f93\u3044\u307e\u3059\uff1a</p> <ol> <li>\u968e\u5c64\u7d99\u627f: \u6a29\u9650\u306f\u7d44\u7e54\u304b\u3089\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3078\u3068\u30ab\u30b9\u30b1\u30fc\u30c9\u3057\u307e\u3059</li> <li>\u6700\u5c0f\u6a29\u9650: \u30e6\u30fc\u30b6\u30fc\u306f\u81ea\u5206\u306e\u5f79\u5272\u306b\u5fc5\u8981\u306a\u6700\u5c0f\u9650\u306e\u6a29\u9650\u3092\u53d6\u5f97\u3057\u307e\u3059</li> <li>\u95a2\u5fc3\u306e\u5206\u96e2: \u7570\u306a\u308b\u7d44\u7e54\u30ec\u30d9\u30eb\u9593\u306e\u660e\u78ba\u306a\u5883\u754c</li> </ol>"},{"location":"ja/rbac/hexabase-rbac/#kubernetes","title":"Kubernetes \u3068\u306e\u7d71\u5408","text":"<p>\u3053\u306e\u30da\u30fc\u30b8\u306f Hexabase \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0 RBAC \u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002Hexabase RBAC \u304c Kubernetes RBAC \u306b\u3069\u306e\u3088\u3046\u306b\u30de\u30c3\u30d7\u3055\u308c\u308b\u304b\u306b\u3064\u3044\u3066\u306f\u3001Kubernetes RBAC \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/rbac/kubernetes-rbac/","title":"Kubernetes RBAC","text":"<p>\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001Hexabase.AI \u304c Kubernetes \u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3068\u3069\u306e\u3088\u3046\u306b\u7d71\u5408\u30fb\u7ba1\u7406\u3059\u308b\u304b\u3092\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/kubernetes-rbac/#_1","title":"\u6982\u8981","text":"<p>Hexabase.AI \u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30ed\u30fc\u30eb\u3068 Kubernetes RBAC \u9593\u306e\u30b7\u30fc\u30e0\u30ec\u30b9\u306a\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u63d0\u4f9b\u3057\u3001\u30e6\u30fc\u30b6\u30fc\u304c Kubernetes \u306e\u8907\u96d1\u3055\u3092\u76f4\u63a5\u6271\u3046\u3053\u3068\u306a\u304f HKS \u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u3092\u901a\u3058\u3066 Kubernetes \u30ea\u30bd\u30fc\u30b9\u3092\u7ba1\u7406\u3067\u304d\u308b\u3088\u3046\u306b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/kubernetes-rbac/#_2","title":"\u30ed\u30fc\u30eb\u30de\u30c3\u30d4\u30f3\u30b0","text":""},{"location":"ja/rbac/kubernetes-rbac/#hexabase-kubernetes","title":"Hexabase \u304b\u3089 Kubernetes \u30ed\u30fc\u30eb\u5909\u63db","text":"Hexabase \u30ed\u30fc\u30eb Kubernetes ClusterRole \u6a29\u9650 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7ba1\u7406\u8005 cluster-admin (namespaced) \u5272\u308a\u5f53\u3066\u3089\u308c\u305f namespace \u5185\u306e\u5b8c\u5168\u5236\u5fa1 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u958b\u767a\u8005 edit \u30a2\u30d7\u30ea\u3068\u30b5\u30fc\u30d3\u30b9\u306e\u4f5c\u6210\u3001\u66f4\u65b0\u3001\u524a\u9664 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u95b2\u89a7\u8005 view \u30ea\u30bd\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9"},{"location":"ja/rbac/kubernetes-rbac/#namespace","title":"Namespace \u5206\u96e2","text":"<p>\u5404 Hexabase \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306f 1\u3064\u4ee5\u4e0a\u306e Kubernetes namespace \u306b\u30de\u30c3\u30d7\u3055\u308c\u307e\u3059\uff1a</p> <ul> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 Namespace: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7528\u306e\u30d7\u30e9\u30a4\u30de\u30ea namespace</li> <li>\u30b7\u30b9\u30c6\u30e0 Namespace: \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u7ba1\u7406\u30ea\u30bd\u30fc\u30b9\u7528</li> <li>\u76e3\u8996 Namespace: \u30aa\u30d6\u30b6\u30fc\u30d0\u30d3\u30ea\u30c6\u30a3\u30c4\u30fc\u30eb\u7528</li> </ul>"},{"location":"ja/rbac/kubernetes-rbac/#_3","title":"\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u7ba1\u7406","text":"<p>Hexabase \u306f Kubernetes \u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u81ea\u52d5\u7684\u306b\u4f5c\u6210\u30fb\u7ba1\u7406\u3057\u307e\u3059\uff1a</p> <ol> <li>\u30e6\u30fc\u30b6\u30fc\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8: \u30af\u30e9\u30b9\u30bf\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b\u4eba\u9593\u30e6\u30fc\u30b6\u30fc\u7528</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8: \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u3068 CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u7528</li> <li>\u30b7\u30b9\u30c6\u30e0\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8: \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u7528</li> </ol>"},{"location":"ja/rbac/kubernetes-rbac/#_4","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li>Hexabase \u30ed\u30fc\u30eb\u3092\u4f7f\u7528: \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306b Kubernetes RBAC \u306e\u8907\u96d1\u3055\u3092\u7ba1\u7406\u3055\u305b\u308b</li> <li>\u5b9a\u671f\u76e3\u67fb: HKS \u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u3092\u901a\u3058\u3066\u30ed\u30fc\u30eb\u5272\u308a\u5f53\u3066\u3092\u30ec\u30d3\u30e5\u30fc</li> <li>\u6700\u5c0f\u6a29\u9650\u306b\u5f93\u3046: \u5fc5\u8981\u6700\u5c0f\u9650\u306e\u6a29\u9650\u3092\u5272\u308a\u5f53\u3066</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u6d3b\u7528: \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u5883\u754c\u306b\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5206\u96e2\u3092\u4f7f\u7528</li> </ol>"},{"location":"ja/rbac/kubernetes-rbac/#_5","title":"\u9ad8\u5ea6\u306a\u8a2d\u5b9a","text":"<p>\u30ab\u30b9\u30bf\u30e0 RBAC \u8981\u4ef6\u306e\u305f\u3081\u3001Hexabase \u306f\u4ee5\u4e0b\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059\uff1a</p> <ul> <li>\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u5b9a\u7fa9</li> <li>\u304d\u3081\u7d30\u304b\u3044\u6a29\u9650\u30dd\u30ea\u30b7\u30fc</li> <li>\u5916\u90e8 ID \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u306e\u7d71\u5408</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u4e3b\u5c0e\u306e\u30a2\u30af\u30bb\u30b9\u5236\u5fa1</li> </ul>"},{"location":"ja/rbac/overview/","title":"RBAC \u6982\u8981","text":"<p>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09\u306f\u3001Hexabase.AI \u5185\u3067\u30e6\u30fc\u30b6\u30fc\u3068\u30b5\u30fc\u30d3\u30b9\u304c\u5b9f\u884c\u3067\u304d\u308b\u3053\u3068\u3092\u5236\u9650\u3059\u308b\u30e1\u30ab\u30cb\u30ba\u30e0\u3067\u3059\u3002\u3053\u308c\u306f\u3001\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u74b0\u5883\u306b\u304a\u3051\u308b\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30ac\u30d0\u30ca\u30f3\u30b9\u306e\u91cd\u8981\u306a\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3067\u3042\u308a\u3001\u30e6\u30fc\u30b6\u30fc\u304c\u81ea\u5206\u306e\u5f79\u5272\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u30ea\u30bd\u30fc\u30b9\u306e\u307f\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3053\u3068\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/overview/#_1","title":"\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8","text":"<ul> <li>\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb: \u8a8d\u8a3c\u53ef\u80fd\u306a\u30a8\u30f3\u30c6\u30a3\u30c6\u30a3\u3002HKS \u3067\u306f\u3001**\u30e6\u30fc\u30b6\u30fc**\u307e\u305f\u306f**\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8**\u306e\u3044\u305a\u308c\u304b\u3067\u3059\u3002</li> <li>\u30ed\u30fc\u30eb: **\u6a29\u9650**\u306e\u96c6\u5408\u3002\u30ed\u30fc\u30eb\u306f\u3001\u4e00\u9023\u306e\u30ea\u30bd\u30fc\u30b9\u3067\u5b9f\u884c\u3067\u304d\u308b\u4e00\u9023\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u3092\u5b9a\u7fa9\u3057\u307e\u3059\u3002</li> <li>\u6a29\u9650: \u7279\u5b9a\u306e\u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3059\u308b\u7279\u5b9a\u306e\u30a2\u30af\u30b7\u30e7\u30f3\uff08\u52d5\u8a5e\uff09\u3092\u8a31\u53ef\u3059\u308b\u500b\u5225\u306e\u30eb\u30fc\u30eb\uff08\u4f8b\uff1a<code>Deployment</code> \u3092 <code>create</code>\u3001<code>Pod \u306e\u30ed\u30b0</code> \u3092 <code>get</code>\uff09\u3002</li> <li>\u30ed\u30fc\u30eb\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0: **\u30ed\u30fc\u30eb**\u3092**\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb**\u306b\u5272\u308a\u5f53\u3066\u308b\u30ea\u30f3\u30af\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u30e6\u30fc\u30b6\u30fc\u307e\u305f\u306f\u30b5\u30fc\u30d3\u30b9\u306b\u6a29\u9650\u304c\u4ed8\u4e0e\u3055\u308c\u307e\u3059\u3002</li> </ul> <p>\u57fa\u672c\u7684\u306a\u95a2\u4fc2\u306f\uff1a**\u30d7\u30ea\u30f3\u30b7\u30d1\u30eb\u306f\u30ed\u30fc\u30eb\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3092\u4ecb\u3057\u3066\u30ed\u30fc\u30eb\u304c\u5272\u308a\u5f53\u3066\u3089\u308c\u308b**\u3067\u3059\u3002</p> <pre><code>graph TD\n    User[\u30e6\u30fc\u30b6\u30fc] --&gt;|\u30d0\u30a4\u30f3\u30c9\u3055\u308c\u308b| RoleBinding(\u30ed\u30fc\u30eb\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0);\n    ServiceAccount[\u30b5\u30fc\u30d3\u30b9\u30a2\u30ab\u30a6\u30f3\u30c8] --&gt;|\u30d0\u30a4\u30f3\u30c9\u3055\u308c\u308b| RoleBinding;\n    RoleBinding --&gt;|\u5272\u308a\u5f53\u3066| Role(\u30ed\u30fc\u30eb);\n    Role --&gt;|\u542b\u3080| Permission1(\u6a29\u9650: get pods);\n    Role --&gt;|\u542b\u3080| Permission2(\u6a29\u9650: create deployments);\n    Role --&gt;|\u542b\u3080| Permission3(\u6a29\u9650: ...);</code></pre>"},{"location":"ja/rbac/overview/#2-rbac","title":"2\u3064\u306e\u30ec\u30d9\u30eb\u306e RBAC","text":"<p>Hexabase.AI \u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u7ba1\u7406\u3068\u305d\u306e\u4e2d\u3067\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7ba1\u7406\u306e\u9593\u3067\u660e\u78ba\u306a\u95a2\u5fc3\u306e\u5206\u96e2\u3092\u63d0\u4f9b\u3059\u308b\u305f\u3081\u306b\u30012\u5c64 RBAC \u30b7\u30b9\u30c6\u30e0\u3092\u7279\u5fb4\u3068\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/rbac/overview/#1-rbac","title":"1. \u7d44\u7e54 RBAC","text":"<ul> <li>\u30b9\u30b3\u30fc\u30d7: \u7d44\u7e54\u5168\u4f53\u306e\u30ea\u30bd\u30fc\u30b9\u3068\u8a2d\u5b9a\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002</li> <li>\u76ee\u7684: \u8acb\u6c42\u3001\u30e6\u30fc\u30b6\u30fc\u62db\u5f85\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u3001SSO \u306a\u3069\u306e\u30b0\u30ed\u30fc\u30d0\u30eb\u8a2d\u5b9a\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002</li> <li>\u4e3b\u8981\u30ed\u30fc\u30eb:</li> <li><code>organization_admin</code>: \u7d44\u7e54\u306e\u5b8c\u5168\u5236\u5fa1\u3002\u8acb\u6c42\u3001\u30e6\u30fc\u30b6\u30fc\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u7ba1\u7406\u3067\u304d\u307e\u3059\u3002</li> <li><code>organization_user</code>: \u7d44\u7e54\u306e\u6a19\u6e96\u30e1\u30f3\u30d0\u30fc\u3002\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u3067\u30ed\u30fc\u30eb\u3092\u5272\u308a\u5f53\u3066\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u304c\u3001\u7d44\u7e54\u81ea\u4f53\u3092\u7ba1\u7406\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002</li> </ul>"},{"location":"ja/rbac/overview/#2-rbac_1","title":"2. \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 RBAC","text":"<ul> <li>\u30b9\u30b3\u30fc\u30d7: \u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08Kubernetes namespace \u306b\u5bfe\u5fdc\uff09_\u5185_\u306e\u30ea\u30bd\u30fc\u30b9\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002</li> <li>\u76ee\u7684: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3001\u30b5\u30fc\u30d3\u30b9\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u3001CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3001\u305d\u306e\u4ed6\u306e Kubernetes \u30cd\u30a4\u30c6\u30a3\u30d6\u30ea\u30bd\u30fc\u30b9\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002</li> <li>\u4e3b\u8981\u30ed\u30fc\u30eb\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\uff09:</li> <li><code>workspace_admin</code>: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e\u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u306e\u5b8c\u5168\u5236\u5fa1\u3002\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3078\u306e\u30e6\u30fc\u30b6\u30fc\u30a2\u30af\u30bb\u30b9\u3092\u7ba1\u7406\u3067\u304d\u307e\u3059\u3002</li> <li><code>developer</code>: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\uff08Deployments\u3001Pods\u3001Services\uff09\u3092\u4f5c\u6210\u3001\u66f4\u65b0\u3001\u524a\u9664\u3067\u304d\u307e\u3059\u3002\u30e6\u30fc\u30b6\u30fc\u30a2\u30af\u30bb\u30b9\u306f\u7ba1\u7406\u3067\u304d\u307e\u305b\u3093\u3002</li> <li><code>viewer</code>: \u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9\u3002\u30ea\u30bd\u30fc\u30b9\u3068\u30ed\u30b0\u3092\u8868\u793a\u3067\u304d\u307e\u3059\u304c\u3001\u5909\u66f4\u306f\u3067\u304d\u307e\u305b\u3093\u3002</li> </ul> <p>\u3053\u306e\u30c7\u30e5\u30a2\u30eb\u30b7\u30b9\u30c6\u30e0\u306b\u3088\u308a\u3001\u4e2d\u592e\u306e IT \u307e\u305f\u306f\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30c1\u30fc\u30e0\u304c\u7d44\u7e54\u5168\u4f53\u3092\u7ba1\u7406\u3057\u306a\u304c\u3089\u3001\u958b\u767a\u30c1\u30fc\u30e0\u304c\u5272\u308a\u5f53\u3066\u3089\u308c\u305f\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u30ac\u30fc\u30c9\u30ec\u30fc\u30eb\u5185\u3067\u72ec\u81ea\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u7ba1\u7406\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002</p>"},{"location":"ja/rbac/overview/#kubernetes-rbac","title":"Kubernetes RBAC \u3068\u306e\u95a2\u4fc2","text":"<p>HKS RBAC \u304c\u30cd\u30a4\u30c6\u30a3\u30d6 Kubernetes RBAC \u30b7\u30b9\u30c6\u30e0\u3068\u3069\u306e\u3088\u3046\u306b\u95a2\u4fc2\u3059\u308b\u304b\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u304c\u91cd\u8981\u3067\u3059\u3002</p> <ul> <li>HKS RBAC \u306f Kubernetes RBAC \u306e\u4e0a\u306e\u62bd\u8c61\u5316\u30ec\u30a4\u30e4\u30fc\u3067\u3059\u3002</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7528\u306b Hexabase.AI \u3067 <code>Role</code> \u3068 <code>RoleBinding</code> \u3092\u4f5c\u6210\u3059\u308b\u3068\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306f\u57fa\u76e4\u3068\u306a\u308b Kubernetes \u30af\u30e9\u30b9\u30bf\u30fc\u5185\u3067\u5bfe\u5fdc\u3059\u308b <code>Role</code> \u3068 <code>RoleBinding</code>\uff08\u307e\u305f\u306f <code>ClusterRole</code> \u3068 <code>ClusterRoleBinding</code>\uff09\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u81ea\u52d5\u7684\u306b\u4f5c\u6210\u3057\u307e\u3059\u3002</li> <li>\u3053\u308c\u306b\u3088\u308a\u3001HKS UI/CLI \u3092\u901a\u3058\u3066\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u5bfe\u8a71\u3059\u308b\u5834\u5408\u3067\u3082\u3001<code>kubectl</code> \u3092\u4ecb\u3057\u3066 Kubernetes API \u30b5\u30fc\u30d0\u30fc\u3068\u76f4\u63a5\u5bfe\u8a71\u3059\u308b\u5834\u5408\u3067\u3082\u3001\u6a29\u9650\u304c\u4e00\u8cab\u3057\u3066\u9069\u7528\u3055\u308c\u308b\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u307e\u3059\u3002</li> </ul> <p>\u3053\u306e\u62bd\u8c61\u5316\u306b\u3088\u308a\u3001\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u74b0\u5883\u3067\u306e\u6a29\u9650\u7ba1\u7406\u304c\u7c21\u7d20\u5316\u3055\u308c\u307e\u3059\u3002HKS \u30ec\u30d9\u30eb\u3067\u30e6\u30fc\u30b6\u30fc\u3068\u30ed\u30fc\u30eb\u3092\u7ba1\u7406\u3059\u308b\u3068\u3001HKS \u304c\u6b63\u3057\u3044 Kubernetes namespace \u3067\u6b63\u3057\u3044\u30d0\u30a4\u30f3\u30c7\u30a3\u30f3\u30b0\u3092\u4f5c\u6210\u3059\u308b\u8907\u96d1\u3055\u3092\u51e6\u7406\u3057\u307e\u3059\u3002</p> <p>\u5404\u30b7\u30b9\u30c6\u30e0\u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001Hexabase RBAC \u304a\u3088\u3073 Kubernetes RBAC \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/rbac/permission-model/","title":"\u6a29\u9650\u30e2\u30c7\u30eb","text":"<p>Hexabase.AI \u6a29\u9650\u30e2\u30c7\u30eb\u306f\u3001\u67d4\u8edf\u3067\u62e1\u5f35\u53ef\u80fd\u306b\u306a\u308b\u3088\u3046\u8a2d\u8a08\u3055\u308c\u3066\u304a\u308a\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5185\u306e\u3059\u3079\u3066\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u306b\u304d\u3081\u7d30\u304b\u3044\u5236\u5fa1\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u307b\u3068\u3093\u3069\u306e\u30e6\u30fc\u30b6\u30fc\u306f\u7d44\u307f\u8fbc\u307f\u30ed\u30fc\u30eb\u3092\u4f7f\u7528\u3057\u307e\u3059\u304c\u3001\u57fa\u76e4\u3068\u306a\u308b\u6a29\u9650\u30e2\u30c7\u30eb\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u306f\u3001\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u305f\u308a\u3001\u76e3\u67fb\u76ee\u7684\u3067\u6709\u7528\u3067\u3059\u3002</p>"},{"location":"ja/rbac/permission-model/#_2","title":"\u6a29\u9650\u306e\u69cb\u9020","text":"<p>\u6a29\u9650\u306f\u3001\u8ab0\u304c\u3069\u306e\u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3057\u3066\u4f55\u3092\u3067\u304d\u308b\u304b\u3092\u5b9a\u7fa9\u3059\u308b\u5358\u4e00\u306e\u30eb\u30fc\u30eb\u3067\u3059\u3002\u5404\u6a29\u9650\u306f3\u3064\u306e\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3067\u69cb\u6210\u3055\u308c\u307e\u3059\uff1a</p> <ol> <li><code>apiGroups</code>: \u30a2\u30af\u30bb\u30b9\u3055\u308c\u308b API \u306e\u30b0\u30eb\u30fc\u30d7\u3002\u30b3\u30a2 Kubernetes \u30ea\u30bd\u30fc\u30b9\u306e\u5834\u5408\u3001\u30b0\u30eb\u30fc\u30d7\u306f <code>\"\"</code>\uff08\u7a7a\u6587\u5b57\u5217\uff09\u3067\u3059\u3002\u305d\u306e\u4ed6\u306e\u5834\u5408\u3001<code>apps</code>\u3001<code>batch</code>\u3001<code>hks.io</code> \u306a\u3069\u306e\u540d\u524d\u4ed8\u304d\u30b0\u30eb\u30fc\u30d7\u3067\u3059\u3002</li> <li><code>resources</code>: \u6a29\u9650\u304c\u9069\u7528\u3055\u308c\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u30bf\u30a4\u30d7\uff08\u4f8b\uff1a<code>pods</code>\u3001<code>deployments</code>\u3001<code>backupplans</code>\uff09\u3002</li> <li><code>verbs</code>: \u30ea\u30bd\u30fc\u30b9\u3067\u8a31\u53ef\u3055\u308c\u308b\u30a2\u30af\u30b7\u30e7\u30f3\uff08\u4f8b\uff1a<code>get</code>\u3001<code>create</code>\u3001<code>delete</code>\uff09\u3002</li> </ol> <p>\u6a29\u9650\u30b9\u30c6\u30fc\u30c8\u30e1\u30f3\u30c8\u306e\u4f8b: \"<code>apps</code>\uff08<code>apiGroup</code>\uff09\u3067 <code>deployments</code>\uff08<code>resource</code>\uff09\u306e <code>creating</code>\uff08<code>verb</code>\uff09\u3092\u8a31\u53ef\u3057\u307e\u3059\u3002\"</p>"},{"location":"ja/rbac/permission-model/#_3","title":"\u30ed\u30fc\u30eb\u5185\u3067\u306e\u6a29\u9650\u306e\u5b9a\u7fa9\u65b9\u6cd5","text":"<p>\u30ab\u30b9\u30bf\u30e0 <code>WorkspaceRole</code> \u3067\u306f\u3001\u6a29\u9650\u306f\u30ea\u30b9\u30c8\u3067\u5b9a\u7fa9\u3055\u308c\u307e\u3059\u3002</p> <pre><code>apiVersion: hks.io/v1\nkind: WorkspaceRole\nmetadata:\n  name: custom-viewer\nspec:\n  permissions:\n    # \u30eb\u30fc\u30eb 1: \u30b3\u30a2\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u30ea\u30bd\u30fc\u30b9\u306e\u8868\u793a\u3092\u8a31\u53ef\n    - apiGroups: [\"\", \"apps\", \"batch\"]\n      resources: [\"pods\", \"deployments\", \"jobs\", \"services\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n    # \u30eb\u30fc\u30eb 2: \u30dd\u30c3\u30c9\u30ed\u30b0\u306e\u8868\u793a\u3092\u8a31\u53ef\n    - apiGroups: [\"\"]\n      resources: [\"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n    # \u30eb\u30fc\u30eb 3: HKS \u56fa\u6709\u30ea\u30bd\u30fc\u30b9\u306e\u8868\u793a\u3092\u8a31\u53ef\n    - apiGroups: [\"hks.io\"]\n      resources: [\"backups\", \"functions\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"ja/rbac/permission-model/#_4","title":"\u4e00\u822c\u7684\u306a\u52d5\u8a5e","text":"<p>\u6a29\u9650\u3067\u5272\u308a\u5f53\u3066\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u6700\u3082\u4e00\u822c\u7684\u306a\u30a2\u30af\u30b7\u30e7\u30f3\uff08\u52d5\u8a5e\uff09\u3067\u3059\u3002</p> \u52d5\u8a5e \u8aac\u660e <code>get</code> \u540d\u524d\u3067\u5358\u4e00\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u53d6\u5f97 <code>list</code> \u30ea\u30bd\u30fc\u30b9\u306e\u30ea\u30b9\u30c8\u3092\u53d6\u5f97 <code>watch</code> \u30ea\u30bd\u30fc\u30b9\u306e\u5909\u66f4\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u300c\u76e3\u8996\u300d <code>create</code> \u65b0\u3057\u3044\u30ea\u30bd\u30fc\u30b9\u3092\u4f5c\u6210 <code>update</code> \u65e2\u5b58\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u5909\u66f4 <code>patch</code> \u65e2\u5b58\u306e\u30ea\u30bd\u30fc\u30b9\u306b\u90e8\u5206\u7684\u306a\u5909\u66f4\u3092\u9069\u7528 <code>delete</code> \u30ea\u30bd\u30fc\u30b9\u3092\u524a\u9664 <code>deletecollection</code> \u8907\u6570\u306e\u30ea\u30bd\u30fc\u30b9\u3092\u4e00\u5ea6\u306b\u524a\u9664 <code>*</code> \u3059\u3079\u3066\u306e\u52d5\u8a5e\u3092\u8868\u3059\u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9\u3002\u6ce8\u610f\u3057\u3066\u4f7f\u7528"},{"location":"ja/rbac/permission-model/#_5","title":"\u30ea\u30bd\u30fc\u30b9\u547d\u540d\u3068\u30b5\u30d6\u30ea\u30bd\u30fc\u30b9","text":"<p>\u4e00\u90e8\u306e\u30ea\u30bd\u30fc\u30b9\u306b\u306f\u3001\u72ec\u7acb\u3057\u3066\u5236\u5fa1\u3067\u304d\u308b\u30b5\u30d6\u30ea\u30bd\u30fc\u30b9\u304c\u3042\u308a\u307e\u3059\u3002\u6700\u3082\u4e00\u822c\u7684\u306a\u4f8b\u306f <code>pods/log</code> \u3067\u3059\u3002</p> <ul> <li>\u30dd\u30c3\u30c9\u3092\u8868\u793a\u3059\u308b\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b\u306b\u306f\u3001<code>pods</code> \u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3059\u308b <code>get</code> \u304c\u5fc5\u8981\u3067\u3059\u3002</li> <li>\u30dd\u30c3\u30c9\u306e\u30ed\u30b0\u3092\u8868\u793a\u3059\u308b\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b\u306b\u306f\u3001<code>pods/log</code> \u30b5\u30d6\u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3059\u308b <code>get</code> \u304c\u5fc5\u8981\u3067\u3059\u3002</li> </ul> <p>\u3053\u308c\u306b\u3088\u308a\u3001\u30dd\u30c3\u30c9\u304c\u52d5\u4f5c\u3057\u3066\u3044\u308b\u3053\u3068\u306f\u78ba\u8a8d\u3067\u304d\u308b\u304c\u3001\u30ed\u30b0\u5185\u306e\u6f5c\u5728\u7684\u306b\u6a5f\u5bc6\u6027\u306e\u9ad8\u3044\u60c5\u5831\u306b\u306f\u30a2\u30af\u30bb\u30b9\u3067\u304d\u306a\u3044\u30e6\u30fc\u30b6\u30fc\u7528\u306e\u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/rbac/permission-model/#_6","title":"\u96c6\u7d04\u30ed\u30fc\u30eb","text":"<p>Hexabase.AI \u306f Kubernetes \u306e\u30ed\u30fc\u30eb\u96c6\u7d04\u6a5f\u80fd\u3092\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u4e00\u90e8\u306e\u30ed\u30fc\u30eb\u304c\u4ed6\u306e\u30ed\u30fc\u30eb\u3067\u69cb\u6210\u3055\u308c\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002</p> <p>\u4f8b\u3048\u3070\u3001HKS \u306e\u7d44\u307f\u8fbc\u307f <code>developer</code> \u30ed\u30fc\u30eb\u306f\u3001\u5b9f\u969b\u306b\u306f\u3088\u308a\u5c0f\u3055\u304f\u3001\u3088\u308a\u7126\u70b9\u3092\u7d5e\u3063\u305f\u8907\u6570\u306e\u30ed\u30fc\u30eb\u3092\u96c6\u7d04\u3057\u3066\u3044\u307e\u3059\uff1a</p> <ul> <li>\u30b3\u30a2\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\uff08<code>pods</code>\u3001<code>deployments</code>\uff09\u3092\u7ba1\u7406\u3059\u308b\u30ed\u30fc\u30eb</li> <li>\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\uff08<code>services</code>\u3001<code>ingresses</code>\uff09\u3092\u7ba1\u7406\u3059\u308b\u30ed\u30fc\u30eb</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e CI/CD \u30ea\u30bd\u30fc\u30b9\u3092\u7ba1\u7406\u3059\u308b\u30ed\u30fc\u30eb</li> </ul> <p>\u3053\u308c\u306b\u3088\u308a\u3001\u30b7\u30b9\u30c6\u30e0\u306e\u7ba1\u7406\u3068\u62e1\u5f35\u304c\u5bb9\u6613\u306b\u306a\u308a\u307e\u3059\u3002HKS \u306b\u65b0\u6a5f\u80fd\u304c\u8ffd\u52a0\u3055\u308c\u308b\u3068\u3001\u305d\u306e\u6a5f\u80fd\u7528\u306e\u65b0\u3057\u3044\u8a73\u7d30\u306a\u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u3001\u30d9\u30fc\u30b9\u30ed\u30fc\u30eb\uff08<code>admin</code>\u3001<code>developer</code>\u3001<code>viewer</code>\uff09\u3092\u76f4\u63a5\u5909\u66f4\u3059\u308b\u3053\u3068\u306a\u304f\u3001\u30d9\u30fc\u30b9\u30ed\u30fc\u30eb\u306b\u96c6\u7d04\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/rbac/permission-model/#kubernetes","title":"\u751f\u306e Kubernetes \u30ed\u30fc\u30eb\u306e\u8868\u793a","text":"<p><code>workspace_admin</code> \u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b\u5834\u5408\u3001HKS \u304c\u72ec\u81ea\u306e <code>WorkspaceRole</code> \u304b\u3089\u751f\u6210\u3059\u308b\u751f\u306e Kubernetes <code>Role</code> \u3092\u8868\u793a\u3067\u304d\u307e\u3059\u3002</p> <pre><code># \u307e\u305a\u3001\u751f\u6210\u3055\u308c\u305f\u30ed\u30fc\u30eb\u306e\u540d\u524d\u3092\u898b\u3064\u3051\u307e\u3059\n# \u901a\u5e38\u3001'hks-' \u304c\u30d7\u30ec\u30d5\u30a3\u30c3\u30af\u30b9\u3068\u3057\u3066\u4ed8\u304d\u307e\u3059\nkubectl get roles -n &lt;your-workspace-namespace&gt;\n\n# \u6b21\u306b\u3001\u30ed\u30fc\u30eb\u306e YAML \u5b9a\u7fa9\u3092\u8868\u793a\u3057\u307e\u3059\nkubectl get role &lt;generated-role-name&gt; -o yaml\n</code></pre> <p>\u3053\u308c\u306f\u3001Kubernetes \u30ec\u30d9\u30eb\u3067\u9069\u7528\u3055\u308c\u3066\u3044\u308b\u6b63\u78ba\u306a\u6a29\u9650\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306e\u6709\u7528\u306a\u30c7\u30d0\u30c3\u30b0\u30c4\u30fc\u30eb\u3067\u3059\u3002</p>"},{"location":"ja/rbac/role-mappings/","title":"\u30ed\u30fc\u30eb\u30de\u30c3\u30d4\u30f3\u30b0","text":"<p>Hexabase.AI \u306e\u7d44\u307f\u8fbc\u307f\u30ed\u30fc\u30eb\u304c\u7279\u5b9a\u306e\u6a29\u9650\u306b\u3069\u306e\u3088\u3046\u306b\u30de\u30c3\u30d7\u3055\u308c\u308b\u304b\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u306f\u3001\u52b9\u679c\u7684\u306a\u30a2\u30af\u30bb\u30b9\u7ba1\u7406\u306e\u9375\u3067\u3059\u3002\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3067\u306f\u3001\u7d44\u7e54\u30ec\u30d9\u30eb\u3068\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30d9\u30eb\u306e\u4e21\u65b9\u3067\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u30ed\u30fc\u30eb\u306b\u95a2\u9023\u3059\u308b\u6a29\u9650\u3092\u8a73\u3057\u304f\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/role-mappings/#_2","title":"\u7d44\u7e54\u30ec\u30d9\u30eb\u30ed\u30fc\u30eb","text":"<p>\u3053\u308c\u3089\u306e\u30ed\u30fc\u30eb\u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u7ba1\u7406\u304a\u3088\u3073\u904b\u55b6\u6a5f\u80fd\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002</p> \u30ed\u30fc\u30eb \u8aac\u660e \u4e3b\u8981\u6a29\u9650 <code>organization_admin</code> \u6700\u9ad8\u30ec\u30d9\u30eb\u306e\u30a2\u30af\u30bb\u30b9\u3002\u7d44\u7e54\u5168\u4f53\u3092\u7ba1\u7406\u3057\u307e\u3059\u3002 - \u30e6\u30fc\u30b6\u30fc\u306e\u62db\u5f85\u3068\u7ba1\u7406- \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u4f5c\u6210\u3001\u66f4\u65b0\u3001\u524a\u9664- \u30b7\u30f3\u30b0\u30eb\u30b5\u30a4\u30f3\u30aa\u30f3\uff08SSO\uff09\u306e\u8a2d\u5b9a- \u8acb\u6c42\u3068\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u306e\u7ba1\u7406- \u7d44\u7e54\u5168\u4f53\u306e\u76e3\u67fb\u30ed\u30b0\u306e\u8868\u793a- \u4efb\u610f\u306e\u30e6\u30fc\u30b6\u30fc\u306b\u4efb\u610f\u306e\u30ed\u30fc\u30eb\u3092\u5272\u308a\u5f53\u3066 <code>organization_user</code> \u7d44\u7e54\u306e\u6a19\u6e96\u30e1\u30f3\u30d0\u30fc\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u30ed\u30fc\u30eb\u3002 - \u62db\u5f85\u3055\u308c\u305f\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u8868\u793a- \u30e6\u30fc\u30b6\u30fc\u3001\u8acb\u6c42\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306f\u7ba1\u7406\u4e0d\u53ef- \u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9_\u5185_\u3067\u30ed\u30fc\u30eb\u3092\u5272\u308a\u5f53\u3066\u53ef\u80fd"},{"location":"ja/rbac/role-mappings/#_3","title":"\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30d9\u30eb\u30ed\u30fc\u30eb","text":"<p>\u3053\u308c\u3089\u306e\u30ed\u30fc\u30eb\u306f\u3001\u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9_\u5185_\u306e Kubernetes \u30ea\u30bd\u30fc\u30b9\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3092\u5236\u5fa1\u3057\u307e\u3059\u3002HKS \u306f\u3001\u6700\u3082\u4e00\u822c\u7684\u306a\u4f7f\u7528\u4f8b\u3092\u30ab\u30d0\u30fc\u3059\u308b3\u3064\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u30ed\u30fc\u30eb\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/rbac/role-mappings/#workspace_admin","title":"<code>workspace_admin</code>","text":"<ul> <li>\u8aac\u660e: \u7279\u5b9a\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u5b8c\u5168\u5236\u5fa1\u3002\u3053\u306e\u30ed\u30fc\u30eb\u306f\u901a\u5e38\u3001\u74b0\u5883\u306b\u8cac\u4efb\u3092\u6301\u3064\u30c1\u30fc\u30e0\u30ea\u30fc\u30c9\u307e\u305f\u306f DevOps \u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u5272\u308a\u5f53\u3066\u3089\u308c\u307e\u3059\u3002</li> <li>\u4e3b\u8981 HKS \u6a29\u9650:</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3078\u306e\u30e6\u30fc\u30b6\u30fc\u30a2\u30af\u30bb\u30b9\u7ba1\u7406\uff08<code>developer</code> \u307e\u305f\u306f <code>viewer</code> \u30ed\u30fc\u30eb\u306e\u5272\u308a\u5f53\u3066\uff09</li> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3084\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dd\u30ea\u30b7\u30fc\u306a\u3069\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u8a2d\u5b9a\u306e\u69cb\u6210</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e\u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u3068\u8a2d\u5b9a\u306e\u8868\u793a</li> <li>\u30de\u30c3\u30d7\u3055\u308c\u305f Kubernetes \u6a29\u9650:</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e namespace \u5185\u306e <code>*</code>\uff08\u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\uff09\u306b\u5bfe\u3059\u308b <code>*</code>\uff08\u3059\u3079\u3066\u306e\u52d5\u8a5e\uff09\u3002\u3053\u308c\u306f Kubernetes \u306e\u7d44\u307f\u8fbc\u307f <code>admin</code> ClusterRole \u3068\u540c\u7b49\u3067\u3059\u304c\u3001namespace \u306b\u30b9\u30b3\u30fc\u30d7\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> </ul>"},{"location":"ja/rbac/role-mappings/#developer","title":"<code>developer</code>","text":"<ul> <li>\u8aac\u660e: \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u958b\u767a\u8005\u306e\u6a19\u6e96\u6a29\u9650\u3002\u6a5f\u5bc6\u6027\u306e\u9ad8\u3044\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3084\u30e6\u30fc\u30b6\u30fc\u7ba1\u7406\u8a2d\u5b9a\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3092\u8a31\u53ef\u3059\u308b\u3053\u3068\u306a\u304f\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u5b8c\u5168\u306a\u30e9\u30a4\u30d5\u30b5\u30a4\u30af\u30eb\u7ba1\u7406\u3092\u53ef\u80fd\u306b\u3057\u307e\u3059\u3002</li> <li>\u4e3b\u8981 HKS \u6a29\u9650:</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306e\u4f5c\u6210\u3001\u66f4\u65b0\u3001\u524a\u9664</li> <li>\u30ed\u30b0\u306e\u8868\u793a\u3068\u30dd\u30c3\u30c9\u3078\u306e exec</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u8a2d\u5b9a\u306e\u7ba1\u7406\uff08ConfigMaps\u3001Secrets\uff09</li> <li>\u30de\u30c3\u30d7\u3055\u308c\u305f Kubernetes \u6a29\u9650\uff08\u8981\u7d04\uff09:</li> <li>\u4ee5\u4e0b\u306b\u5bfe\u3059\u308b <code>get</code>\u3001<code>list</code>\u3001<code>watch</code>\u3001<code>create</code>\u3001<code>update</code>\u3001<code>patch</code>\u3001<code>delete</code>:<ul> <li><code>pods</code>\u3001<code>deployments</code>\u3001<code>statefulsets</code>\u3001<code>daemonsets</code></li> <li><code>services</code>\u3001<code>ingresses</code></li> <li><code>jobs</code>\u3001<code>cronjobs</code></li> <li><code>configmaps</code>\u3001<code>secrets</code></li> <li><code>persistentvolumeclaims</code></li> </ul> </li> <li><code>pods/log</code> \u306b\u5bfe\u3059\u308b <code>get</code>\u3001<code>list</code>\u3001<code>watch</code></li> </ul>"},{"location":"ja/rbac/role-mappings/#viewer","title":"<code>viewer</code>","text":"<ul> <li>\u8aac\u660e: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3078\u306e\u8aad\u307f\u53d6\u308a\u5c02\u7528\u30a2\u30af\u30bb\u30b9\u3002\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u89b3\u5bdf\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u5909\u66f4\u3059\u308b\u5fc5\u8981\u304c\u306a\u3044\u30b9\u30c6\u30fc\u30af\u30db\u30eb\u30c0\u30fc\u3001\u30b5\u30dd\u30fc\u30c8\u30b9\u30bf\u30c3\u30d5\u3001\u30b8\u30e5\u30cb\u30a2\u958b\u767a\u8005\u306b\u6700\u9069\u3067\u3059\u3002</li> <li>\u4e3b\u8981 HKS \u6a29\u9650:</li> <li>\u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u3068\u305d\u306e\u8a2d\u5b9a\u306e\u8868\u793a</li> <li>\u30ed\u30b0\u306e\u8868\u793a</li> <li>\u30de\u30c3\u30d7\u3055\u308c\u305f Kubernetes \u6a29\u9650:</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e namespace \u5185\u306e\u3059\u3079\u3066\u306e\u30ea\u30bd\u30fc\u30b9\u306b\u5bfe\u3059\u308b <code>get</code>\u3001<code>list</code>\u3001<code>watch</code>\u3002\u3053\u308c\u306f Kubernetes \u306e\u7d44\u307f\u8fbc\u307f <code>view</code> ClusterRole \u3068\u540c\u7b49\u3067\u3059\u3002</li> </ul>"},{"location":"ja/rbac/role-mappings/#_4","title":"\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u306e\u4f5c\u6210\uff08\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\uff09","text":"<p>\u3088\u308a\u304d\u3081\u7d30\u304b\u3044\u5236\u5fa1\u304c\u5fc5\u8981\u306a\u7d44\u7e54\u5411\u3051\u306b\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u3067\u306f\u30ab\u30b9\u30bf\u30e0\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ed\u30fc\u30eb\u306e\u4f5c\u6210\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u4f8b: <code>db_operator</code> \u30ed\u30fc\u30eb\u306e\u4f5c\u6210</p> <p>StatefulSets\uff08\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u7528\uff09\u3068\u305d\u308c\u306b\u95a2\u9023\u3059\u308b Secrets \u3068 PVC \u306e\u307f\u3092\u7ba1\u7406\u3067\u304d\u308b\u30ed\u30fc\u30eb\u304c\u5fc5\u8981\u3060\u3068\u3057\u307e\u3059\u3002</p> <pre><code># custom-role-db-operator.yaml\napiVersion: hks.io/v1\nkind: WorkspaceRole\nmetadata:\n  name: db-operator\nspec:\n  # \u3053\u306e\u30ed\u30fc\u30eb\u304c\u4ed8\u4e0e\u3059\u308b\u6a29\u9650\n  permissions:\n    # StatefulSets \u306e\u5b8c\u5168\u5236\u5fa1\u3092\u8a31\u53ef\n    - resources: [\"statefulsets\"]\n      verbs: [\"*\"]\n    # secrets \u3068 PVC \u306e\u5b8c\u5168\u5236\u5fa1\u3092\u8a31\u53ef\n    - resources: [\"secrets\", \"persistentvolumeclaims\"]\n      verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n    # \u30c7\u30d0\u30c3\u30b0\u306e\u305f\u3081\u306e\u30dd\u30c3\u30c9\u8868\u793a\u3092\u8a31\u53ef\n    - resources: [\"pods\", \"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>\u3053\u306e\u30de\u30cb\u30d5\u30a7\u30b9\u30c8\u3092\u9069\u7528\u3057\u305f\u5f8c\u3001\u7d44\u307f\u8fbc\u307f\u30ed\u30fc\u30eb\u3068\u540c\u69d8\u306b\u3001\u4efb\u610f\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3067\u30e6\u30fc\u30b6\u30fc\u306b <code>db_operator</code> \u30ed\u30fc\u30eb\u3092\u5272\u308a\u5f53\u3066\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002HKS \u306f\u3001\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5bfe\u5fdc\u3059\u308b Kubernetes <code>Role</code> \u3068 <code>RoleBinding</code> \u3092\u81ea\u52d5\u7684\u306b\u751f\u6210\u3057\u307e\u3059\u3002</p>"},{"location":"ja/registry/","title":"\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30fc\u30d3\u30b9","text":"<p>Hexabase.AI \u306f\u3001\u7d44\u7e54\u5185\u3067\u306e\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u5b89\u5168\u306a\u4fdd\u5b58\u3001\u7ba1\u7406\u3001\u914d\u5e03\u3092\u53ef\u80fd\u306b\u3059\u308b\u5305\u62ec\u7684\u306a\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30fc\u30d3\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u3057\u3066 Harbor \u3092\u57fa\u76e4\u3068\u3057\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3001\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001CI/CD \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3068\u306e\u30b7\u30fc\u30e0\u30ec\u30b9\u306a\u7d71\u5408\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002</p>"},{"location":"ja/registry/#_2","title":"\u6982\u8981","text":"<p>\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30fc\u30d3\u30b9\u306f\u3001\u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u4e2d\u592e\u30cf\u30d6\u3068\u3057\u3066\u6a5f\u80fd\u3057\u3001\u5b89\u5168\u306a\u4fdd\u5b58\u3001\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3\u3001\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u306e\u30c7\u30d7\u30ed\u30a4\u3001CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u7ba1\u7406\u3001\u8907\u6570\u74b0\u5883\u306b\u308f\u305f\u308b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u914d\u5e03\u306a\u3069\u3001\u69d8\u3005\u306a\u7528\u9014\u3067\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u5b89\u5168\u6027\u3001\u30a2\u30af\u30bb\u30b7\u30d3\u30ea\u30c6\u30a3\u3001\u9069\u5207\u306a\u7ba1\u7406\u3092\u4fdd\u8a3c\u3057\u307e\u3059\u3002</p>"},{"location":"ja/registry/#_3","title":"\u4e3b\u8981\u6a5f\u80fd","text":"<ul> <li> \u30bb\u30ad\u30e5\u30a2\u30a4\u30e1\u30fc\u30b8\u30b9\u30c8\u30ec\u30fc\u30b8</li> </ul> <p>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u3068\u30a4\u30e1\u30fc\u30b8\u7f72\u540d\u306b\u3088\u308b\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3</p> <p> \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u6a5f\u80fd</p> <ul> <li> \u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3</li> </ul> <p>\u8a73\u7d30\u306a\u8106\u5f31\u6027\u30ec\u30dd\u30fc\u30c8\u4ed8\u304d\u81ea\u52d5\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30f3</p> <p> \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30f3</p> <ul> <li> \u30de\u30eb\u30c1\u30ec\u30b8\u30b9\u30c8\u30ea\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3</li> </ul> <p>\u30af\u30ed\u30b9\u30ea\u30fc\u30b8\u30e7\u30f3\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u707d\u5bb3\u5fa9\u65e7\u6a5f\u80fd</p> <p> \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3</p> <ul> <li> API\u7d71\u5408</li> </ul> <p>\u30b7\u30fc\u30e0\u30ec\u30b9\u306aCI/CD\u7d71\u5408\u306e\u305f\u3081\u306eRESTful API\u3068Webhook\u30b5\u30dd\u30fc\u30c8</p> <p> API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9</p>"},{"location":"ja/registry/#harbor","title":"Harbor\uff1a\u30c7\u30d5\u30a9\u30eb\u30c8\u30ec\u30b8\u30b9\u30c8\u30ea\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0","text":"<p>Hexabase.AI \u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u3057\u3066 Harbor \u3092\u4f7f\u7528\u3057\u3001\u4ee5\u4e0b\u3092\u63d0\u4f9b\u3057\u307e\u3059\uff1a</p>"},{"location":"ja/registry/#harbor_1","title":"Harbor \u306e\u30b3\u30a2\u6a5f\u80fd","text":"<ul> <li>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30d9\u30fc\u30b9\u7d44\u7e54: \u7d30\u304b\u3044\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u4ed8\u304d\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5225\u30a4\u30e1\u30fc\u30b8\u6574\u7406</li> <li>\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09: \u30e6\u30fc\u30b6\u30fc\u3068\u30b0\u30eb\u30fc\u30d7\u306e\u7d30\u5bc6\u306a\u6a29\u9650\u8a2d\u5b9a</li> <li>\u30a4\u30e1\u30fc\u30b8\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3: Trivy \u3068 Clair \u306b\u3088\u308b\u7d44\u307f\u8fbc\u307f\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30f3</li> <li>\u30b3\u30f3\u30c6\u30f3\u30c8\u30c8\u30e9\u30b9\u30c8: Docker Content Trust \u3068 Notary \u306b\u3088\u308b\u30a4\u30e1\u30fc\u30b8\u7f72\u540d</li> <li>\u30ac\u30d9\u30fc\u30b8\u30b3\u30ec\u30af\u30b7\u30e7\u30f3: \u672a\u4f7f\u7528\u30a4\u30e1\u30fc\u30b8\u3068\u30ec\u30a4\u30e4\u30fc\u306e\u81ea\u52d5\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7</li> <li>\u76e3\u67fb\u30ed\u30b0: \u3059\u3079\u3066\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u64cd\u4f5c\u306e\u5305\u62ec\u7684\u30ed\u30b0\u8a18\u9332</li> </ul>"},{"location":"ja/registry/#_4","title":"\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u62e1\u5f35\u6a5f\u80fd","text":"<ul> <li>\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30b7\u30fc\u30b5\u30dd\u30fc\u30c8: \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u6bce\u306e\u5206\u96e2\u3055\u308c\u305f\u30ec\u30b8\u30b9\u30c8\u30ea\u7a7a\u9593</li> <li>SSO\u7d71\u5408: \u30a2\u30a4\u30c7\u30f3\u30c6\u30a3\u30c6\u30a3\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u306e\u30b7\u30fc\u30e0\u30ec\u30b9\u7d71\u5408</li> <li>\u9ad8\u53ef\u7528\u6027: \u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b7\u30f3\u30b0\u4ed8\u304d\u30af\u30e9\u30b9\u30bf\u30fc\u5c55\u958b</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3068\u5fa9\u65e7: \u30dd\u30a4\u30f3\u30c8\u30a4\u30f3\u30bf\u30a4\u30e0\u5fa9\u65e7\u4ed8\u304d\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7</li> <li>\u76e3\u8996\u7d71\u5408: \u7d44\u307f\u8fbc\u307f\u30e1\u30c8\u30ea\u30af\u30b9\u3068\u30a2\u30e9\u30fc\u30c8</li> </ul>"},{"location":"ja/registry/#_5","title":"\u30ec\u30b8\u30b9\u30c8\u30ea\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":""},{"location":"ja/registry/#_6","title":"\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Hexabase.AI                          \u2502\n\u2502                 \u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9A\u2502  \u2502\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9B\u2502  \u2502\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9C\u2502     \u2502\n\u2502  \u2502  \u30ec\u30b8\u30b9\u30c8\u30ea \u2502  \u2502  \u30ec\u30b8\u30b9\u30c8\u30ea \u2502  \u2502  \u30ec\u30b8\u30b9\u30c8\u30ea \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                   Harbor \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0              \u2502\n\u2502              (\u30c7\u30d5\u30a9\u30eb\u30c8\u30ec\u30b8\u30b9\u30c8\u30ea\u30a8\u30f3\u30b8\u30f3)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    \u30b9\u30c8\u30ec\u30fc\u30b8\u30d0\u30c3\u30af\u30a8\u30f3\u30c9 (\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30b9\u30c8\u30ec\u30fc\u30b8 + DB)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/registry/#_7","title":"\u30b5\u30fc\u30d3\u30b9\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8","text":"<ul> <li>\u30ec\u30b8\u30b9\u30c8\u30ea\u30b3\u30a2: OCI\u6e96\u62e0\u306eHarbor\u30ec\u30b8\u30b9\u30c8\u30ea\u30a8\u30f3\u30b8\u30f3</li> <li>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9: \u30e1\u30bf\u30c7\u30fc\u30bf\u3068\u8a2d\u5b9a\u7528PostgreSQL</li> <li>Redis\u30ad\u30e3\u30c3\u30b7\u30e5: \u9ad8\u6027\u80fd\u30ad\u30e3\u30c3\u30b7\u30e5\u30ec\u30a4\u30e4\u30fc</li> <li>\u30b9\u30c8\u30ec\u30fc\u30b8\u30d0\u30c3\u30af\u30a8\u30f3\u30c9: \u30b3\u30f3\u30c6\u30ca\u30ec\u30a4\u30e4\u30fc\u7528\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30b9\u30c8\u30ec\u30fc\u30b8</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30b9\u30ad\u30e3\u30ca\u30fc: \u7d71\u5408\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3\u30a8\u30f3\u30b8\u30f3</li> <li>\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30f3\u30c8\u30ed\u30fc\u30e9\u30fc: \u30af\u30ed\u30b9\u30ea\u30fc\u30b8\u30e7\u30f3\u540c\u671f</li> </ul>"},{"location":"ja/registry/#_8","title":"\u4f7f\u3044\u59cb\u3081\u308b","text":""},{"location":"ja/registry/#1","title":"1. \u30ec\u30b8\u30b9\u30c8\u30ea\u3078\u306e\u30a2\u30af\u30bb\u30b9","text":"<p>\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306f\u5c02\u7528\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u53d6\u5f97\u3057\u307e\u3059\uff1a</p> <pre><code># \u30ec\u30b8\u30b9\u30c8\u30eaURL\u5f62\u5f0f\nhttps://&lt;workspace-id&gt;.registry.hexabase.ai\n\n# \u4f8b\nhttps://prod-workspace.registry.hexabase.ai\n</code></pre>"},{"location":"ja/registry/#2","title":"2. \u8a8d\u8a3c","text":""},{"location":"ja/registry/#docker-cli","title":"Docker CLI \u306e\u4f7f\u7528","text":"<pre><code># \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30ec\u30b8\u30b9\u30c8\u30ea\u306b\u30ed\u30b0\u30a4\u30f3\ndocker login prod-workspace.registry.hexabase.ai\n\n# Hexabase.AI\u8a8d\u8a3c\u60c5\u5831\u3092\u5165\u529b\nUsername: your-username\nPassword: your-token-or-password\n</code></pre>"},{"location":"ja/registry/#_9","title":"\u30ed\u30dc\u30c3\u30c8\u30a2\u30ab\u30a6\u30f3\u30c8\u306e\u4f7f\u7528","text":"<p>\u81ea\u52d5\u5316\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u7528\u306b\u30ed\u30dc\u30c3\u30c8\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u4f5c\u6210\uff1a</p> <pre><code># CLI\u7d4c\u7531\u3067\u30ed\u30dc\u30c3\u30c8\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u4f5c\u6210\nhb registry robot create \\\n  --name ci-cd-bot \\\n  --workspace production \\\n  --permissions read,write \\\n  --description \"CI/CD\u81ea\u52d5\u5316\u30a2\u30ab\u30a6\u30f3\u30c8\"\n\n# \u30ed\u30dc\u30c3\u30c8\u8a8d\u8a3c\u60c5\u5831\u3092\u4f7f\u7528\ndocker login prod-workspace.registry.hexabase.ai \\\n  -u robot$ci-cd-bot \\\n  -p &lt;robot-token&gt;\n</code></pre>"},{"location":"ja/registry/#3","title":"3. \u57fa\u672c\u64cd\u4f5c","text":""},{"location":"ja/registry/#_10","title":"\u30a4\u30e1\u30fc\u30b8\u306e\u30d7\u30c3\u30b7\u30e5","text":"<pre><code># \u30a4\u30e1\u30fc\u30b8\u306b\u30bf\u30b0\u4ed8\u3051\ndocker tag myapp:latest prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# \u30ec\u30b8\u30b9\u30c8\u30ea\u306b\u30d7\u30c3\u30b7\u30e5\ndocker push prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"ja/registry/#_11","title":"\u30a4\u30e1\u30fc\u30b8\u306e\u30d7\u30eb","text":"<pre><code># \u30ec\u30b8\u30b9\u30c8\u30ea\u304b\u3089\u30d7\u30eb\ndocker pull prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# Kubernetes\u306b\u30c7\u30d7\u30ed\u30a4\nkubectl create deployment myapp \\\n  --image=prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"ja/registry/#_12","title":"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u7ba1\u7406","text":""},{"location":"ja/registry/#_13","title":"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u4f5c\u6210","text":"<p>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u6574\u7406\u3057\u3001\u30a2\u30af\u30bb\u30b9\u30dd\u30ea\u30b7\u30fc\u3092\u5b9a\u7fa9\u3057\u307e\u3059\uff1a</p> <pre><code># \u65b0\u3057\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u4f5c\u6210\nhb registry project create \\\n  --name frontend-services \\\n  --workspace production \\\n  --visibility private \\\n  --description \"\u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\"\n\n# \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u30ea\u30b9\u30c8\nhb registry project list --workspace production\n</code></pre>"},{"location":"ja/registry/#_14","title":"\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u8a2d\u5b9a","text":""},{"location":"ja/registry/#_15","title":"\u30a2\u30af\u30bb\u30b9\u5236\u5fa1","text":"<pre><code># \u30d7\u30ed\u30b8\u30a7\u30af\u30c8RBAC\u8a2d\u5b9a\nproject: frontend-services\nmembers:\n  - user: \"alice@company.com\"\n    role: \"ProjectAdmin\"\n  - user: \"bob@company.com\"\n    role: \"Developer\"\n  - group: \"frontend-team\"\n    role: \"Developer\"\n\npolicies:\n  vulnerability_scanning: true\n  content_trust: required\n  prevent_vulnerable_images: true\n  auto_scan_on_push: true\n</code></pre>"},{"location":"ja/registry/#_16","title":"\u4fdd\u6301\u30dd\u30ea\u30b7\u30fc","text":"<pre><code># \u30a4\u30e1\u30fc\u30b8\u4fdd\u6301\u8a2d\u5b9a\nretention_policy:\n  rules:\n    - priority: 1\n      disabled: false\n      action: \"retain\"\n      template: \"latestPushedK\"\n      params:\n        latestPushedK: 10  # \u6700\u65b010\u30a4\u30e1\u30fc\u30b8\u3092\u4fdd\u6301\n      tag_selectors:\n        - kind: \"doublestar\"\n          decoration: \"matches\"\n          pattern: \"**\"\n      scope_selectors:\n        - repository:\n            - kind: \"doublestar\"\n              decoration: \"repoMatches\"\n              pattern: \"**\"\n</code></pre>"},{"location":"ja/registry/#_17","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u6a5f\u80fd","text":""},{"location":"ja/registry/#_18","title":"\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3","text":""},{"location":"ja/registry/#_19","title":"\u81ea\u52d5\u30b9\u30ad\u30e3\u30f3","text":"<ul> <li>\u30d7\u30c3\u30b7\u30e5\u6642\u30b9\u30ad\u30e3\u30f3: \u30a4\u30e1\u30fc\u30b8\u30a2\u30c3\u30d7\u30ed\u30fc\u30c9\u6642\u306e\u81ea\u52d5\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3</li> <li>\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u30b9\u30ad\u30e3\u30f3: \u65b0\u3057\u3044\u8106\u5f31\u6027\u306b\u5bfe\u3059\u308b\u65e2\u5b58\u30a4\u30e1\u30fc\u30b8\u306e\u5b9a\u671f\u30b9\u30ad\u30e3\u30f3</li> <li>\u30de\u30eb\u30c1\u30b9\u30ad\u30e3\u30ca\u30fc\u30b5\u30dd\u30fc\u30c8: Trivy\u3001Clair\u3001\u305d\u306e\u4ed6\u30b9\u30ad\u30e3\u30ca\u30fc\u3068\u306e\u7d71\u5408</li> </ul>"},{"location":"ja/registry/#_20","title":"\u8106\u5f31\u6027\u30ec\u30dd\u30fc\u30c8","text":"<pre><code># \u8106\u5f31\u6027\u30ec\u30dd\u30fc\u30c8\u3092\u53d6\u5f97\nhb registry scan report \\\n  --image prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# \u51fa\u529b\u4f8b\n\u8106\u5f31\u6027\u30b5\u30de\u30ea\u30fc:\n  \u9ad8: 2\n  \u4e2d: 5\n  \u4f4e: 12\n  \u4e0d\u660e: 1\n\n\u91cd\u8981\u306a\u8106\u5f31\u6027:\n  CVE-2023-12345: libssl \u3067\u306e\u30ea\u30e2\u30fc\u30c8\u30b3\u30fc\u30c9\u5b9f\u884c\n  CVE-2023-67890: \u30d9\u30fc\u30b9\u30a4\u30e1\u30fc\u30b8\u3067\u306e\u30d0\u30c3\u30d5\u30a1\u30aa\u30fc\u30d0\u30fc\u30d5\u30ed\u30fc\n</code></pre>"},{"location":"ja/registry/#_21","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc","text":"<pre><code># \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u8a2d\u5b9a\nsecurity_policy:\n  prevent_vulnerable_images:\n    enabled: true\n    severity_threshold: \"high\"\n\n  content_trust:\n    enabled: true\n    cosign_verification: true\n\n  image_scanning:\n    auto_scan: true\n    scan_on_push: true\n    scanner: \"trivy\"\n</code></pre>"},{"location":"ja/registry/#_22","title":"\u30b3\u30f3\u30c6\u30f3\u30c8\u30c8\u30e9\u30b9\u30c8\u3068\u7f72\u540d","text":""},{"location":"ja/registry/#docker-content-trust","title":"Docker Content Trust","text":"<pre><code># \u30b3\u30f3\u30c6\u30f3\u30c8\u30c8\u30e9\u30b9\u30c8\u3092\u6709\u52b9\u5316\nexport DOCKER_CONTENT_TRUST=1\nexport DOCKER_CONTENT_TRUST_SERVER=https://prod-workspace.registry.hexabase.ai:4443\n\n# \u7f72\u540d\u4ed8\u304d\u30a4\u30e1\u30fc\u30b8\u3092\u30d7\u30c3\u30b7\u30e5\ndocker push prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"ja/registry/#cosign","title":"Cosign\u7d71\u5408","text":"<pre><code># Cosign\u3067\u30a4\u30e1\u30fc\u30b8\u306b\u7f72\u540d\ncosign sign prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# \u7f72\u540d\u3092\u691c\u8a3c\ncosign verify prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"ja/registry/#_23","title":"\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3","text":""},{"location":"ja/registry/#_24","title":"\u30af\u30ed\u30b9\u30ea\u30fc\u30b8\u30e7\u30f3\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3","text":"<p>\u707d\u5bb3\u5fa9\u65e7\u3068\u30b0\u30ed\u30fc\u30d0\u30eb\u914d\u5e03\u306e\u305f\u3081\u306e\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u8a2d\u5b9a\uff1a</p> <pre><code># \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u4f5c\u6210\nhb registry replication endpoint create \\\n  --name disaster-recovery \\\n  --url https://dr-region.registry.hexabase.ai \\\n  --workspace production\n\n# \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30eb\u30fc\u30eb\u3092\u4f5c\u6210\nhb registry replication rule create \\\n  --name prod-to-dr \\\n  --source-workspace production \\\n  --destination-endpoint disaster-recovery \\\n  --filter-pattern \"production/**\" \\\n  --trigger manual\n</code></pre>"},{"location":"ja/registry/#_25","title":"\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u8a2d\u5b9a","text":"<pre><code># \u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30eb\u30fc\u30eb\u8a2d\u5b9a\nreplication_rule:\n  name: \"prod-to-dr\"\n  description: \"\u672c\u756a\u74b0\u5883\u304b\u3089\u707d\u5bb3\u5fa9\u65e7\u3078\u306e\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\"\n  source_registry:\n    type: \"harbor\"\n    url: \"https://prod-workspace.registry.hexabase.ai\"\n  destination_registry:\n    type: \"harbor\"\n    url: \"https://dr-workspace.registry.hexabase.ai\"\n  filters:\n    - type: \"repository\"\n      value: \"production/**\"\n    - type: \"tag\"\n      value: \"v*\"\n  trigger:\n    type: \"scheduled\"\n    schedule: \"0 2 * * *\"  # \u6bce\u65e5\u5348\u524d2\u6642\n  settings:\n    override: false\n    deletion: false\n</code></pre>"},{"location":"ja/registry/#cicd","title":"CI/CD\u7d71\u5408","text":""},{"location":"ja/registry/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/build-and-push.yml\nname: \u30ec\u30b8\u30b9\u30c8\u30ea\u3078\u306e\u30d3\u30eb\u30c9\u3068\u30d7\u30c3\u30b7\u30e5\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Hexabase\u30ec\u30b8\u30b9\u30c8\u30ea\u306b\u30ed\u30b0\u30a4\u30f3\n        uses: docker/login-action@v2\n        with:\n          registry: prod-workspace.registry.hexabase.ai\n          username: ${{ secrets.REGISTRY_USERNAME }}\n          password: ${{ secrets.REGISTRY_PASSWORD }}\n\n      - name: \u30d3\u30eb\u30c9\u3068\u30d7\u30c3\u30b7\u30e5\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          push: true\n          tags: |\n            prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n            prod-workspace.registry.hexabase.ai/myproject/myapp:${{ github.sha }}\n\n      - name: \u30a4\u30e1\u30fc\u30b8\u30b9\u30ad\u30e3\u30f3\n        run: |\n          hb registry scan start \\\n            --image prod-workspace.registry.hexabase.ai/myproject/myapp:${{ github.sha }} \\\n            --wait\n</code></pre>"},{"location":"ja/registry/#gitlab-ci","title":"GitLab CI","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - build\n  - scan\n  - deploy\n\nvariables:\n  REGISTRY: \"prod-workspace.registry.hexabase.ai\"\n  IMAGE_NAME: \"$REGISTRY/myproject/myapp\"\n\nbuild:\n  stage: build\n  script:\n    - docker login -u $REGISTRY_USERNAME -p $REGISTRY_PASSWORD $REGISTRY\n    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA .\n    - docker push $IMAGE_NAME:$CI_COMMIT_SHA\n\nsecurity_scan:\n  stage: scan\n  script:\n    - hb registry scan start --image $IMAGE_NAME:$CI_COMMIT_SHA --wait\n    - hb registry scan report --image $IMAGE_NAME:$CI_COMMIT_SHA --format json &gt; scan-results.json\n  artifacts:\n    reports:\n      vulnerability: scan-results.json\n</code></pre>"},{"location":"ja/registry/#_26","title":"\u76e3\u8996\u3068\u5206\u6790","text":""},{"location":"ja/registry/#_27","title":"\u30ec\u30b8\u30b9\u30c8\u30ea\u30e1\u30c8\u30ea\u30af\u30b9","text":"<p>\u30ec\u30b8\u30b9\u30c8\u30ea\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u4f7f\u7528\u72b6\u6cc1\u3092\u76e3\u8996\uff1a</p> <pre><code># \u30ec\u30b8\u30b9\u30c8\u30ea\u7d71\u8a08\u3092\u53d6\u5f97\nhb registry stats --workspace production\n\n# \u51fa\u529b\u4f8b\n\u30ec\u30b8\u30b9\u30c8\u30ea\u7d71\u8a08:\n  \u7dcf\u30ea\u30dd\u30b8\u30c8\u30ea\u6570: 156\n  \u7dcf\u30a4\u30e1\u30fc\u30b8\u6570: 1,247\n  \u4f7f\u7528\u30b9\u30c8\u30ec\u30fc\u30b8: 2.3 TB\n  \u30d7\u30eb\u6570 (24\u6642\u9593): 15,847\n  \u30d7\u30c3\u30b7\u30e5\u6570 (24\u6642\u9593): 234\n  \u30a2\u30af\u30c6\u30a3\u30d6\u30e6\u30fc\u30b6\u30fc: 45\n</code></pre>"},{"location":"ja/registry/#_28","title":"\u4e00\u822c\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9","text":"<ul> <li>\u30b9\u30c8\u30ec\u30fc\u30b8\u4f7f\u7528\u91cf: \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5225\u30b9\u30c8\u30ec\u30fc\u30b8\u6d88\u8cbb\u91cf\u306e\u8ffd\u8de1</li> <li>\u30d7\u30eb/\u30d7\u30c3\u30b7\u30e5\u7387: \u30ec\u30b8\u30b9\u30c8\u30ea\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3068\u4f7f\u7528\u30d1\u30bf\u30fc\u30f3\u306e\u76e3\u8996</li> <li>\u8106\u5f31\u6027\u30c8\u30ec\u30f3\u30c9: \u6642\u9593\u7d4c\u904e\u306b\u4f34\u3046\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u6539\u5584\u306e\u8ffd\u8de1</li> <li>\u30e6\u30fc\u30b6\u30fc\u6d3b\u52d5: \u30a2\u30af\u30bb\u30b9\u30d1\u30bf\u30fc\u30f3\u3068\u4f7f\u7528\u72b6\u6cc1\u306e\u76e3\u8996</li> <li>\u30ec\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u72b6\u614b: \u30af\u30ed\u30b9\u30ea\u30fc\u30b8\u30e7\u30f3\u540c\u671f\u30d8\u30eb\u30b9\u306e\u76e3\u8996</li> </ul>"},{"location":"ja/registry/#_29","title":"\u30a2\u30e9\u30fc\u30c8\u3068\u901a\u77e5","text":"<pre><code># \u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\nalerts:\n  - name: \"high_storage_usage\"\n    condition: \"storage_usage &gt; 80%\"\n    notification:\n      - webhook: \"https://hooks.slack.com/services/...\"\n      - email: \"ops-team@company.com\"\n\n  - name: \"vulnerability_detected\"\n    condition: \"new_critical_vulnerability == true\"\n    notification:\n      - webhook: \"https://hooks.teams.microsoft.com/...\"\n</code></pre>"},{"location":"ja/registry/#_30","title":"\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"ja/registry/#_31","title":"\u30a4\u30e1\u30fc\u30b8\u7ba1\u7406","text":"<ol> <li>\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30cb\u30f3\u30b0\u306e\u4f7f\u7528: \u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30f3\uff08v1.2.3\uff09\u3067\u30a4\u30e1\u30fc\u30b8\u306b\u30bf\u30b0\u4ed8\u3051</li> <li>\u4e0d\u5909\u30bf\u30b0: \u65e2\u5b58\u30bf\u30b0\u306e\u4e0a\u66f8\u304d\u3092\u907f\u3051\u308b</li> <li>\u30de\u30eb\u30c1\u30b9\u30c6\u30fc\u30b8\u30d3\u30eb\u30c9: \u30a4\u30e1\u30fc\u30b8\u30b5\u30a4\u30ba\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u6700\u9069\u5316</li> <li>\u30d9\u30fc\u30b9\u30a4\u30e1\u30fc\u30b8\u66f4\u65b0: \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d1\u30c3\u30c1\u306e\u305f\u3081\u306e\u30d9\u30fc\u30b9\u30a4\u30e1\u30fc\u30b8\u5b9a\u671f\u66f4\u65b0</li> </ol>"},{"location":"ja/registry/#_32","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":"<ol> <li>\u5b9a\u671f\u30b9\u30ad\u30e3\u30f3: \u81ea\u52d5\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3\u306e\u6709\u52b9\u5316</li> <li>\u6700\u5c0f\u30a4\u30e1\u30fc\u30b8: distroless \u307e\u305f\u306f\u6700\u5c0f\u30d9\u30fc\u30b9\u30a4\u30e1\u30fc\u30b8\u306e\u4f7f\u7528</li> <li>\u30a4\u30e1\u30fc\u30b8\u7f72\u540d: \u30b3\u30f3\u30c6\u30f3\u30c8\u30c8\u30e9\u30b9\u30c8\u3068\u30a4\u30e1\u30fc\u30b8\u7f72\u540d\u306e\u5b9f\u88c5</li> <li>\u30a2\u30af\u30bb\u30b9\u5236\u5fa1: \u6700\u5c0f\u6a29\u9650\u306e\u539f\u5247\u306b\u5f93\u3046</li> <li>\u79d8\u5bc6\u7ba1\u7406: \u30a4\u30e1\u30fc\u30b8\u306b\u79d8\u5bc6\u3092\u542b\u3081\u306a\u3044</li> </ol>"},{"location":"ja/registry/#_33","title":"\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316","text":"<ol> <li>\u30ec\u30a4\u30e4\u30fc\u30ad\u30e3\u30c3\u30b7\u30e5: \u30ec\u30a4\u30e4\u30fc\u518d\u5229\u7528\u306e\u305f\u3081\u306eDockerfile\u6700\u9069\u5316</li> <li>\u30ec\u30b8\u30b9\u30c8\u30ea\u5834\u6240: \u3088\u308a\u9ad8\u901f\u306a\u30d7\u30eb\u306e\u305f\u3081\u306e\u30ea\u30fc\u30b8\u30e7\u30ca\u30eb\u30ec\u30b8\u30b9\u30c8\u30ea\u4f7f\u7528</li> <li>\u30af\u30ea\u30fc\u30f3\u30a2\u30c3\u30d7\u30dd\u30ea\u30b7\u30fc: \u30b9\u30c8\u30ec\u30fc\u30b8\u7ba1\u7406\u306e\u305f\u3081\u306e\u4fdd\u6301\u30dd\u30ea\u30b7\u30fc\u5b9f\u88c5</li> <li>\u4e26\u5217\u30d7\u30eb: \u540c\u6642\u30ec\u30a4\u30e4\u30fc\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u306e\u8a2d\u5b9a</li> </ol>"},{"location":"ja/registry/#_34","title":"\u5c06\u6765\u306e\u30ed\u30fc\u30c9\u30de\u30c3\u30d7","text":""},{"location":"ja/registry/#_35","title":"\u4ee3\u66ff\u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30dd\u30fc\u30c8","text":"<p>Harbor \u304c\u30c7\u30d5\u30a9\u30eb\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3068\u3057\u3066\u6a5f\u80fd\u3059\u308b\u4e00\u65b9\u3067\u3001\u8ffd\u52a0\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30b5\u30dd\u30fc\u30c8\u3092\u8a08\u753b\u3057\u3066\u3044\u307e\u3059\uff1a</p>"},{"location":"ja/registry/#q1-q2","title":"\u77ed\u671f\uff08Q1-Q2\uff09","text":"<ul> <li>AWS ECR\u7d71\u5408: Amazon Elastic Container Registry \u306e\u30cd\u30a4\u30c6\u30a3\u30d6\u30b5\u30dd\u30fc\u30c8</li> <li>Azure ACR \u30b5\u30dd\u30fc\u30c8: Azure Container Registry \u3068\u306e\u7d71\u5408</li> <li>Google GCR/Artifact Registry: Google Cloud \u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30fc\u30d3\u30b9\u306e\u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/registry/#q3-q4","title":"\u4e2d\u671f\uff08Q3-Q4\uff09","text":"<ul> <li>GitLab Container Registry: GitLab \u30ec\u30b8\u30b9\u30c8\u30ea\u3068\u306e\u76f4\u63a5\u7d71\u5408</li> <li>JFrog Artifactory: \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30a2\u30fc\u30c6\u30a3\u30d5\u30a1\u30af\u30c8\u7ba1\u7406\u7d71\u5408</li> <li>Nexus Repository: \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u9867\u5ba2\u5411\u3051 Sonatype Nexus \u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/registry/#_36","title":"\u9577\u671f\uff08\u6765\u5e74\uff09","text":"<ul> <li>\u30de\u30eb\u30c1\u30ec\u30b8\u30b9\u30c8\u30ea\u30d5\u30a7\u30c7\u30ec\u30fc\u30b7\u30e7\u30f3: \u8907\u6570\u30ec\u30b8\u30b9\u30c8\u30ea\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u7d71\u4e00\u30d3\u30e5\u30fc</li> <li>\u30ec\u30b8\u30b9\u30c8\u30ea\u30e1\u30c3\u30b7\u30e5: \u5206\u6563\u30ec\u30b8\u30b9\u30c8\u30ea\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> <li>AI\u99c6\u52d5\u6700\u9069\u5316: \u30a4\u30f3\u30c6\u30ea\u30b8\u30a7\u30f3\u30c8\u30a4\u30e1\u30fc\u30b8\u6700\u9069\u5316\u3068\u63a8\u5968</li> <li>OCI \u30a2\u30fc\u30c6\u30a3\u30d5\u30a1\u30af\u30c8: \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u4ee5\u5916\u306eOCI\u30a2\u30fc\u30c6\u30a3\u30d5\u30a1\u30af\u30c8\u30bf\u30a4\u30d7\u306e\u5b8c\u5168\u30b5\u30dd\u30fc\u30c8</li> </ul>"},{"location":"ja/registry/#_37","title":"\u5f37\u5316\u6a5f\u80fd","text":"<ul> <li>\u9ad8\u5ea6\u306a\u30ad\u30e3\u30c3\u30b7\u30e5: \u30a4\u30e1\u30fc\u30b8\u7528\u30b0\u30ed\u30fc\u30d0\u30eb\u30b3\u30f3\u30c6\u30f3\u30c4\u914d\u4fe1\u30cd\u30c3\u30c8\u30ef\u30fc\u30af</li> <li>\u30d3\u30eb\u30c9\u30ad\u30e3\u30c3\u30b7\u30e5: \u3088\u308a\u9ad8\u901f\u306aCI/CD\u306e\u305f\u3081\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u30d9\u30fc\u30b9\u30d3\u30eb\u30c9\u30ad\u30e3\u30c3\u30b7\u30e5</li> <li>\u30a4\u30e1\u30fc\u30b8\u30d7\u30ed\u30e2\u30fc\u30b7\u30e7\u30f3: \u81ea\u52d5\u30a4\u30e1\u30fc\u30b8\u30d7\u30ed\u30e2\u30fc\u30b7\u30e7\u30f3\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30b9\u30ad\u30e3\u30f3: \u5f37\u5316\u3055\u308c\u305f\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u3068\u30dd\u30ea\u30b7\u30fc\u57f7\u884c</li> </ul>"},{"location":"ja/registry/#_38","title":"\u30d8\u30eb\u30d7\u306e\u53d6\u5f97","text":""},{"location":"ja/registry/#_39","title":"\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3068\u30b5\u30dd\u30fc\u30c8","text":"<pre><code># \u30ec\u30b8\u30b9\u30c8\u30ea\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u53d6\u5f97\nhb registry help\n\n# \u30ec\u30b8\u30b9\u30c8\u30ea\u30b5\u30fc\u30d3\u30b9\u72b6\u614b\u3092\u30c1\u30a7\u30c3\u30af\nhb registry status --workspace production\n\n# \u30ec\u30b8\u30b9\u30c8\u30ea\u30ed\u30b0\u3092\u8868\u793a\nhb registry logs --follow --workspace production\n</code></pre>"},{"location":"ja/registry/#_40","title":"\u4e00\u822c\u7684\u306a\u554f\u984c\u306e\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/registry/#_41","title":"\u8a8d\u8a3c\u554f\u984c","text":"<pre><code># Docker\u8a8d\u8a3c\u60c5\u5831\u3092\u30af\u30ea\u30a2\ndocker logout prod-workspace.registry.hexabase.ai\n\n# \u518d\u8a8d\u8a3c\ndocker login prod-workspace.registry.hexabase.ai\n\n# \u63a5\u7d9a\u3092\u30c6\u30b9\u30c8\ndocker pull prod-workspace.registry.hexabase.ai/library/hello-world\n</code></pre>"},{"location":"ja/registry/#_42","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u554f\u984c","text":"<pre><code># \u30ec\u30b8\u30b9\u30c8\u30ea\u63a5\u7d9a\u3092\u30c6\u30b9\u30c8\ncurl -v https://prod-workspace.registry.hexabase.ai/v2/\n\n# DNS\u89e3\u6c7a\u3092\u30c1\u30a7\u30c3\u30af\nnslookup prod-workspace.registry.hexabase.ai\n</code></pre>"},{"location":"ja/registry/#_43","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ul> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8 - \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3067\u306e\u30ec\u30b8\u30b9\u30c8\u30ea\u30a4\u30e1\u30fc\u30b8\u4f7f\u7528</li> <li>CI/CD\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 - \u30ec\u30b8\u30b9\u30c8\u30ea\u3068\u306e\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u7d71\u5408 (English)</li> <li>AI\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3 - AI\u99c6\u52d5\u306e\u904b\u7528\u7ba1\u7406</li> <li>RBAC\u8a2d\u5b9a - \u30ec\u30b8\u30b9\u30c8\u30ea\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u306e\u7ba1\u7406</li> <li>API\u30ea\u30d5\u30a1\u30ec\u30f3\u30b9 - \u5b8c\u5168\u306aAPI\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8</li> </ul>"},{"location":"ja/usecases/","title":"\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9","text":"<p>Hexabase.AI \u3092\u6d3b\u7528\u3057\u3001 Kubernetes \u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5909\u9769\u3057\u3001\u30af\u30e9\u30a6\u30c9\u30cd\u30a4\u30c6\u30a3\u30d6\u306a IT \u30b5\u30fc\u30d3\u30b9\u63d0\u4f9b\u3057\u307e\u3059</p>"},{"location":"ja/usecases/#1","title":"1. \u6982\u8981","text":"<p>Hexabase.AI \u306f\u3001\u521d\u56de\u306e\u30de\u30a4\u30af\u30ed\u30b5\u30fc\u30d3\u30b9\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u304b\u3089\u8907\u96d1\u306a\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u30bf\u30fc\u74b0\u5883\u3092\u7ba1\u7406\u3059\u308b\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u307e\u3067\u3001\u696d\u754c\u3092\u6a2a\u65ad\u3059\u308b\u591a\u69d8\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306b\u5bfe\u5fdc\u3057\u307e\u3059\u3002\u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u304b\u3089\u6700\u5927\u306e\u4fa1\u5024\u3092\u5f97\u308b\u305f\u3081\u306e\u4e00\u822c\u7684\u306a\u30b7\u30ca\u30ea\u30aa\u3068\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092\u3054\u7d39\u4ecb\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/#2","title":"2. \u4e3b\u8981\u306a\u30e1\u30ea\u30c3\u30c8","text":"<ul> <li> \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30e2\u30c0\u30ca\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3</li> </ul> <p>\u958b\u767a\u3057\u305f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u7c21\u5358\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u3001\u62e1\u5f35\u6027\u306e\u9ad8\u3044 Kubernetes \u3067\u904b\u7528\u3067\u304d\u307e\u3059</p> <p> \u30e2\u30c0\u30ca\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3\u3092\u63a2\u308b</p> <ul> <li> \u8907\u6570\u306e\u74b0\u5883\u7ba1\u7406\uff08\u958b\u767a\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u3001\u672c\u756a)</li> </ul> <p>\u958b\u767a\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u3001\u672c\u756a\u74b0\u5883\u3092\u52b9\u7387\u7684\u306b\u7ba1\u7406\u3057\u307e\u3059</p> <p> \u30de\u30eb\u30c1\u74b0\u5883\u3092\u5b66\u3076</p> <ul> <li> \u30c1\u30fc\u30e0\u30b3\u30e9\u30dc\u30ec\u30fc\u30b7\u30e7\u30f3</li> </ul> <p>\u8907\u6570\u306e\u30c1\u30fc\u30e0\u304c\u5171\u6709\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3067\u72ec\u7acb\u3057\u3066\u4f5c\u696d\u3067\u304d\u307e\u3059</p> <p> \u30c1\u30fc\u30e0\u30b3\u30e9\u30dc\u30ec\u30fc\u30b7\u30e7\u30f3\u30ac\u30a4\u30c9</p> <ul> <li> \u30b3\u30b9\u30c8\u6700\u9069\u5316</li> </ul> <p>AI \u3092\u6d3b\u7528\u3057\u305f\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316\u3067\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u30b3\u30b9\u30c8\u3092\u524a\u6e1b\u3057\u307e\u3059</p> <p> \u30b3\u30b9\u30c8\u6700\u9069\u5316\u6226\u7565</p>"},{"location":"ja/usecases/#3","title":"3. \u30d7\u30e9\u30f3\u306e\u3054\u6848\u5185","text":"<p>Hexabase.AI \u306f\u3001\u5229\u7528\u5171\u306b\u6210\u9577\u3059\u308b\u3088\u3046\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u65b0\u3057\u3044\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u59cb\u3081\u308b\u500b\u4eba\u958b\u767a\u8005\u304b\u3089\u3001\u8907\u96d1\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30ac\u30d0\u30ca\u30f3\u30b9\u8981\u4ef6\u3092\u6301\u3064\u5927\u4f01\u696d\u307e\u3067\u3001\u3042\u306a\u305f\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306b\u9069\u3057\u305f\u30d7\u30e9\u30f3\u304c\u3042\u308a\u307e\u3059\u3002\u5c0f\u3055\u304f\u59cb\u3081\u3066\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\u3059\u308b\u6e96\u5099\u304c\u3067\u304d\u3066\u3044\u307e\u3059\u3002</p> <ul> <li> \u30b7\u30f3\u30b0\u30eb\u30e6\u30fc\u30b6\u30fc/Hobby \u30d7\u30e9\u30f3</li> </ul> <p>\u500b\u4eba\u306e Private \u306a\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3067 Hexabase \u3092\u4f53\u9a13\u3092\u958b\u59cb\u3057\u307e\u3057\u3087\u3046\u3002\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u3001\u30b7\u30f3\u30d7\u30eb\u306a CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u529b\u3092\u611f\u3058\u3066\u304f\u3060\u3055\u3044\u3002\u3053\u306e\u30d7\u30e9\u30f3\u306f\u3001\u500b\u4eba\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3068\u5b66\u7fd2\u306b\u6700\u9069\u3067\u3059\u3002</p> <p> \u30b7\u30f3\u30b0\u30eb\u30e6\u30fc\u30b6\u30fc\u30b7\u30ca\u30ea\u30aa\u3092\u898b\u308b</p> <ul> <li> \u30b7\u30f3\u30b0\u30eb\u30e6\u30fc\u30b6\u30fc/Pro \u30d7\u30e9\u30f3</li> </ul> <p>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u304c\u6210\u9577\u3057\u3001\u3088\u308a\u591a\u304f\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3084\u30ea\u30bd\u30fc\u30b9\u4fdd\u8a3c\u304c\u5fc5\u8981\u306b\u306a\u3063\u305f\u3089\u3001\u672c\u756a\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u7528\u306e\u5f37\u529b\u306a\u5c02\u7528\u30ce\u30fc\u30c9\u3092\u542b\u3080 Pro \u30d7\u30e9\u30f3\u3078\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3067\u304d\u307e\u3059\u3002</p> <p> Pro \u30d7\u30e9\u30f3\u306e\u6a5f\u80fd\u3092\u898b\u308b</p> <ul> <li> \u30c1\u30fc\u30e0\u30d7\u30e9\u30f3</li> </ul> <p>\u30c1\u30fc\u30e0\u3092\u53c2\u52a0\u3055\u305b\u3066\u3001\u8907\u6570\u4eba\u3067\u30d7\u30ed\u30c0\u30af\u30c8\u3084\u30b7\u30b9\u30c6\u30e0\u306e\u904b\u7528\u3092\u30b9\u30bf\u30fc\u30c8\u3057\u307e\u3057\u3087\u3046\u3002\u9867\u5ba2\u3084\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u9700\u8981\u306b\u5fdc\u3058\u3066\u4f5c\u6210\u53ef\u80fd\u306a\u8907\u6570\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3001\u3088\u308a\u67d4\u8edf\u306a CI/CD\u3001\u9032\u5316\u3057\u305f AIOps \u304c\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u652f\u63f4\u3057\u307e\u3059\u3002\u3000\u3042\u306a\u305f\u304c\u6240\u5c5e\u3059\u308b\u7d44\u7e54\uff08Organization\uff09\u306f\u3001\u6b63\u3057\u304f\u6a29\u9650\u7ba1\u7406\u3055\u308c\u3001\u5206\u96e2\u3055\u308c\u3001\u6a29\u9650\u304c\u7d71\u5236\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u3084\u5c11\u4eba\u6570\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3001\u4e2d\u5c0f\u4f01\u696d\u3067\u306e\u30b7\u30b9\u30c6\u30e0\u30b5\u30fc\u30d3\u30b9\u306b\u6700\u9069\u3067\u3059\u3002</p> <p> \u30c1\u30fc\u30e0\u30b7\u30ca\u30ea\u30aa\u3092\u898b\u308b</p> <ul> <li> \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3</li> </ul> <p>\u5927\u898f\u6a21\u7d44\u7e54\u5411\u3051\u306b Hexabase.AI \u306e\u3059\u3079\u3066\u306e\u6a5f\u80fd\u3092\u89e3\u304d\u653e\u3061\u307e\u3059\u3002\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b0\u30ec\u30fc\u30c9\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3001\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30d1\u30c3\u30af\u3001\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3001\u4e88\u7b97\u8a08\u753b\u3001\u30d7\u30ec\u30df\u30a2\u30e0\u30b5\u30dd\u30fc\u30c8\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p> <p> \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30b7\u30ca\u30ea\u30aa\u3092\u898b\u308b</p>"},{"location":"ja/usecases/#4","title":"4. \u3069\u306e\u3088\u3046\u306a\u65b9\u306b\u30b5\u30fc\u30d3\u30b9\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\u304b\uff1f","text":""},{"location":"ja/usecases/#_2","title":"\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u958b\u767a\u30c1\u30fc\u30e0","text":"<ul> <li>\u8ab2\u984c: \u8907\u96d1\u306a Kubernetes \u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3068\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9</li> <li>\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u304c\u7d44\u307f\u8fbc\u307e\u308c\u305f\u30bb\u30eb\u30d5\u30b5\u30fc\u30d3\u30b9\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8</li> <li>\u30e1\u30ea\u30c3\u30c8: \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u6642\u9593\u306e 80% \u524a\u6e1b\u3001\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3067\u306f\u306a\u304f\u30b3\u30fc\u30c9\u306b\u96c6\u4e2d</li> </ul>"},{"location":"ja/usecases/#it","title":"\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba IT","text":"<ul> <li>\u8ab2\u984c: \u8907\u6570\u306e\u30c1\u30fc\u30e0\u3068\u74b0\u5883\u3092\u5b89\u5168\u306b\u7ba1\u7406</li> <li>\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: RBAC \u3068\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u5099\u3048\u305f\u30de\u30eb\u30c1\u30c6\u30ca\u30f3\u30c8\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3</li> <li>\u30e1\u30ea\u30c3\u30c8: \u30c1\u30fc\u30e0\u306e\u81ea\u5f8b\u6027\u3092\u4fdd\u3061\u306a\u304c\u3089\u96c6\u4e2d\u30ac\u30d0\u30ca\u30f3\u30b9</li> </ul>"},{"location":"ja/usecases/#saas","title":"SaaS \u30d7\u30ed\u30d0\u30a4\u30c0\u30fc","text":"<ul> <li>\u8ab2\u984c: \u9867\u5ba2\u306e\u6210\u9577\u306b\u5408\u308f\u305b\u3066\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3092\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0</li> <li>\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: AI \u3092\u6d3b\u7528\u3057\u305f\u81ea\u52d5\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3068\u30ea\u30bd\u30fc\u30b9\u6700\u9069\u5316</li> <li>\u30e1\u30ea\u30c3\u30c8: \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u5411\u4e0a\u3055\u305b\u306a\u304c\u3089 40% \u306e\u30b3\u30b9\u30c8\u524a\u6e1b</li> </ul>"},{"location":"ja/usecases/#_3","title":"\u6559\u80b2\u6a5f\u95a2","text":"<ul> <li>\u8ab2\u984c: \u5b66\u751f\u306b\u9694\u96e2\u3055\u308c\u305f\u74b0\u5883\u3092\u63d0\u4f9b</li> <li>\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3: \u30ea\u30bd\u30fc\u30b9\u5236\u9650\u4ed8\u304d\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30d9\u30fc\u30b9\u306e\u9694\u96e2</li> <li>\u30e1\u30ea\u30c3\u30c8: \u5b89\u5168\u3067\u8cbb\u7528\u5bfe\u52b9\u679c\u306e\u9ad8\u3044\u5b66\u7fd2\u74b0\u5883</li> </ul>"},{"location":"ja/usecases/#5","title":"5. \u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9","text":""},{"location":"ja/usecases/#1_1","title":"1. \u5c0f\u3055\u304f\u59cb\u3081\u3066\u3001\u30b9\u30de\u30fc\u30c8\u306b\u30b9\u30b1\u30fc\u30eb","text":"<p>\u5358\u4e00\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3067\u30d1\u30a4\u30ed\u30c3\u30c8\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u958b\u59cb\u3057\u3001\u5b66\u7fd2\u306b\u57fa\u3065\u3044\u3066\u62e1\u5f35\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/#2-ai","title":"2. AI \u30a4\u30f3\u30b5\u30a4\u30c8\u3092\u6d3b\u7528","text":"<p>AIOps \u306e\u63a8\u5968\u4e8b\u9805\u3092\u4f7f\u7528\u3057\u3066\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u3092\u6700\u9069\u5316\u3057\u3001\u30b3\u30b9\u30c8\u3092\u524a\u6e1b\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/#3_1","title":"3. \u3059\u3079\u3066\u3092\u81ea\u52d5\u5316","text":"<p>\u5305\u62ec\u7684\u306a API \u3092\u4f7f\u7528\u3057\u3066 CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3068\u7d71\u5408\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/#4_1","title":"4. \u76e3\u8996\u3068\u53cd\u5fa9","text":"<p>\u7d44\u307f\u8fbc\u307e\u308c\u305f\u53ef\u89b3\u6e2c\u6027\u3092\u4f7f\u7528\u3057\u3066\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u7d99\u7d9a\u7684\u306b\u6539\u5584\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/#6","title":"6. \u6e96\u5099\u306f\u3067\u304d\u3066\u3044\u307e\u3059\u304b\uff1f","text":"<p>Hexabase.AI \u304c\u3042\u306a\u305f\u306e Kubernetes \u30b8\u30e3\u30fc\u30cb\u30fc\u3092\u3069\u306e\u3088\u3046\u306b\u5909\u9769\u3067\u304d\u308b\u304b\u3092\u63a2\u308b\u6e96\u5099\u306f\u3067\u304d\u3066\u3044\u307e\u3059\u304b\uff1f</p> <ol> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u7279\u5b9a: \u4e0a\u8a18\u306e\u30b7\u30ca\u30ea\u30aa\u3067\u3042\u306a\u305f\u306e\u30cb\u30fc\u30ba\u306b\u4e00\u81f4\u3059\u308b\u3082\u306e\u3092\u898b\u3064\u3051\u307e\u3059</li> <li>\u30c8\u30e9\u30a4\u30a2\u30eb\u3092\u958b\u59cb: \u7121\u6599\u30c8\u30e9\u30a4\u30a2\u30eb\u3067\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u4f53\u9a13\u3057\u307e\u3059</li> <li>\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u306b\u5f93\u3046: \u6700\u9069\u306a\u7d50\u679c\u3092\u5f97\u308b\u305f\u3081\u306b\u30ac\u30a4\u30c9\u3092\u4f7f\u7528\u3057\u307e\u3059</li> <li>\u30b5\u30dd\u30fc\u30c8\u3092\u53d7\u3051\u308b: \u79c1\u305f\u3061\u306e\u30c1\u30fc\u30e0\u304c\u3042\u306a\u305f\u306e\u6210\u529f\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u307e\u3059</li> </ol>"},{"location":"ja/usecases/#_4","title":"\u95a2\u9023\u30ea\u30bd\u30fc\u30b9","text":"<ul> <li>\u30b3\u30a2\u30b3\u30f3\u30bb\u30d7\u30c8</li> <li>\u306f\u3058\u3081\u306b\u30ac\u30a4\u30c9</li> <li>RBAC \u8a2d\u5b9a</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7ba1\u7406</li> </ul>"},{"location":"ja/usecases/enterprise-plan/","title":"\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u30b7\u30ca\u30ea\u30aa","text":"<p>**\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3**\u306f Hexabase.AI \u306e\u30d7\u30ec\u30df\u30a2\u30aa\u30d5\u30a1\u30ea\u30f3\u30b0\u3067\u3042\u308a\u3001\u53b3\u683c\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3001\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u3001\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3001\u30ac\u30d0\u30ca\u30f3\u30b9\u8981\u4ef6\u3092\u6301\u3064\u5927\u898f\u6a21\u7d44\u7e54\u5411\u3051\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3067\u306f\u3001\u5927\u4f01\u696d\u304c\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u5168\u6a5f\u80fd\u3092\u6d3b\u7528\u3059\u308b\u65b9\u6cd5\u3092\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"ja/usecases/enterprise-plan/#_2","title":"\u76ee\u6a19","text":"<p>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u306e\u76ee\u6a19\u306f\u3001\u5927\u898f\u6a21\u7d44\u7e54\u306b\u9ad8\u5ea6\u306b\u5b89\u5168\u3067\u3001\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u306b\u6e96\u62e0\u3057\u3001\u30b9\u30b1\u30fc\u30e9\u30d6\u30eb\u3067\u7d71\u5236\u53ef\u80fd\u306a\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u91d1\u878d\u3084\u533b\u7642\u306a\u3069\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8981\u4ef6\u304c\u53b3\u3057\u3044\u4f01\u696d\u3001\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3001\u8a73\u7d30\u306a\u30b3\u30b9\u30c8\u7ba1\u7406\u3001\u5305\u62ec\u7684\u306a\u76e3\u67fb\u6a5f\u80fd\u3092\u5fc5\u8981\u3068\u3059\u308b\u4f01\u696d\u5411\u3051\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/usecases/enterprise-plan/#1","title":"1. \u96c6\u4e2d\u30ac\u30d0\u30ca\u30f3\u30b9\u3068\u7d44\u7e54","text":"<ul> <li>\u4f01\u696d\u306f Hexabase.AI \u4e0a\u306b\u4e2d\u592e\u7d44\u7e54\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002</li> <li>\u30b7\u30fc\u30e0\u30ec\u30b9\u3067\u5b89\u5168\u306a\u30e6\u30fc\u30b6\u30fc\u8a8d\u8a3c\u306e\u305f\u3081\u306b\u3001\u65e2\u5b58\u306e\u30b7\u30f3\u30b0\u30eb\u30b5\u30a4\u30f3\u30aa\u30f3\uff08SSO\uff09\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\uff08Okta \u3084 Azure AD \u306a\u3069\uff09\u3092\u7d71\u5408\u3057\u307e\u3059\u3002</li> <li>\u5185\u90e8\u306e\u4f01\u696d\u69cb\u9020\u306b\u76f4\u63a5\u30de\u30c3\u30d4\u30f3\u30b0\u3055\u308c\u308b\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3068\u30dd\u30ea\u30b7\u30fc\u3092\u4f7f\u7528\u3057\u305f\u3001\u304d\u3081\u7d30\u304b\u3044 RBAC \u30e2\u30c7\u30eb\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#2","title":"2. \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3068\u30b3\u30b9\u30c8\u7ba1\u7406","text":"<ul> <li>\u4e2d\u592e IT \u90e8\u9580\u306f\u3001\u7570\u306a\u308b\u4e8b\u696d\u90e8\u9580\u7528\u306b\u8907\u6570\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\uff08\u4f8b\uff1a<code>Finance-BU</code>\u3001<code>Healthcare-Analytics</code>\u3001<code>Retail-Apps</code>\uff09\u3002</li> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u306e\u4e3b\u8981\u6a5f\u80fd\u306f**\u4e88\u7b97\u8a08\u753b**\u3067\u3059\u3002\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u7279\u5b9a\u306e\u4e88\u7b97\u3068\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u5272\u308a\u5f53\u3066\u307e\u3059\u3002</li> <li>\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306f\u8a73\u7d30\u306a\u30b3\u30b9\u30c8\u914d\u5206\u30ec\u30dd\u30fc\u30c8\u3092\u63d0\u4f9b\u3057\u3001\u7d44\u7e54\u306f\u4e8b\u696d\u90e8\u9580\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3001\u307e\u305f\u306f\u7279\u5b9a\u306e\u30e9\u30d9\u30eb\u3054\u3068\u306b\u652f\u51fa\u3092\u8ffd\u8de1\u3067\u304d\u3001\u8ca1\u52d9\u30ac\u30d0\u30ca\u30f3\u30b9\u306b\u3068\u3063\u3066\u91cd\u8981\u3067\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#3","title":"3. \u59a5\u5354\u306e\u306a\u3044\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9","text":"<ul> <li>\u5b8c\u5168\u306a\u76e3\u67fb\u30ed\u30b0\uff1a\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u306f\u3001\u9577\u671f\u4fdd\u6301\u3092\u5099\u3048\u305f\u5305\u62ec\u7684\u3067\u4e0d\u5909\u306e\u76e3\u67fb\u30ed\u30b0\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3059\u3079\u3066\u306e\u30a2\u30af\u30b7\u30e7\u30f3\u304c\u30ed\u30b0\u306b\u8a18\u9332\u3055\u308c\u3001SIEM\uff08\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u60c5\u5831\u30a4\u30d9\u30f3\u30c8\u7ba1\u7406\uff09\u30b7\u30b9\u30c6\u30e0\u306b\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3067\u304d\u307e\u3059\u3002</li> <li>\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30d1\u30c3\u30af\uff1a\u4f01\u696d\u306f\u95a2\u9023\u3059\u308b\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b PCI-DSS \u3068 HIPAA \u7528\u306e\u4e8b\u524d\u69cb\u7bc9\u3055\u308c\u305f\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30d1\u30c3\u30af\u3092\u9069\u7528\u3057\u3001\u3053\u308c\u3089\u306e\u6a19\u6e96\u306b\u5fc5\u8981\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u3068\u69cb\u6210\u3092\u81ea\u52d5\u7684\u306b\u5b9f\u65bd\u3057\u307e\u3059\u3002</li> <li>\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\uff1a\u6a5f\u5bc6\u30c7\u30fc\u30bf\u3092\u6271\u3046\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306f\u3001\u5c02\u7528 VPN \u30b2\u30fc\u30c8\u30a6\u30a7\u30a4\u3092\u4ecb\u3057\u3066\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u306b\u63a5\u7d9a\u3055\u308c\u3001\u5b89\u5168\u3067\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u306a\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u3092\u78ba\u4fdd\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#4","title":"4. \u9ad8\u5ea6\u306a\u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3\u3068\u4fe1\u983c\u6027","text":"<ul> <li>\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u30d7\u30e9\u30f3\uff1a\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306f\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u304a\u3088\u3073\u30de\u30eb\u30c1\u30af\u30e9\u30a6\u30c9\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u7528\u306b\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u91d1\u878d\u4e8b\u696d\u90e8\u9580\u306e\u30df\u30c3\u30b7\u30e7\u30f3\u30af\u30ea\u30c6\u30a3\u30ab\u30eb\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001\u6700\u5927\u306e\u53ef\u7528\u6027\u306e\u305f\u3081\u306b 2 \u3064\u306e\u7570\u306a\u308b\u30af\u30e9\u30a6\u30c9\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u9593\u3067\u30a2\u30af\u30c6\u30a3\u30d6-\u30a2\u30af\u30c6\u30a3\u30d6\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002</li> <li>\u9ad8\u5ea6\u306a\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3068 DR\uff1a\u4f01\u696d\u306f\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u30dd\u30a4\u30f3\u30c8\u30a4\u30f3\u30bf\u30a4\u30e0\u30ea\u30ab\u30d0\u30ea\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5bfe\u5fdc\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30dd\u30ea\u30b7\u30fc\u3001\u81ea\u52d5\u707d\u5bb3\u5fa9\u65e7\u8a08\u753b\u30c6\u30b9\u30c8\u3092\u53ef\u80fd\u306b\u3059\u308b\u9ad8\u5ea6\u306a\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u6226\u7565\u3092\u8a2d\u8a08\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#5-aiops","title":"5. \u30d5\u30eb\u6a5f\u80fd\u306e AIOps","text":"<ul> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u306f\u3001\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u5b8c\u5168\u306a **AIOps \u30b9\u30a4\u30fc\u30c8**\u3092\u89e3\u304d\u653e\u3061\u307e\u3059\uff1a</li> <li>\u4e88\u6e2c\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\uff1aAIOps \u30a8\u30f3\u30b8\u30f3\u306f\u5c65\u6b74\u30c8\u30ec\u30f3\u30c9\u3092\u5206\u6790\u3057\u3066\u30c8\u30e9\u30d5\u30a3\u30c3\u30af\u30b9\u30d1\u30a4\u30af\uff08\u91d1\u878d\u30a2\u30d7\u30ea\u306e\u5e02\u5834\u958b\u59cb\u6642\u306a\u3069\uff09\u3092\u4e88\u6e2c\u3057\u3001\u5148\u5236\u7684\u306b\u30ea\u30bd\u30fc\u30b9\u3092\u30b9\u30b1\u30fc\u30eb\u3057\u307e\u3059\u3002</li> <li>\u81ea\u52d5\u6839\u672c\u539f\u56e0\u5206\u6790\uff1a\u554f\u984c\u304c\u767a\u751f\u3059\u308b\u3068\u3001AIOps \u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u306f\u554f\u984c\u3092\u7279\u5b9a\u3059\u308b\u3060\u3051\u3067\u306a\u304f\u3001\u305d\u308c\u3092\u5f15\u304d\u8d77\u3053\u3057\u305f\u7279\u5b9a\u306e\u30b3\u30fc\u30c9\u30b3\u30df\u30c3\u30c8\u307e\u305f\u306f\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u306e\u5909\u66f4\u307e\u3067\u554f\u984c\u3092\u8ffd\u8de1\u3057\u307e\u3059\u3002</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8105\u5a01\u691c\u51fa\uff1aAI \u306f\u3001\u7570\u5e38\u306a API \u30a2\u30af\u30bb\u30b9\u30d1\u30bf\u30fc\u30f3\u3084\u30c7\u30fc\u30bf\u306e\u5916\u90e8\u6d41\u51fa\u306e\u8a66\u307f\u306a\u3069\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8105\u5a01\u3092\u793a\u3059\u53ef\u80fd\u6027\u306e\u3042\u308b\u7570\u5e38\u306a\u52d5\u4f5c\u3092\u7d99\u7d9a\u7684\u306b\u76e3\u8996\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#6","title":"6. \u30ab\u30b9\u30bf\u30e0\u5951\u7d04\u3068\u30b5\u30dd\u30fc\u30c8","text":"<ul> <li>\u4f01\u696d\u306f\u4e88\u7b97\u30b5\u30a4\u30af\u30eb\u306b\u5408\u308f\u305b\u305f\u56fa\u5b9a\u4fa1\u683c\u30e2\u30c7\u30eb\u3067**\u7279\u5225\u5951\u7d04**\u3092\u7d50\u3076\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</li> <li>\u307e\u305f\u3001\u5c02\u4efb\u306e\u30c6\u30af\u30cb\u30ab\u30eb\u30a2\u30ab\u30a6\u30f3\u30c8\u30de\u30cd\u30fc\u30b8\u30e3\u30fc\uff08TAM\uff09\u3068 24 \u6642\u9593 365 \u65e5\u306e\u30d7\u30ec\u30df\u30a2\u30e0\u30b5\u30dd\u30fc\u30c8 SLA \u3092\u53d7\u3051\u3001\u5c02\u9580\u5bb6\u306e\u30d8\u30eb\u30d7\u304c\u5e38\u306b\u5229\u7528\u53ef\u80fd\u3067\u3059\u3002</li> </ul>"},{"location":"ja/usecases/enterprise-plan/#_3","title":"\u4f7f\u7528\u6a5f\u80fd\u306e\u6982\u8981","text":"\u6a5f\u80fd \u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u306e\u4f7f\u7528 \u30ac\u30d0\u30ca\u30f3\u30b9 SSO \u7d71\u5408\u3001\u30ab\u30b9\u30bf\u30e0 RBAC\u3001\u96c6\u4e2d\u30dd\u30ea\u30b7\u30fc\u7ba1\u7406 \u30b3\u30b9\u30c8\u7ba1\u7406 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3054\u3068\u306e\u4e88\u7b97\u8a08\u753b\u3001\u8a73\u7d30\u306a\u30b3\u30b9\u30c8\u914d\u5206\u3001\u56fa\u5b9a\u4fa1\u683c\u5951\u7d04 \u76e3\u67fb\u30ed\u30b0 \u9577\u671f\u4fdd\u6301\u3068 SIEM \u7d71\u5408\u3092\u5099\u3048\u305f\u5b8c\u5168\u3067\u4e0d\u5909\u306e\u76e3\u67fb\u30ed\u30b0 \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3 \u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u30d1\u30c3\u30af\uff08PCI\u3001HIPAA\uff09\u3001\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30cd\u30c3\u30c8\u30ef\u30fc\u30ad\u30f3\u30b0\u3001\u9ad8\u5ea6\u306a\u8105\u5a01\u691c\u51fa \u30b9\u30b1\u30fc\u30e9\u30d3\u30ea\u30c6\u30a3 \u81ea\u52d5\u30b9\u30b1\u30fc\u30eb\u30a2\u30a6\u30c8\u30d7\u30e9\u30f3\u3092\u5099\u3048\u305f\u30de\u30eb\u30c1\u30ea\u30fc\u30b8\u30e7\u30f3\u3001\u30de\u30eb\u30c1\u30af\u30e9\u30a6\u30c9\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8 \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3068 DR \u9ad8\u5ea6\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u5bfe\u5fdc\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u6226\u7565\u3068\u81ea\u52d5 DR \u30c6\u30b9\u30c8 AIOps \u4e88\u6e2c\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3001\u81ea\u52d5\u6839\u672c\u539f\u56e0\u5206\u6790\u3001AI \u99c6\u52d5\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3092\u542b\u3080\u30d5\u30eb\u30b9\u30a4\u30fc\u30c8 \u30b5\u30dd\u30fc\u30c8 \u5c02\u4efb TAM\u3001\u30d7\u30ec\u30df\u30a2\u30e0\u30b5\u30dd\u30fc\u30c8\u3001\u30ab\u30b9\u30bf\u30e0 SLA"},{"location":"ja/usecases/on-premise-deployment/","title":"\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u5c55\u958b","text":""},{"location":"ja/usecases/on-premise-deployment/#_2","title":"\u6982\u8981","text":"<p>Hexabase.AI \u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u5c55\u958b\u306b\u3088\u308a\u3001\u7d44\u7e54\u306f AI \u6307\u5411\u306e Kubernetes \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u5168\u4f53\u3092\u81ea\u793e\u306e\u30c7\u30fc\u30bf\u30bb\u30f3\u30bf\u30fc\u5185\u3067\u5b9f\u884c\u3067\u304d\u3001\u6700\u5927\u9650\u306e\u5236\u5fa1\u3001\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3001\u30b3\u30f3\u30d7\u30e9\u30a4\u30a2\u30f3\u30b9\u6a5f\u80fd\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002\u3053\u306e\u5c55\u958b\u30e2\u30c7\u30eb\u306f\u3001\u53b3\u683c\u306a\u30c7\u30fc\u30bf\u4e3b\u6a29\u8981\u4ef6\u3001\u898f\u5236\u5236\u7d04\u3001\u307e\u305f\u306f\u30aa\u30f3\u30d7\u30ec\u30df\u30b9\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3092\u7fa9\u52d9\u4ed8\u3051\u308b\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u3092\u6301\u3064\u7d44\u7e54\u306b\u6700\u9069\u3067\u3059\u3002</p>"},{"location":"ja/usecases/on-premise-deployment/#_3","title":"\u524d\u63d0\u6761\u4ef6","text":""},{"location":"ja/usecases/on-premise-deployment/#_4","title":"\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u8981\u4ef6","text":""},{"location":"ja/usecases/on-premise-deployment/#_5","title":"\u6700\u5c0f\u69cb\u6210","text":"<p>\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9\uff08HA\u7528\u306b3\u30ce\u30fc\u30c9\u63a8\u5968\uff09\uff1a - CPU: \u30ce\u30fc\u30c9\u3042\u305f\u308a8\u30b3\u30a2 - RAM: \u30ce\u30fc\u30c9\u3042\u305f\u308a32 GB - \u30b9\u30c8\u30ec\u30fc\u30b8: \u30ce\u30fc\u30c9\u3042\u305f\u308a500 GB SSD - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af: 10 Gbps \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</p> <p>\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\uff08\u6700\u5c0f3\u30ce\u30fc\u30c9\uff09\uff1a - CPU: \u30ce\u30fc\u30c9\u3042\u305f\u308a16\u30b3\u30a2 - RAM: \u30ce\u30fc\u30c9\u3042\u305f\u308a64 GB - \u30b9\u30c8\u30ec\u30fc\u30b8: \u30ce\u30fc\u30c9\u3042\u305f\u308a1 TB NVMe SSD - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af: 10 Gbps \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</p>"},{"location":"ja/usecases/on-premise-deployment/#_6","title":"\u63a8\u5968\u672c\u756a\u69cb\u6210","text":"<p>\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9\uff083\u30ce\u30fc\u30c9\uff09\uff1a - CPU: \u30ce\u30fc\u30c9\u3042\u305f\u308a16\u30b3\u30a2 - RAM: \u30ce\u30fc\u30c9\u3042\u305f\u308a64 GB - \u30b9\u30c8\u30ec\u30fc\u30b8: \u30ce\u30fc\u30c9\u3042\u305f\u308a1 TB NVMe SSD - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af: 25 Gbps \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</p> <p>\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\uff085+\u30ce\u30fc\u30c9\uff09\uff1a - CPU: \u30ce\u30fc\u30c9\u3042\u305f\u308a32\u30b3\u30a2 - RAM: \u30ce\u30fc\u30c9\u3042\u305f\u308a128 GB - \u30b9\u30c8\u30ec\u30fc\u30b8: \u30ce\u30fc\u30c9\u3042\u305f\u308a2 TB NVMe SSD + \u72ec\u7acb\u30b9\u30c8\u30ec\u30fc\u30b8\u30cd\u30c3\u30c8\u30ef\u30fc\u30af - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af: 25 Gbps \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</p> <p>GPU \u30ce\u30fc\u30c9\uff08AI \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u7528\uff09\uff1a - CPU: \u30ce\u30fc\u30c9\u3042\u305f\u308a32\u30b3\u30a2 - RAM: \u30ce\u30fc\u30c9\u3042\u305f\u308a256 GB - GPU: NVIDIA A100 \u307e\u305f\u306f H100 \u30b7\u30ea\u30fc\u30ba - \u30b9\u30c8\u30ec\u30fc\u30b8: \u30ce\u30fc\u30c9\u3042\u305f\u308a4 TB NVMe SSD - \u30cd\u30c3\u30c8\u30ef\u30fc\u30af: 100 Gbps \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9</p>"},{"location":"ja/usecases/on-premise-deployment/#_7","title":"\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u8981\u4ef6","text":""},{"location":"ja/usecases/on-premise-deployment/#_8","title":"\u30aa\u30da\u30ec\u30fc\u30c6\u30a3\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0","text":"<ul> <li>Ubuntu: 22.04 LTS \u4ee5\u964d</li> <li>RHEL/CentOS: 8.x \u4ee5\u964d</li> <li>SUSE Linux: 15.x \u4ee5\u964d</li> </ul>"},{"location":"ja/usecases/on-premise-deployment/#_9","title":"\u5fc5\u8981\u306a\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2","text":"<ul> <li>Docker: 24.0+ \u307e\u305f\u306f containerd 1.7+</li> <li>Kubernetes: 1.28+\uff08K3s\u7d4c\u7531\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff09</li> <li>Helm: 3.12+</li> <li>PostgreSQL: 15+\uff08\u5916\u90e8\u53ef\uff09</li> <li>Redis: 7.0+\uff08\u5916\u90e8\u53ef\uff09</li> </ul>"},{"location":"ja/usecases/on-premise-deployment/#_10","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8981\u4ef6","text":""},{"location":"ja/usecases/on-premise-deployment/#_11","title":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30c8\u30dd\u30ed\u30b8\u30fc","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         DMZ \u30cd\u30c3\u30c8\u30ef\u30fc\u30af             \u2502\n\u2502    (\u30ed\u30fc\u30c9\u30d0\u30e9\u30f3\u30b5\u30fc, Ingress)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      \u7ba1\u7406\u30cd\u30c3\u30c8\u30ef\u30fc\u30af               \u2502\n\u2502   (\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3, \u76e3\u8996)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      \u30af\u30e9\u30b9\u30bf\u30fc\u30cd\u30c3\u30c8\u30ef\u30fc\u30af         \u2502\n\u2502    (\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9, \u30b9\u30c8\u30ec\u30fc\u30b8)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_12","title":"\u5fc5\u8981\u306a\u30dd\u30fc\u30c8","text":"<p>\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\uff1a - 6443: Kubernetes API \u30b5\u30fc\u30d0\u30fc - 2379-2380: etcd - 10250: kubelet - 10259: kube-scheduler - 10257: kube-controller-manager</p> <p>\u30ef\u30fc\u30ab\u30fc\u30ce\u30fc\u30c9\uff1a - 10250: kubelet - 30000-32767: NodePort \u30b5\u30fc\u30d3\u30b9 - 179: BGP\uff08Calico\u4f7f\u7528\u6642\uff09</p> <p>Hexabase.AI \u5c02\u7528\uff1a - 8080: Hexabase.AI API - 5432: PostgreSQL - 6379: Redis - 4222: NATS</p>"},{"location":"ja/usecases/on-premise-deployment/#_13","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30ac\u30a4\u30c9","text":""},{"location":"ja/usecases/on-premise-deployment/#1","title":"\u30d5\u30a7\u30fc\u30ba1: \u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u6e96\u5099","text":""},{"location":"ja/usecases/on-premise-deployment/#1_1","title":"1. \u7269\u7406\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u306e\u6e96\u5099","text":"<pre><code># \u5197\u9577\u6027\u306e\u305f\u3081\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30dc\u30f3\u30c7\u30a3\u30f3\u30b0\u8a2d\u5b9a\nsudo modprobe bonding\necho \"alias bond0 bonding\" &gt;&gt; /etc/modprobe.conf\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\ncat &gt; /etc/netplan/01-network.yaml &lt;&lt; EOF\nnetwork:\n  version: 2\n  bonds:\n    bond0:\n      interfaces: [enp1s0, enp2s0]\n      parameters:\n        mode: 802.3ad\n        mii-monitor-interval: 100\n      addresses: [192.168.1.10/24]\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\nEOF\n\nsudo netplan apply\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2","title":"2. \u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u8a2d\u5b9a","text":"<pre><code># \u5206\u6563\u30b9\u30c8\u30ec\u30fc\u30b8\u7528\u306eCeph\u30af\u30e9\u30b9\u30bf\u30fc\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n# cephadm\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\ncurl --silent --remote-name --location https://github.com/ceph/ceph/raw/quincy/src/cephadm/cephadm\nchmod +x cephadm\nsudo ./cephadm add-repo --release quincy\nsudo ./cephadm install\n\n# Ceph\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u30d6\u30fc\u30c8\u30b9\u30c8\u30e9\u30c3\u30d7\nsudo cephadm bootstrap --mon-ip 192.168.1.10\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2-kubernetes","title":"\u30d5\u30a7\u30fc\u30ba2: Kubernetes \u30af\u30e9\u30b9\u30bf\u30fc\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":""},{"location":"ja/usecases/on-premise-deployment/#1-k3s","title":"1. K3s \u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code># \u6700\u521d\u306e\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9\u3067\ncurl -sfL https://get.k3s.io | sh -s - server \\\n  --cluster-init \\\n  --disable traefik \\\n  --disable servicelb \\\n  --disable metrics-server \\\n  --node-ip=192.168.1.10 \\\n  --cluster-cidr=10.42.0.0/16 \\\n  --service-cidr=10.43.0.0/16 \\\n  --flannel-backend=none\n\n# \u30ce\u30fc\u30c9\u30c8\u30fc\u30af\u30f3\u306e\u53d6\u5f97\nsudo cat /var/lib/rancher/k3s/server/node-token\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2_1","title":"2. \u8ffd\u52a0\u306e\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9\u306e\u53c2\u52a0","text":"<pre><code># \u8ffd\u52a0\u306e\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c9\u3067\ncurl -sfL https://get.k3s.io | sh -s - server \\\n  --server https://192.168.1.10:6443 \\\n  --token &lt;NODE_TOKEN&gt; \\\n  --disable traefik \\\n  --disable servicelb \\\n  --disable metrics-server \\\n  --node-ip=192.168.1.11\n\n# \u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u30d7\u30ec\u30fc\u30f3\u30ce\u30fc\u30c93\u3067IP 192.168.1.12\u3092\u4f7f\u7528\u3057\u3066\u7e70\u308a\u8fd4\u3057\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#3-hexabaseai","title":"\u30d5\u30a7\u30fc\u30ba3: Hexabase.AI \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":""},{"location":"ja/usecases/on-premise-deployment/#1-postgresql","title":"1. PostgreSQL \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code># PostgreSQL \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u306e\u4f5c\u6210\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm install postgresql bitnami/postgresql \\\n  --set auth.postgresPassword=hexabase-secure-password \\\n  --set auth.database=hexabase \\\n  --set primary.persistence.size=100Gi \\\n  --namespace hexabase-system \\\n  --create-namespace\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2-hexabaseai","title":"2. Hexabase.AI \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code># Hexabase.AI Helm\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u8ffd\u52a0\nhelm repo add hexabase https://charts.hexabase.ai\nhelm repo update\n\n# Hexabase.AI \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\nhelm install hexabase hexabase/hexabase-ai \\\n  --namespace hexabase-system\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_14","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5f8c\u306e\u8a2d\u5b9a","text":""},{"location":"ja/usecases/on-premise-deployment/#1-hexabaseai","title":"1. Hexabase.AI \u306e\u521d\u671f\u5316","text":"<pre><code># \u7ba1\u7406\u8005\u8a8d\u8a3c\u60c5\u5831\u306e\u53d6\u5f97\nkubectl get secret hexabase-admin-credentials \\\n  -n hexabase-system \\\n  -o jsonpath='{.data.username}' | base64 -d\n\n# \u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3078\u306e\u30a2\u30af\u30bb\u30b9\necho \"https://hexabase.example.com\"\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2_2","title":"2. \u7d44\u7e54\u3068\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u8a2d\u5b9a","text":"<pre><code># Hexabase CLI \u3092\u4f7f\u7528\u3057\u305f\u521d\u671f\u8a2d\u5b9a\ncurl -L https://github.com/hexabase/cli/releases/latest/download/hb-linux-amd64.tar.gz | tar xz\nsudo mv hb /usr/local/bin/\n\n# \u7d44\u7e54\u306e\u4f5c\u6210\nhb organization create \"\u30de\u30a4\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\" \\\n  --plan enterprise \\\n  --admin-email admin@example.com\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_15","title":"\u76e3\u8996\u3068\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9","text":""},{"location":"ja/usecases/on-premise-deployment/#_16","title":"\u30d8\u30eb\u30b9\u30c1\u30a7\u30c3\u30af","text":"<pre><code># \u30af\u30e9\u30b9\u30bf\u30fc\u30d8\u30eb\u30b9\u306e\u78ba\u8a8d\nkubectl get nodes\nkubectl get pods -A\nkubectl top nodes\nkubectl top pods -A\n\n# Hexabase.AI \u5c02\u7528\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306e\u78ba\u8a8d\nkubectl get pods -n hexabase-system\nkubectl logs -f deployment/hexabase-api -n hexabase-system\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_17","title":"\u5b9a\u671f\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u30bf\u30b9\u30af","text":""},{"location":"ja/usecases/on-premise-deployment/#_18","title":"\u9031\u6b21\u30bf\u30b9\u30af","text":"<ul> <li>\u30b7\u30b9\u30c6\u30e0\u30ed\u30b0\u306e\u30a8\u30e9\u30fc\u78ba\u8a8d</li> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u7387\u306e\u78ba\u8a8d</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5b8c\u4e86\u306e\u78ba\u8a8d</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d1\u30c3\u30c1\u306e\u66f4\u65b0</li> </ul>"},{"location":"ja/usecases/on-premise-deployment/#_19","title":"\u6708\u6b21\u30bf\u30b9\u30af","text":"<ul> <li>\u8a8d\u8a3c\u60c5\u5831\u306e\u78ba\u8a8d\u3068\u30ed\u30fc\u30c6\u30fc\u30b7\u30e7\u30f3</li> <li>\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u30d7\u30e9\u30f3\u30cb\u30f3\u30b0\u8a55\u4fa1</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u6700\u9069\u5316</li> <li>\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8106\u5f31\u6027\u30b9\u30ad\u30e3\u30f3</li> </ul>"},{"location":"ja/usecases/on-premise-deployment/#_20","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":""},{"location":"ja/usecases/on-premise-deployment/#_21","title":"\u4e00\u822c\u7684\u306a\u554f\u984c","text":""},{"location":"ja/usecases/on-premise-deployment/#1_2","title":"1. \u30dd\u30c3\u30c9\u30b9\u30b1\u30b8\u30e5\u30fc\u30ea\u30f3\u30b0\u306e\u554f\u984c","text":"<pre><code># \u30ce\u30fc\u30c9\u30ea\u30bd\u30fc\u30b9\u306e\u78ba\u8a8d\nkubectl describe nodes\n\n# \u30c6\u30a4\u30f3\u30c8\u3068\u8a31\u5bb9\u306e\u78ba\u8a8d\nkubectl describe node &lt;node-name&gt;\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2_3","title":"2. \u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u554f\u984c","text":"<pre><code># Ceph\u30af\u30e9\u30b9\u30bf\u30fc\u30d8\u30eb\u30b9\u306e\u78ba\u8a8d\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph status\n\n# PVC \u30b9\u30c6\u30fc\u30bf\u30b9\u306e\u78ba\u8a8d\nkubectl get pvc -A\nkubectl describe pvc &lt;pvc-name&gt;\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_22","title":"\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8003\u616e\u4e8b\u9805","text":""},{"location":"ja/usecases/on-premise-deployment/#1_3","title":"1. \u30a8\u30a2\u30ae\u30e3\u30c3\u30d7\u5c55\u958b","text":"<p>\u6700\u5927\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u305f\u3081\u3001Hexabase.AI \u306f\u5b8c\u5168\u306b\u30a8\u30a2\u30ae\u30e3\u30c3\u30d7\u3055\u308c\u305f\u74b0\u5883\u306b\u5c55\u958b\u3067\u304d\u307e\u3059\uff1a</p> <pre><code># \u30ed\u30fc\u30ab\u30eb\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea\u306e\u4f5c\u6210\ndocker run -d -p 5000:5000 --name registry registry:2\n\n# Hexabase.AI \u30a4\u30e1\u30fc\u30b8\u306e\u30ed\u30fc\u30ab\u30eb\u30ec\u30b8\u30b9\u30c8\u30ea\u3078\u306e\u30d7\u30c3\u30b7\u30e5\ndocker tag hexabase/api:v1.0.0 localhost:5000/hexabase/api:v1.0.0\ndocker push localhost:5000/hexabase/api:v1.0.0\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#2_4","title":"2. \u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30e2\u30b8\u30e5\u30fc\u30eb\u7d71\u5408","text":"<pre><code># \u30ad\u30fc\u7ba1\u7406\u7528\u306eHSM\u8a2d\u5b9a\ncat &gt; hsm-config.yaml &lt;&lt; EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hsm-config\n  namespace: hexabase-system\ntype: Opaque\ndata:\n  hsm-endpoint: &lt;base64-encoded-endpoint&gt;\n  hsm-token: &lt;base64-encoded-token&gt;\nEOF\n\nkubectl apply -f hsm-config.yaml\n</code></pre>"},{"location":"ja/usecases/on-premise-deployment/#_23","title":"\u95a2\u9023\u30c8\u30d4\u30c3\u30af","text":"<ul> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u6a5f\u80fd - \u5b8c\u5168\u306a\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u6a5f\u80fd</li> <li>RBAC\u8a2d\u5b9a - \u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u8a2d\u5b9a</li> <li>RBAC\u8a2d\u5b9a - \u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u8a2d\u5b9a</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u7ba1\u7406 - \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30ac\u30a4\u30c9</li> </ul>"},{"location":"ja/usecases/single-user-plan/","title":"\u30b7\u30f3\u30b0\u30eb\u30e6\u30fc\u30b6\u30fc\u30d7\u30e9\u30f3\u30b7\u30ca\u30ea\u30aa","text":"<p>\u3053\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3067\u306f\u3001Hexabase.AI \u3092\u4f7f\u7528\u3059\u308b\u500b\u4eba\u958b\u767a\u8005\u306e\u30b8\u30e3\u30fc\u30cb\u30fc\u3092\u8aac\u660e\u3057\u307e\u3059\u3002\u500b\u4eba\u958b\u767a\u8005\u5411\u3051\u306b2\u3064\u306e\u30d7\u30e9\u30f3\u3092\u63d0\u4f9b\u3057\u3066\u3044\u307e\u3059\uff1a\u500b\u4eba\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3068\u5b66\u7fd2\u7528\u306e Hobby \u30d7\u30e9\u30f3\u3001\u5c02\u7528\u30ea\u30bd\u30fc\u30b9\u304c\u5fc5\u8981\u306a\u672c\u756a\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u7528\u306e **Pro \u30d7\u30e9\u30f3**\u3067\u3059\u3002</p>"},{"location":"ja/usecases/single-user-plan/#_2","title":"\u76ee\u6a19","text":"<p>\u30b7\u30f3\u30b0\u30eb\u30e6\u30fc\u30b6\u30fc\u30d7\u30e9\u30f3\u306e\u76ee\u6a19\u306f\u3001\u500b\u4eba\u958b\u767a\u8005\u306b\u5f37\u529b\u3067\u30b3\u30b9\u30c8\u52b9\u7387\u304c\u9ad8\u304f\u3001\u4fe1\u983c\u6027\u306e\u9ad8\u3044\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u69cb\u7bc9\u3001\u30c6\u30b9\u30c8\u3001\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u500b\u4eba\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3001\u30d5\u30ea\u30fc\u30e9\u30f3\u30b9\u30ef\u30fc\u30af\u3001\u307e\u305f\u306f\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u7ba1\u7406\u306e\u8907\u96d1\u3055\u306a\u3057\u306b\u65b0\u3057\u3044\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u30a2\u30a4\u30c7\u30a2\u306e\u30d7\u30ed\u30c8\u30bf\u30a4\u30d4\u30f3\u30b0\u306b\u6700\u9069\u3067\u3059\u3002</p>"},{"location":"ja/usecases/single-user-plan/#1","title":"1. \u521d\u56de\u30ed\u30b0\u30a4\u30f3\u3068\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ul> <li>\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u5f8c\u3001\u958b\u767a\u8005\u306f\u521d\u3081\u3066\u30ed\u30b0\u30a4\u30f3\u3057\u307e\u3059\u3002</li> <li><code>dev-workspace</code> \u306a\u3069\u306e\u500b\u4eba\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u304c\u81ea\u52d5\u7684\u306b\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002</li> <li>\u3053\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306f\u5b8c\u5168\u306b\u9694\u96e2\u3055\u308c\u305f\u74b0\u5883\u3067\u3001\u958b\u767a\u8005\u306b\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8 Kubernetes \u30cd\u30fc\u30e0\u30b9\u30da\u30fc\u30b9\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#2","title":"2. \u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30c7\u30d7\u30ed\u30a4","text":"<ul> <li>\u958b\u767a\u8005\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u3001Node.js \u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3068 React \u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</li> <li>HKS CLI \u3092\u4f7f\u7528\u3057\u3066\u3001\u958b\u767a\u8005\u306f\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30f3\u30c6\u30ca\u3092**\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb**\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u958b\u767a\u3068\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u306b\u6700\u9069\u306a\u30b3\u30b9\u30c8\u52b9\u7387\u306e\u9ad8\u3044\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u3059\u3002</li> <li>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u5fc5\u8981\u306a\u5834\u5408\u3001HKS \u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30a4\u30b9\u304b\u3089 PostgreSQL \u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3067\u304d\u307e\u3059\u3002\u3053\u308c\u306f\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8\u30dc\u30ea\u30e5\u30fc\u30e0\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u30d7\u30e9\u30f3\u306b\u306f\u9650\u5b9a\u91cf\u306e\u9ad8\u901f\u30b9\u30c8\u30ec\u30fc\u30b8\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#3-cicd","title":"3. CI/CD \u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ul> <li>\u958b\u767a\u8005\u306f\u500b\u4eba\u306e GitHub \u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306b\u63a5\u7d9a\u3057\u307e\u3059\u3002</li> <li>\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3092\u4f7f\u7528\u3057\u3066\u30b7\u30f3\u30d7\u30eb\u306a CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\uff1a</li> <li><code>git push</code> \u306e\u305f\u3073\u306b\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306f\u81ea\u52d5\u7684\u306b\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u30d3\u30eb\u30c9\u3057\u307e\u3059\u3002</li> <li>\u30e6\u30cb\u30c3\u30c8\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u5185\u306e\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u74b0\u5883\u306b\u65b0\u3057\u3044\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#4","title":"4. \u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u3068\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u30b8\u30e7\u30d6\u306e\u6d3b\u7528","text":"<ul> <li>\u6bce\u65e5\u306e\u30b5\u30de\u30ea\u30fc\u30e1\u30fc\u30eb\u9001\u4fe1\u306a\u3069\u306e\u30bf\u30b9\u30af\u3092\u51e6\u7406\u3059\u308b\u305f\u3081\u306b\u3001\u958b\u767a\u8005\u306f1\u65e51\u56de\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9 Function \u3092\u30c8\u30ea\u30ac\u30fc\u3059\u308b CronJob \u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</li> <li>Function \u306b\u306f\u30d3\u30b8\u30cd\u30b9\u30ed\u30b8\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u304a\u308a\u3001\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3055\u308c\u305f\u30bf\u30b9\u30af\u3092\u5b9f\u884c\u3059\u308b\u975e\u5e38\u306b\u52b9\u7387\u7684\u306a\u65b9\u6cd5\u3067\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#5-aiops","title":"5. AIOps \u30a2\u30b7\u30b9\u30bf\u30f3\u30b9","text":"<ul> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u554f\u984c\u3092\u7d4c\u9a13\u3057\u305f\u5834\u5408\u3001\u7d71\u5408\u3055\u308c\u305f **AIOps \u30a2\u30b7\u30b9\u30bf\u30f3\u30c8**\u304c\u7570\u5e38\uff08\u30e1\u30e2\u30ea\u30ea\u30fc\u30af\u306a\u3069\uff09\u3092\u691c\u51fa\u3067\u304d\u307e\u3059\u3002</li> <li>\u8a73\u7d30\u306a\u30ec\u30dd\u30fc\u30c8\u3068\u4fee\u6b63\u306e\u63d0\u6848\u3092\u542b\u3080 Slack \u901a\u77e5\u3067\u958b\u767a\u8005\u306b\u7a4d\u6975\u7684\u306b\u901a\u77e5\u3067\u304d\u3001\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u306e\u6642\u9593\u3092\u7bc0\u7d04\u3057\u307e\u3059\u3002</li> <li>\u3053\u306e\u30d7\u30e9\u30f3\u306e AIOps \u6a5f\u80fd\u306f\u3001\u30b3\u30a2\u76e3\u8996\u3068\u7570\u5e38\u691c\u51fa\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#6","title":"6. \u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\uff1a\u5c02\u7528\u30ce\u30fc\u30c9","text":"<ul> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u672c\u756a\u74b0\u5883\u306e\u6e96\u5099\u304c\u3067\u304d\u308b\u3068\u3001\u3088\u308a\u591a\u304f\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30ea\u30bd\u30fc\u30b9\u4fdd\u8a3c\u304c\u5fc5\u8981\u306b\u306a\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002</li> <li>\u958b\u767a\u8005\u306f**\u5c02\u7528\u30ce\u30fc\u30c9**\u3092\u542b\u3080\u3088\u3046\u306b\u30d7\u30e9\u30f3\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3067\u304d\u307e\u3059\u3002</li> <li>UI \u304b\u3089\u3001\u65b0\u3057\u3044\u5c02\u7528\u30ce\u30fc\u30c9\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u8ffd\u52a0\u3055\u308c\u3001\u3088\u308a\u9ad8\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u5206\u96e2\u306e\u305f\u3081\u306b\u672c\u756a\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u79fb\u52d5\u3067\u304d\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/single-user-plan/#_3","title":"\u6a5f\u80fd\u306e\u6982\u8981","text":""},{"location":"ja/usecases/single-user-plan/#hobby","title":"Hobby \u30d7\u30e9\u30f3\u306e\u6a5f\u80fd","text":"\u6a5f\u80fd Hobby \u30d7\u30e9\u30f3\u306e\u4f7f\u7528 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 1\u3064\u306e\u500b\u4eba\u7528\u9694\u96e2\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 \u30ce\u30fc\u30c9 \u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306e\u307f CI/CD \u57fa\u672c\u7684\u306a\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u30d9\u30fc\u30b9\u306e\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 Functions \u6700\u59275\u3064\u306e\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570 CronJobs \u6700\u592710\u500b\u306e\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u30b8\u30e7\u30d6 \u30b9\u30c8\u30ec\u30fc\u30b8 10GB \u306e\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8 AIOps \u57fa\u672c\u7684\u306a\u76e3\u8996\u3068\u30a2\u30e9\u30fc\u30c8 \u30b5\u30dd\u30fc\u30c8 \u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u30b5\u30dd\u30fc\u30c8"},{"location":"ja/usecases/single-user-plan/#pro","title":"Pro \u30d7\u30e9\u30f3\u306e\u6a5f\u80fd","text":"<p>\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u672c\u756a\u74b0\u5883\u306b\u79fb\u884c\u3059\u308b\u6e96\u5099\u304c\u3067\u304d\u305f\u3089\u3001Pro \u30d7\u30e9\u30f3\u306b\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3057\u3066\u62e1\u5f35\u6a5f\u80fd\u3092\u5229\u7528\u3067\u304d\u307e\u3059\uff1a</p> \u6a5f\u80fd Pro \u30d7\u30e9\u30f3\u306e\u4f7f\u7528 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 \u672c\u756a\u30b0\u30ec\u30fc\u30c9\u306e\u5206\u96e2\u3092\u5099\u3048\u305f1\u3064\u306e\u500b\u4eba\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 \u30ce\u30fc\u30c9 \u5c02\u7528\u30ce\u30fc\u30c91\u53f0\u542b\u3080\uff08\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u53ef\u80fd\uff09 CI/CD \u4e26\u5217\u30d3\u30eb\u30c9\u3092\u5099\u3048\u305f\u9ad8\u5ea6\u306a\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 Functions \u7121\u5236\u9650\u306e\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570 CronJobs \u7121\u5236\u9650\u306e\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u30b8\u30e7\u30d6 \u30b9\u30c8\u30ec\u30fc\u30b8 100GB \u306e\u9ad8\u6027\u80fd SSD \u30b9\u30c8\u30ec\u30fc\u30b8 AIOps \u30d5\u30eb AIOps \u30b9\u30a4\u30fc\u30c8\uff1a\u7570\u5e38\u691c\u51fa\u3001\u4e88\u6e2c\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3001\u30b3\u30b9\u30c8\u6700\u9069\u5316 \u30d0\u30c3\u30af\u30a2\u30c3\u30d7 7\u65e5\u9593\u4fdd\u6301\u306e\u81ea\u52d5\u65e5\u6b21\u30d0\u30c3\u30af\u30a2\u30c3\u30d7 \u30b5\u30dd\u30fc\u30c8 24\u6642\u9593\u5fdc\u7b54\u306e\u512a\u5148\u30e1\u30fc\u30eb\u30b5\u30dd\u30fc\u30c8 SLA 99.9% \u30a2\u30c3\u30d7\u30bf\u30a4\u30e0\u4fdd\u8a3c"},{"location":"ja/usecases/single-user-plan/#hobby-pro","title":"Hobby \u304b\u3089 Pro \u3078\u306e\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9","text":"<p>\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u30d7\u30ed\u30bb\u30b9\u306f\u30b7\u30fc\u30e0\u30ec\u30b9\u3067\u3059\uff1a</p> <ol> <li>\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u3067\u300cPro \u306b\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u300d\u3092\u30af\u30ea\u30c3\u30af</li> <li>\u65e2\u5b58\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306f\u4e2d\u65ad\u306a\u304f\u5b9f\u884c\u3092\u7d9a\u3051\u307e\u3059</li> <li>\u5c02\u7528\u30ce\u30fc\u30c9\u304c\u6570\u5206\u4ee5\u5185\u306b\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u307e\u3059</li> <li>\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u5411\u4e0a\u306e\u305f\u3081\u306b\u91cd\u8981\u306a\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u3092\u5c02\u7528\u30ce\u30fc\u30c9\u306b\u79fb\u884c</li> <li>\u62e1\u5f35\u6a5f\u80fd\u3068\u30b5\u30dd\u30fc\u30c8\u3092\u3059\u3050\u306b\u5229\u7528\u958b\u59cb</li> </ol>"},{"location":"ja/usecases/team-plan/","title":"\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u30b7\u30ca\u30ea\u30aa","text":"<p>\u3053\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3067\u306f\u3001Hexabase.AI \u306e **\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3**\u3092\u6d3b\u7528\u3059\u308b\u958b\u767a\u30c1\u30fc\u30e0\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002\u3053\u306e\u30d7\u30e9\u30f3\u306f\u3001\u5171\u6709\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3068\u30ac\u30d0\u30ca\u30f3\u30b9\u3067\u8907\u6570\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3067\u30b3\u30e9\u30dc\u30ec\u30fc\u30b7\u30e7\u30f3\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u3084\u4e2d\u5c0f\u4f01\u696d\u306b\u6700\u9069\u3067\u3059\u3002</p>"},{"location":"ja/usecases/team-plan/#_2","title":"\u76ee\u6a19","text":"<p>\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u306e\u76ee\u6a19\u306f\u3001\u30b9\u30bf\u30fc\u30c8\u30a2\u30c3\u30d7\u3084\u958b\u767a\u30c1\u30fc\u30e0\u306b\u5354\u8abf\u7684\u3067\u5b89\u5168\u304b\u3064\u7d71\u5236\u3055\u308c\u305f\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u5171\u6709\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3\u3068\u660e\u78ba\u306a\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\u306b\u3088\u308a\u3001\u7570\u306a\u308b\u74b0\u5883\uff08\u958b\u767a\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u3001\u672c\u756a\u306a\u3069\uff09\u306b\u308f\u305f\u308b\u8907\u6570\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3092\u7ba1\u7406\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u30c1\u30fc\u30e0\u5411\u3051\u306b\u8a2d\u8a08\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"ja/usecases/team-plan/#1","title":"1. \u7d44\u7e54\u3068\u30c1\u30fc\u30e0\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ul> <li>\u7ba1\u7406\u8005\u304c\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u306b\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u3057\u3001\u7d44\u7e54\uff08\u4f8b\uff1a<code>MyStartupInc</code>\uff09\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002</li> <li>\u7ba1\u7406\u8005\u306f DevOps \u30a8\u30f3\u30b8\u30cb\u30a2\u3092 **\u7d44\u7e54\u7ba1\u7406\u8005**\u3068\u3057\u3066\u3001\u4ed6\u306e\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3092 **\u7d44\u7e54\u30e6\u30fc\u30b6\u30fc**\u3068\u3057\u3066\u62db\u5f85\u3057\u307e\u3059\u3002</li> <li>\u3053\u306e\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff08RBAC\uff09\u306b\u3088\u308a\u3001\u7d44\u7e54\u7ba1\u7406\u8005\u306e\u307f\u304c\u8acb\u6c42\u7ba1\u7406\u3001\u65b0\u3057\u3044\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u4f5c\u6210\u3001\u7d44\u7e54\u5168\u4f53\u306e\u30dd\u30ea\u30b7\u30fc\u8a2d\u5b9a\u3092\u884c\u3048\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#2","title":"2. \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u4f5c\u6210","text":"<ul> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u306f\u74b0\u5883\u3092\u5206\u96e2\u3059\u308b\u305f\u3081\u306b\u8907\u6570\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u3057\u307e\u3059\uff1a</li> <li><code>SaaS-Product-Dev</code>\uff1a\u65e5\u3005\u306e\u958b\u767a\u3068\u30c6\u30b9\u30c8\u7528</li> <li><code>SaaS-Product-Staging</code>\uff1a\u672c\u756a\u524d\u30c6\u30b9\u30c8\u7528\u306e\u3088\u308a\u5b89\u5b9a\u3057\u305f\u74b0\u5883</li> <li>\u7ba1\u7406\u8005\u306f\u3053\u308c\u3089\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u30c1\u30fc\u30e0\u3068\u30e6\u30fc\u30b6\u30fc\u3092\u5272\u308a\u5f53\u3066\u3001\u9069\u5207\u306a\u6a29\u9650\uff08<code>workspace-admin</code>\u3001<code>developer</code> \u306a\u3069\uff09\u3092\u4ed8\u4e0e\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#3","title":"3. \u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u3068\u30a4\u30f3\u30d5\u30e9\u30b9\u30c8\u30e9\u30af\u30c1\u30e3","text":"<ul> <li>\u30c1\u30fc\u30e0\u306e\u30cb\u30fc\u30ba\u3092\u30b5\u30dd\u30fc\u30c8\u3059\u308b\u305f\u3081\u3001\u7d44\u7e54\u7ba1\u7406\u8005\u306f\u7d44\u7e54\u7528\u306b\u3044\u304f\u3064\u304b\u306e**\u5c02\u7528\u30ce\u30fc\u30c9**\u3092\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3057\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u3067\u5171\u6709\u3067\u304d\u307e\u3059\u3002</li> <li>\u307e\u305f\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u7528\u306e\u9ad8\u6027\u80fd**\u30d6\u30ed\u30c3\u30af\u30b9\u30c8\u30ec\u30fc\u30b8**\u3068\u3001**\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7**\u7528\u306e\u5225\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30b9\u30c8\u30ec\u30fc\u30b8\u30d0\u30b1\u30c3\u30c8\u3092\u63a5\u7d9a\u3057\u307e\u3059\u3002</li> <li>\u958b\u767a\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u8a2d\u5b9a\u3057\u3001\u5358\u4e00\u30e6\u30fc\u30b6\u30fc\u304c\u904e\u5270\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u6d88\u8cbb\u3059\u308b\u306e\u3092\u9632\u304e\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#4-cicd","title":"4. \u5354\u8abf\u958b\u767a\u3068 CI/CD","text":"<ul> <li>\u30c1\u30fc\u30e0\u306e\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306f GitLab \u3084 GitHub \u306a\u3069\u306e\u4e2d\u592e Git \u30ea\u30dd\u30b8\u30c8\u30ea\u3067\u30db\u30b9\u30c8\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> <li>DevOps \u30a8\u30f3\u30b8\u30cb\u30a2\u304c\u9ad8\u5ea6\u306a CI/CD \u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\uff1a</li> <li>\u30d5\u30a3\u30fc\u30c1\u30e3\u30fc\u30d6\u30e9\u30f3\u30c1\u306f\u81ea\u52d5\u7684\u306b\u9694\u96e2\u3055\u308c\u305f\u30d7\u30ec\u30d3\u30e5\u30fc\u74b0\u5883\u306b\u30c7\u30d7\u30ed\u30a4\u3055\u308c\u307e\u3059\u3002</li> <li><code>main</code> \u30d6\u30e9\u30f3\u30c1\u3078\u306e\u30de\u30fc\u30b8\u306f <code>SaaS-Product-Dev</code> \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3078\u306e\u30c7\u30d7\u30ed\u30a4\u3092\u30c8\u30ea\u30ac\u30fc\u3057\u307e\u3059\u3002</li> <li>\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u3078\u306e\u30d7\u30ed\u30e2\u30fc\u30b7\u30e7\u30f3\u306b\u306f\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u7ba1\u7406\u8005\u304b\u3089\u306e\u624b\u52d5\u627f\u8a8d\u30b9\u30c6\u30c3\u30d7\u304c\u5fc5\u8981\u3067\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#5-aiops","title":"5. \u9ad8\u5ea6\u306a AIOps \u3068\u53ef\u89b3\u6e2c\u6027","text":"<ul> <li>\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u3068\u672c\u756a\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3067\u306f\u3001\u30d5\u30eb\u6a5f\u80fd\u306e AIOps \u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002</li> <li>AIOps \u30a2\u30b7\u30b9\u30bf\u30f3\u30c8\u306f\u30ed\u30b0\u3001\u30c8\u30ec\u30fc\u30b9\u3001\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u5206\u6790\u3057\u3066\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u6f5c\u5728\u7684\u306a\u30dc\u30c8\u30eb\u30cd\u30c3\u30af\u306b\u95a2\u3059\u308b\u6d1e\u5bdf\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</li> <li>\u307e\u305f\u3001\u904e\u5270\u306b\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30ea\u30bd\u30fc\u30b9\u306e\u30b5\u30a4\u30ba\u9069\u6b63\u5316\u3092\u63d0\u6848\u3059\u308b\u306a\u3069\u3001\u30b3\u30b9\u30c8\u6700\u9069\u5316\u306e\u63a8\u5968\u4e8b\u9805\u3082\u63d0\u4f9b\u3057\u307e\u3059\u3002</li> <li>\u30c1\u30fc\u30e0\u306f\u5f37\u529b\u306a\u53ef\u89b3\u6e2c\u6027\u30c4\u30fc\u30eb\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u307e\u3059\u304c\u3001\u3053\u306e\u30d7\u30e9\u30f3\u3067\u306f\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u3068\u6bd4\u8f03\u3057\u3066**\u76e3\u67fb\u30ed\u30b0**\u306e\u4fdd\u6301\u671f\u9593\u306b\u4e00\u90e8\u5236\u9650\u304c\u3042\u308a\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#6-dr","title":"6. \u707d\u5bb3\u5fa9\u65e7\uff08DR\uff09\u3068\u30d0\u30c3\u30af\u30a2\u30c3\u30d7","text":"<ul> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u306f\u57fa\u672c\u7684\u306a\u707d\u5bb3\u5fa9\u65e7\u8a08\u753b\u3092\u69cb\u6210\u3057\u307e\u3059\u3002</li> <li>\u91cd\u8981\u306a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30dc\u30ea\u30e5\u30fc\u30e0\u306e\u65e5\u6b21\u30b9\u30ca\u30c3\u30d7\u30b7\u30e7\u30c3\u30c8\u304c\u81ea\u52d5\u7684\u306b\u53d6\u5f97\u3055\u308c\u3001\u5b89\u5168\u3067\u5730\u7406\u5197\u9577\u6027\u306e\u3042\u308b\u5834\u6240\u306b\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002</li> <li>\u30c1\u30fc\u30e0\u306f\u30c7\u30fc\u30bf\u640d\u5931\u306e\u5834\u5408\u3001\u3053\u308c\u3089\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u304b\u3089\u7c21\u5358\u306b\u5fa9\u5143\u3067\u304d\u307e\u3059\u3002</li> </ul>"},{"location":"ja/usecases/team-plan/#_3","title":"\u4f7f\u7528\u6a5f\u80fd\u306e\u6982\u8981","text":"\u6a5f\u80fd \u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u306e\u4f7f\u7528 \u7d44\u7e54 \u30e6\u30fc\u30b6\u30fc\u3001\u8acb\u6c42\u3001\u30ea\u30bd\u30fc\u30b9\u306e\u96c6\u4e2d\u7ba1\u7406 RBAC \u7d44\u7e54\u7ba1\u7406\u8005\u3068\u7d44\u7e54\u30e6\u30fc\u30b6\u30fc\u306e\u30ed\u30fc\u30eb\u3001\u660e\u78ba\u306a\u8077\u52d9\u5206\u96e2\u3092\u63d0\u4f9b \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 \u7570\u306a\u308b\u74b0\u5883\uff08\u958b\u767a\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\uff09\u7528\u306e\u8907\u6570\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9 \u30ce\u30fc\u30c9 \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u3067\u5171\u6709\u3067\u304d\u308b\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3068\u5171\u6709\u6a5f\u80fd \u30b9\u30c8\u30ec\u30fc\u30b8\u3068\u30d0\u30c3\u30af\u30a2\u30c3\u30d7 \u9ad8\u5ea6\u306a\u30b9\u30c8\u30ec\u30fc\u30b8\u30bd\u30ea\u30e5\u30fc\u30b7\u30e7\u30f3\u3068\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u69cb\u6210\u306e\u30b5\u30dd\u30fc\u30c8 \u707d\u5bb3\u5fa9\u65e7 \u57fa\u672c\u7684\u306a\u707d\u5bb3\u5fa9\u65e7\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u5229\u7528\u53ef\u80fd CI/CD \u627f\u8a8d\u3068\u30de\u30eb\u30c1\u74b0\u5883\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u5099\u3048\u305f\u5b8c\u5168\u306b\u6a5f\u80fd\u3059\u308b\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3 AIOps \u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3068\u30b3\u30b9\u30c8\u6700\u9069\u5316\u306e\u305f\u3081\u306e\u9ad8\u5ea6\u306a AIOps \u6a5f\u80fd \u76e3\u67fb\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3 \u76e3\u67fb\u30ed\u30b0\u3068\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u6a5f\u80fd\u3078\u306e\u30a2\u30af\u30bb\u30b9\u3001\u4fdd\u6301\u671f\u9593\u3068\u7bc4\u56f2\u306b\u4e00\u90e8\u5236\u9650\u3042\u308a"},{"location":"ja/usecases-description/common/external-auth-signup/","title":"\u5916\u90e8\u8a8d\u8a3c\u3067Hexabase.AI\u306b\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u3059\u308b","text":""},{"location":"ja/usecases-description/common/external-auth-signup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u5916\u90e8\u8a8d\u8a3c\u3067Hexabase.AI\u306b\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u3059\u308b</p>"},{"location":"ja/usecases-description/common/external-auth-signup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u65b0\u898f\u30e6\u30fc\u30b6\u30fc  </li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\uff08GitHub\u3001Google\uff09</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\uff08GitHub \u307e\u305f\u306f Google\uff09\u306e\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u63a5\u7d9a\u304c\u5229\u7528\u53ef\u80fd\u3067\u3042\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304cHexabase.AI\u306e\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u6301\u3063\u3066\u3044\u306a\u3044</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u30e6\u30fc\u30b6\u30fc\u304cHexabase.AI\u306e\u516c\u5f0f\u30b5\u30a4\u30c8\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30e6\u30fc\u30b6\u30fc\u3092\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306b\u30ea\u30c0\u30a4\u30ec\u30af\u30c8\u3059\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u8a8d\u8a3c\u3092\u884c\u3046</li> <li>\u30e6\u30fc\u30b6\u30fc\u304cHexabase.AI\u3078\u306e\u30a2\u30af\u30bb\u30b9\u8a31\u53ef\u3092\u627f\u8a8d\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30e6\u30fc\u30b6\u30fc\u3092Hexabase.AI\u30b5\u30a4\u30c8\u306b\u623b\u3059</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30ab\u30a6\u30f3\u30c8\u8a2d\u5b9a\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5229\u7528\u30d7\u30e9\u30f3\u3092\u9078\u629e\u3059\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u5229\u7528\u898f\u7d04\u3068\u30d7\u30e9\u30a4\u30d0\u30b7\u30fc\u30dd\u30ea\u30b7\u30fc\u306b\u540c\u610f\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30ab\u30a6\u30f3\u30c8\u3092\u4f5c\u6210\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30e6\u30fc\u30b6\u30fc\u3092\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u6848\u5185\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/common/external-auth-signup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":""},{"location":"ja/usecases-description/common/external-auth-signup/#51","title":"5.1 \u65e2\u5b58\u30a2\u30ab\u30a6\u30f3\u30c8\u3068\u306e\u91cd\u8907","text":"<ul> <li>7.1a. \u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u304c\u65e2\u306b\u767b\u9332\u3055\u308c\u3066\u3044\u308b</li> <li>7.1b. \u30b7\u30b9\u30c6\u30e0\u304c\u300c\u3053\u306e\u30a2\u30ab\u30a6\u30f3\u30c8\u306f\u65e2\u306b\u767b\u9332\u3055\u308c\u3066\u3044\u307e\u3059\u300d\u3068\u8868\u793a\u3059\u308b</li> <li>7.1c. \u30e6\u30fc\u30b6\u30fc\u304c\u30ed\u30b0\u30a4\u30f3\u30da\u30fc\u30b8\u306b\u79fb\u52d5\u3059\u308b</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#52","title":"5.2 \u8a8d\u8a3c\u306e\u62d2\u5426\u307e\u305f\u306f\u30ad\u30e3\u30f3\u30bb\u30eb","text":"<ul> <li>5.2a. \u30e6\u30fc\u30b6\u30fc\u304c\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u306e\u8a8d\u8a3c\u3092\u30ad\u30e3\u30f3\u30bb\u30eb\u3059\u308b</li> <li>5.2b. \u30b7\u30b9\u30c6\u30e0\u304c\u300c\u8a8d\u8a3c\u304c\u30ad\u30e3\u30f3\u30bb\u30eb\u3055\u308c\u307e\u3057\u305f\u300d\u3068\u8868\u793a\u3059\u308b</li> <li>5.2c. \u30e6\u30fc\u30b6\u30fc\u304c\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u30da\u30fc\u30b8\u306b\u623b\u308b</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#53","title":"5.3 \u5916\u90e8\u8a8d\u8a3c\u30b5\u30fc\u30d3\u30b9\u969c\u5bb3","text":"<ul> <li>3.3a. \u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u306e\u30b5\u30fc\u30d3\u30b9\u304c\u5229\u7528\u3067\u304d\u306a\u3044</li> <li>3.3b. \u30b7\u30b9\u30c6\u30e0\u304c\u300c\u8a8d\u8a3c\u30b5\u30fc\u30d3\u30b9\u304c\u4e00\u6642\u7684\u306b\u5229\u7528\u3067\u304d\u307e\u305b\u3093\u300d\u3068\u8868\u793a\u3059\u308b</li> <li>3.3c. \u30e6\u30fc\u30b6\u30fc\u304c\u5f8c\u3067\u518d\u8a66\u884c\u3059\u308b\u304b\u3001\u5225\u306e\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3092\u9078\u629e\u3059\u308b</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u65b0\u898f\u30e6\u30fc\u30b6\u30fc\u30a2\u30ab\u30a6\u30f3\u30c8\u304cHexabase.AI\u306b\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u30ed\u30b0\u30a4\u30f3\u72b6\u614b\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u9078\u629e\u3055\u308c\u305f\u30d7\u30e9\u30f3\u304c\u9069\u7528\u3055\u308c\u3066\u3044\u308b</li> <li>\u5916\u90e8\u8a8d\u8a3c\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068\u306e\u9023\u643a\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b</li> </ul>"},{"location":"ja/usecases-description/common/external-auth-signup/#7","title":"7. \u88dc\u8db3\u4e8b\u9805","text":"<ul> <li>GitHub\u306e\u5834\u5408\uff1a2\u6bb5\u968e\u8a8d\u8a3c\u3084\u30e1\u30fc\u30eb\u975e\u516c\u958b\u8a2d\u5b9a\u306b\u3088\u308a\u8ffd\u52a0\u30b9\u30c6\u30c3\u30d7\u304c\u767a\u751f\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b</li> <li>Google\u306e\u5834\u5408\uff1a\u8907\u6570\u30a2\u30ab\u30a6\u30f3\u30c8\u9078\u629e\u3084\u4f01\u696d\u5236\u9650\u306b\u3088\u308a\u8ffd\u52a0\u78ba\u8a8d\u304c\u5fc5\u8981\u306a\u5834\u5408\u304c\u3042\u308b</li> </ul>"},{"location":"ja/usecases-description/enterprise/cost-management/","title":"\u30b3\u30b9\u30c8\u7ba1\u7406\u3068\u4e88\u7b97\u8a08\u753b\u3092\u5b9f\u884c\u3059\u308b","text":""},{"location":"ja/usecases-description/enterprise/cost-management/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u30b3\u30b9\u30c8\u7ba1\u7406\u3068\u4e88\u7b97\u8a08\u753b\u3092\u5b9f\u884c\u3059\u308b</p>"},{"location":"ja/usecases-description/enterprise/cost-management/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u8ca1\u52d9\u7ba1\u7406\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a IT\u90e8\u9580\u7ba1\u7406\u8005\u3001Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u5404\u4e8b\u696d\u90e8\u9580\u8cac\u4efb\u8005</li> </ul>"},{"location":"ja/usecases-description/enterprise/cost-management/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u304c\u5951\u7d04\u6e08\u307f\u3067\u3042\u308b</li> <li>\u8907\u6570\u306e\u4e8b\u696d\u90e8\u9580\u5411\u3051\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u304c\u5b58\u5728\u3059\u308b</li> <li>\u4f01\u696d\u306e\u4e88\u7b97\u30b5\u30a4\u30af\u30eb\u3068\u627f\u8a8d\u30d7\u30ed\u30bb\u30b9\u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b</li> <li>\u30b3\u30b9\u30c8\u914d\u5206\u306e\u57fa\u6e96\uff08\u4e8b\u696d\u90e8\u9580\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u3001\u30e9\u30d9\u30eb\uff09\u304c\u6c7a\u5b9a\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/enterprise/cost-management/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u300c\u30b3\u30b9\u30c8\u7ba1\u7406\u300d\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u73fe\u5728\u306e\u5168\u4f53\u7684\u306a\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u3068\u30b3\u30b9\u30c8\u3092\u8868\u793a\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u300c\u4e88\u7b97\u8a08\u753b\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u65b0\u5e74\u5ea6\u306e\u4e88\u7b97\u8a08\u753b\u3092\u958b\u59cb\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u4e8b\u696d\u90e8\u9580\u3054\u3068\u306e\u4e88\u7b97\u914d\u5206\u3092\u8a2d\u5b9a\u3059\u308b\uff08Finance-BU: $50,000\u3001Healthcare-Analytics: $80,000\uff09</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3054\u3068\u306e\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u4e88\u7b97\u306b\u57fa\u3065\u3044\u3066\u8a2d\u5b9a\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30a2\u30e9\u30fc\u30c8\u95be\u5024\uff08\u4e88\u7b97\u306e80%\u300190%\uff09\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u4e88\u7b97\u8a08\u753b\u3092\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u9069\u7528\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u300c\u30b3\u30b9\u30c8\u914d\u5206\u30ec\u30dd\u30fc\u30c8\u300d\u8a2d\u5b9a\u753b\u9762\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30b3\u30b9\u30c8\u5206\u6790\u306e\u8ef8\u3092\u8a2d\u5b9a\u3059\u308b\uff08\u4e8b\u696d\u90e8\u9580\u5225\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5225\u3001\u30ea\u30bd\u30fc\u30b9\u30bf\u30a4\u30d7\u5225\uff09</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30e9\u30d9\u30eb\u30d9\u30fc\u30b9\u306e\u30b3\u30b9\u30c8\u8ffd\u8de1\u3092\u6709\u52b9\u5316\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u904e\u53bb3\u30f6\u6708\u306e\u30b3\u30b9\u30c8\u5206\u6790\u30ec\u30dd\u30fc\u30c8\u3092\u751f\u6210\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30ec\u30dd\u30fc\u30c8\u306e\u81ea\u52d5\u914d\u4fe1\u8a2d\u5b9a\u3092\u884c\u3046\uff08\u6708\u6b21\u3001\u5404\u4e8b\u696d\u90e8\u9580\u8cac\u4efb\u8005\u5b9b\uff09</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u300c\u56fa\u5b9a\u4fa1\u683c\u5951\u7d04\u300d\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u78ba\u8a8d\u3057\u3001\u5e74\u9593\u5951\u7d04\u3078\u306e\u79fb\u884c\u3092\u691c\u8a0e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u4e88\u7b97\u76e3\u8996\u3068\u30a2\u30e9\u30fc\u30c8\u6a5f\u80fd\u3092\u6709\u52b9\u5316\u3059\u308b</li> <li>\u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u8a2d\u5b9a\u5b8c\u4e86\u78ba\u8a8d\u3068\u6b21\u56de\u30ec\u30d3\u30e5\u30fc\u65e5\u7a0b\u3092\u8a18\u9332\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/enterprise/cost-management/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u4e88\u7b97\u8d85\u904e\u30a2\u30e9\u30fc\u30c8 - 15a. Healthcare-Analytics\u4e8b\u696d\u90e8\u9580\u304c\u4e88\u7b97\u306e80%\u306b\u5230\u9054\u3059\u308b - 15b. \u30b7\u30b9\u30c6\u30e0\u304c\u8ca1\u52d9\u7ba1\u7406\u8005\u3068\u4e8b\u696d\u90e8\u9580\u8cac\u4efb\u8005\u306b\u30a2\u30e9\u30fc\u30c8\u3092\u9001\u4fe1\u3059\u308b - 15c. \u4e8b\u696d\u90e8\u9580\u8cac\u4efb\u8005\u304c\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u3092\u898b\u76f4\u3059\u304b\u3001\u8ffd\u52a0\u4e88\u7b97\u3092\u7533\u8acb\u3059\u308b - 15d. \u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u4e88\u7b97\u8abf\u6574\u3092\u627f\u8a8d\u3059\u308b</p> <p>5b. \u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u4e0d\u8db3 - 6a. \u8a2d\u5b9a\u3057\u305f\u4e88\u7b97\u306b\u5bfe\u3057\u3066\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u4e0d\u5341\u5206\u3067\u3042\u308b - 6b. \u30b7\u30b9\u30c6\u30e0\u304c\u63a8\u5968\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u3092\u63d0\u793a\u3059\u308b - 6c. \u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u4e88\u7b97\u914d\u5206\u3092\u8abf\u6574\u3059\u308b\u304b\u3001\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u4fee\u6b63\u3059\u308b</p> <p>5c. \u30ec\u30dd\u30fc\u30c8\u751f\u6210\u5931\u6557 - 12a. \u904e\u53bb\u30c7\u30fc\u30bf\u306e\u4e0d\u6574\u5408\u306b\u3088\u308a\u30ec\u30dd\u30fc\u30c8\u751f\u6210\u304c\u5931\u6557\u3059\u308b - 12b. \u30b7\u30b9\u30c6\u30e0\u304c\u30c7\u30fc\u30bf\u306e\u554f\u984c\u7b87\u6240\u3092\u7279\u5b9a\u3057\u3001\u30a8\u30e9\u30fc\u30ec\u30dd\u30fc\u30c8\u3092\u8868\u793a\u3059\u308b - 12c. IT\u90e8\u9580\u7ba1\u7406\u8005\u304c\u30c7\u30fc\u30bf\u4fee\u6b63\u3092\u5b9f\u884c\u3059\u308b - 12d. \u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u30ec\u30dd\u30fc\u30c8\u751f\u6210\u3092\u518d\u5b9f\u884c\u3059\u308b</p> <p>5d. \u627f\u8a8d\u30d7\u30ed\u30bb\u30b9\u9045\u5ef6 - 14a. \u4e8b\u696d\u90e8\u9580\u8cac\u4efb\u8005\u304b\u3089\u306e\u4e88\u7b97\u627f\u8a8d\u304c\u671f\u9650\u5185\u306b\u5f97\u3089\u308c\u306a\u3044 - 14b. \u30b7\u30b9\u30c6\u30e0\u304c\u627f\u8a8d\u5f85\u3061\u30b9\u30c6\u30fc\u30bf\u30b9\u3068\u671f\u9650\u3092\u8868\u793a\u3059\u308b - 14c. \u8ca1\u52d9\u7ba1\u7406\u8005\u304c\u627f\u8a8d\u50ac\u4fc3\u307e\u305f\u306f\u66ab\u5b9a\u4e88\u7b97\u9069\u7528\u3092\u6c7a\u5b9a\u3059\u308b</p>"},{"location":"ja/usecases-description/enterprise/cost-management/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u5404\u4e8b\u696d\u90e8\u9580\u306b\u5e74\u9593\u4e88\u7b97\u304c\u5272\u308a\u5f53\u3066\u3089\u308c\u3066\u3044\u308b</li> <li>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3054\u3068\u306b\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u4e88\u7b97\u8d85\u904e\u30a2\u30e9\u30fc\u30c8\u6a5f\u80fd\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u8a73\u7d30\u306a\u30b3\u30b9\u30c8\u914d\u5206\u30ec\u30dd\u30fc\u30c8\u304c\u5b9a\u671f\u7684\u306b\u751f\u6210\u3055\u308c\u308b</li> <li>\u4e8b\u696d\u90e8\u9580\u5225\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u5225\u306e\u30b3\u30b9\u30c8\u8ffd\u8de1\u304c\u5b9f\u73fe\u3055\u308c\u3066\u3044\u308b</li> <li>\u30e9\u30d9\u30eb\u30d9\u30fc\u30b9\u306e\u30b3\u30b9\u30c8\u5206\u6790\u304c\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u8ca1\u52d9\u30ac\u30d0\u30ca\u30f3\u30b9\u3068\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u304c\u78ba\u7acb\u3055\u308c\u3066\u3044\u308b</li> <li>\u56fa\u5b9a\u4fa1\u683c\u5951\u7d04\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u8a55\u4fa1\u3055\u308c\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u9069\u7528\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/enterprise/governance-setup/","title":"\u96c6\u4e2d\u30ac\u30d0\u30ca\u30f3\u30b9\u3068SSO\u7d71\u5408\u3092\u8a2d\u5b9a\u3059\u308b","text":""},{"location":"ja/usecases-description/enterprise/governance-setup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u96c6\u4e2d\u30ac\u30d0\u30ca\u30f3\u30b9\u3068SSO\u7d71\u5408\u3092\u8a2d\u5b9a\u3059\u308b</p>"},{"location":"ja/usecases-description/enterprise/governance-setup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a IT\u90e8\u9580\u7ba1\u7406\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001SSO\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\uff08Okta/Azure AD\uff09\u3001\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30e6\u30fc\u30b6\u30fc</li> </ul>"},{"location":"ja/usecases-description/enterprise/governance-setup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30d7\u30e9\u30f3\u304c\u5951\u7d04\u6e08\u307f\u3067\u3042\u308b</li> <li>\u65e2\u5b58\u306eSSO\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\uff08Okta\u3001Azure AD\u306a\u3069\uff09\u304c\u904b\u7528\u3055\u308c\u3066\u3044\u308b</li> <li>\u4f01\u696d\u306e\u5185\u90e8\u7d44\u7e54\u69cb\u9020\u3068\u30ed\u30fc\u30eb\u5b9a\u7fa9\u304c\u660e\u78ba\u5316\u3055\u308c\u3066\u3044\u308b</li> <li>SAML/OIDC\u306e\u6280\u8853\u4ed5\u69d8\u306b\u3064\u3044\u3066\u7406\u89e3\u3057\u3066\u3044\u308b\u62c5\u5f53\u8005\u304c\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/enterprise/governance-setup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>IT\u90e8\u9580\u7ba1\u7406\u8005\u304cHexabase.AI\u30a8\u30f3\u30bf\u30fc\u30d7\u30e9\u30a4\u30ba\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u30ed\u30b0\u30a4\u30f3\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u300c\u7d44\u7e54\u8a2d\u5b9a\u300d\u2192\u300cSSO\u7d71\u5408\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cSSO\u8a2d\u5b9a\u30a6\u30a3\u30b6\u30fc\u30c9\u3092\u8868\u793a\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304cSSO\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u30bf\u30a4\u30d7\uff08Okta\uff09\u3092\u9078\u629e\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304cOkta\u306e\u30e1\u30bf\u30c7\u30fc\u30bfURL\u3001Entity ID\u3001\u8a3c\u660e\u66f8\u60c5\u5831\u3092\u5165\u529b\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cSSO\u8a2d\u5b9a\u306e\u691c\u8a3c\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u30c6\u30b9\u30c8\u30e6\u30fc\u30b6\u30fc\u3067SSO\u8a8d\u8a3c\u3092\u30c6\u30b9\u30c8\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cSSO\u8a8d\u8a3c\u304c\u6210\u529f\u3057\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u300c\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u7ba1\u7406\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u4f01\u696d\u306e\u7d44\u7e54\u69cb\u9020\u306b\u57fa\u3065\u3044\u305f\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u3092\u4f5c\u6210\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u5404\u90e8\u9580\uff08Finance\u3001Engineering\u3001Operations\uff09\u306b\u5bfe\u5fdc\u3059\u308b\u30ed\u30fc\u30eb\u3092\u5b9a\u7fa9\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u5404\u30ed\u30fc\u30eb\u306b\u5bfe\u3059\u308b\u8a73\u7d30\u306a\u6a29\u9650\uff08\u30ea\u30bd\u30fc\u30b9\u4f5c\u6210\u3001\u524a\u9664\u3001\u95b2\u89a7\u306a\u3069\uff09\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30ed\u30fc\u30eb\u8a2d\u5b9a\u3092RBAC\u30b7\u30b9\u30c6\u30e0\u306b\u9069\u7528\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304cSSO\u5c5e\u6027\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u8a2d\u5b9a\u3057\u3001Okta\u306e\u30b0\u30eb\u30fc\u30d7\u60c5\u5831\u3092Hexabase\u30ed\u30fc\u30eb\u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b</li> <li>\u7ba1\u7406\u8005\u304c\u300c\u7d44\u7e54\u30dd\u30ea\u30b7\u30fc\u300d\u3092\u8a2d\u5b9a\u3057\u3001\u30d1\u30b9\u30ef\u30fc\u30c9\u8981\u4ef6\u3001\u30bb\u30c3\u30b7\u30e7\u30f3\u7ba1\u7406\u306a\u3069\u3092\u69cb\u6210\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5168\u8a2d\u5b9a\u3092\u4fdd\u5b58\u3057\u3001SSO\u7d71\u5408\u3092\u6709\u52b9\u5316\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/enterprise/governance-setup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. SSO\u8a8d\u8a3c\u5931\u6557 - 7a. \u30c6\u30b9\u30c8\u30e6\u30fc\u30b6\u30fc\u3067\u306eSSO\u8a8d\u8a3c\u304c\u5931\u6557\u3059\u308b - 7b. \u30b7\u30b9\u30c6\u30e0\u304c\u8a73\u7d30\u306a\u30a8\u30e9\u30fc\u30ed\u30b0\uff08\u8a3c\u660e\u66f8\u3001\u30e1\u30bf\u30c7\u30fc\u30bf\u30a8\u30e9\u30fc\u306a\u3069\uff09\u3092\u8868\u793a\u3059\u308b - 7c. \u7ba1\u7406\u8005\u304cSSO\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u8a2d\u5b9a\u3092\u78ba\u8a8d\u30fb\u4fee\u6b63\u3059\u308b - 7d. \u7ba1\u7406\u8005\u304cSSO\u8a2d\u5b9a\u3092\u518d\u30c6\u30b9\u30c8\u3059\u308b</p> <p>5b. \u5c5e\u6027\u30de\u30c3\u30d4\u30f3\u30b0\u30a8\u30e9\u30fc - 14a. SSO\u5c5e\u6027\u306e\u30de\u30c3\u30d4\u30f3\u30b0\u304c\u6b63\u3057\u304f\u52d5\u4f5c\u3057\u306a\u3044 - 14b. \u30e6\u30fc\u30b6\u30fc\u304c\u671f\u5f85\u3055\u308c\u308b\u30ed\u30fc\u30eb\u3067\u8a8d\u8a3c\u3055\u308c\u306a\u3044 - 14c. \u7ba1\u7406\u8005\u304cOkta\u30b0\u30eb\u30fc\u30d7\u8a2d\u5b9a\u3068\u30de\u30c3\u30d4\u30f3\u30b0\u8a2d\u5b9a\u3092\u78ba\u8a8d\u3059\u308b - 14d. \u7ba1\u7406\u8005\u304c\u5c5e\u6027\u30de\u30c3\u30d4\u30f3\u30b0\u3092\u4fee\u6b63\u3057\u3001\u518d\u30c6\u30b9\u30c8\u3059\u308b</p> <p>5c. \u6a29\u9650\u8a2d\u5b9a\u306e\u7af6\u5408 - 12a. \u8a2d\u5b9a\u3057\u305f\u6a29\u9650\u306b\u77db\u76fe\u3084\u7af6\u5408\u304c\u5b58\u5728\u3059\u308b - 12b. \u30b7\u30b9\u30c6\u30e0\u304c\u6a29\u9650\u7af6\u5408\u306e\u8b66\u544a\u3092\u8868\u793a\u3059\u308b - 12c. \u7ba1\u7406\u8005\u304c\u6a29\u9650\u8a2d\u5b9a\u3092\u898b\u76f4\u3057\u3001\u7af6\u5408\u3092\u89e3\u6c7a\u3059\u308b</p> <p>5d. \u65e2\u5b58\u30e6\u30fc\u30b6\u30fc\u306e\u79fb\u884c\u554f\u984c - 16a. SSO\u6709\u52b9\u5316\u5f8c\u3001\u65e2\u5b58\u306e\u975eSSO\u30e6\u30fc\u30b6\u30fc\u304c\u30a2\u30af\u30bb\u30b9\u3067\u304d\u306a\u304f\u306a\u308b - 16b. \u30b7\u30b9\u30c6\u30e0\u304c\u79fb\u884c\u30ac\u30a4\u30c9\u3068\u4e00\u6642\u7684\u306a\u30a2\u30af\u30bb\u30b9\u65b9\u6cd5\u3092\u63d0\u793a\u3059\u308b - 16c. \u7ba1\u7406\u8005\u304c\u6bb5\u968e\u7684\u79fb\u884c\u30d7\u30e9\u30f3\u3092\u5b9f\u884c\u3059\u308b</p>"},{"location":"ja/usecases-description/enterprise/governance-setup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>SSO\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3068Hexabase.AI\u304c\u6b63\u5e38\u306b\u7d71\u5408\u3055\u308c\u3066\u3044\u308b</li> <li>\u4f01\u696d\u306e\u5185\u90e8\u7d44\u7e54\u69cb\u9020\u306b\u5bfe\u5fdc\u3057\u305f\u30ab\u30b9\u30bf\u30e0\u30ed\u30fc\u30eb\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u30e6\u30fc\u30b6\u30fc\u304c\u4f01\u696d\u306eID\u30d7\u30ed\u30d0\u30a4\u30c0\u30fc\u3067\u30b7\u30fc\u30e0\u30ec\u30b9\u306b\u8a8d\u8a3c\u3067\u304d\u308b</li> <li>\u304d\u3081\u7d30\u304b\u306aRBAC\u6a29\u9650\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u7d44\u7e54\u5168\u4f53\u306e\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30dd\u30ea\u30b7\u30fc\u304c\u9069\u7528\u3055\u308c\u3066\u3044\u308b</li> <li>\u4e2d\u592e\u96c6\u6a29\u7684\u306a\u7d44\u7e54\u7ba1\u7406\u304c\u5b9f\u73fe\u3055\u308c\u3066\u3044\u308b</li> <li>\u76e3\u67fb\u30ed\u30b0\u304c\u6709\u52b9\u306b\u306a\u308a\u3001\u5168\u30a2\u30af\u30c6\u30a3\u30d3\u30c6\u30a3\u304c\u8a18\u9332\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/application-deployment/","title":"\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b","text":""},{"location":"ja/usecases-description/single-user/application-deployment/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3092\u30c7\u30d7\u30ed\u30a4\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/application-deployment/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a HKS CLI\u3001Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea</li> </ul>"},{"location":"ja/usecases-description/single-user/application-deployment/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u6240\u6709\u3057\u3066\u3044\u308b</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\uff08Node.js\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3001React\u30d5\u30ed\u30f3\u30c8\u30a8\u30f3\u30c9\uff09\u304c\u958b\u767a\u6e08\u307f\u3067\u3042\u308b</li> <li>HKS CLI\u304c\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3001\u8a8d\u8a3c\u8a2d\u5b9a\u304c\u5b8c\u4e86\u3057\u3066\u3044\u308b</li> <li>Docker\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/application-deployment/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304cHKS CLI\u3092\u4f7f\u7528\u3057\u3066\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30f3\u30c6\u30ca\u3092\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306b\u914d\u7f6e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u3092\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8\u30ec\u30b8\u30b9\u30c8\u30ea\u304b\u3089\u30d7\u30eb\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cKubernetes\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3068\u30b5\u30fc\u30d3\u30b9\u3092\u4f5c\u6210\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u5fc5\u8981\u3067\u3042\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b</li> <li>\u958b\u767a\u8005\u304cHKS\u30de\u30fc\u30b1\u30c3\u30c8\u30d7\u30ec\u30a4\u30b9\u304b\u3089PostgreSQL\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8\u30dc\u30ea\u30e5\u30fc\u30e0\u3092\u4f5c\u6210\u3057\u3001PostgreSQL\u3092\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u9593\u306e\u63a5\u7d9a\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306eURL\u3068\u30a2\u30af\u30bb\u30b9\u60c5\u5831\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u52d5\u4f5c\u3092\u78ba\u8a8d\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/single-user/application-deployment/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u5931\u6557 - 4a. \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u30d7\u30eb\u306b\u5931\u6557\u3059\u308b - 4b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u30ed\u30b0\u3092\u8868\u793a\u3059\u308b - 4c. \u958b\u767a\u8005\u304c\u30a4\u30e1\u30fc\u30b8\u306e\u5b58\u5728\u3068\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u3092\u78ba\u8a8d\u3059\u308b - 4d. \u958b\u767a\u8005\u304c\u4fee\u6b63\u5f8c\u3001\u518d\u30c7\u30d7\u30ed\u30a4\u3092\u5b9f\u884c\u3059\u308b</p> <p>5b. \u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3 - 2a. \u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306b\u30ea\u30bd\u30fc\u30b9\u304c\u4e0d\u8db3\u3057\u3066\u3044\u308b - 2b. \u30b7\u30b9\u30c6\u30e0\u304c\u5f85\u6a5f\u72b6\u614b\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 2c. \u30b7\u30b9\u30c6\u30e0\u304c\u30ea\u30bd\u30fc\u30b9\u304c\u5229\u7528\u53ef\u80fd\u306b\u306a\u308a\u6b21\u7b2c\u3001\u81ea\u52d5\u7684\u306b\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u7d99\u7d9a\u3059\u308b</p> <p>5c. \u30b9\u30c8\u30ec\u30fc\u30b8\u5236\u9650\u8d85\u904e - 7a. \u6c38\u7d9a\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u5236\u9650\u3092\u8d85\u904e\u3057\u3066\u3044\u308b - 7b. \u30b7\u30b9\u30c6\u30e0\u304c\u5236\u9650\u8d85\u904e\u306e\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 7c. \u958b\u767a\u8005\u304c\u4e0d\u8981\u306a\u30c7\u30fc\u30bf\u3092\u524a\u9664\u3059\u308b\u304b\u3001\u30d7\u30e9\u30f3\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/application-deployment/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3067\u5b9f\u884c\u3055\u308c\u3066\u3044\u308b</li> <li>PostgreSQL\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u3001\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u30d1\u30d6\u30ea\u30c3\u30afURL\u3067\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u91cf\u304c\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/cicd-setup/","title":"CI/CD\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u8a2d\u5b9a\u3059\u308b","text":""},{"location":"ja/usecases-description/single-user/cicd-setup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>CI/CD\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u8a2d\u5b9a\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/cicd-setup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a GitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u3001Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30b3\u30f3\u30c6\u30ca\u30ec\u30b8\u30b9\u30c8\u30ea</li> </ul>"},{"location":"ja/usecases-description/single-user/cicd-setup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u6240\u6709\u3057\u3066\u3044\u308b</li> <li>GitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30b3\u30fc\u30c9\u304c\u5b58\u5728\u3059\u308b</li> <li>\u958b\u767a\u8005\u304cGitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u3078\u306e\u7ba1\u7406\u8005\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>Hexabase.AI\u30a2\u30ab\u30a6\u30f3\u30c8\u3068GitHub\u30a2\u30ab\u30a6\u30f3\u30c8\u304c\u9023\u643a\u53ef\u80fd\u306a\u72b6\u614b\u3067\u3042\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/cicd-setup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304cHexabase.AI\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306eCI/CD\u8a2d\u5b9a\u753b\u9762\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cGitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u63a5\u7d9a\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cGitHub\u8a8d\u8a3c\u753b\u9762\u306b\u30ea\u30c0\u30a4\u30ec\u30af\u30c8\u3059\u308b</li> <li>\u958b\u767a\u8005\u304cGitHub\u3067\u30a2\u30af\u30bb\u30b9\u8a31\u53ef\u3092\u627f\u8a8d\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5229\u7528\u53ef\u80fd\u306a\u30ea\u30dd\u30b8\u30c8\u30ea\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u5bfe\u8c61\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cCI/CD\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u9078\u629e\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cNode.js + React\u300d\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u8a2d\u5b9a\u306e\u8a73\u7d30\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30d3\u30eb\u30c9\u8a2d\u5b9a\u3068\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u8a2d\u5b9a\u3092\u78ba\u8a8d\u30fb\u8abf\u6574\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cWebhook\u3092GitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u8a2d\u5b9a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u521d\u56de\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5b9f\u884c\u3092\u958b\u59cb\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5b9f\u884c\u72b6\u6cc1\u3092\u8868\u793a\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/single-user/cicd-setup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. GitHub\u8a8d\u8a3c\u5931\u6557 - 4a. GitHub\u8a8d\u8a3c\u3067\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 4b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 4c. \u958b\u767a\u8005\u304cGitHub\u306e\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u3092\u78ba\u8a8d\u3059\u308b - 4d. \u958b\u767a\u8005\u304c\u518d\u8a8d\u8a3c\u3092\u8a66\u884c\u3059\u308b</p> <p>5b. \u521d\u56de\u30d3\u30eb\u30c9\u5931\u6557 - 13a. \u521d\u56de\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5b9f\u884c\u3067\u30d3\u30eb\u30c9\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 13b. \u30b7\u30b9\u30c6\u30e0\u304c\u8a73\u7d30\u306a\u30a8\u30e9\u30fc\u30ed\u30b0\u3092\u8868\u793a\u3059\u308b - 13c. \u958b\u767a\u8005\u304c\u30d3\u30eb\u30c9\u8a2d\u5b9a\u3092\u4fee\u6b63\u3059\u308b - 13d. \u958b\u767a\u8005\u304c\u624b\u52d5\u3067\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u3092\u518d\u5b9f\u884c\u3059\u308b</p> <p>5c. \u30ea\u30dd\u30b8\u30c8\u30ea\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u4e0d\u8db3 - 6a. \u9078\u629e\u3057\u305f\u30ea\u30dd\u30b8\u30c8\u30ea\u3078\u306e\u30a2\u30af\u30bb\u30b9\u6a29\u9650\u304c\u4e0d\u8db3\u3057\u3066\u3044\u308b - 6b. \u30b7\u30b9\u30c6\u30e0\u304c\u6a29\u9650\u4e0d\u8db3\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 6c. \u958b\u767a\u8005\u304c\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u6a29\u9650\u8a2d\u5b9a\u3092\u78ba\u8a8d\u30fb\u8abf\u6574\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/cicd-setup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>GitHub\u30ea\u30dd\u30b8\u30c8\u30ea\u3068Hexabase.AI\u304c\u9023\u643a\u3055\u308c\u3066\u3044\u308b</li> <li>CI/CD\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li><code>git push</code>\u3067\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u304c\u81ea\u52d5\u5b9f\u884c\u3055\u308c\u308b\u8a2d\u5b9a\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u74b0\u5883\u3078\u306e\u81ea\u52d5\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u5b9f\u884c\u5c65\u6b74\u304c\u78ba\u8a8d\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/","title":"\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\uff1a\u5c02\u7528\u30ce\u30fc\u30c9","text":""},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u30b9\u30b1\u30fc\u30eb\u30a2\u30c3\u30d7\uff1a\u5c02\u7528\u30ce\u30fc\u30c9</p>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001Kubernetes\u30af\u30e9\u30b9\u30bf\u30fc\u3001\u30ea\u30bd\u30fc\u30b9\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u30b5\u30fc\u30d3\u30b9</li> </ul>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304cPro\u30d7\u30e9\u30f3\u3092\u5229\u7528\u3057\u3066\u3044\u308b</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u672c\u756a\u74b0\u5883\u306e\u6e96\u5099\u304c\u3067\u304d\u3066\u3044\u308b</li> <li>\u3088\u308a\u591a\u304f\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30ea\u30bd\u30fc\u30b9\u4fdd\u8a3c\u304c\u5fc5\u8981\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u304b\u3089\u5c02\u7528\u30ea\u30bd\u30fc\u30b9\u3078\u306e\u79fb\u884c\u304c\u691c\u8a0e\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304c\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306e\u300c\u30ce\u30fc\u30c9\u7ba1\u7406\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u73fe\u5728\u306e\u30ea\u30bd\u30fc\u30b9\u4f7f\u7528\u72b6\u6cc1\u3068\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u306e\u5236\u9650\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u5c02\u7528\u30ce\u30fc\u30c9\u8ffd\u52a0\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u8a2d\u5b9a\u30a6\u30a3\u30b6\u30fc\u30c9\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30ce\u30fc\u30c9\u30b5\u30a4\u30ba\uff08CPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\uff09\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u63a8\u5b9a\u6708\u984d\u6599\u91d1\u3068\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u5411\u4e0a\u306e\u8aac\u660e\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30ce\u30fc\u30c9\u8a2d\u5b9a\u3092\u78ba\u8a8d\u3057\u3001\u300c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u958b\u59cb\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3092\u958b\u59cb\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u9032\u884c\u72b6\u6cc1\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u8868\u793a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u6e96\u5099\u5b8c\u4e86\u901a\u77e5\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u79fb\u884c\u300d\u753b\u9762\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u79fb\u884c\u53ef\u80fd\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30b5\u30fc\u30d3\u30b9\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u672c\u756a\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u3092\u9078\u629e\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u5c02\u7528\u30ce\u30fc\u30c9\u306b\u79fb\u884c\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30bc\u30ed\u30c0\u30a6\u30f3\u30bf\u30a4\u30e0\u79fb\u884c\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u79fb\u884c\u5b8c\u4e86\u3068\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u5411\u4e0a\u3092\u78ba\u8a8d\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u65b0\u3057\u3044\u5c02\u7528\u30ea\u30bd\u30fc\u30b9\u3067\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u78ba\u8a8d\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u5c02\u7528\u30ce\u30fc\u30c9\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u5931\u6557 - 8a. \u5c02\u7528\u30ce\u30fc\u30c9\u306e\u4f5c\u6210\u4e2d\u306b\u30ea\u30bd\u30fc\u30b9\u5236\u7d04\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 8b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u8a73\u7d30\u3068\u4ee3\u66ff\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u8868\u793a\u3059\u308b - 8c. \u30b7\u30b9\u30c6\u30e0\u304c\u7570\u306a\u308b\u30ea\u30fc\u30b8\u30e7\u30f3\u3067\u306e\u518d\u8a66\u884c\u3092\u63d0\u6848\u3059\u308b - 8d. \u958b\u767a\u8005\u304c\u4ee3\u66ff\u8a2d\u5b9a\u3092\u9078\u629e\u3057\u3001\u518d\u5ea6\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3059\u308b</p> <p>5b. \u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u79fb\u884c\u30a8\u30e9\u30fc - 15a. \u672c\u756a\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u306e\u79fb\u884c\u4e2d\u306b\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 15b. \u30b7\u30b9\u30c6\u30e0\u304c\u81ea\u52d5\u7684\u306b\u30ed\u30fc\u30eb\u30d0\u30c3\u30af\u3092\u5b9f\u884c\u3059\u308b - 15c. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u539f\u56e0\u3068\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u624b\u9806\u3092\u8868\u793a\u3059\u308b - 15d. \u958b\u767a\u8005\u304c\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u8a2d\u5b9a\u3092\u78ba\u8a8d\u30fb\u4fee\u6b63\u3059\u308b - 15e. \u958b\u767a\u8005\u304c\u518d\u5ea6\u79fb\u884c\u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b</p> <p>5c. \u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\u8b66\u544a - 5c1. \u9078\u629e\u3057\u305f\u30ce\u30fc\u30c9\u30b5\u30a4\u30ba\u304c\u73fe\u5728\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u306b\u5bfe\u3057\u3066\u904e\u5c0f\u3067\u3042\u308b - 5c2. \u30b7\u30b9\u30c6\u30e0\u304c\u63a8\u5968\u30b5\u30a4\u30ba\u3068\u8b66\u544a\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 5c3. \u958b\u767a\u8005\u304c\u3088\u308a\u5927\u304d\u306a\u30ce\u30fc\u30c9\u30b5\u30a4\u30ba\u3092\u9078\u629e\u3059\u308b - 5c4. \u307e\u305f\u306f\u6bb5\u968e\u7684\u79fb\u884c\u8a08\u753b\u3092\u7acb\u3066\u308b</p> <p>5d. \u79fb\u884c\u4e2d\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u554f\u984c - 5d1. \u79fb\u884c\u4e2d\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306e\u30ec\u30b9\u30dd\u30f3\u30b9\u6642\u9593\u304c\u5897\u52a0\u3059\u308b - 5d2. \u30b7\u30b9\u30c6\u30e0\u304c\u4e00\u6642\u7684\u306a\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u4f4e\u4e0b\u3092\u691c\u51fa\u3057\u3001\u901a\u77e5\u3059\u308b - 5d3. \u30b7\u30b9\u30c6\u30e0\u304c\u79fb\u884c\u30d7\u30ed\u30bb\u30b9\u3092\u4e00\u6642\u505c\u6b62\u3059\u308b - 5d4. \u958b\u767a\u8005\u304c\u79fb\u884c\u30bf\u30a4\u30df\u30f3\u30b0\u3092\u8abf\u6574\u3057\u3001\u51e6\u7406\u3092\u518d\u958b\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/dedicated-node-scaleup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u5c02\u7528\u30ce\u30fc\u30c9\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u3001\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u672c\u756a\u30c7\u30d7\u30ed\u30a4\u30e1\u30f3\u30c8\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306b\u79fb\u884c\u3055\u308c\u3066\u3044\u308b</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u5411\u4e0a\u3057\u3066\u3044\u308b</li> <li>\u30ea\u30bd\u30fc\u30b9\u5206\u96e2\u304c\u5b9f\u73fe\u3055\u308c\u3066\u3044\u308b</li> <li>\u5c02\u7528\u30ea\u30bd\u30fc\u30b9\u306b\u3088\u308b\u5b89\u5b9a\u3057\u305f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u4fdd\u8a3c\u304c\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b</li> <li>\u3088\u308a\u9ad8\u3044\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3068\u30ea\u30bd\u30fc\u30b9\u4fdd\u8a3c\u304c\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u958b\u767a\u8005\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u76e3\u8996\u3068\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b</li> <li>\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u304b\u3089\u306e\u5b8c\u5168\u306a\u5206\u96e2\u304c\u9054\u6210\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/initial-setup/","title":"\u521d\u56de\u30ed\u30b0\u30a4\u30f3\u3068\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u8a2d\u5b9a\u3059\u308b","text":""},{"location":"ja/usecases-description/single-user/initial-setup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u521d\u56de\u30ed\u30b0\u30a4\u30f3\u3068\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u8a2d\u5b9a\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/initial-setup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0</li> </ul>"},{"location":"ja/usecases-description/single-user/initial-setup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304cHexabase.AI\u30a2\u30ab\u30a6\u30f3\u30c8\u306b\u65e2\u306b\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u3057\u3066\u3044\u308b</li> <li>\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u63a5\u7d9a\u304c\u5229\u7528\u53ef\u80fd\u3067\u3042\u308b</li> <li>\u30d6\u30e9\u30a6\u30b6\u307e\u305f\u306fHKS CLI\u304c\u5229\u7528\u53ef\u80fd\u3067\u3042\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/initial-setup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304cHexabase.AI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306b\u30ed\u30b0\u30a4\u30f3\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u65b0\u898f\u30e6\u30fc\u30b6\u30fc\u3067\u3042\u308b\u3053\u3068\u3092\u691c\u51fa\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u81ea\u52d5\u7684\u306b\u500b\u4eba\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08\u4f8b\uff1a<code>dev-workspace</code>\uff09\u3092\u4f5c\u6210\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8Kubernetes\u30cd\u30fc\u30e0\u30b9\u30da\u30fc\u30b9\u3092\u958b\u767a\u8005\u306b\u5272\u308a\u5f53\u3066\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u521d\u671f\u8a2d\u5b9a\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u540d\u3092\u78ba\u8a8d\u307e\u305f\u306f\u5909\u66f4\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3092\u5b8c\u4e86\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u3092\u8868\u793a\u3057\u3001\u5229\u7528\u53ef\u80fd\u306a\u30ea\u30bd\u30fc\u30b9\u3068\u30af\u30a9\u30fc\u30bf\u3092\u793a\u3059</li> </ol>"},{"location":"ja/usecases-description/single-user/initial-setup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u5931\u6557 - 4a. \u30b7\u30b9\u30c6\u30e0\u3067\u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\u306b\u3088\u308a\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u304c\u5931\u6557\u3059\u308b - 4b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 4c. \u30b7\u30b9\u30c6\u30e0\u304c\u518d\u8a66\u884c\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u63d0\u4f9b\u3059\u308b - 4d. \u958b\u767a\u8005\u304c\u518d\u8a66\u884c\u3059\u308b\u304b\u3001\u30b5\u30dd\u30fc\u30c8\u306b\u9023\u7d61\u3059\u308b</p> <p>5b. \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u63a5\u7d9a\u554f\u984c - 1a. \u30ed\u30b0\u30a4\u30f3\u4e2d\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u63a5\u7d9a\u304c\u5931\u308f\u308c\u308b - 1b. \u30b7\u30b9\u30c6\u30e0\u304c\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u30a8\u30e9\u30fc\u3092\u8868\u793a\u3059\u308b - 1c. \u958b\u767a\u8005\u304c\u63a5\u7d9a\u3092\u78ba\u8a8d\u3057\u3066\u518d\u5ea6\u30ed\u30b0\u30a4\u30f3\u3092\u8a66\u884c\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/initial-setup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u5c02\u7528\u306e\u9694\u96e2\u3055\u308c\u305f\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b</li> <li>\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8Kubernetes\u30cd\u30fc\u30e0\u30b9\u30da\u30fc\u30b9\u304c\u5272\u308a\u5f53\u3066\u3089\u308c\u3066\u3044\u308b</li> <li>\u958b\u767a\u8005\u304c\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u72b6\u614b\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3068\u5236\u9650\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/plan-upgrade/","title":"\u30d7\u30e9\u30f3\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3059\u308b","text":""},{"location":"ja/usecases-description/single-user/plan-upgrade/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u30d7\u30e9\u30f3\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/plan-upgrade/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u6c7a\u6e08\u30b7\u30b9\u30c6\u30e0\u3001Kubernetes\u30af\u30e9\u30b9\u30bf\u30fc</li> </ul>"},{"location":"ja/usecases-description/single-user/plan-upgrade/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304cHobby\u30d7\u30e9\u30f3\u3092\u5229\u7528\u3057\u3066\u3044\u308b</li> <li>\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u672c\u756a\u74b0\u5883\u3078\u306e\u79fb\u884c\u6e96\u5099\u304c\u3067\u304d\u3066\u3044\u308b</li> <li>\u958b\u767a\u8005\u304c\u652f\u6255\u3044\u60c5\u5831\uff08\u30af\u30ec\u30b8\u30c3\u30c8\u30ab\u30fc\u30c9\u306a\u3069\uff09\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u65e2\u5b58\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u304c\u5171\u6709\u30ce\u30fc\u30c9\u30d7\u30fc\u30eb\u3067\u5b9f\u884c\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/plan-upgrade/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304c\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306e\u300c\u30d7\u30e9\u30f3\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u73fe\u5728\u306eHobby\u30d7\u30e9\u30f3\u306e\u5229\u7528\u72b6\u6cc1\u3068\u5236\u9650\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cPro\u306b\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cPro\u30d7\u30e9\u30f3\u306e\u6a5f\u80fd\u6bd4\u8f03\u3068\u4fa1\u683c\u60c5\u5831\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u958b\u59cb\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u652f\u6255\u3044\u60c5\u5831\u5165\u529b\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30af\u30ec\u30b8\u30c3\u30c8\u30ab\u30fc\u30c9\u60c5\u5831\u3092\u5165\u529b\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u652f\u6255\u3044\u60c5\u5831\u3092\u691c\u8a3c\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u5229\u7528\u898f\u7d04\u3092\u78ba\u8a8d\u3057\u3001\u540c\u610f\u30c1\u30a7\u30c3\u30af\u30dc\u30c3\u30af\u30b9\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u5b9f\u884c\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u6c7a\u6e08\u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d7\u30e9\u30f3\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3092\u958b\u59cb\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u306e\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3092\u958b\u59cb\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u9032\u884c\u72b6\u6cc1\u3092\u8868\u793a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u5b8c\u4e86\u901a\u77e5\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u62e1\u5f35\u6a5f\u80fd\uff08\u7121\u5236\u9650Functions\u3001\u9ad8\u5ea6\u306aAIOps\uff09\u3092\u78ba\u8a8d\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/single-user/plan-upgrade/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u6c7a\u6e08\u5931\u6557 - 11a. \u30af\u30ec\u30b8\u30c3\u30c8\u30ab\u30fc\u30c9\u6c7a\u6e08\u304c\u5931\u6557\u3059\u308b - 11b. \u30b7\u30b9\u30c6\u30e0\u304c\u6c7a\u6e08\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 11c. \u958b\u767a\u8005\u304c\u652f\u6255\u3044\u60c5\u5831\u3092\u78ba\u8a8d\u30fb\u4fee\u6b63\u3059\u308b - 11d. \u958b\u767a\u8005\u304c\u518d\u5ea6\u6c7a\u6e08\u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b</p> <p>5b. \u5c02\u7528\u30ce\u30fc\u30c9\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u5931\u6557 - 13a. \u5c02\u7528\u30ce\u30fc\u30c9\u306e\u4f5c\u6210\u4e2d\u306b\u30ea\u30bd\u30fc\u30b9\u4e0d\u8db3\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 13b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u72b6\u6cc1\u3092\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u8868\u793a\u3059\u308b - 13c. \u30b7\u30b9\u30c6\u30e0\u304c\u81ea\u52d5\u7684\u306b\u518d\u8a66\u884c\u3092\u5b9f\u884c\u3059\u308b - 13d. \u518d\u8a66\u884c\u304c\u5931\u6557\u3057\u305f\u5834\u5408\u3001\u30b5\u30dd\u30fc\u30c8\u30c1\u30fc\u30e0\u304c\u624b\u52d5\u3067\u5bfe\u5fdc\u3059\u308b</p> <p>5c. \u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u4e2d\u65ad - 12a. \u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u51e6\u7406\u4e2d\u306b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u63a5\u7d9a\u304c\u5931\u308f\u308c\u308b - 12b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3092\u4e00\u6642\u505c\u6b62\u3059\u308b - 12c. \u63a5\u7d9a\u5fa9\u65e7\u5f8c\u3001\u30b7\u30b9\u30c6\u30e0\u304c\u51e6\u7406\u3092\u81ea\u52d5\u7684\u306b\u518d\u958b\u3059\u308b - 12d. \u958b\u767a\u8005\u304c\u9032\u884c\u72b6\u6cc1\u3092\u518d\u78ba\u8a8d\u3059\u308b</p> <p>5d. \u65e2\u5b58\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u5f71\u97ff - 12a. \u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u4e2d\u306b\u65e2\u5b58\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u4e00\u6642\u7684\u306b\u30a2\u30af\u30bb\u30b9\u4e0d\u80fd\u306b\u306a\u308b - 12b. \u30b7\u30b9\u30c6\u30e0\u304c\u5f71\u97ff\u3092\u6700\u5c0f\u9650\u306b\u6291\u3048\u308b\u6bb5\u968e\u7684\u79fb\u884c\u3092\u5b9f\u884c\u3059\u308b - 12c. \u30b7\u30b9\u30c6\u30e0\u304c\u79fb\u884c\u5b8c\u4e86\u5f8c\u306b\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u30a2\u30af\u30bb\u30b9\u3092\u5fa9\u65e7\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/plan-upgrade/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u30a2\u30ab\u30a6\u30f3\u30c8\u304cPro\u30d7\u30e9\u30f3\u306b\u5909\u66f4\u3055\u308c\u3066\u3044\u308b</li> <li>\u5c02\u7528\u30ce\u30fc\u30c9\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u3001\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u65e2\u5b58\u306e\u30ef\u30fc\u30af\u30ed\u30fc\u30c9\u304c\u4e2d\u65ad\u306a\u304f\u5b9f\u884c\u3092\u7d99\u7d9a\u3057\u3066\u3044\u308b</li> <li>\u7121\u5236\u9650\u306eFunctions\u3001CronJobs\u304c\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u9ad8\u5ea6\u306aAIOps\u6a5f\u80fd\uff08\u7570\u5e38\u691c\u51fa\u3001\u4e88\u6e2c\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\uff09\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>100GB\u306e\u9ad8\u6027\u80fdSSD\u30b9\u30c8\u30ec\u30fc\u30b8\u304c\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>99.9%\u30a2\u30c3\u30d7\u30bf\u30a4\u30e0\u4fdd\u8a3c\u304c\u9069\u7528\u3055\u308c\u3066\u3044\u308b</li> <li>\u512a\u5148\u30e1\u30fc\u30eb\u30b5\u30dd\u30fc\u30c8\u304c\u5229\u7528\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/","title":"\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570\u3068CronJob\u3092\u4f5c\u6210\u3059\u308b","text":""},{"location":"ja/usecases-description/single-user/serverless-cronjob/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9\u95a2\u6570\u3068CronJob\u3092\u4f5c\u6210\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u500b\u4eba\u958b\u767a\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30e1\u30fc\u30eb\u30b5\u30fc\u30d3\u30b9\u3001Kubernetes\u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc</li> </ul>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u6240\u6709\u3057\u3066\u3044\u308b</li> <li>\u958b\u767a\u8005\u304cFunction\u4f5c\u6210\u306e\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u30b5\u30de\u30ea\u30fc\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u305f\u3081\u306e\u30d3\u30b8\u30cd\u30b9\u30ed\u30b8\u30c3\u30af\u304c\u6e96\u5099\u3055\u308c\u3066\u3044\u308b</li> <li>\u30e1\u30fc\u30eb\u9001\u4fe1\u306b\u5fc5\u8981\u306a\u5916\u90e8\u30b5\u30fc\u30d3\u30b9\u8a2d\u5b9a\uff08SMTP\u307e\u305f\u306fAPI\uff09\u304c\u5229\u7528\u53ef\u80fd\u3067\u3042\u308b</li> </ul>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u958b\u767a\u8005\u304cHexabase.AI\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306e\u300cFunctions\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u65b0\u3057\u3044Function\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cFunction\u4f5c\u6210\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304cFunction\u540d\uff08\u4f8b\uff1a<code>daily-summary-email</code>\uff09\u3092\u5165\u529b\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30e9\u30f3\u30bf\u30a4\u30e0\uff08Node.js\uff09\u3092\u9078\u629e\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30e1\u30fc\u30eb\u9001\u4fe1\u306e\u30d3\u30b8\u30cd\u30b9\u30ed\u30b8\u30c3\u30af\u3092\u30b3\u30fc\u30c9\u30a8\u30c7\u30a3\u30bf\u306b\u5165\u529b\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u74b0\u5883\u5909\u6570\uff08SMTP\u8a2d\u5b9a\u3001API\u30ad\u30fc\u306a\u3069\uff09\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cFunction\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cFunction\u3092\u30c7\u30d7\u30ed\u30a4\u3057\u3001\u5b9f\u884c\u53ef\u80fd\u72b6\u614b\u306b\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cCronJobs\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300c\u65b0\u3057\u3044CronJob\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\uff08\u4f8b\uff1a\u6bce\u65e5\u5348\u524d9\u6642\uff09\u3092cron\u5f62\u5f0f\u3067\u5165\u529b\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u5b9f\u884c\u3059\u308bFunction\u3068\u3057\u3066\u5148\u307b\u3069\u4f5c\u6210\u3057\u305fFunction\u3092\u9078\u629e\u3059\u308b</li> <li>\u958b\u767a\u8005\u304c\u300cCronJob\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cCronJob\u3092\u30b9\u30b1\u30b8\u30e5\u30fc\u30e9\u30fc\u306b\u767b\u9332\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u8a2d\u5b9a\u5b8c\u4e86\u30e1\u30c3\u30bb\u30fc\u30b8\u3068\u6b21\u56de\u5b9f\u884c\u6642\u523b\u3092\u8868\u793a\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. Function\u5b9f\u884c\u30a8\u30e9\u30fc - 9a. Function\u306e\u30c7\u30d7\u30ed\u30a4\u4e2d\u306b\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 9b. \u30b7\u30b9\u30c6\u30e0\u304c\u8a73\u7d30\u306a\u30a8\u30e9\u30fc\u30ed\u30b0\u3092\u8868\u793a\u3059\u308b - 9c. \u958b\u767a\u8005\u304c\u30b3\u30fc\u30c9\u306e\u69cb\u6587\u30a8\u30e9\u30fc\u307e\u305f\u306f\u4f9d\u5b58\u95a2\u4fc2\u3092\u78ba\u8a8d\u3059\u308b - 9d. \u958b\u767a\u8005\u304c\u30b3\u30fc\u30c9\u3092\u4fee\u6b63\u3057\u3066\u518d\u30c7\u30d7\u30ed\u30a4\u3059\u308b</p> <p>5b. \u74b0\u5883\u5909\u6570\u8a2d\u5b9a\u4e0d\u5099 - 7a. \u5fc5\u8981\u306a\u74b0\u5883\u5909\u6570\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044 - 7b. Function\u5b9f\u884c\u6642\u306b\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 7c. \u30b7\u30b9\u30c6\u30e0\u304c\u74b0\u5883\u5909\u6570\u95a2\u9023\u306e\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 7d. \u958b\u767a\u8005\u304c\u74b0\u5883\u5909\u6570\u3092\u8ffd\u52a0\u30fb\u4fee\u6b63\u3059\u308b</p> <p>5c. CronJob\u5b9f\u884c\u5931\u6557 - 15a. \u521d\u56de\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u5b9f\u884c\u6642\u306bFunction\u304c\u5931\u6557\u3059\u308b - 15b. \u30b7\u30b9\u30c6\u30e0\u304c\u5b9f\u884c\u30ed\u30b0\u306b\u30a8\u30e9\u30fc\u3092\u8a18\u9332\u3059\u308b - 15c. \u958b\u767a\u8005\u304c\u5b9f\u884c\u30ed\u30b0\u3092\u78ba\u8a8d\u3057\u3066\u30a8\u30e9\u30fc\u539f\u56e0\u3092\u7279\u5b9a\u3059\u308b - 15d. \u958b\u767a\u8005\u304cFunction\u307e\u305f\u306fCronJob\u8a2d\u5b9a\u3092\u4fee\u6b63\u3059\u308b</p> <p>5d. \u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u5f62\u5f0f\u30a8\u30e9\u30fc - 12a. \u5165\u529b\u3055\u308c\u305fcron\u5f62\u5f0f\u304c\u7121\u52b9\u3067\u3042\u308b - 12b. \u30b7\u30b9\u30c6\u30e0\u304cvalidation\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 12c. \u958b\u767a\u8005\u304c\u6b63\u3057\u3044cron\u5f62\u5f0f\u3067\u518d\u5165\u529b\u3059\u308b</p>"},{"location":"ja/usecases-description/single-user/serverless-cronjob/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u30b5\u30fc\u30d0\u30fc\u30ec\u30b9Function\u304c\u4f5c\u6210\u30fb\u30c7\u30d7\u30ed\u30a4\u3055\u308c\u3066\u3044\u308b</li> <li>CronJob\u304c\u6307\u5b9a\u3055\u308c\u305f\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3067\u767b\u9332\u3055\u308c\u3066\u3044\u308b</li> <li>\u6bce\u65e5\u6307\u5b9a\u3055\u308c\u305f\u6642\u523b\u306bFunction\u304c\u81ea\u52d5\u5b9f\u884c\u3055\u308c\u308b\u8a2d\u5b9a\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>Function\u5b9f\u884c\u30ed\u30b0\u304c\u78ba\u8a8d\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u5b9f\u884c\u5931\u6557\u6642\u306e\u30a2\u30e9\u30fc\u30c8\u8a2d\u5b9a\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/","title":"\u707d\u5bb3\u5fa9\u65e7\uff08DR\uff09\u3068\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u306e\u30e6\u30fc\u30b6\u30fc\u64cd\u4f5c","text":""},{"location":"ja/usecases-description/team/disaster-recovery-backup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u707d\u5bb3\u5fa9\u65e7\uff08DR\uff09\u3068\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u306e\u30e6\u30fc\u30b6\u30fc\u64cd\u4f5c</p>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u7d44\u7e54\u7ba1\u7406\u8005\u3001DevOps\u30a8\u30f3\u30b8\u30cb\u30a2</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b5\u30fc\u30d3\u30b9\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\u30b7\u30b9\u30c6\u30e0</li> </ul>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u91cd\u8981\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304c\u7a3c\u50cd\u3057\u3066\u3044\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u9069\u5207\u306a\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30c8\u30ec\u30fc\u30b8\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306e\u300c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7 &amp; DR\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u73fe\u5728\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u72b6\u6cc1\u3068\u8a2d\u5b9a\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u707d\u5bb3\u5fa9\u65e7\u8a08\u753b\u8a2d\u5b9a\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cDR\u8a2d\u5b9a\u30a6\u30a3\u30b6\u30fc\u30c9\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u91cd\u8981\u306a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30dc\u30ea\u30e5\u30fc\u30e0\uff08PostgreSQL\u3001MySQL\u7b49\uff09\u3092\u9078\u629e\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u983b\u5ea6\uff08\u65e5\u6b21\u3001\u9031\u6b21\uff09\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5730\u7406\u5197\u9577\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30c8\u30ec\u30fc\u30b8\u306e\u5834\u6240\u3092\u9078\u629e\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a08\u753b\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3092\u4f5c\u6210\u3057\u3001\u9069\u7528\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u521d\u56de\u30d5\u30eb\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5b9f\u884c\u72b6\u6cc1\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u76e3\u8996\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5b8c\u4e86\u901a\u77e5\u3092\u9001\u4fe1\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u5fa9\u65e7\u30c6\u30b9\u30c8\u300d\u6a5f\u80fd\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30c6\u30b9\u30c8\u7528\u306e\u5fa9\u65e7\u30b7\u30ca\u30ea\u30aa\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u9694\u96e2\u3055\u308c\u305f\u74b0\u5883\u3067\u30c7\u30fc\u30bf\u5fa9\u65e7\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5fa9\u65e7\u30c6\u30b9\u30c8\u7d50\u679c\u3068\u30c7\u30fc\u30bf\u6574\u5408\u6027\u30ec\u30dd\u30fc\u30c8\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u3068DR\u8a08\u753b\u3092\u78ba\u8a8d\u30fb\u627f\u8a8d\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5b9f\u884c\u5931\u6557 - 10a. \u521d\u56de\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u306e\u5b9f\u884c\u4e2d\u306b\u30b9\u30c8\u30ec\u30fc\u30b8\u5bb9\u91cf\u4e0d\u8db3\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 10b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u8a73\u7d30\u3068\u30b9\u30c8\u30ec\u30fc\u30b8\u4f7f\u7528\u91cf\u3092\u8868\u793a\u3059\u308b - 10c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30b9\u30c8\u30ec\u30fc\u30b8\u30d7\u30e9\u30f3\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3059\u308b - 10d. \u307e\u305f\u306f\u4e0d\u8981\u306a\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u3092\u524a\u9664\u3059\u308b - 10e. \u30b7\u30b9\u30c6\u30e0\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u51e6\u7406\u3092\u518d\u5b9f\u884c\u3059\u308b</p> <p>5b. \u5730\u7406\u5197\u9577\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u30a8\u30e9\u30fc - 7a. \u9078\u629e\u3057\u305f\u5730\u7406\u7684\u5834\u6240\u3067\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30c8\u30ec\u30fc\u30b8\u304c\u5229\u7528\u4e0d\u53ef\u80fd\u306b\u306a\u308b - 7b. \u30b7\u30b9\u30c6\u30e0\u304c\u4ee3\u66ff\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u5834\u6240\u306e\u9078\u629e\u80a2\u3092\u8868\u793a\u3059\u308b - 7c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5225\u306e\u5730\u7406\u7684\u5834\u6240\u3092\u9078\u629e\u3059\u308b - 7d. \u30b7\u30b9\u30c6\u30e0\u304c\u65b0\u3057\u3044\u5834\u6240\u3067\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u3092\u69cb\u6210\u3059\u308b</p> <p>5c. \u5fa9\u65e7\u30c6\u30b9\u30c8\u5931\u6557 - 15a. \u30c7\u30fc\u30bf\u5fa9\u65e7\u30c6\u30b9\u30c8\u4e2d\u306b\u30c7\u30fc\u30bf\u6574\u5408\u6027\u30a8\u30e9\u30fc\u304c\u691c\u51fa\u3055\u308c\u308b - 15b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u8a73\u7d30\u3068\u63a8\u5968\u5bfe\u51e6\u6cd5\u3092\u8868\u793a\u3059\u308b - 15c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u3092\u898b\u76f4\u3059 - 15d. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u3088\u308a\u983b\u7e41\u306a\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3092\u8a2d\u5b9a\u3059\u308b - 15e. \u30b7\u30b9\u30c6\u30e0\u304c\u6539\u5584\u3055\u308c\u305f\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a08\u753b\u3092\u518d\u9069\u7528\u3059\u308b</p> <p>5d. \u5b9f\u969b\u306e\u707d\u5bb3\u6642\u5fa9\u65e7\u64cd\u4f5c - \u707d\u5bb3\u767a\u751f\u6642\u306e\u7dca\u6025\u5fa9\u65e7\u30d5\u30ed\u30fc\uff1a - 1d. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u7dca\u6025\u5fa9\u65e7\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b - 2d. \u30b7\u30b9\u30c6\u30e0\u304c\u6700\u65b0\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u3092\u7279\u5b9a\u3059\u308b - 3d. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5fa9\u65e7\u5bfe\u8c61\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3068\u30b5\u30fc\u30d3\u30b9\u3092\u9078\u629e\u3059\u308b - 4d. \u30b7\u30b9\u30c6\u30e0\u304c\u7dca\u6025\u5fa9\u65e7\u51e6\u7406\u3092\u958b\u59cb\u3059\u308b - 5d. \u30b7\u30b9\u30c6\u30e0\u304c\u5fa9\u65e7\u9032\u884c\u72b6\u6cc1\u3092\u30ea\u30a2\u30eb\u30bf\u30a4\u30e0\u3067\u8868\u793a\u3059\u308b - 6d. \u30b7\u30b9\u30c6\u30e0\u304c\u5fa9\u65e7\u5b8c\u4e86\u3068\u30c7\u30fc\u30bf\u6574\u5408\u6027\u78ba\u8a8d\u3092\u901a\u77e5\u3059\u308b</p> <p>5e. \u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u5909\u66f4 - 6a. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u65e2\u5b58\u306e\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u983b\u5ea6\u3092\u5909\u66f4\u3057\u305f\u3044 - 6b. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u8a2d\u5b9a\u5909\u66f4\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b - 6c. \u30b7\u30b9\u30c6\u30e0\u304c\u8a2d\u5b9a\u5909\u66f4\u306e\u5f71\u97ff\u7bc4\u56f2\u3092\u8868\u793a\u3059\u308b - 6d. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5909\u66f4\u3092\u78ba\u8a8d\u30fb\u627f\u8a8d\u3059\u308b - 6e. \u30b7\u30b9\u30c6\u30e0\u304c\u65b0\u3057\u3044\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30b9\u30b1\u30b8\u30e5\u30fc\u30eb\u3092\u9069\u7528\u3059\u308b</p>"},{"location":"ja/usecases-description/team/disaster-recovery-backup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u57fa\u672c\u7684\u306a\u707d\u5bb3\u5fa9\u65e7\u8a08\u753b\u304c\u69cb\u6210\u3055\u308c\u3066\u3044\u308b</li> <li>\u91cd\u8981\u306a\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30dc\u30ea\u30e5\u30fc\u30e0\u306e\u65e5\u6b21\u81ea\u52d5\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u30c7\u30fc\u30bf\u304c\u5730\u7406\u5197\u9577\u6027\u306e\u3042\u308b\u5b89\u5168\u306a\u5834\u6240\u306b\u4fdd\u5b58\u3055\u308c\u3066\u3044\u308b</li> <li>\u5fa9\u65e7\u30c6\u30b9\u30c8\u304c\u6b63\u5e38\u306b\u5b8c\u4e86\u3057\u3001\u30c7\u30fc\u30bf\u6574\u5408\u6027\u304c\u78ba\u8a8d\u3055\u308c\u3066\u3044\u308b</li> <li>\u707d\u5bb3\u767a\u751f\u6642\u306e\u5fa9\u65e7\u624b\u9806\u304c\u6587\u66f8\u5316\u3055\u308c\u3001\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u76e3\u8996\u3068\u30a2\u30e9\u30fc\u30c8\u6a5f\u80fd\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u7d44\u7e54\u30e1\u30f3\u30d0\u30fc\u304c\u30d0\u30c3\u30af\u30a2\u30c3\u30d7\u72b6\u6cc1\u3092\u78ba\u8a8d\u3067\u304d\u308b</li> <li>\u7dca\u6025\u6642\u306e\u8fc5\u901f\u306a\u5fa9\u65e7\u304c\u53ef\u80fd\u306a\u4f53\u5236\u304c\u6574\u3063\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/team/organization-setup/","title":"\u7d44\u7e54\u3068\u30c1\u30fc\u30e0\u3092\u8a2d\u5b9a\u3059\u308b","text":""},{"location":"ja/usecases-description/team/organization-setup/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u7d44\u7e54\u3068\u30c1\u30fc\u30e0\u3092\u8a2d\u5b9a\u3059\u308b</p>"},{"location":"ja/usecases-description/team/organization-setup/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u7d44\u7e54\u7ba1\u7406\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3001\u30e1\u30fc\u30eb\u914d\u4fe1\u30b7\u30b9\u30c6\u30e0</li> </ul>"},{"location":"ja/usecases-description/team/organization-setup/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30c1\u30fc\u30e0\u30d7\u30e9\u30f3\u306b\u30b5\u30a4\u30f3\u30a2\u30c3\u30d7\u6e08\u307f\u3067\u3042\u308b</li> <li>\u62db\u5f85\u3059\u308b\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u30ea\u30b9\u30c8\u304c\u6e96\u5099\u3055\u308c\u3066\u3044\u308b</li> <li>\u7d44\u7e54\u306e\u57fa\u672c\u60c5\u5831\uff08\u4f1a\u793e\u540d\u3001\u696d\u754c\u306a\u3069\uff09\u304c\u6c7a\u5b9a\u3055\u308c\u3066\u3044\u308b</li> </ul>"},{"location":"ja/usecases-description/team/organization-setup/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304cHexabase.AI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u306b\u30ed\u30b0\u30a4\u30f3\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u7d44\u7e54\u4f5c\u6210\u30a6\u30a3\u30b6\u30fc\u30c9\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u540d\uff08\u4f8b\uff1a<code>MyStartupInc</code>\uff09\u3092\u5165\u529b\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u306e\u696d\u754c\u3068\u898f\u6a21\u3092\u9078\u629e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u7d44\u7e54\u3092\u4f5c\u6210\u3057\u3001\u7ba1\u7406\u8005\u306b\u7d44\u7e54\u7ba1\u7406\u8005\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u62db\u5f85\u753b\u9762\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304cDevOps\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u5165\u529b\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304cDevOps\u30a8\u30f3\u30b8\u30cb\u30a2\u306b\u300c\u7d44\u7e54\u7ba1\u7406\u8005\u300d\u30ed\u30fc\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u4ed6\u306e\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u306e\u30e1\u30fc\u30eb\u30a2\u30c9\u30ec\u30b9\u3092\u5165\u529b\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u4ed6\u306e\u30e1\u30f3\u30d0\u30fc\u306b\u300c\u7d44\u7e54\u30e6\u30fc\u30b6\u30fc\u300d\u30ed\u30fc\u30eb\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u62db\u5f85\u9001\u4fe1\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5404\u30e1\u30f3\u30d0\u30fc\u306b\u62db\u5f85\u30e1\u30fc\u30eb\u3092\u9001\u4fe1\u3059\u308b</li> <li>\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304c\u62db\u5f85\u30e1\u30fc\u30eb\u3092\u53d7\u4fe1\u3057\u3001\u62db\u5f85\u30ea\u30f3\u30af\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304c\u30a2\u30ab\u30a6\u30f3\u30c8\u4f5c\u6210\u307e\u305f\u306f\u30ed\u30b0\u30a4\u30f3\u3092\u5b8c\u4e86\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3092\u7d44\u7e54\u306b\u8ffd\u52a0\u3057\u3001\u9069\u5207\u306a\u30ed\u30fc\u30eb\u3092\u4ed8\u4e0e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u7d44\u7e54\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u3092\u8868\u793a\u3057\u3001\u30e1\u30f3\u30d0\u30fc\u4e00\u89a7\u3092\u78ba\u8a8d\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/team/organization-setup/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u62db\u5f85\u30e1\u30fc\u30eb\u9001\u4fe1\u5931\u6557 - 12a. \u30e1\u30fc\u30eb\u914d\u4fe1\u30b7\u30b9\u30c6\u30e0\u306e\u554f\u984c\u3067\u62db\u5f85\u30e1\u30fc\u30eb\u304c\u9001\u4fe1\u3055\u308c\u306a\u3044 - 12b. \u30b7\u30b9\u30c6\u30e0\u304c\u9001\u4fe1\u5931\u6557\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 12c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u624b\u52d5\u3067\u62db\u5f85\u30ea\u30f3\u30af\u3092\u30b3\u30d4\u30fc\u3057\u3066\u30e1\u30f3\u30d0\u30fc\u306b\u5171\u6709\u3059\u308b - 12d. \u307e\u305f\u306f\u3001\u5f8c\u3067\u62db\u5f85\u3092\u518d\u9001\u4fe1\u3059\u308b</p> <p>5b. \u91cd\u8907\u3057\u305f\u7d44\u7e54\u540d - 5a. \u5165\u529b\u3057\u305f\u7d44\u7e54\u540d\u304c\u65e2\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b - 5b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3068\u4ee3\u66ff\u6848\u3092\u8868\u793a\u3059\u308b - 5c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5225\u306e\u7d44\u7e54\u540d\u3092\u5165\u529b\u3059\u308b</p> <p>5c. \u62db\u5f85\u53d7\u8afe\u671f\u9650\u5207\u308c - 14a. \u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304c\u62db\u5f85\u30ea\u30f3\u30af\u306e\u6709\u52b9\u671f\u9650\u5185\u306b\u30a2\u30af\u30bb\u30b9\u3057\u306a\u3044 - 14b. \u62db\u5f85\u30ea\u30f3\u30af\u304c\u7121\u52b9\u306b\u306a\u308b - 14c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u518d\u5ea6\u62db\u5f85\u3092\u9001\u4fe1\u3059\u308b</p> <p>5d. \u6a29\u9650\u8a2d\u5b9a\u30a8\u30e9\u30fc - 8a. \u30ed\u30fc\u30eb\u8a2d\u5b9a\u3067\u8aa4\u3063\u305f\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b - 8b. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u8a2d\u5b9a\u753b\u9762\u3067\u30ed\u30fc\u30eb\u3092\u4fee\u6b63\u3059\u308b - 8c. \u30b7\u30b9\u30c6\u30e0\u304c\u5909\u66f4\u3055\u308c\u305f\u6a29\u9650\u3092\u9069\u7528\u3059\u308b</p>"},{"location":"ja/usecases-description/team/organization-setup/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u7d44\u7e54\u304c\u4f5c\u6210\u3055\u308c\u3001\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>DevOps\u30a8\u30f3\u30b8\u30cb\u30a2\u304c\u7d44\u7e54\u7ba1\u7406\u8005\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u4ed6\u306e\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304c\u7d44\u7e54\u30e6\u30fc\u30b6\u30fc\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>RBAC\uff08\u30ed\u30fc\u30eb\u30d9\u30fc\u30b9\u30a2\u30af\u30bb\u30b9\u5236\u5fa1\uff09\u304c\u6709\u52b9\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u7d44\u7e54\u30e1\u30f3\u30d0\u30fc\u5168\u54e1\u304c\u7d44\u7e54\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306b\u30a2\u30af\u30bb\u30b9\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u8acb\u6c42\u7ba1\u7406\u3068\u30ea\u30bd\u30fc\u30b9\u7ba1\u7406\u306e\u6a29\u9650\u304c\u9069\u5207\u306b\u5206\u96e2\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"ja/usecases-description/team/workspace-management/","title":"\u8907\u6570\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u30fb\u7ba1\u7406\u3059\u308b","text":""},{"location":"ja/usecases-description/team/workspace-management/#1","title":"1. \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u540d","text":"<p>\u8907\u6570\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u30fb\u7ba1\u7406\u3059\u308b</p>"},{"location":"ja/usecases-description/team/workspace-management/#2","title":"2. \u30a2\u30af\u30bf\u30fc\uff08\u5b9f\u884c\u8005\uff09","text":"<ul> <li>\u4e3b\u30a2\u30af\u30bf\u30fc\uff1a \u7d44\u7e54\u7ba1\u7406\u8005</li> <li>\u526f\u30a2\u30af\u30bf\u30fc\uff1a Hexabase.AI\u30b7\u30b9\u30c6\u30e0\u3001\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3001Kubernetes\u30af\u30e9\u30b9\u30bf\u30fc</li> </ul>"},{"location":"ja/usecases-description/team/workspace-management/#3","title":"3. \u4e8b\u524d\u6761\u4ef6","text":"<ul> <li>\u7d44\u7e54\u3068\u30c1\u30fc\u30e0\u304c\u8a2d\u5b9a\u6e08\u307f\u3067\u3042\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u7ba1\u7406\u6a29\u9650\u3092\u6301\u3063\u3066\u3044\u308b</li> <li>\u74b0\u5883\u5206\u96e2\u6226\u7565\uff08\u958b\u767a\u3001\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\uff09\u304c\u8a08\u753b\u3055\u308c\u3066\u3044\u308b</li> <li>\u5c02\u7528\u30ce\u30fc\u30c9\u30ea\u30bd\u30fc\u30b9\u304c\u5229\u7528\u53ef\u80fd\u3067\u3042\u308b</li> </ul>"},{"location":"ja/usecases-description/team/workspace-management/#4","title":"4. \u6210\u529f\u30b7\u30ca\u30ea\u30aa\uff08\u57fa\u672c\u30d5\u30ed\u30fc\uff09","text":"<ol> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u7d44\u7e54\u30c0\u30c3\u30b7\u30e5\u30dc\u30fc\u30c9\u306e\u300c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u300d\u30bb\u30af\u30b7\u30e7\u30f3\u306b\u30a2\u30af\u30bb\u30b9\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u65b0\u3057\u3044\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u30a6\u30a3\u30b6\u30fc\u30c9\u3092\u8868\u793a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u540d\uff08\u4f8b\uff1a<code>SaaS-Product-Dev</code>\uff09\u3092\u5165\u529b\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u7528\u9014\uff08\u958b\u767a\u74b0\u5883\uff09\u3092\u9078\u629e\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\uff08CPU\u3001\u30e1\u30e2\u30ea\u3001\u30b9\u30c8\u30ec\u30fc\u30b8\uff09\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u4f5c\u6210\u300d\u30dc\u30bf\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304cKubernetes\u30cd\u30fc\u30e0\u30b9\u30da\u30fc\u30b9\u3092\u4f5c\u6210\u3057\u3001\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u9069\u7528\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u306e\u5272\u308a\u5f53\u3066\u753b\u9762\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u958b\u767a\u8005\u3092\u9078\u629e\u3057\u3001<code>developer</code>\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304cDevOps\u30a8\u30f3\u30b8\u30cb\u30a2\u306b<code>workspace-admin</code>\u6a29\u9650\u3092\u4ed8\u4e0e\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u6a29\u9650\u8a2d\u5b9a\u3092\u9069\u7528\u3057\u3001\u30e1\u30f3\u30d0\u30fc\u306b\u30a2\u30af\u30bb\u30b9\u6a29\u3092\u4ed8\u4e0e\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u540c\u3058\u624b\u9806\u30672\u3064\u76ee\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08<code>SaaS-Product-Staging</code>\uff09\u3092\u4f5c\u6210\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u7528\u306b\u3088\u308a\u9ad8\u3044\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u3092\u8a2d\u5b9a\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u4e21\u65b9\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u4f5c\u6210\u5b8c\u4e86\u3092\u78ba\u8a8d\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u300c\u5c02\u7528\u30ce\u30fc\u30c9\u7ba1\u7406\u300d\u753b\u9762\u306b\u79fb\u52d5\u3059\u308b</li> <li>\u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u3092\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3059\u308b</li> <li>\u30b7\u30b9\u30c6\u30e0\u304c\u5c02\u7528\u30ce\u30fc\u30c9\u3092\u4f5c\u6210\u3057\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u3067\u5171\u6709\u53ef\u80fd\u306b\u8a2d\u5b9a\u3059\u308b</li> </ol>"},{"location":"ja/usecases-description/team/workspace-management/#5","title":"5. \u4ee3\u66ff\u30b7\u30ca\u30ea\u30aa\uff08\u4ee3\u66ff\u30d5\u30ed\u30fc\uff09","text":"<p>5a. \u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u8d85\u904e - 6a. \u8a2d\u5b9a\u3057\u305f\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u7d44\u7e54\u306e\u5229\u7528\u53ef\u80fd\u30ea\u30bd\u30fc\u30b9\u3092\u8d85\u904e\u3059\u308b - 6b. \u30b7\u30b9\u30c6\u30e0\u304c\u5236\u9650\u8d85\u904e\u306e\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 6c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30ea\u30bd\u30fc\u30b9\u914d\u5206\u3092\u8abf\u6574\u3059\u308b - 6d. \u307e\u305f\u306f\u65e2\u5b58\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u30af\u30a9\u30fc\u30bf\u3092\u898b\u76f4\u3059</p> <p>5b. \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u540d\u91cd\u8907 - 4a. \u5165\u529b\u3057\u305f\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u540d\u304c\u7d44\u7e54\u5185\u3067\u65e2\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b - 4b. \u30b7\u30b9\u30c6\u30e0\u304c\u91cd\u8907\u30a8\u30e9\u30fc\u3068\u4ee3\u66ff\u6848\u3092\u8868\u793a\u3059\u308b - 4c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u5225\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u540d\u3092\u5165\u529b\u3059\u308b</p> <p>5c. \u5c02\u7528\u30ce\u30fc\u30c9\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u5931\u6557 - 17a. \u5c02\u7528\u30ce\u30fc\u30c9\u306e\u4f5c\u6210\u4e2d\u306b\u30a4\u30f3\u30d5\u30e9\u30a8\u30e9\u30fc\u304c\u767a\u751f\u3059\u308b - 17b. \u30b7\u30b9\u30c6\u30e0\u304c\u30a8\u30e9\u30fc\u8a73\u7d30\u3068\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u60c5\u5831\u3092\u8868\u793a\u3059\u308b - 17c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30b5\u30dd\u30fc\u30c8\u306b\u9023\u7d61\u3059\u308b\u304b\u3001\u5f8c\u3067\u518d\u8a66\u884c\u3059\u308b</p> <p>5d. \u6a29\u9650\u4ed8\u4e0e\u30a8\u30e9\u30fc - 11a. \u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u3078\u306e\u6a29\u9650\u4ed8\u4e0e\u304c\u5931\u6557\u3059\u308b - 11b. \u30b7\u30b9\u30c6\u30e0\u304c\u6a29\u9650\u30a8\u30e9\u30fc\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u8868\u793a\u3059\u308b - 11c. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u30e1\u30f3\u30d0\u30fc\u306e\u7d44\u7e54\u6240\u5c5e\u72b6\u6cc1\u3092\u78ba\u8a8d\u3059\u308b - 11d. \u7d44\u7e54\u7ba1\u7406\u8005\u304c\u6a29\u9650\u8a2d\u5b9a\u3092\u518d\u5b9f\u884c\u3059\u308b</p>"},{"location":"ja/usecases-description/team/workspace-management/#6","title":"6. \u4e8b\u5f8c\u6761\u4ef6","text":"<ul> <li>\u958b\u767a\u7528\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08<code>SaaS-Product-Dev</code>\uff09\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b</li> <li>\u30b9\u30c6\u30fc\u30b8\u30f3\u30b0\u7528\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\uff08<code>SaaS-Product-Staging</code>\uff09\u304c\u4f5c\u6210\u3055\u308c\u3066\u3044\u308b</li> <li>\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u9069\u5207\u306a\u30ea\u30bd\u30fc\u30b9\u30af\u30a9\u30fc\u30bf\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u308b</li> <li>\u30c1\u30fc\u30e0\u30e1\u30f3\u30d0\u30fc\u304c\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u9069\u5207\u306a\u6a29\u9650\u3067\u5272\u308a\u5f53\u3066\u3089\u308c\u3066\u3044\u308b</li> <li>\u5c02\u7528\u30ce\u30fc\u30c9\u304c\u30d7\u30ed\u30d3\u30b8\u30e7\u30cb\u30f3\u30b0\u3055\u308c\u3001\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u9593\u3067\u5171\u6709\u53ef\u80fd\u306b\u306a\u3063\u3066\u3044\u308b</li> <li>\u74b0\u5883\u5206\u96e2\u304c\u5b9f\u73fe\u3055\u308c\u3066\u3044\u308b</li> <li>\u5404\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u304c\u72ec\u7acb\u3057\u3066\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u3055\u308c\u3066\u3044\u308b </li> </ul>"},{"location":"nodes/","title":"Nodes","text":"<p>This section covers everything related to node management in Hexabase.AI (HKS). Nodes are the fundamental compute units in your Kubernetes clusters, providing the infrastructure where your applications run.</p>"},{"location":"nodes/#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Node Types: Understanding different node configurations and their use cases</li> <li>Node Management: Adding, removing, and maintaining nodes in your clusters</li> <li>Node Monitoring: Tracking node health, performance metrics, and resource utilization</li> <li>Scaling: Auto-scaling policies and manual scaling procedures</li> <li>Troubleshooting: Common node issues and their solutions</li> </ul>"},{"location":"nodes/#key-topics","title":"Key Topics","text":"<ul> <li>Worker nodes vs. control plane nodes</li> <li>Node pools and node groups</li> <li>Node labels and taints</li> <li>Resource allocation and limits</li> <li>Node maintenance and upgrades</li> <li>Integration with AI-Ops for predictive maintenance</li> </ul> <p>Whether you're managing a small development cluster or a large production environment, this section will guide you through effective node management strategies in HKS.</p>"},{"location":"nodes/configuration/","title":"Node Configuration","text":"<p>This guide covers advanced configuration options for dedicated nodes in Hexabase.AI. While default settings are optimized for general use, you may need to customize your nodes for specific workloads.</p>"},{"location":"nodes/configuration/#node-labels-and-taints","title":"Node Labels and Taints","text":"<p>Labels and taints are the primary mechanisms for controlling how pods are scheduled onto your nodes.</p> <ul> <li>Labels: Used with <code>nodeSelector</code> and <code>nodeAffinity</code> to attract pods to a node.</li> <li>Taints: Used to repel pods from a node, unless they have a matching <code>toleration</code>.</li> </ul>"},{"location":"nodes/configuration/#common-labeling-schemes","title":"Common Labeling Schemes","text":"<ul> <li>By Workload Type: <code>workload-type=database</code>, <code>workload-type=frontend</code>, <code>workload-type=ml</code></li> <li>By Environment: <code>environment=production</code>, <code>environment=staging</code></li> <li>By Hardware: <code>gpu=nvidia-a10g</code>, <code>disk=fast-ssd</code></li> <li>By Team: <code>team=backend</code>, <code>team=data-science</code></li> </ul>"},{"location":"nodes/configuration/#common-taints","title":"Common Taints","text":"<ul> <li>Dedicated Hardware: Tainting a GPU node (<code>gpu=true:NoSchedule</code>) ensures that only pods specifically requesting a GPU will be scheduled there.</li> <li>Node Maintenance: Before performing maintenance, you can manually taint a node with <code>maintenance=true:NoExecute</code>. The <code>NoExecute</code> effect will evict any running pods that do not tolerate the taint.</li> </ul>"},{"location":"nodes/configuration/#updating-labels-and-taints","title":"Updating Labels and Taints","text":"<p>You can add or remove labels and taints from a node at any time via the HKS UI or CLI.</p> <pre><code># Add a new label to a node\nhb node label my-node-01 owner=sre-team\n\n# Add a new taint to a node\nhb node taint my-node-01 sensitive=true:NoSchedule\n\n# Remove a taint from a node\nhb node taint my-node-01 sensitive:NoSchedule-\n</code></pre>"},{"location":"nodes/configuration/#node-pools","title":"Node Pools","text":"<p>A Node Pool is a group of dedicated nodes that share the same configuration (instance type, disk size, labels, taints). Using node pools simplifies management when you need multiple nodes of the same type.</p> <pre><code># Create a node pool with 3 identical nodes\nhb nodepool create production-workers \\\n  --node-type c5.xlarge \\\n  --node-count 3 \\\n  --labels \"pool=production-workers\" \\\n  --enable-autoscaling --min-nodes 2 --max-nodes 10\n</code></pre>"},{"location":"nodes/configuration/#autoscaling-node-pools","title":"Autoscaling Node Pools","text":"<p>When autoscaling is enabled on a node pool, Hexabase.AI will automatically add or remove nodes based on resource demand.</p> <ul> <li>Scale-Up: If there are pending pods that cannot be scheduled due to insufficient resources in the pool, a new node is added (up to <code>max-nodes</code>).</li> <li>Scale-Down: If a node in the pool is under-utilized for a specified period and its pods can be safely rescheduled elsewhere, it is drained and terminated (down to <code>min-nodes</code>).</li> </ul>"},{"location":"nodes/configuration/#custom-node-configuration-enterprise-plan","title":"Custom Node Configuration (Enterprise Plan)","text":"<p>For advanced use cases, Enterprise Plan customers can apply custom configurations to their nodes using a <code>NodeConfig</code> resource.</p>"},{"location":"nodes/configuration/#custom-kernel-parameters","title":"Custom Kernel Parameters","text":"<p>You can tune <code>sysctl</code> kernel parameters for specific workloads, such as high-performance networking or database applications.</p> <pre><code>apiVersion: hks.io/v1\nkind: NodeConfig\nmetadata:\n  name: high-performance-net\nspec:\n  # Apply this config to nodes with this label\n  nodeSelector:\n    workload-type: \"real-time-bidding\"\n\n  # Kernel settings to apply\n  kernel:\n    sysctl:\n      net.core.somaxconn: \"65535\"\n      net.ipv4.tcp_max_syn_backlog: \"16384\"\n      vm.max_map_count: \"262144\"\n</code></pre>"},{"location":"nodes/configuration/#custom-startup-scripts","title":"Custom Startup Scripts","text":"<p>Run a custom script on node startup to perform actions like:</p> <ul> <li>Installing third-party monitoring or security agents.</li> <li>Downloading and caching large datasets.</li> <li>Performing custom hardware configuration.</li> </ul> <pre><code>apiVersion: hks.io/v1\nkind: NodeConfig\nmetadata:\n  name: install-custom-agent\nspec:\n  nodeSelector:\n    team: \"security\"\n\n  startupScript: |\n    #!/bin/bash\n    set -e\n    echo \"Installing custom security agent...\"\n    curl -sSL https://my-agent.com/install.sh | bash\n    systemctl enable --now my-custom-agent\n</code></pre> <p>Security Note: All startup scripts are run in a sandboxed environment and are subject to review by the Hexabase.AI security team. Not all actions may be permitted.</p>"},{"location":"nodes/configuration/#managing-node-images","title":"Managing Node Images","text":"<p>Hexabase.AI manages a set of optimized, hardened OS images for dedicated nodes. These images are based on common Linux distributions (like Ubuntu or Bottlerocket) and are pre-configured with the necessary components like the <code>kubelet</code>, container runtime, and HKS agents.</p> <ul> <li>Automatic Updates: HKS automatically rolls out new node images to apply security patches and OS updates in a non-disruptive, rolling fashion.</li> <li>Custom Images (Enterprise Plan): For organizations with strict requirements to use their own \"golden\" OS images, HKS can work with you to integrate your custom image into the provisioning pipeline, provided it meets certain security and compatibility standards.</li> </ul>"},{"location":"nodes/health-monitoring/","title":"Node Health Monitoring","text":"<p>Ensuring the health of the underlying nodes is fundamental to cluster stability and application performance. Hexabase.AI provides a comprehensive, automated system for monitoring the health of every node in your cluster, both shared and dedicated.</p>"},{"location":"nodes/health-monitoring/#automated-health-checks","title":"Automated Health Checks","text":"<p>The HKS control plane continuously monitors every node for a variety of health signals. It uses a combination of the <code>kubelet</code> status and its own node-agent metrics.</p>"},{"location":"nodes/health-monitoring/#key-monitored-conditions","title":"Key Monitored Conditions","text":"<ul> <li>Node Status: The primary status reported by Kubernetes. The ideal state is <code>Ready</code>.</li> <li><code>Ready</code>: The node is healthy and can accept new pods.</li> <li> <p><code>NotReady</code>: The node has failed a health check and cannot accept new pods. HKS will automatically begin investigating the cause.</p> </li> <li> <p>Resource Pressure: The node is running low on critical resources.</p> </li> <li><code>MemoryPressure</code>: Available memory on the node is low. Kubernetes will stop scheduling new pods and may begin evicting existing pods.</li> <li><code>DiskPressure</code>: Available disk space on the root or image volume is low. This can prevent new images from being pulled or new pods from starting.</li> <li> <p><code>PIDPressure</code>: The number of available process IDs on the node is low.</p> </li> <li> <p>Network Health:</p> </li> <li><code>NetworkUnavailable</code>: The network for the node has not been properly configured or is experiencing issues.</li> </ul>"},{"location":"nodes/health-monitoring/#node-problem-detector","title":"Node Problem Detector","text":"<p>Hexabase.AI runs the Node Problem Detector on every node. This is a background service that actively monitors for common node-level issues that might not be immediately visible to Kubernetes, such as:</p> <ul> <li>Hardware issues (bad disks, CPU faults).</li> <li>Kernel deadlocks or panics.</li> <li>Corrupted file systems.</li> <li>Issues with the container runtime (e.g., Docker or containerd becoming unresponsive).</li> </ul> <p>When the Node Problem Detector finds an issue, it automatically adds a taint to the node and reports the condition to the HKS control plane.</p>"},{"location":"nodes/health-monitoring/#automated-remediation","title":"Automated Remediation","text":"<p>When a node is determined to be unhealthy, the HKS AIOps engine initiates an automated remediation process.</p>"},{"location":"nodes/health-monitoring/#the-cordon-and-drain-process","title":"The \"Cordon and Drain\" Process","text":"<ol> <li>Cordon: The unhealthy node is immediately marked as \"unschedulable\" (<code>cordoned</code>). This prevents the Kubernetes scheduler from placing any new pods on it.</li> <li>Drain: The system gracefully evicts the existing pods from the unhealthy node.<ul> <li>For pods that are part of a <code>Deployment</code> or <code>StatefulSet</code>, the corresponding controller will automatically create replacement pods on other healthy nodes in the cluster.</li> <li>This process respects <code>PodDisruptionBudgets</code> to ensure your application's availability is maintained.</li> </ul> </li> <li>Investigate/Replace:<ul> <li>For transient issues (like a temporary <code>MemoryPressure</code> event), the AIOps engine may simply monitor the node to see if it recovers.</li> <li>For persistent failures (like a <code>NotReady</code> status or a hardware issue), the system will automatically provision a new, healthy node and terminate the failing one.</li> </ul> </li> </ol> <p>This automated self-healing capability ensures that node-level failures have a minimal impact on your applications.</p>"},{"location":"nodes/health-monitoring/#monitoring-node-health-in-the-ui","title":"Monitoring Node Health in the UI","text":"<p>The Hexabase.AI UI provides a dedicated \"Nodes\" section where you can view the health of your entire fleet.</p> <ul> <li>Node List View: See a list of all your nodes with their current status, IP addresses, resource allocation (CPU/memory), and the number of pods they are running.</li> <li>Detailed Node View: Click on any node to see a detailed dashboard with:</li> <li>Time-series graphs of CPU, memory, disk, and network usage.</li> <li>A list of all pods currently scheduled on the node.</li> <li>Any active conditions or taints applied to the node.</li> <li>A log of recent events related to the node, such as health checks and scheduling decisions.</li> </ul>"},{"location":"nodes/health-monitoring/#configuring-node-health-alerts","title":"Configuring Node Health Alerts","text":"<p>You can configure alerts to be notified of node health issues.</p> <pre><code># alert-rule-node-notready.yaml\napiVersion: hks.io/v1\nkind: AlertRule\nmetadata:\n  name: node-not-ready-alert\nspec:\n  condition:\n    type: metric\n    # The 'kube_node_status_condition' metric tracks health conditions\n    query: 'kube_node_status_condition{condition=\"Ready\",status=\"false\"} == 1'\n    for: 5m\n\n  severity: critical\n  summary: \"Node {{ $labels.node }} is NotReady.\"\n  description: \"Node {{ $labels.node }} has been in a NotReady state for over 5 minutes. HKS will begin automated remediation.\"\n\n  notification:\n    channel: \"pagerduty-sre-oncall\"\n</code></pre> <p>This alert would notify the on-call SRE team via PagerDuty if any node remains in a <code>NotReady</code> state for more than 5 minutes, providing an extra layer of visibility on top of the automated remediation process.</p>"},{"location":"nodes/scaling/","title":"Node Scaling Strategies","text":"<p>Scaling your node infrastructure is essential for handling variable application load while optimizing for cost. Hexabase.AI provides several strategies for both horizontal and vertical scaling of your dedicated nodes.</p>"},{"location":"nodes/scaling/#horizontal-scaling-scaling-out","title":"Horizontal Scaling (Scaling Out)","text":"<p>Horizontal scaling involves adding more nodes to or removing nodes from your cluster. This is the most common scaling strategy for handling changes in application traffic.</p>"},{"location":"nodes/scaling/#node-pool-autoscaling","title":"Node Pool Autoscaling","text":"<p>The primary mechanism for horizontal scaling is the Node Pool Autoscaler. As described in the Node Configuration guide, you can enable autoscaling when you create a node pool.</p> <pre><code># Create an autoscaling node pool\nhb nodepool create web-workers \\\n  --node-type m5.large \\\n  --enable-autoscaling \\\n  --min-nodes 3 \\\n  --max-nodes 20\n</code></pre> <p>How it works: The cluster autoscaler, managed by HKS, monitors for pods in the <code>Pending</code> state that cannot be scheduled due to a lack of resources (CPU, memory, or GPU).</p> <ul> <li>Scale-Up: If pending pods exist, and adding a new node to the pool would allow them to be scheduled, a new node is provisioned (up to the <code>max-nodes</code> limit).</li> <li>Scale-Down: The autoscaler periodically checks for nodes that are significantly under-utilized. If a node's workloads can be safely moved to other nodes in the pool, the node is cordoned, drained, and terminated (down to the <code>min-nodes</code> limit).</li> </ul>"},{"location":"nodes/scaling/#aiops-powered-predictive-scaling-enterprise-plan","title":"AIOps-Powered Predictive Scaling (Enterprise Plan)","text":"<p>For workloads with predictable, cyclical traffic patterns (e.g., an e-commerce site with a daily traffic spike), the AIOps engine can enable predictive scaling.</p> <ol> <li>Learning Phase: The AIOps engine analyzes the historical resource usage of your node pool.</li> <li>Prediction: It builds a model to predict future demand.</li> <li>Proactive Scaling: It proactively scales up the node pool before the anticipated traffic spike, ensuring that resources are available when needed and avoiding the slight delay of reactive scaling.</li> </ol> <pre><code># Enable predictive scaling on a node pool\napiVersion: hks.io/v1\nkind: NodePool\nmetadata:\n  name: web-workers\nspec:\n  # ... other node pool config ...\n  autoscaling:\n    enabled: true\n    min: 3\n    max: 20\n    # Enable the AI-powered predictive mode\n    mode: predictive\n    learningPeriod: \"14d\" # Analyze the last 14 days of data\n</code></pre>"},{"location":"nodes/scaling/#vertical-scaling-scaling-up","title":"Vertical Scaling (Scaling Up)","text":"<p>Vertical scaling involves increasing the resources (CPU, memory) of your existing nodes. This is less common than horizontal scaling for stateless applications but can be useful for specific stateful workloads like large databases.</p>"},{"location":"nodes/scaling/#manually-resizing-a-node-or-node-pool","title":"Manually Resizing a Node or Node Pool","text":"<p>You can manually change the instance type of a dedicated node or a node pool.</p> <pre><code># Change the instance type for an entire node pool\nhb nodepool update database-workers --node-type r5.2xlarge\n</code></pre> <p>Process: Hexabase.AI will perform a rolling replacement to apply the change without downtime.</p> <ol> <li>A new node with the larger instance type (<code>r5.2xlarge</code>) is added to the pool.</li> <li>One of the old, smaller nodes is cordoned and drained.</li> <li>Its pods are rescheduled onto the new, larger node.</li> <li>The old node is terminated.</li> <li>This process repeats until all nodes in the pool have been replaced with the new instance type.</li> </ol>"},{"location":"nodes/scaling/#best-practices-for-node-scaling","title":"Best Practices for Node Scaling","text":"<ol> <li>Prefer Horizontal Scaling: For most web applications and microservices, horizontal scaling is more resilient and cost-effective than vertical scaling. Design your applications to be stateless so they can be scaled out easily.</li> <li>Use Homogeneous Node Pools: It is generally better to have separate, autoscaling node pools for different workload types (e.g., a pool for general-purpose web apps, a pool for GPU workloads) rather than a single, large pool of mixed instance types.</li> <li>Configure Pod Disruption Budgets (PDBs): A PDB tells the cluster autoscaler how many of your application's pods must be running at all times. This prevents the autoscaler from draining too many nodes at once during a scale-down event and causing an outage for your application.     <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: my-app-pdb\nspec:\n  minAvailable: 2 # Always keep at least 2 pods running\n  selector:\n    matchLabels:\n      app: my-app\n</code></pre></li> <li>Set Appropriate Resource Requests: The autoscaler's decisions are based on the resource <code>requests</code> of your pods. If your pods don't have accurate requests set, the autoscaler will not function correctly. Use the HKS AIOps recommendations to rightsize your pod requests.</li> <li>Use Taints for Special Workloads: Ensure that your specialized, non-autoscaled nodes (e.g., for databases) are tainted so that the autoscaler doesn't try to schedule general-purpose pods onto them.</li> </ol>"},{"location":"nodes/vm-management/","title":"Dedicated VM Management","text":"<p>While Hexabase.AI provides a shared node pool for general-purpose workloads, the Team and Enterprise plans allow you to provision and manage dedicated Virtual Machines (VMs) for your workspaces. Dedicated nodes provide guaranteed resources, enhanced security isolation, and the ability to run specialized workloads.</p>"},{"location":"nodes/vm-management/#why-use-dedicated-nodes","title":"Why Use Dedicated Nodes?","text":"<ul> <li>Guaranteed Performance: The CPU, memory, and I/O of a dedicated node are reserved exclusively for your workloads, eliminating the \"noisy neighbor\" problem.</li> <li>Security and Compliance: Some compliance standards (like PCI-DSS) may require workloads to run on dedicated, isolated hardware.</li> <li>Specialized Hardware: You can provision nodes with specific hardware, such as GPUs for machine learning, or high-memory instances for in-memory databases.</li> <li>Custom Configurations: Apply custom kernel settings, install specific drivers, or run privileged daemons that are not allowed on the shared node pool.</li> </ul>"},{"location":"nodes/vm-management/#provisioning-a-dedicated-node","title":"Provisioning a Dedicated Node","text":"<p>Dedicated nodes can be provisioned directly from the Hexabase.AI UI or via the CLI.</p>"},{"location":"nodes/vm-management/#using-the-cli","title":"Using the CLI","text":"<pre><code># Provision a new dedicated node for your organization\nhb node create my-gpu-node-01 \\\n  --type g5.2xlarge \\\n  --disk-size 200Gi \\\n  --region us-east-1 \\\n  --labels \"workload-type=ml,gpu=nvidia-a10g\" \\\n  --taints \"gpu=true:NoSchedule\"\n</code></pre> <p>Key Parameters:</p> <ul> <li><code>--type</code>: The instance type/size from the underlying cloud provider (e.g., <code>m5.xlarge</code> on AWS).</li> <li><code>--disk-size</code>: The size of the root disk.</li> <li><code>--labels</code>: Kubernetes labels to apply to the node. This is crucial for scheduling pods to specific nodes.</li> <li><code>--taints</code>: Kubernetes taints to apply to the node. Taints prevent general-purpose pods from being scheduled onto the node unless they have a matching \"toleration\".</li> </ul>"},{"location":"nodes/vm-management/#assigning-nodes-to-workspaces","title":"Assigning Nodes to Workspaces","text":"<p>Once a node is provisioned at the organization level, an <code>organization_admin</code> can assign it to one or more workspaces.</p> <pre><code># Assign the newly created node to the 'ml-research' workspace\nhb node assign my-gpu-node-01 --workspace ml-research\n</code></pre> <p>A node can be exclusively assigned to one workspace or shared between multiple workspaces within the same organization.</p>"},{"location":"nodes/vm-management/#scheduling-pods-to-dedicated-nodes","title":"Scheduling Pods to Dedicated Nodes","text":"<p>To ensure your application's pods land on your dedicated nodes, you use standard Kubernetes scheduling mechanisms: <code>nodeSelector</code> or <code>nodeAffinity</code>.</p>"},{"location":"nodes/vm-management/#using-nodeselector","title":"Using <code>nodeSelector</code>","text":"<p>This is the simplest method. Add a <code>nodeSelector</code> to your pod spec that matches the labels you applied to the node.</p> <pre><code># pod-with-nodeselector.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: cuda-pod\nspec:\n  containers:\n    - name: cuda-container\n      image: nvidia/cuda:11.8.0-base-ubuntu22.04\n  # This pod will only be scheduled on nodes with this label\n  nodeSelector:\n    workload-type: ml\n</code></pre>"},{"location":"nodes/vm-management/#using-nodeaffinity","title":"Using <code>nodeAffinity</code>","text":"<p>Node affinity provides more expressive rules, such as \"preferred\" scheduling or matching on a set of values.</p> <pre><code># pod-with-nodeaffinity.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: data-processing-job\nspec:\n  # ...\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n          - matchExpressions:\n              - key: workload-type\n                operator: In\n                values:\n                  - data-processing\n                  - analytics\n</code></pre> <p>You must also add a toleration to your pod spec to allow it to be scheduled on a tainted node.</p> <pre><code># Pod spec continued...\ntolerations:\n  - key: \"gpu\"\n    operator: \"Equal\"\n    value: \"true\"\n    effect: \"NoSchedule\"\n</code></pre>"},{"location":"nodes/vm-management/#monitoring-dedicated-nodes","title":"Monitoring Dedicated Nodes","text":"<p>The HKS UI provides a dedicated view for node health and utilization.</p> <ul> <li>CPU, Memory, and Disk Usage: See the real-time and historical resource consumption of your nodes.</li> <li>Pod Density: View all the pods currently running on a specific node.</li> <li>Node Conditions: See the status of the node (e.g., <code>Ready</code>, <code>DiskPressure</code>, <code>MemoryPressure</code>).</li> <li>AIOps Insights: The AIOps engine will provide recommendations for your dedicated nodes, such as rightsizing recommendations if a node is consistently under-utilized.</li> </ul>"},{"location":"nodes/vm-management/#node-maintenance-and-upgrades","title":"Node Maintenance and Upgrades","text":"<p>Hexabase.AI handles the underlying OS patching and security updates for your dedicated VMs. When a major Kubernetes version upgrade is required, the process is managed with zero downtime for your applications.</p> <ol> <li>A new, upgraded node is provisioned.</li> <li>The old node is cordoned, which prevents new pods from being scheduled on it.</li> <li>Pods from the old node are gracefully drained (evicted) and rescheduled by Kubernetes onto the new node.</li> <li>Once the old node is empty, it is de-provisioned.</li> </ol> <p>This entire process is automated and orchestrated by the HKS control plane.</p>"},{"location":"observability/","title":"Observability","text":"<p>Gain deep insights into your applications and infrastructure with Hexabase.AI's comprehensive observability platform.</p>"},{"location":"observability/#overview","title":"Overview","text":"<p>Hexabase.AI provides a unified observability platform that combines metrics, logs, traces, and alerts to give you complete visibility into your Kubernetes workloads. Our AI-powered insights help you quickly identify issues, optimize performance, and ensure reliability.</p>"},{"location":"observability/#observability-components","title":"Observability Components","text":"<ul> <li> Metrics &amp; Monitoring</li> </ul> <p>Real-time metrics collection and visualization</p> <p> Explore Metrics</p> <ul> <li> Logging</li> </ul> <p>Centralized log aggregation and analysis</p> <p> Logging Guide</p> <ul> <li> Distributed Tracing</li> </ul> <p>Track requests across microservices</p> <p> Tracing Guide</p> <ul> <li> Alerting</li> </ul> <p>Intelligent alerts and incident management</p> <p> Alerting Setup</p>"},{"location":"observability/#the-three-pillars-of-observability","title":"The Three Pillars of Observability","text":""},{"location":"observability/#1-metrics","title":"1. Metrics","text":"<p>Quantitative measurements of system behavior</p> <ul> <li>System Metrics: CPU, memory, disk, network usage</li> <li>Application Metrics: Request rates, error rates, latency</li> <li>Business Metrics: User activity, transaction volumes</li> <li>Custom Metrics: Application-specific measurements</li> </ul>"},{"location":"observability/#2-logs","title":"2. Logs","text":"<p>Detailed records of system events</p> <ul> <li>Application Logs: Debug messages, errors, audit trails</li> <li>System Logs: Kernel messages, container runtime logs</li> <li>Access Logs: HTTP requests, API calls</li> <li>Security Logs: Authentication attempts, policy violations</li> </ul>"},{"location":"observability/#3-traces","title":"3. Traces","text":"<p>End-to-end request flow tracking</p> <ul> <li>Distributed Traces: Cross-service request paths</li> <li>Performance Analysis: Identify bottlenecks</li> <li>Dependency Mapping: Service interaction visualization</li> <li>Error Propagation: Track error sources</li> </ul>"},{"location":"observability/#ai-powered-features","title":"AI-Powered Features","text":""},{"location":"observability/#anomaly-detection","title":"Anomaly Detection","text":"<ul> <li>Automatic baseline learning</li> <li>Real-time anomaly alerts</li> <li>Predictive failure detection</li> <li>Seasonal pattern recognition</li> </ul>"},{"location":"observability/#root-cause-analysis","title":"Root Cause Analysis","text":"<ul> <li>Intelligent correlation of metrics, logs, and traces</li> <li>Automated incident investigation</li> <li>Suggested remediation steps</li> <li>Historical pattern matching</li> </ul>"},{"location":"observability/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Resource usage recommendations</li> <li>Cost optimization suggestions</li> <li>Scaling predictions</li> <li>Capacity planning insights</li> </ul>"},{"location":"observability/#observability-stack","title":"Observability Stack","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Dashboards &amp; UI               \u2502\n\u2502     (Grafana, Custom Dashboards)        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Query &amp; Analytics               \u2502\n\u2502   (PromQL, LogQL, TraceQL, AI/ML)      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502           Data Storage                  \u2502\n\u2502  (Prometheus, Loki, Tempo, S3)         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         Data Collection                 \u2502\n\u2502  (Agents, Sidecars, OpenTelemetry)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          Applications                   \u2502\n\u2502    (Your Workloads, System Pods)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"observability/#quick-start","title":"Quick Start","text":""},{"location":"observability/#1-enable-observability","title":"1. Enable Observability","text":"<pre><code>hb observability enable --workspace my-workspace\n</code></pre>"},{"location":"observability/#2-view-metrics-dashboard","title":"2. View Metrics Dashboard","text":"<pre><code>hb dashboard open metrics --workspace my-workspace\n</code></pre>"},{"location":"observability/#3-search-logs","title":"3. Search Logs","text":"<pre><code>hb logs search \"error\" --workspace my-workspace --last 1h\n</code></pre>"},{"location":"observability/#4-create-alert","title":"4. Create Alert","text":"<pre><code>hb alert create high-cpu \\\n  --metric \"cpu_usage &gt; 80\" \\\n  --duration 5m \\\n  --notify slack\n</code></pre>"},{"location":"observability/#common-use-cases","title":"Common Use Cases","text":""},{"location":"observability/#application-performance-monitoring","title":"Application Performance Monitoring","text":"<ul> <li>Track response times and error rates</li> <li>Identify slow endpoints</li> <li>Monitor database query performance</li> <li>Analyze user experience metrics</li> </ul>"},{"location":"observability/#infrastructure-monitoring","title":"Infrastructure Monitoring","text":"<ul> <li>Resource utilization tracking</li> <li>Capacity planning</li> <li>Cost optimization</li> <li>Predictive scaling</li> </ul>"},{"location":"observability/#security-monitoring","title":"Security Monitoring","text":"<ul> <li>Detect unusual access patterns</li> <li>Monitor failed authentication attempts</li> <li>Track configuration changes</li> <li>Compliance auditing</li> </ul>"},{"location":"observability/#business-intelligence","title":"Business Intelligence","text":"<ul> <li>User behavior analytics</li> <li>Feature adoption tracking</li> <li>Revenue impact analysis</li> <li>SLA compliance monitoring</li> </ul>"},{"location":"observability/#best-practices","title":"Best Practices","text":""},{"location":"observability/#1-structured-logging","title":"1. Structured Logging","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"ERROR\",\n  \"service\": \"payment-api\",\n  \"trace_id\": \"abc123\",\n  \"user_id\": \"user456\",\n  \"message\": \"Payment processing failed\",\n  \"error\": \"Insufficient funds\"\n}\n</code></pre>"},{"location":"observability/#2-meaningful-metrics","title":"2. Meaningful Metrics","text":"<pre><code># Good metric naming\nhttp_requests_total{method=\"GET\", endpoint=\"/api/users\", status=\"200\"}\npayment_processing_duration_seconds{gateway=\"stripe\"}\n\n# Include relevant labels\ndeployment_info{version=\"1.2.3\", environment=\"production\"}\n</code></pre>"},{"location":"observability/#3-effective-alerting","title":"3. Effective Alerting","text":"<ul> <li>Alert on symptoms, not causes</li> <li>Include runbook links</li> <li>Set appropriate severity levels</li> <li>Avoid alert fatigue</li> </ul>"},{"location":"observability/#4-cost-management","title":"4. Cost Management","text":"<ul> <li>Use sampling for high-volume data</li> <li>Set retention policies</li> <li>Archive old data to object storage</li> <li>Monitor observability costs</li> </ul>"},{"location":"observability/#integration-examples","title":"Integration Examples","text":""},{"location":"observability/#opentelemetry-sdk","title":"OpenTelemetry SDK","text":"<pre><code>from opentelemetry import trace, metrics\n\ntracer = trace.get_tracer(__name__)\nmeter = metrics.get_meter(__name__)\n\ncounter = meter.create_counter(\n    \"api_calls\",\n    description=\"Number of API calls\"\n)\n\n@tracer.start_as_current_span(\"process_request\")\ndef process_request(request):\n    counter.add(1, {\"endpoint\": request.path})\n    # Process request...\n</code></pre>"},{"location":"observability/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code>var (\n    httpDuration = prometheus.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Name: \"http_request_duration_seconds\",\n            Help: \"Duration of HTTP requests in seconds\",\n        },\n        []string{\"path\", \"method\"},\n    )\n)\n\nfunc init() {\n    prometheus.MustRegister(httpDuration)\n}\n</code></pre>"},{"location":"observability/#compliance-and-governance","title":"Compliance and Governance","text":"<ul> <li>Data Retention: Configurable retention policies</li> <li>Access Control: RBAC for observability data</li> <li>Audit Logging: Track who accessed what data</li> <li>Data Privacy: PII masking and encryption</li> <li>Compliance Reports: SOC2, HIPAA, GDPR ready</li> </ul>"},{"location":"observability/#next-steps","title":"Next Steps","text":"<ul> <li>Metrics: Set up Metrics &amp; Monitoring</li> <li>Logs: Configure Centralized Logging</li> <li>Traces: Implement Distributed Tracing</li> <li>Alerts: Create Intelligent Alerts</li> </ul>"},{"location":"observability/#related-documentation","title":"Related Documentation","text":"<ul> <li>AIOps Features</li> <li>Architecture Overview</li> <li>API Reference</li> <li>Best Practices</li> </ul>"},{"location":"observability/clickhouse-analytics/","title":"ClickHouse Analytics","text":"<p>While most observability interactions (logs, metrics, traces) happen through the high-level HKS UI and APIs, Hexabase.AI provides direct access to the underlying ClickHouse database for advanced analytics and custom data exploration. This is a powerful feature for data scientists, analysts, and engineers who need to run complex, ad-hoc queries against their observability data.</p>"},{"location":"observability/clickhouse-analytics/#why-clickhouse","title":"Why ClickHouse?","text":"<p>Hexabase.AI uses ClickHouse as the storage backend for logs, traces, and some metric data for several key reasons:</p> <ul> <li>Blazing Speed: ClickHouse is an open-source columnar database designed for Online Analytical Processing (OLAP). It can scan billions of rows and terabytes of data in milliseconds.</li> <li>High Compression: Its columnar nature allows for excellent data compression, reducing storage costs.</li> <li>SQL Interface: It uses a familiar SQL dialect, making it accessible to a wide range of users.</li> <li>Scalability: It is horizontally scalable, capable of handling petabytes of data.</li> </ul>"},{"location":"observability/clickhouse-analytics/#connecting-to-clickhouse","title":"Connecting to ClickHouse","text":"<p>Direct access to ClickHouse is available on Enterprise Plans. You can connect using any standard SQL client that supports the ClickHouse JDBC or HTTP interface.</p> <ol> <li>Get Credentials: An Organization Admin can generate read-only database credentials from the HKS settings panel. This will include:<ul> <li>Hostname</li> <li>Port</li> <li>Database name</li> <li>Username</li> <li>Password</li> </ul> </li> <li>Configure Your Client: Use a tool like DBeaver, DataGrip, or even the <code>clickhouse-client</code> CLI to connect to the provided endpoint. It is recommended to connect over a secure connection (e.g., via a VPN or private link established with your HKS environment).</li> </ol>"},{"location":"observability/clickhouse-analytics/#key-data-tables","title":"Key Data Tables","text":"<p>Your observability data is organized into several key tables within the <code>hks_data</code> database.</p>"},{"location":"observability/clickhouse-analytics/#logs-table","title":"<code>logs</code> table","text":"<p>This table contains all your log data.</p> Column Type Description <code>timestamp</code> <code>DateTime64(9)</code> The nanosecond-precision timestamp of the log entry. <code>trace_id</code> <code>String</code> The trace ID, if correlated with a distributed trace. <code>severity</code> <code>Enum(...)</code> The log level (e.g., <code>info</code>, <code>warn</code>, <code>error</code>). <code>message</code> <code>String</code> The raw log message. <code>resource</code> <code>Map(String, String)</code> Kubernetes resource metadata (e.g., <code>pod_name</code>, <code>namespace</code>). <code>attributes</code> <code>Map(String, String)</code> Structured log attributes parsed from JSON. <p>Example Query:</p> <pre><code>-- Count the number of error logs per service in the last 24 hours\nSELECT\n    resource['k8s.container.name'] AS service,\n    count() AS error_count\nFROM logs\nWHERE timestamp &gt;= now() - INTERVAL 1 DAY\n  AND severity = 'error'\nGROUP BY service\nORDER BY error_count DESC;\n</code></pre>"},{"location":"observability/clickhouse-analytics/#traces-table","title":"<code>traces</code> table","text":"<p>This table contains all the span data from distributed traces.</p> Column Type Description <code>timestamp</code> <code>DateTime64(9)</code> The start time of the span. <code>trace_id</code> <code>String</code> The ID of the trace this span belongs to. <code>span_id</code> <code>String</code> The unique ID of this span. <code>parent_span_id</code> <code>String</code> The ID of the parent span. <code>service_name</code> <code>String</code> The name of the service that emitted the span. <code>span_name</code> <code>String</code> The name of the operation (e.g., <code>HTTP GET /users</code>). <code>duration_ms</code> <code>Int64</code> The duration of the span in milliseconds. <code>attributes</code> <code>Map(String, String)</code> Span attributes/tags (e.g., <code>http.status_code</code>). <p>Example Query:</p> <pre><code>-- Find the top 5 slowest API endpoints (p95 latency) in the last hour\nSELECT\n    service_name,\n    span_name,\n    quantile(0.95)(duration_ms) AS p95_latency\nFROM traces\nWHERE timestamp &gt;= now() - INTERVAL 1 HOUR\n  AND attributes['span.kind'] = 'server'\nGROUP BY service_name, span_name\nORDER BY p95_latency DESC\nLIMIT 5;\n</code></pre>"},{"location":"observability/clickhouse-analytics/#use-cases-for-direct-analytics","title":"Use Cases for Direct Analytics","text":"<ul> <li>Custom Reporting: Build custom reports and visualizations in external BI tools (like Tableau or PowerBI) by connecting them to ClickHouse.</li> <li>Security Forensics: Perform deep forensic analysis during a security investigation by running complex queries across logs and network flow data.</li> <li>Business Intelligence: Correlate application data (like <code>user_id</code> or <code>tenant_id</code> from your structured logs) with performance metrics to understand how specific customers are experiencing your application.</li> <li>Long-Term Trend Analysis: Analyze months or years of data to identify long-term performance trends, capacity planning insights, or seasonal patterns.</li> </ul>"},{"location":"observability/clickhouse-analytics/#performance-considerations","title":"Performance Considerations","text":"<p>While ClickHouse is incredibly fast, it's still important to write efficient queries.</p> <ul> <li>Filter on <code>timestamp</code> first: Always include a time range filter in your <code>WHERE</code> clause. This is the primary partitioning key.</li> <li>Select only the columns you need: Avoid <code>SELECT *</code>. Columnar databases are most efficient when you only read the columns required for your query.</li> <li>Use <code>SAMPLE</code> for exploration: For very large tables, use the <code>SAMPLE</code> clause (<code>... FROM logs SAMPLE 0.1</code>) to run your query on a 10% sample of the data for faster, exploratory analysis.</li> </ul>"},{"location":"observability/dashboards-alerts/","title":"Dashboards and Alerts","text":"<p>Visualizing your system's health and being proactively notified of issues are core components of observability. Hexabase.AI provides a powerful, integrated solution for creating custom dashboards and configuring intelligent alerts.</p>"},{"location":"observability/dashboards-alerts/#dashboards","title":"Dashboards","text":"<p>Dashboards in Hexabase.AI allow you to create a customized, at-a-glance view of the metrics, logs, and traces that are most important to you. The dashboarding system is built on Grafana, providing a rich set of visualization options.</p>"},{"location":"observability/dashboards-alerts/#default-dashboards","title":"Default Dashboards","text":"<p>Out of the box, HKS provides several pre-configured dashboards for common use cases:</p> <ul> <li>Kubernetes Cluster Health: Overview of CPU, memory, and disk usage across all nodes.</li> <li>Application Performance (RED): Key metrics for your services: Rate, Errors, and Duration.</li> <li>Pod Resource Usage: Detailed CPU and memory consumption for individual pods.</li> <li>Nginx Ingress Controller: Metrics for ingress traffic, including request volume and error rates.</li> </ul>"},{"location":"observability/dashboards-alerts/#creating-a-custom-dashboard","title":"Creating a Custom Dashboard","text":"<p>You can easily create your own dashboards to visualize application-specific metrics.</p> <ol> <li>Navigate to the Dashboards section in the HKS UI.</li> <li>Create a new dashboard and add a panel.</li> <li>Select a Data Source: Your primary data source will be the HKS Metrics store (Prometheus/VictoriaMetrics), but you can also query logs from ClickHouse.</li> <li>Write a Query: Use PromQL (Prometheus Query Language) to select the metric you want to visualize.     <pre><code># Example: Graph the 95th percentile latency for a specific service\nhistogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"my-app\"}[5m])) by (le))\n</code></pre></li> <li>Choose a Visualization: Select from a wide range of panel types, including:<ul> <li>Graphs and time series</li> <li>Stat panels and gauges</li> <li>Tables</li> <li>Heatmaps</li> <li>Logs panels</li> </ul> </li> </ol>"},{"location":"observability/dashboards-alerts/#dashboard-as-code","title":"Dashboard as Code","text":"<p>For better version control and repeatability, you can define your dashboards as code using a <code>ConfigMap</code>.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-app-dashboard\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  my-app.json: |\n    {\n      \"__inputs\": [],\n      \"__requires\": [],\n      \"annotations\": { ... },\n      \"editable\": true,\n      \"panels\": [ ... ],\n      \"title\": \"My Application Dashboard\"\n    }\n</code></pre> <p>HKS will automatically discover this ConfigMap and import the dashboard into the UI.</p>"},{"location":"observability/dashboards-alerts/#alerting","title":"Alerting","text":"<p>The HKS alerting system, powered by the AIOps engine, allows you to define alerts based on metrics, logs, or traces.</p>"},{"location":"observability/dashboards-alerts/#creating-an-alert-rule","title":"Creating an Alert Rule","text":"<p>Alert rules are defined as a custom resource.</p> <pre><code># alert-rule.yaml\napiVersion: hks.io/v1\nkind: AlertRule\nmetadata:\n  name: high-cpu-utilization\nspec:\n  # The condition that triggers the alert\n  condition:\n    type: metric\n    query: 'sum(rate(container_cpu_usage_seconds_total{container!=\"\"}[5m])) by (pod) &gt; 0.8'\n    for: 5m # Fire only if the condition is true for 5 continuous minutes\n\n  # Severity of the alert\n  severity: warning\n\n  # Information about the alert\n  summary: \"Pod {{ $labels.pod }} has high CPU usage.\"\n  description: \"The pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been using over 80% CPU for the last 5 minutes.\"\n\n  # Where to send the notification\n  notification:\n    channel: \"slack-channel-prod-alerts\"\n</code></pre>"},{"location":"observability/dashboards-alerts/#supported-alert-conditions","title":"Supported Alert Conditions","text":"<ul> <li>Metric-based: Trigger an alert when a PromQL query returns a value that crosses a threshold (e.g., <code>cpu &gt; 80%</code>, <code>error_rate &gt; 5%</code>).</li> <li>Log-based: Trigger an alert when a certain pattern appears in the logs (e.g., <code>level=error</code> or <code>message contains \"fatal\"</code>).</li> <li>AIOps Anomaly Detection: Trigger an alert when the AIOps engine detects a significant deviation from the normal behavior of a metric (e.g., a sudden drop in request rate).</li> </ul>"},{"location":"observability/dashboards-alerts/#notification-channels","title":"Notification Channels","text":"<p>You can configure multiple channels to send alert notifications to.</p> <pre><code>apiVersion: hks.io/v1\nkind: NotificationChannel\nmetadata:\n  name: slack-channel-prod-alerts\nspec:\n  type: slack\n  config:\n    urlSecretRef:\n      name: slack-webhook-secret\n      key: url\n    channel: \"#production-alerts\"\n---\napiVersion: hks.io/v1\nkind: NotificationChannel\nmetadata:\n  name: pagerduty-sre-oncall\nspec:\n  type: pagerduty\n  config:\n    integrationKeySecretRef:\n      name: pagerduty-api-key\n      key: key\n</code></pre> <p>Supported Channel Types:</p> <ul> <li>Slack</li> <li>PagerDuty</li> <li>Email</li> <li>Opsgenie</li> <li>Generic Webhook</li> </ul>"},{"location":"observability/dashboards-alerts/#best-practices","title":"Best Practices","text":"<ol> <li>Dashboard for Your Audience: Create different dashboards for different teams. A developer might need detailed application-level metrics, while a platform administrator might need a high-level cluster health overview.</li> <li>Alert on Symptoms, Not Causes: Your primary alerts should focus on user-facing symptoms like high error rates, high latency, or low availability. These are what directly impact the user experience. Alerting on causes (like high CPU) is still useful but should generally be a lower severity.</li> <li>Avoid Alert Fatigue: Be selective about what you alert on. If an alert is not actionable, it's just noise. Fine-tune your thresholds and use <code>for</code> durations to avoid alerts for transient spikes.</li> <li>Use Templates: Use dashboard and alert rule templates to ensure consistency across your services.</li> <li>Document Your Alerts: In the <code>description</code> or <code>runbook_url</code> field of your alert rule, provide clear instructions on how to diagnose and mitigate the issue. This helps the on-call engineer resolve the problem quickly.</li> </ol>"},{"location":"observability/logging/","title":"Logging Architecture","text":"<p>A comprehensive logging strategy is essential for debugging applications, monitoring system health, and performing security audits. The Hexabase.AI platform provides a centralized, scalable, and real-time logging architecture that aggregates logs from every component of your system.</p>"},{"location":"observability/logging/#overview","title":"Overview","text":"<p>The logging architecture is designed to automatically capture, parse, and index logs from:</p> <ul> <li>Your Applications: Logs written to <code>stdout</code> and <code>stderr</code> from your containers.</li> <li>Kubernetes System Components: Logs from the API server, scheduler, kubelet, etc.</li> <li>HKS Control Plane: Logs from the Hexabase.AI platform services.</li> <li>Node-level Logs: System logs from the underlying virtual machine nodes (<code>syslog</code>, <code>journald</code>).</li> </ul> <pre><code>graph TD\n    subgraph \"Nodes\"\n        App1[Pod: App A&lt;br&gt;logs to stdout] --&gt; Agent;\n        App2[Pod: App B&lt;br&gt;logs to stdout] --&gt; Agent;\n        Kubelet[Kubelet Logs] --&gt; Agent;\n        Syslog[System Logs] --&gt; Agent;\n        Agent(Log Agent&lt;br&gt;Fluent Bit);\n    end\n\n    subgraph \"HKS Logging Pipeline\"\n        Agent --&gt; Router{Log Router/Parser};\n        Router --&gt;|Parsed &amp; Enriched| Indexer[Log Indexer&lt;br&gt;ClickHouse];\n    end\n\n    subgraph \"Users &amp; Services\"\n        CLI[HKS CLI&lt;br&gt;hb logs] --&gt; QueryAPI;\n        UI[HKS UI&lt;br&gt;Log Viewer] --&gt; QueryAPI;\n        AIOps[AIOps Engine] --&gt; QueryAPI;\n        QueryAPI(Log Query API)--&gt; Indexer;\n    end\n\n    style Indexer fill:#00C6AB,stroke:#333,stroke-width:2px</code></pre>"},{"location":"observability/logging/#how-it-works","title":"How It Works","text":"<ol> <li>Log Collection: A lightweight logging agent (<code>Fluent Bit</code>) runs as a <code>DaemonSet</code> on every node in the cluster. It automatically tails log files from all containers running on that node, as well as system-level logs.</li> <li>Parsing and Enrichment: Logs are forwarded to a central log routing layer. Here, they are parsed (e.g., JSON logs are broken into fields) and enriched with metadata, including:<ul> <li>Kubernetes labels (<code>app</code>, <code>version</code>, etc.)</li> <li>Pod and container name</li> <li>Namespace / Workspace</li> <li>Node name</li> <li>Timestamp</li> </ul> </li> <li>Indexing: The enriched logs are sent to a high-performance, horizontally scalable log indexing engine built on ClickHouse. ClickHouse is a columnar database optimized for fast queries over large volumes of data, making it ideal for real-time log analysis.</li> <li>Querying: All logs are made available through a unified Log Query API. The HKS UI, CLI, and AIOps engine all use this API to search, filter, and stream logs.</li> </ol>"},{"location":"observability/logging/#application-logging-best-practices","title":"Application Logging Best Practices","text":"<p>To get the most out of the HKS logging platform, you should follow these best practices for your own applications.</p>"},{"location":"observability/logging/#1-log-to-stdout-and-stderr","title":"1. Log to <code>stdout</code> and <code>stderr</code>","text":"<ul> <li>Do: Configure your application to write all logs to standard output (<code>stdout</code>) and standard error (<code>stderr</code>). The container runtime and the HKS logging agent are designed to capture these streams automatically.</li> <li>Don't: Write logs to files inside the container. This complicates log collection, rotation, and management. If you must write to a file, use a sidecar container to tail that file and forward its contents to <code>stdout</code>.</li> </ul>"},{"location":"observability/logging/#2-use-structured-logging-json","title":"2. Use Structured Logging (JSON)","text":"<p>While the platform can parse plain text logs, structured logs provide much more powerful filtering and analysis capabilities.</p> <ul> <li>Do: Configure your application's logger to output logs in JSON format.</li> <li>Don't: Use multi-line log formats or unstructured text if you can avoid it.</li> </ul> <p>Example: Unstructured vs. Structured Log</p> <p>Bad (Unstructured):</p> <pre><code>INFO [2025-06-15T10:00:00Z] Request received: GET /api/users/123 from 10.1.2.3\n</code></pre> <p>Good (Structured JSON):</p> <pre><code>{\n  \"timestamp\": \"2025-06-15T10:00:00Z\",\n  \"level\": \"info\",\n  \"message\": \"Request received\",\n  \"http_method\": \"GET\",\n  \"http_path\": \"/api/users/123\",\n  \"source_ip\": \"10.1.2.3\"\n}\n</code></pre> <p>When HKS ingests the structured log, <code>http_method</code>, <code>http_path</code>, and <code>source_ip</code> will become searchable fields, allowing you to easily query for all <code>GET</code> requests or all requests from a specific IP.</p>"},{"location":"observability/logging/#querying-logs","title":"Querying Logs","text":""},{"location":"observability/logging/#using-the-cli","title":"Using the CLI","text":"<p>The <code>hb logs</code> command is a powerful tool for interacting with your logs.</p> <pre><code># Follow the logs for a deployment in real-time\nhb logs -f deployment/my-app\n\n# Get logs from the past hour for a specific pod\nhb logs my-app-pod-xyz --since 1h\n\n# Use a selector to get logs from multiple pods\nhb logs -l app=my-app\n\n# Filter logs based on their content (requires structured logging)\nhb logs -l app=my-app --filter \"level=error\"\nhb logs -l app=my-app --filter \"http_status&gt;=500\"\n</code></pre>"},{"location":"observability/logging/#using-the-ui","title":"Using the UI","text":"<p>The HKS web UI provides a rich log exploration interface with:</p> <ul> <li>Real-time log streaming.</li> <li>Time range selection.</li> <li>Free-text search.</li> <li>Advanced filtering using a query builder.</li> <li>The ability to save and share queries.</li> </ul>"},{"location":"observability/logging/#log-retention","title":"Log Retention","text":"<p>Log data is retained according to your organization's plan:</p> <ul> <li>Single User: 7 days</li> <li>Team: 30 days</li> <li>Enterprise: 1 year or custom (configurable)</li> </ul> <p>For long-term archival beyond these periods, you can configure a Log Sink to stream logs to your own storage solution (e.g., an S3 bucket or an external logging service).</p>"},{"location":"observability/monitoring-setup/","title":"Monitoring Setup Guide","text":"<p>Comprehensive guide for setting up monitoring and observability for Hexabase AI platform.</p>"},{"location":"observability/monitoring-setup/#overview","title":"Overview","text":"<p>The Hexabase AI monitoring stack includes: - Prometheus: Metrics collection and storage - Grafana: Visualization and dashboards - Loki: Log aggregation - Alertmanager: Alert routing and management - ClickHouse: Long-term log storage - OpenTelemetry: Distributed tracing</p>"},{"location":"observability/monitoring-setup/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Applications  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Prometheus    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502     Grafana     \u2502\n\u2502  (metrics/logs) \u2502     \u2502  (time-series)  \u2502     \u2502  (visualization)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                                \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502      Loki       \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502  (log storage)  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502   ClickHouse    \u2502\n                        \u2502 (long-term logs)\u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"observability/monitoring-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster with Hexabase AI installed</li> <li>Helm 3.x</li> <li>kubectl configured</li> <li>Storage class for persistent volumes</li> <li>DNS configured for monitoring endpoints</li> </ul>"},{"location":"observability/monitoring-setup/#installation","title":"Installation","text":""},{"location":"observability/monitoring-setup/#1-create-monitoring-namespace","title":"1. Create Monitoring Namespace","text":"<pre><code>kubectl create namespace monitoring\n</code></pre>"},{"location":"observability/monitoring-setup/#2-install-prometheus-stack","title":"2. Install Prometheus Stack","text":"<pre><code># Add Prometheus community Helm repository\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n\n# Create values file for Prometheus\ncat &gt; prometheus-values.yaml &lt;&lt;EOF\nprometheus:\n  prometheusSpec:\n    retention: 30d\n    retentionSize: 100GB\n    storageSpec:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: fast-ssd\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 200Gi\n\n    # Resource limits\n    resources:\n      requests:\n        cpu: 1000m\n        memory: 2Gi\n      limits:\n        cpu: 2000m\n        memory: 4Gi\n\n    # Additional scrape configs\n    additionalScrapeConfigs:\n    - job_name: 'hexabase-api'\n      kubernetes_sd_configs:\n      - role: pod\n        namespaces:\n          names:\n          - hexabase-system\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n        action: keep\n        regex: true\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n        action: replace\n        target_label: __metrics_path__\n        regex: (.+)\n      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n        action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: \\$1:\\$2\n        target_label: __address__\n\nalertmanager:\n  alertmanagerSpec:\n    storage:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: fast-ssd\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 10Gi\n\n  config:\n    global:\n      resolve_timeout: 5m\n      slack_api_url: '$SLACK_WEBHOOK_URL'\n\n    route:\n      group_by: ['alertname', 'cluster', 'service']\n      group_wait: 10s\n      group_interval: 10s\n      repeat_interval: 12h\n      receiver: 'default-receiver'\n      routes:\n      - match:\n          severity: critical\n        receiver: 'critical-receiver'\n        continue: true\n      - match:\n          severity: warning\n        receiver: 'warning-receiver'\n\n    receivers:\n    - name: 'default-receiver'\n      slack_configs:\n      - channel: '#alerts'\n        title: 'Hexabase Alert'\n        text: '{{ range .Alerts }}{{ .Annotations.summary }}\\n{{ end }}'\n\n    - name: 'critical-receiver'\n      slack_configs:\n      - channel: '#critical-alerts'\n        title: '\ud83d\udea8 CRITICAL: Hexabase Alert'\n      pagerduty_configs:\n      - service_key: '$PAGERDUTY_SERVICE_KEY'\n\n    - name: 'warning-receiver'\n      slack_configs:\n      - channel: '#alerts'\n        title: '\u26a0\ufe0f Warning: Hexabase Alert'\n\ngrafana:\n  enabled: true\n  adminPassword: '$GRAFANA_ADMIN_PASSWORD'\n\n  persistence:\n    enabled: true\n    storageClassName: fast-ssd\n    size: 50Gi\n\n  ingress:\n    enabled: true\n    ingressClassName: nginx\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    hosts:\n    - monitoring.hexabase.ai\n    tls:\n    - secretName: grafana-tls\n      hosts:\n      - monitoring.hexabase.ai\n\n  datasources:\n    datasources.yaml:\n      apiVersion: 1\n      datasources:\n      - name: Prometheus\n        type: prometheus\n        url: http://prometheus-kube-prometheus-prometheus:9090\n        access: proxy\n        isDefault: true\n      - name: Loki\n        type: loki\n        url: http://loki:3100\n        access: proxy\nEOF\n\n# Install Prometheus stack\nhelm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --values prometheus-values.yaml\n</code></pre>"},{"location":"observability/monitoring-setup/#3-install-loki-for-log-aggregation","title":"3. Install Loki for Log Aggregation","text":"<pre><code># Add Grafana Helm repository\nhelm repo add grafana https://grafana.github.io/helm-charts\n\n# Create Loki values\ncat &gt; loki-values.yaml &lt;&lt;EOF\nloki:\n  auth_enabled: false\n\n  storage:\n    type: filesystem\n    filesystem:\n      chunks_directory: /data/loki/chunks\n      rules_directory: /data/loki/rules\n\n  persistence:\n    enabled: true\n    storageClassName: fast-ssd\n    size: 100Gi\n\n  config:\n    table_manager:\n      retention_deletes_enabled: true\n      retention_period: 168h  # 7 days\n\n    limits_config:\n      enforce_metric_name: false\n      reject_old_samples: true\n      reject_old_samples_max_age: 168h\n      max_query_length: 0h\n      max_streams_per_user: 10000\n\n    ingester:\n      chunk_idle_period: 30m\n      max_chunk_age: 1h\n      chunk_target_size: 1572864\n      chunk_retain_period: 30s\n      max_transfer_retries: 0\n\npromtail:\n  enabled: true\n\n  config:\n    clients:\n    - url: http://loki:3100/loki/api/v1/push\n\n    positions:\n      filename: /tmp/positions.yaml\n\n    target_config:\n      sync_period: 10s\n\n    pipeline_stages:\n    - regex:\n        expression: '^(?P&lt;namespace&gt;\\S+)\\s+(?P&lt;pod&gt;\\S+)\\s+(?P&lt;container&gt;\\S+)\\s+(?P&lt;level&gt;\\S+)\\s+(?P&lt;message&gt;.*)$'\n    - labels:\n        namespace:\n        pod:\n        container:\n        level:\n    - timestamp:\n        source: time\n        format: RFC3339\n    - output:\n        source: message\nEOF\n\n# Install Loki\nhelm install loki grafana/loki-stack \\\n  --namespace monitoring \\\n  --values loki-values.yaml\n</code></pre>"},{"location":"observability/monitoring-setup/#4-install-clickhouse-for-long-term-storage","title":"4. Install ClickHouse for Long-term Storage","text":"<pre><code># Create ClickHouse configuration\ncat &gt; clickhouse-values.yaml &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: clickhouse-config\n  namespace: monitoring\ndata:\n  config.xml: |\n    &lt;clickhouse&gt;\n      &lt;logger&gt;\n        &lt;level&gt;information&lt;/level&gt;\n        &lt;log&gt;/var/log/clickhouse-server/clickhouse-server.log&lt;/log&gt;\n        &lt;errorlog&gt;/var/log/clickhouse-server/clickhouse-server.err.log&lt;/errorlog&gt;\n        &lt;size&gt;1000M&lt;/size&gt;\n        &lt;count&gt;10&lt;/count&gt;\n      &lt;/logger&gt;\n\n      &lt;max_connections&gt;4096&lt;/max_connections&gt;\n      &lt;keep_alive_timeout&gt;3&lt;/keep_alive_timeout&gt;\n      &lt;max_concurrent_queries&gt;100&lt;/max_concurrent_queries&gt;\n\n      &lt;profiles&gt;\n        &lt;default&gt;\n          &lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;\n          &lt;load_balancing&gt;random&lt;/load_balancing&gt;\n        &lt;/default&gt;\n      &lt;/profiles&gt;\n\n      &lt;users&gt;\n        &lt;default&gt;\n          &lt;password_sha256_hex&gt;$CLICKHOUSE_PASSWORD_SHA256&lt;/password_sha256_hex&gt;\n          &lt;networks&gt;\n            &lt;ip&gt;::/0&lt;/ip&gt;\n          &lt;/networks&gt;\n          &lt;profile&gt;default&lt;/profile&gt;\n          &lt;quota&gt;default&lt;/quota&gt;\n        &lt;/default&gt;\n      &lt;/users&gt;\n    &lt;/clickhouse&gt;\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: clickhouse\n  namespace: monitoring\nspec:\n  serviceName: clickhouse\n  replicas: 3\n  selector:\n    matchLabels:\n      app: clickhouse\n  template:\n    metadata:\n      labels:\n        app: clickhouse\n    spec:\n      containers:\n      - name: clickhouse\n        image: clickhouse/clickhouse-server:23.8\n        ports:\n        - containerPort: 8123\n          name: http\n        - containerPort: 9000\n          name: native\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/clickhouse\n        - name: config\n          mountPath: /etc/clickhouse-server/config.d\n        resources:\n          requests:\n            cpu: 2000m\n            memory: 8Gi\n          limits:\n            cpu: 4000m\n            memory: 16Gi\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: fast-ssd\n      resources:\n        requests:\n          storage: 500Gi\nEOF\n\nkubectl apply -f clickhouse-values.yaml\n\n# Create ClickHouse schema for logs\nkubectl exec -n monitoring clickhouse-0 -- clickhouse-client --query \"\nCREATE DATABASE IF NOT EXISTS logs;\n\nCREATE TABLE IF NOT EXISTS logs.hexabase (\n    timestamp DateTime64(3),\n    level String,\n    namespace String,\n    pod String,\n    container String,\n    message String,\n    trace_id String,\n    span_id String,\n    user_id String,\n    workspace_id String,\n    project_id String,\n    method String,\n    path String,\n    status_code UInt16,\n    duration_ms UInt32,\n    INDEX idx_timestamp timestamp TYPE minmax GRANULARITY 1,\n    INDEX idx_trace_id trace_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_workspace workspace_id TYPE bloom_filter GRANULARITY 1\n) ENGINE = MergeTree()\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (namespace, pod, timestamp)\nTTL timestamp + INTERVAL 90 DAY;\n\"\n</code></pre>"},{"location":"observability/monitoring-setup/#5-configure-log-forwarding-to-clickhouse","title":"5. Configure Log Forwarding to ClickHouse","text":"<pre><code># fluent-bit-clickhouse.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluent-bit-config\n  namespace: monitoring\ndata:\n  fluent-bit.conf: |\n    [SERVICE]\n        Flush         5\n        Log_Level     info\n        Daemon        off\n        Parsers_File  parsers.conf\n\n    [INPUT]\n        Name              tail\n        Path              /var/log/containers/*hexabase*.log\n        Parser            docker\n        Tag               kube.*\n        Refresh_Interval  5\n        Mem_Buf_Limit     50MB\n        Skip_Long_Lines   On\n\n    [FILTER]\n        Name                kubernetes\n        Match               kube.*\n        Kube_URL            https://kubernetes.default.svc:443\n        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\n        Merge_Log           On\n        K8S-Logging.Parser  On\n        K8S-Logging.Exclude On\n\n    [OUTPUT]\n        Name          http\n        Match         *\n        Host          clickhouse.monitoring.svc.cluster.local\n        Port          8123\n        URI           /\n        Format        json_lines\n        Header        X-ClickHouse-Database logs\n        Header        X-ClickHouse-Table hexabase\n        Header        X-ClickHouse-Format JSONEachRow\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluent-bit\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:\n      app: fluent-bit\n  template:\n    metadata:\n      labels:\n        app: fluent-bit\n    spec:\n      serviceAccountName: fluent-bit\n      containers:\n      - name: fluent-bit\n        image: fluent/fluent-bit:2.1\n        volumeMounts:\n        - name: config\n          mountPath: /fluent-bit/etc/\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: fluent-bit-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n</code></pre>"},{"location":"observability/monitoring-setup/#6-set-up-opentelemetry-for-tracing","title":"6. Set Up OpenTelemetry for Tracing","text":"<pre><code># Install OpenTelemetry Collector\nhelm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts\n\ncat &gt; otel-values.yaml &lt;&lt;EOF\nmode: deployment\n\nconfig:\n  receivers:\n    otlp:\n      protocols:\n        grpc:\n          endpoint: 0.0.0.0:4317\n        http:\n          endpoint: 0.0.0.0:4318\n\n  processors:\n    batch:\n      timeout: 1s\n      send_batch_size: 1024\n\n    memory_limiter:\n      check_interval: 1s\n      limit_mib: 2048\n      spike_limit_mib: 512\n\n  exporters:\n    prometheus:\n      endpoint: 0.0.0.0:8889\n\n    jaeger:\n      endpoint: jaeger-collector.monitoring.svc.cluster.local:14250\n      tls:\n        insecure: true\n\n    logging:\n      loglevel: info\n\n  service:\n    pipelines:\n      traces:\n        receivers: [otlp]\n        processors: [memory_limiter, batch]\n        exporters: [jaeger, logging]\n\n      metrics:\n        receivers: [otlp]\n        processors: [memory_limiter, batch]\n        exporters: [prometheus]\n\nservice:\n  type: ClusterIP\n  ports:\n    otlp-grpc:\n      port: 4317\n    otlp-http:\n      port: 4318\n    metrics:\n      port: 8889\n\nresources:\n  limits:\n    cpu: 1000m\n    memory: 2Gi\n  requests:\n    cpu: 200m\n    memory: 400Mi\nEOF\n\nhelm install opentelemetry-collector open-telemetry/opentelemetry-collector \\\n  --namespace monitoring \\\n  --values otel-values.yaml\n</code></pre>"},{"location":"observability/monitoring-setup/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"observability/monitoring-setup/#1-import-hexabase-dashboards","title":"1. Import Hexabase Dashboards","text":"<pre><code># Download Hexabase dashboards\ncurl -O https://raw.githubusercontent.com/hexabase/monitoring/main/dashboards/api-performance.json\ncurl -O https://raw.githubusercontent.com/hexabase/monitoring/main/dashboards/workspace-usage.json\ncurl -O https://raw.githubusercontent.com/hexabase/monitoring/main/dashboards/resource-utilization.json\n\n# Import via Grafana API\nGRAFANA_URL=\"https://monitoring.hexabase.ai\"\nGRAFANA_API_KEY=\"your-api-key\"\n\nfor dashboard in *.json; do\n  curl -X POST \\\n    -H \"Authorization: Bearer $GRAFANA_API_KEY\" \\\n    -H \"Content-Type: application/json\" \\\n    -d @$dashboard \\\n    \"$GRAFANA_URL/api/dashboards/db\"\ndone\n</code></pre>"},{"location":"observability/monitoring-setup/#2-key-dashboards-to-create","title":"2. Key Dashboards to Create","text":""},{"location":"observability/monitoring-setup/#api-performance-dashboard","title":"API Performance Dashboard","text":"<ul> <li>Request rate by endpoint</li> <li>Response time percentiles (p50, p95, p99)</li> <li>Error rate by status code</li> <li>Active connections</li> <li>Request size distribution</li> </ul>"},{"location":"observability/monitoring-setup/#workspace-usage-dashboard","title":"Workspace Usage Dashboard","text":"<ul> <li>Active workspaces</li> <li>Resource usage per workspace</li> <li>vCluster provisioning times</li> <li>Workspace creation/deletion trends</li> <li>Cost allocation by workspace</li> </ul>"},{"location":"observability/monitoring-setup/#infrastructure-dashboard","title":"Infrastructure Dashboard","text":"<ul> <li>Node CPU/Memory usage</li> <li>Pod distribution across nodes</li> <li>Storage utilization</li> <li>Network traffic</li> <li>Certificate expiration</li> </ul>"},{"location":"observability/monitoring-setup/#alert-rules","title":"Alert Rules","text":""},{"location":"observability/monitoring-setup/#1-critical-alerts","title":"1. Critical Alerts","text":"<pre><code># critical-alerts.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: hexabase-critical\n  namespace: monitoring\nspec:\n  groups:\n  - name: critical\n    interval: 30s\n    rules:\n    - alert: APIDown\n      expr: up{job=\"hexabase-api\"} == 0\n      for: 1m\n      labels:\n        severity: critical\n        team: platform\n      annotations:\n        summary: \"Hexabase API is down\"\n        description: \"{{ $labels.instance }} API endpoint has been down for more than 1 minute.\"\n\n    - alert: DatabaseDown\n      expr: pg_up == 0\n      for: 1m\n      labels:\n        severity: critical\n        team: platform\n      annotations:\n        summary: \"PostgreSQL database is down\"\n        description: \"PostgreSQL instance {{ $labels.instance }} is down.\"\n\n    - alert: HighErrorRate\n      expr: |\n        sum(rate(http_requests_total{status=~\"5..\"}[5m])) \n        / \n        sum(rate(http_requests_total[5m])) &gt; 0.05\n      for: 5m\n      labels:\n        severity: critical\n        team: platform\n      annotations:\n        summary: \"High API error rate\"\n        description: \"Error rate is above 5% for the last 5 minutes.\"\n\n    - alert: CertificateExpiringSoon\n      expr: certmanager_certificate_expiration_timestamp_seconds - time() &lt; 7 * 24 * 3600\n      for: 1h\n      labels:\n        severity: critical\n        team: platform\n      annotations:\n        summary: \"Certificate expiring soon\"\n        description: \"Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} expires in less than 7 days.\"\n</code></pre>"},{"location":"observability/monitoring-setup/#2-warning-alerts","title":"2. Warning Alerts","text":"<pre><code># warning-alerts.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: hexabase-warnings\n  namespace: monitoring\nspec:\n  groups:\n  - name: warnings\n    interval: 1m\n    rules:\n    - alert: HighMemoryUsage\n      expr: |\n        (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) \n        / node_memory_MemTotal_bytes &gt; 0.85\n      for: 10m\n      labels:\n        severity: warning\n        team: platform\n      annotations:\n        summary: \"High memory usage on node\"\n        description: \"Node {{ $labels.instance }} memory usage is above 85%.\"\n\n    - alert: HighDiskUsage\n      expr: |\n        (node_filesystem_size_bytes - node_filesystem_avail_bytes) \n        / node_filesystem_size_bytes &gt; 0.80\n      for: 10m\n      labels:\n        severity: warning\n        team: platform\n      annotations:\n        summary: \"High disk usage\"\n        description: \"Disk usage on {{ $labels.instance }} is above 80%.\"\n\n    - alert: SlowAPIResponse\n      expr: |\n        histogram_quantile(0.95, \n          sum(rate(http_request_duration_seconds_bucket[5m])) \n          by (le, endpoint)\n        ) &gt; 1\n      for: 10m\n      labels:\n        severity: warning\n        team: platform\n      annotations:\n        summary: \"Slow API response times\"\n        description: \"95th percentile response time for {{ $labels.endpoint }} is above 1 second.\"\n\n    - alert: PodCrashLooping\n      expr: rate(kube_pod_container_status_restarts_total[15m]) &gt; 0\n      for: 5m\n      labels:\n        severity: warning\n        team: platform\n      annotations:\n        summary: \"Pod is crash looping\"\n        description: \"Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping.\"\n</code></pre>"},{"location":"observability/monitoring-setup/#custom-metrics","title":"Custom Metrics","text":""},{"location":"observability/monitoring-setup/#1-application-metrics","title":"1. Application Metrics","text":"<pre><code>// internal/observability/metrics.go\npackage observability\n\nimport (\n    \"github.com/prometheus/client_golang/prometheus\"\n    \"github.com/prometheus/client_golang/prometheus/promauto\"\n)\n\nvar (\n    // API metrics\n    RequestDuration = promauto.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Name: \"hexabase_api_request_duration_seconds\",\n            Help: \"API request duration in seconds\",\n            Buckets: prometheus.DefBuckets,\n        },\n        []string{\"method\", \"endpoint\", \"status\"},\n    )\n\n    ActiveWorkspaces = promauto.NewGauge(\n        prometheus.GaugeOpts{\n            Name: \"hexabase_active_workspaces\",\n            Help: \"Number of active workspaces\",\n        },\n    )\n\n    WorkspaceResources = promauto.NewGaugeVec(\n        prometheus.GaugeOpts{\n            Name: \"hexabase_workspace_resources\",\n            Help: \"Resource usage by workspace\",\n        },\n        []string{\"workspace_id\", \"resource_type\"},\n    )\n\n    // Business metrics\n    WorkspacesCreated = promauto.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"hexabase_workspaces_created_total\",\n            Help: \"Total number of workspaces created\",\n        },\n        []string{\"plan\"},\n    )\n\n    APICallsTotal = promauto.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"hexabase_api_calls_total\",\n            Help: \"Total number of API calls\",\n        },\n        []string{\"workspace_id\", \"endpoint\"},\n    )\n)\n</code></pre>"},{"location":"observability/monitoring-setup/#2-slislo-monitoring","title":"2. SLI/SLO Monitoring","text":"<pre><code># slo-rules.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: hexabase-slo\n  namespace: monitoring\nspec:\n  groups:\n  - name: slo\n    interval: 30s\n    rules:\n    # API Availability SLO: 99.9%\n    - record: slo:api_availability:ratio\n      expr: |\n        sum(rate(http_requests_total{status!~\"5..\"}[5m]))\n        /\n        sum(rate(http_requests_total[5m]))\n\n    - alert: APIAvailabilitySLO\n      expr: slo:api_availability:ratio &lt; 0.999\n      for: 5m\n      labels:\n        severity: critical\n        slo: true\n      annotations:\n        summary: \"API availability SLO breach\"\n        description: \"API availability is {{ $value | humanizePercentage }}, below 99.9% SLO\"\n\n    # Latency SLO: 95% of requests &lt; 500ms\n    - record: slo:api_latency:ratio\n      expr: |\n        histogram_quantile(0.95,\n          sum(rate(http_request_duration_seconds_bucket{le=\"0.5\"}[5m]))\n          by (le)\n        )\n\n    - alert: APILatencySLO\n      expr: slo:api_latency:ratio &lt; 0.95\n      for: 5m\n      labels:\n        severity: warning\n        slo: true\n      annotations:\n        summary: \"API latency SLO breach\"\n        description: \"95th percentile latency SLO breach\"\n</code></pre>"},{"location":"observability/monitoring-setup/#log-analysis-queries","title":"Log Analysis Queries","text":""},{"location":"observability/monitoring-setup/#clickhouse-queries","title":"ClickHouse Queries","text":"<pre><code>-- Top errors by workspace\nSELECT \n    workspace_id,\n    level,\n    COUNT(*) as error_count,\n    groupArray(message)[1:5] as sample_messages\nFROM logs.hexabase\nWHERE level = 'ERROR'\n    AND timestamp &gt; now() - INTERVAL 1 HOUR\nGROUP BY workspace_id, level\nORDER BY error_count DESC\nLIMIT 10;\n\n-- API performance by endpoint\nSELECT \n    path,\n    quantile(0.5)(duration_ms) as p50,\n    quantile(0.95)(duration_ms) as p95,\n    quantile(0.99)(duration_ms) as p99,\n    COUNT(*) as requests\nFROM logs.hexabase\nWHERE timestamp &gt; now() - INTERVAL 1 HOUR\n    AND status_code &lt; 500\nGROUP BY path\nORDER BY requests DESC;\n\n-- User activity timeline\nSELECT \n    toStartOfMinute(timestamp) as minute,\n    COUNT(DISTINCT user_id) as unique_users,\n    COUNT(*) as total_requests\nFROM logs.hexabase\nWHERE timestamp &gt; now() - INTERVAL 1 DAY\nGROUP BY minute\nORDER BY minute;\n</code></pre>"},{"location":"observability/monitoring-setup/#loki-logql-queries","title":"Loki LogQL Queries","text":"<pre><code># Error logs from API pods\n{namespace=\"hexabase-system\", container=\"api\"} |= \"ERROR\"\n\n# Slow requests (&gt;1s)\n{namespace=\"hexabase-system\"} \n  | json \n  | duration_ms &gt; 1000\n  | line_format \"{{.timestamp}} {{.path}} {{.duration_ms}}ms\"\n\n# Authentication failures\n{namespace=\"hexabase-system\"} \n  |= \"authentication failed\"\n  | json\n  | line_format \"{{.timestamp}} user={{.user_email}} ip={{.client_ip}}\"\n\n# Workspace provisioning timeline\n{namespace=\"hexabase-system\"} \n  |~ \"workspace.*provisioning|vcluster.*created\"\n  | json\n  | line_format \"{{.timestamp}} {{.workspace_id}} {{.message}}\"\n</code></pre>"},{"location":"observability/monitoring-setup/#maintenance","title":"Maintenance","text":""},{"location":"observability/monitoring-setup/#1-retention-policies","title":"1. Retention Policies","text":"<pre><code># Configure Prometheus retention\nkubectl patch prometheus kube-prometheus-stack-prometheus \\\n  -n monitoring \\\n  --type merge \\\n  -p '{\"spec\":{\"retention\":\"30d\",\"retentionSize\":\"100GB\"}}'\n\n# Configure Loki retention\nkubectl patch configmap loki \\\n  -n monitoring \\\n  --type merge \\\n  -p '{\"data\":{\"loki.yaml\":\"table_manager:\\n  retention_period: 168h\"}}'\n</code></pre>"},{"location":"observability/monitoring-setup/#2-backup-monitoring-data","title":"2. Backup Monitoring Data","text":"<pre><code># Backup Prometheus data\nkubectl exec -n monitoring prometheus-kube-prometheus-prometheus-0 -- \\\n  tar czf /tmp/prometheus-backup.tar.gz /prometheus\n\nkubectl cp monitoring/prometheus-kube-prometheus-prometheus-0:/tmp/prometheus-backup.tar.gz \\\n  ./prometheus-backup-$(date +%Y%m%d).tar.gz\n\n# Backup Grafana dashboards\nkubectl exec -n monitoring deployment/kube-prometheus-stack-grafana -- \\\n  grafana-cli admin export-dashboard --dir=/tmp/dashboards\n\nkubectl cp monitoring/deployment/kube-prometheus-stack-grafana:/tmp/dashboards \\\n  ./grafana-dashboards-$(date +%Y%m%d)\n</code></pre>"},{"location":"observability/monitoring-setup/#3-performance-tuning","title":"3. Performance Tuning","text":"<pre><code># Optimize Prometheus performance\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-optimization\n  namespace: monitoring\ndata:\n  prometheus.yaml: |\n    global:\n      scrape_interval: 30s      # Reduce frequency\n      evaluation_interval: 30s\n      external_labels:\n        cluster: 'production'\n        region: 'us-east-1'\n\n    # Optimize TSDB\n    storage:\n      tsdb:\n        out_of_order_time_window: 30m\n        min_block_duration: 2h\n        max_block_duration: 48h\n        retention.size: 100GB\n</code></pre>"},{"location":"observability/monitoring-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"observability/monitoring-setup/#common-issues","title":"Common Issues","text":"<p>High Prometheus memory usage <pre><code># Check memory usage\nkubectl top pod -n monitoring -l app.kubernetes.io/name=prometheus\n\n# Reduce metric cardinality\nkubectl exec -n monitoring prometheus-kube-prometheus-prometheus-0 -- \\\n  promtool tsdb analyze /prometheus\n\n# Identify high cardinality metrics\ncurl -s http://localhost:9090/api/v1/label/__name__/values | \\\n  jq -r '.data[]' | \\\n  xargs -I {} curl -s \"http://localhost:9090/api/v1/query?query=count(count+by(__name__)({__name__=\\\"{}\\\"}))\" | \\\n  jq -r '.data.result[0].value[1] // 0' | \\\n  sort -nr | head -20\n</code></pre></p> <p>Grafana not loading dashboards <pre><code># Check datasources\nkubectl exec -n monitoring deployment/kube-prometheus-stack-grafana -- \\\n  grafana-cli admin data-sources list\n\n# Restart Grafana\nkubectl rollout restart deployment/kube-prometheus-stack-grafana -n monitoring\n</code></pre></p> <p>Missing logs in Loki <pre><code># Check Promtail status\nkubectl logs -n monitoring daemonset/loki-promtail --tail=100\n\n# Verify log parsing\nkubectl exec -n monitoring daemonset/loki-promtail -- \\\n  promtail --dry-run --config.file=/etc/promtail/config.yml\n</code></pre></p>"},{"location":"observability/monitoring-setup/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Enable authentication for all monitoring endpoints</li> <li>Use TLS for all monitoring traffic</li> <li>Implement RBAC for Grafana users</li> <li>Rotate credentials regularly</li> <li>Audit access to monitoring systems</li> <li>Encrypt backups of monitoring data</li> <li>Restrict network access to monitoring endpoints</li> </ol>"},{"location":"observability/monitoring-setup/#resources","title":"Resources","text":"<ul> <li>Prometheus Documentation</li> <li>Grafana Documentation</li> <li>Loki Documentation</li> <li>OpenTelemetry Documentation</li> <li>ClickHouse Documentation</li> </ul>"},{"location":"observability/tracing/","title":"Distributed Tracing","text":"<p>In a microservices architecture, a single user request can travel through dozens of different services before a response is returned. Distributed tracing is the key to understanding this complex journey. It allows you to visualize the entire request path, identify performance bottlenecks, and debug issues that span multiple services.</p>"},{"location":"observability/tracing/#how-distributed-tracing-works-in-hks","title":"How Distributed Tracing Works in HKS","text":"<p>Hexabase.AI has a built-in, OpenTelemetry-compatible distributed tracing platform.</p> <ol> <li>Instrumentation: Your application code is \"instrumented\" with a tracing library. This library automatically creates spans for incoming and outgoing requests. A span is a single unit of work (e.g., an API call, a database query) and contains a start time, end time, and metadata (tags).</li> <li>Context Propagation: When a service makes a call to another service, the tracing library injects a <code>trace_id</code> into the request headers. The downstream service extracts this <code>trace_id</code>, allowing all subsequent spans to be linked together into a single trace.</li> <li>Trace Collection: The instrumented libraries send these spans to the OpenTelemetry Collector, which is managed by HKS.</li> <li>Storage and Visualization: The Collector forwards the traces to a backend storage and visualization tool (like Jaeger or Zipkin), which is integrated into the HKS UI.</li> </ol> <pre><code>graph TD\n    User --&gt;|Request| A[Service A: Frontend];\n\n    subgraph Trace: abc-123\n        A -- R1 --- B[Service B: Auth];\n        A -- R2 --- C[Service C: Products];\n        C -- R3 --- D[Database: product-db];\n    end\n\n    style A fill:#00C6AB\n    style B fill:#FF346B\n    style C fill:#FF346B\n    style D fill:#2196F3</code></pre> <p>A single trace showing a request flow from the Frontend to the Auth and Products services.</p>"},{"location":"observability/tracing/#automatic-instrumentation","title":"Automatic Instrumentation","text":"<p>For many common languages and frameworks, Hexabase.AI can automatically instrument your applications without requiring any code changes. This is the easiest way to get started with distributed tracing.</p> <p>Auto-instrumentation is enabled by adding an annotation to your Deployment.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-python-app\n  annotations:\n    # Enable automatic tracing for this deployment\n    instrumentation.hks.io/inject-python: \"true\"\nspec:\n  # ...\n</code></pre> <p>When this annotation is present, the HKS control plane uses a mutating webhook to inject the OpenTelemetry instrumentation library and its configuration into your application's pod at runtime.</p> <p>Supported Languages for Auto-Instrumentation:</p> <ul> <li>Java</li> <li>Python</li> <li>Node.js</li> <li>.NET</li> <li>Go (limited support)</li> </ul>"},{"location":"observability/tracing/#manual-instrumentation","title":"Manual Instrumentation","text":"<p>For unsupported languages or for more control over your traces, you can manually instrument your code using the standard OpenTelemetry SDKs.</p> <p>Example: Manual Instrumentation in Python</p> <pre><code># app.py\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n\n# For production, you would use the OTLPExporter to send to the HKS collector\n# provider = TracerProvider()\n# processor = BatchSpanProcessor(ConsoleSpanExporter())\n# provider.add_span_processor(processor)\n# trace.set_tracer_provider(provider)\n\ntracer = trace.get_tracer(__name__)\n\ndef handle_request():\n    # This creates a parent span for the request\n    with tracer.start_as_current_span(\"handle_request\") as parent_span:\n        # This creates a child span for a specific unit of work\n        with tracer.start_as_current_span(\"process_data\") as child_span:\n            # Add attributes (tags) to the span\n            child_span.set_attribute(\"data.size\", 1024)\n            # ... do some work ...\n            child_span.set_status(trace.Status(trace.StatusCode.OK))\n\n        parent_span.add_event(\"Finished processing\")\n</code></pre> <p>You will also need to configure the OpenTelemetry exporter to point to the HKS OpenTelemetry Collector endpoint, which is available as an environment variable (<code>OTEL_EXPORTER_OTLP_ENDPOINT</code>) in your pods.</p>"},{"location":"observability/tracing/#visualizing-traces","title":"Visualizing Traces","text":"<p>The Hexabase.AI UI provides a powerful interface for exploring your distributed traces.</p> <ul> <li>Search for Traces: Find traces based on service name, endpoint, duration, or tags.</li> <li>Trace Gantt Chart: View a timeline of the entire request, showing the duration and relationship between all the spans. This makes it easy to spot bottlenecks.</li> <li>Span Details: Click on any span to see its detailed metadata, including HTTP status codes, database queries, error messages, and any custom tags you added.</li> <li>Service Map: See a high-level dependency graph of your services, showing request rates and error rates between them.</li> </ul>"},{"location":"observability/tracing/#best-practices-for-tracing","title":"Best Practices for Tracing","text":"<ol> <li>Use Auto-Instrumentation First: It's the easiest way to get comprehensive tracing with minimal effort.</li> <li>Add Custom Attributes: Enrich your spans with application-specific context. Add attributes for user IDs, tenant IDs, business transaction names, etc. This makes it much easier to find relevant traces when debugging.</li> <li>Trace Everything in Production: Distributed tracing has a low performance overhead and provides invaluable insights. It is recommended to leave it enabled for all services in your production environment.</li> <li>Integrate with Logs: Your tracing library can automatically inject the <code>trace_id</code> into your application's logs. When HKS ingests these logs, it correlates them with the traces, allowing you to jump directly from a specific span to the logs for that exact request.</li> <li>Sample Strategically: For very high-throughput services, you might not need to capture a trace for every single request. Configure sampling to capture a certain percentage of requests (e.g., 10%) or to only capture traces that are slow or have errors.</li> </ol>"},{"location":"rbac/","title":"Kubernetes RBAC","text":"<p>Learn how Hexabase.AI implements and manages Role-Based Access Control (RBAC) for secure multi-tenant Kubernetes operations.</p>"},{"location":"rbac/#overview","title":"Overview","text":"<p>Hexabase.AI provides a sophisticated RBAC system that extends Kubernetes native RBAC with additional features for multi-tenancy, simplified management, and enhanced security. Our RBAC implementation ensures that users have exactly the permissions they need\u2014no more, no less.</p>"},{"location":"rbac/#rbac-components","title":"RBAC Components","text":"<ul> <li> Roles and Permissions</li> </ul> <p>Understand predefined roles and custom permission models</p> <p> Explore Roles</p> <ul> <li> User Management</li> </ul> <p>Managing users, groups, and service accounts</p> <p> User Management Guide</p> <ul> <li> Policy Configuration</li> </ul> <p>Configure and customize access policies</p> <p> Policy Configuration</p> <ul> <li> Best Practices</li> </ul> <p>Security best practices and common patterns</p> <p> RBAC Best Practices</p>"},{"location":"rbac/#rbac-model","title":"RBAC Model","text":"<p>Hexabase.AI implements a hierarchical RBAC model that provides fine-grained access control:</p> <pre><code>Organization\n\u251c\u2500\u2500 Organization Roles (Admin, Viewer)\n\u2514\u2500\u2500 Workspace\n    \u251c\u2500\u2500 Workspace Roles (Owner, Developer, Viewer)\n    \u2514\u2500\u2500 Project\n        \u2514\u2500\u2500 Kubernetes RBAC (Native Roles)\n</code></pre>"},{"location":"rbac/#key-features","title":"Key Features","text":""},{"location":"rbac/#1-multi-level-permissions","title":"1. Multi-level Permissions","text":"<ul> <li>Organization Level: Control who can create workspaces and manage billing</li> <li>Workspace Level: Manage project deployment and resource quotas</li> <li>Project Level: Fine-grained Kubernetes permissions</li> </ul>"},{"location":"rbac/#2-predefined-roles","title":"2. Predefined Roles","text":"<ul> <li>Organization Admin: Full control over organization</li> <li>Workspace Owner: Manage workspace and deploy projects</li> <li>Developer: Deploy and manage applications</li> <li>Viewer: Read-only access to resources</li> </ul>"},{"location":"rbac/#3-custom-roles","title":"3. Custom Roles","text":"<ul> <li>Create custom roles with specific permissions</li> <li>Combine multiple permissions for complex scenarios</li> <li>Template-based role creation</li> </ul>"},{"location":"rbac/#4-dynamic-permission-inheritance","title":"4. Dynamic Permission Inheritance","text":"<ul> <li>Permissions cascade from organization to workspace</li> <li>Override inherited permissions at lower levels</li> <li>Automatic permission propagation</li> </ul>"},{"location":"rbac/#common-rbac-scenarios","title":"Common RBAC Scenarios","text":""},{"location":"rbac/#scenario-1-development-team-setup","title":"Scenario 1: Development Team Setup","text":"<pre><code>Team Structure:\n  - Team Lead: Workspace Owner\n  - Developers: Developer role with deployment permissions\n  - QA Engineers: Viewer role with log access\n  - CI/CD Service: Service account with deployment permissions\n</code></pre>"},{"location":"rbac/#scenario-2-multi-environment-access","title":"Scenario 2: Multi-Environment Access","text":"<pre><code>Environment Setup:\n  - Production: Limited to senior developers and SREs\n  - Staging: Open to all developers\n  - Development: Self-service for all team members\n</code></pre>"},{"location":"rbac/#scenario-3-client-access","title":"Scenario 3: Client Access","text":"<pre><code>External Access:\n  - Client stakeholders: Viewer role for specific workspaces\n  - Contractors: Time-limited developer access\n  - Auditors: Read-only access with audit log visibility\n</code></pre>"},{"location":"rbac/#security-considerations","title":"Security Considerations","text":""},{"location":"rbac/#principle-of-least-privilege","title":"Principle of Least Privilege","text":"<ul> <li>Users get minimal permissions required</li> <li>Regular permission audits</li> <li>Automated permission cleanup</li> </ul>"},{"location":"rbac/#separation-of-duties","title":"Separation of Duties","text":"<ul> <li>Different roles for deployment and approval</li> <li>Separate production access controls</li> <li>Audit trail for all permission changes</li> </ul>"},{"location":"rbac/#defense-in-depth","title":"Defense in Depth","text":"<ul> <li>Multiple layers of access control</li> <li>Network policies complement RBAC</li> <li>Resource quotas prevent abuse</li> </ul>"},{"location":"rbac/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"rbac/#granting-developer-access","title":"Granting Developer Access","text":"<pre><code>hb rbac grant-role developer user@example.com --workspace my-workspace\n</code></pre>"},{"location":"rbac/#creating-custom-role","title":"Creating Custom Role","text":"<pre><code>hb rbac create-role custom-deployer \\\n  --permissions deploy,view-logs,manage-secrets \\\n  --workspace my-workspace\n</code></pre>"},{"location":"rbac/#viewing-user-permissions","title":"Viewing User Permissions","text":"<pre><code>hb rbac list-permissions user@example.com\n</code></pre>"},{"location":"rbac/#integration-with-kubernetes","title":"Integration with Kubernetes","text":"<p>Hexabase.AI RBAC seamlessly integrates with native Kubernetes RBAC:</p> <ol> <li>Automatic Translation: Platform roles map to Kubernetes roles</li> <li>Service Account Management: Automated service account creation</li> <li>Namespace Isolation: RBAC policies enforce namespace boundaries</li> <li>Audit Compliance: All actions logged for compliance</li> </ol>"},{"location":"rbac/#next-steps","title":"Next Steps","text":"<ul> <li>New to RBAC? Start with Roles and Permissions</li> <li>Setting up users? Follow the User Management Guide</li> <li>Need custom policies? Learn about Policy Configuration</li> <li>Security focus? Review RBAC Best Practices</li> </ul>"},{"location":"rbac/#related-documentation","title":"Related Documentation","text":"<ul> <li>Security Architecture</li> <li>Core Concepts</li> <li>API Authentication</li> <li>Audit Logging</li> </ul>"},{"location":"rbac/best-practices/","title":"RBAC Best Practices","text":"<p>Properly configuring Role-Based Access Control (RBAC) is one of the most important aspects of securing your Hexabase.AI environment. Following these best practices will help you maintain a secure and manageable system.</p>"},{"location":"rbac/best-practices/#1-adhere-to-the-principle-of-least-privilege-polp","title":"1. Adhere to the Principle of Least Privilege (PoLP)","text":"<p>This is the most fundamental principle of access control.</p> <ul> <li>Grant only what is needed: Users and service accounts should only have the permissions absolutely necessary to perform their jobs.</li> <li>Avoid wildcard permissions: Do not use <code>*</code> for resources or verbs in custom roles unless it is truly required. Be explicit.</li> <li>Start with <code>viewer</code>: When a new user joins a project, grant them the <code>viewer</code> role first. Elevate their permissions to <code>developer</code> only when they need to start making changes.</li> <li>Use <code>workspace_admin</code> sparingly: The <code>workspace_admin</code> role is highly privileged. Reserve it for team leads or platform administrators responsible for managing the workspace itself, not for daily development tasks.</li> </ul>"},{"location":"rbac/best-practices/#2-separate-user-and-service-account-management","title":"2. Separate User and Service Account Management","text":"<ul> <li>No shared accounts: Every human user should have their own named account. Do not use shared accounts (e.g., a single <code>developer</code> account for the whole team). This ensures accountability through audit logs.</li> <li>Dedicated service accounts for applications: Each application or CI/CD job should have its own dedicated <code>ServiceAccount</code>. This isolates permissions, so if one service account is compromised, the blast radius is limited. For example, the <code>ci-builder</code> service account should not have the same permissions as the <code>production-app</code> service account.</li> </ul>"},{"location":"rbac/best-practices/#3-leverage-the-two-tiered-rbac-system","title":"3. Leverage the Two-Tiered RBAC System","text":"<ul> <li>Use Organization roles for platform administration: Manage users, workspaces, and billing at the organization level with <code>organization_admin</code>.</li> <li>Use Workspace roles for application development: Manage Kubernetes resources and application lifecycles at the workspace level with <code>workspace_admin</code>, <code>developer</code>, and <code>viewer</code>.</li> <li>Do not give everyone <code>organization_admin</code>: This role is equivalent to being a super-user for your entire HKS environment. Its use should be restricted to a very small number of trusted platform administrators.</li> </ul>"},{"location":"rbac/best-practices/#4-regularly-audit-rbac-policies-and-bindings","title":"4. Regularly Audit RBAC Policies and Bindings","text":"<ul> <li>Schedule periodic reviews: At least quarterly, an <code>organization_admin</code> or <code>workspace_admin</code> should review all role bindings.</li> <li>Look for stale access: Remove users who are no longer on the project.</li> <li>Identify overly permissive roles: Check if any users have more permissions than they need. Could a <code>workspace_admin</code> be a <code>developer</code> instead?</li> <li>Automate auditing: Use the <code>hks</code> CLI to script parts of your audit.</li> </ul> <pre><code># List all users in a workspace and their roles\nhb list-users --workspace my-prod-space\n\n# Check the permissions of a specific custom role\nhb get workspacerole custom-role -o yaml\n</code></pre>"},{"location":"rbac/best-practices/#5-use-custom-roles-for-fine-grained-control","title":"5. Use Custom Roles for Fine-Grained Control","text":"<ul> <li>Don't stretch default roles: If the built-in <code>developer</code> role is too permissive for a specific task, don't just grant it anyway. Create a custom role instead.</li> <li>Example: Create a <code>ci-runner</code> role that can only create <code>Pods</code> and <code>Jobs</code> but cannot create <code>Deployments</code> or <code>Services</code>.</li> <li>Example: Create a <code>support-staff</code> role that can view all resources and <code>exec</code> into pods for debugging, but cannot view <code>Secrets</code>.</li> </ul>"},{"location":"rbac/best-practices/#6-secure-the-underlying-kubernetes-rbac","title":"6. Secure the Underlying Kubernetes RBAC","text":"<ul> <li>Avoid manual <code>kubectl</code> changes: Do not manually create <code>Roles</code> or <code>RoleBindings</code> using <code>kubectl</code>. Let Hexabase.AI manage the Kubernetes RBAC resources. Manually creating bindings can lead to confusion and a \"split-brain\" scenario where the HKS UI and the Kubernetes state are out of sync.</li> <li>Restrict direct <code>kubectl</code> access: For most users, all interactions should be through the HKS platform (UI, CLI, API). Limit direct <code>kubectl</code> access to platform administrators or for break-glass emergency scenarios. This ensures all actions go through the HKS audit log.</li> </ul>"},{"location":"rbac/hexabase-rbac/","title":"Hexabase RBAC","text":"<p>This section covers Role-Based Access Control (RBAC) implementation within the Hexabase.AI platform itself.</p>"},{"location":"rbac/hexabase-rbac/#overview","title":"Overview","text":"<p>Hexabase.AI implements a comprehensive RBAC system to manage access control across the multi-tenant platform. This system defines how users interact with the platform at different organizational levels.</p>"},{"location":"rbac/hexabase-rbac/#role-hierarchy","title":"Role Hierarchy","text":""},{"location":"rbac/hexabase-rbac/#organization-level-roles","title":"Organization Level Roles","text":"<ul> <li>Organization Admin: Full control over the organization</li> <li>Organization Viewer: Read-only access to organization resources</li> </ul>"},{"location":"rbac/hexabase-rbac/#workspace-level-roles","title":"Workspace Level Roles","text":"<ul> <li>Workspace Admin: Full control over workspace resources</li> <li>Workspace Developer: Can create and manage applications</li> <li>Workspace Viewer: Read-only access to workspace resources</li> </ul>"},{"location":"rbac/hexabase-rbac/#project-level-roles","title":"Project Level Roles","text":"<ul> <li>Project Owner: Full control over project resources</li> <li>Project Collaborator: Can modify project resources</li> <li>Project Viewer: Read-only access to project resources</li> </ul>"},{"location":"rbac/hexabase-rbac/#permission-model","title":"Permission Model","text":"<p>The Hexabase RBAC system follows these principles:</p> <ol> <li>Hierarchical Inheritance: Permissions cascade from organization to workspace to project</li> <li>Least Privilege: Users get minimal permissions required for their role</li> <li>Separation of Concerns: Clear boundaries between different organizational levels</li> </ol>"},{"location":"rbac/hexabase-rbac/#integration-with-kubernetes","title":"Integration with Kubernetes","text":"<p>This page focuses on Hexabase platform RBAC. For information on how Hexabase RBAC maps to Kubernetes RBAC, see Kubernetes RBAC.</p>"},{"location":"rbac/kubernetes-rbac/","title":"Kubernetes RBAC","text":"<p>This section explains how Hexabase.AI integrates with and manages Kubernetes Role-Based Access Control.</p>"},{"location":"rbac/kubernetes-rbac/#overview","title":"Overview","text":"<p>Hexabase.AI provides a seamless mapping between platform roles and Kubernetes RBAC, allowing users to manage Kubernetes resources through the HKS interface without directly dealing with Kubernetes complexity.</p>"},{"location":"rbac/kubernetes-rbac/#role-mappings","title":"Role Mappings","text":""},{"location":"rbac/kubernetes-rbac/#hexabase-to-kubernetes-role-translation","title":"Hexabase to Kubernetes Role Translation","text":"Hexabase Role Kubernetes ClusterRole Permissions Workspace Admin cluster-admin (namespaced) Full control within assigned namespaces Workspace Developer edit Create, update, delete apps and services Workspace Viewer view Read-only access to resources"},{"location":"rbac/kubernetes-rbac/#namespace-isolation","title":"Namespace Isolation","text":"<p>Each Hexabase workspace maps to one or more Kubernetes namespaces:</p> <ul> <li>Workspace Namespace: Primary namespace for applications</li> <li>System Namespace: For platform-managed resources</li> <li>Monitoring Namespace: For observability tools</li> </ul>"},{"location":"rbac/kubernetes-rbac/#service-account-management","title":"Service Account Management","text":"<p>Hexabase automatically creates and manages Kubernetes service accounts:</p> <ol> <li>User Service Accounts: For human users accessing the cluster</li> <li>Application Service Accounts: For workloads and CI/CD pipelines</li> <li>System Service Accounts: For platform components</li> </ol>"},{"location":"rbac/kubernetes-rbac/#best-practices","title":"Best Practices","text":"<ol> <li>Use Hexabase Roles: Let the platform manage Kubernetes RBAC complexity</li> <li>Audit Regularly: Review role assignments through the HKS dashboard</li> <li>Follow Least Privilege: Assign minimal required permissions</li> <li>Leverage Workspaces: Use workspace isolation for security boundaries</li> </ol>"},{"location":"rbac/kubernetes-rbac/#advanced-configuration","title":"Advanced Configuration","text":"<p>For custom RBAC requirements, Hexabase supports:</p> <ul> <li>Custom role definitions</li> <li>Fine-grained permission policies</li> <li>Integration with external identity providers</li> <li>Compliance-driven access controls</li> </ul>"},{"location":"rbac/overview/","title":"RBAC Overview","text":"<p>Role-Based Access Control (RBAC) is the mechanism that restricts what users and services are allowed to do within Hexabase.AI. It is a critical component for security and governance in a multi-tenant environment, ensuring users only have access to the resources necessary to perform their roles.</p>"},{"location":"rbac/overview/#core-concepts","title":"Core Concepts","text":"<ul> <li>Principal: An entity that can be authenticated. In HKS, this is either a User or a Service Account.</li> <li>Role: A collection of Permissions. A Role defines a set of actions that can be performed on a set of resources.</li> <li>Permission: An individual rule that allows a specific action (verb) on a specific resource (e.g., <code>create</code> a <code>Deployment</code>, <code>get</code> a <code>Pod's logs</code>).</li> <li>Role Binding: The link that assigns a Role to a Principal. This is what grants the permissions to the user or service.</li> </ul> <p>The basic relationship is: A Principal is assigned a Role via a Role Binding.</p> <pre><code>graph TD\n    User[User] --&gt;|Bound by| RoleBinding(Role Binding);\n    ServiceAccount[Service Account] --&gt;|Bound by| RoleBinding;\n    RoleBinding --&gt;|Assigns| Role(Role);\n    Role --&gt;|Contains| Permission1(Permission: get pods);\n    Role --&gt;|Contains| Permission2(Permission: create deployments);\n    Role --&gt;|Contains| Permission3(Permission: ...);</code></pre>"},{"location":"rbac/overview/#two-levels-of-rbac","title":"Two Levels of RBAC","text":"<p>Hexabase.AI features a two-tiered RBAC system to provide a clear separation of concerns between managing the platform and managing applications within it.</p>"},{"location":"rbac/overview/#1-organization-rbac","title":"1. Organization RBAC","text":"<ul> <li>Scope: Controls access to organization-wide resources and settings.</li> <li>Purpose: Manages billing, user invitations, workspace creation, and global settings like SSO.</li> <li>Key Roles:</li> <li><code>organization_admin</code>: Full control over the organization. Can manage billing, users, and workspaces.</li> <li><code>organization_user</code>: A standard member of the organization. Can be assigned roles within workspaces but cannot manage the organization itself.</li> </ul>"},{"location":"rbac/overview/#2-workspace-rbac","title":"2. Workspace RBAC","text":"<ul> <li>Scope: Controls access to resources within a specific workspace (which corresponds to a Kubernetes namespace).</li> <li>Purpose: Manages application deployments, services, storage, CI/CD pipelines, and other Kubernetes-native resources.</li> <li>Key Roles (Default):</li> <li><code>workspace_admin</code>: Full control over all resources within the workspace. Can manage user access to the workspace.</li> <li><code>developer</code>: Can create, update, and delete application workloads (Deployments, Pods, Services). Cannot manage user access.</li> <li><code>viewer</code>: Read-only access. Can view resources and logs but cannot make any changes.</li> </ul> <p>This dual system allows a central IT or platform team to manage the overall organization while empowering development teams to manage their own applications within the guardrails of their assigned workspaces.</p>"},{"location":"rbac/overview/#relationship-to-kubernetes-rbac","title":"Relationship to Kubernetes RBAC","text":"<p>It's important to understand how HKS RBAC relates to the native Kubernetes RBAC system.</p> <ul> <li>HKS RBAC is an abstraction layer on top of Kubernetes RBAC.</li> <li>When you create a <code>Role</code> and <code>RoleBinding</code> in Hexabase.AI for a workspace, the platform automatically creates corresponding <code>Role</code> and <code>RoleBinding</code> (or <code>ClusterRole</code> and <code>ClusterRoleBinding</code>) objects in the underlying Kubernetes cluster.</li> <li>This ensures that permissions are enforced consistently, whether you are interacting with the platform through the HKS UI/CLI or directly with the Kubernetes API server via <code>kubectl</code>.</li> </ul> <p>This abstraction simplifies permission management in a multi-tenant environment. You manage users and roles at the HKS level, and HKS handles the complexity of creating the correct bindings in the correct Kubernetes namespaces.</p> <p>See Hexabase RBAC and Kubernetes RBAC for a deeper dive into each system.</p>"},{"location":"rbac/permission-model/","title":"Permission Model","text":"<p>The Hexabase.AI permission model is designed to be flexible and extensible, providing fine-grained control over every action within the platform. While most users will interact with the built-in roles, understanding the underlying permission model is useful for creating custom roles or for auditing purposes.</p>"},{"location":"rbac/permission-model/#the-structure-of-a-permission","title":"The Structure of a Permission","text":"<p>A permission is a single rule that defines who can do what to which resources. Each permission consists of three components:</p> <ol> <li><code>apiGroups</code>: The group of the API being accessed. For core Kubernetes resources, the group is <code>\"\"</code> (an empty string). For others, it's a named group like <code>apps</code>, <code>batch</code>, or <code>hks.io</code>.</li> <li><code>resources</code>: The type of object the permission applies to (e.g., <code>pods</code>, <code>deployments</code>, <code>backupplans</code>).</li> <li><code>verbs</code>: The action that is allowed on the resource (e.g., <code>get</code>, <code>create</code>, <code>delete</code>).</li> </ol> <p>Example Permission Statement: \"Allow <code>creating</code> (<code>verb</code>) <code>deployments</code> (<code>resource</code>) in the <code>apps</code> (<code>apiGroup</code>).\"</p>"},{"location":"rbac/permission-model/#how-permissions-are-defined-in-a-role","title":"How Permissions Are Defined in a Role","text":"<p>In a custom <code>WorkspaceRole</code>, permissions are defined in a list.</p> <pre><code>apiVersion: hks.io/v1\nkind: WorkspaceRole\nmetadata:\n  name: custom-viewer\nspec:\n  permissions:\n    # Rule 1: Allow viewing of core workload resources\n    - apiGroups: [\"\", \"apps\", \"batch\"]\n      resources: [\"pods\", \"deployments\", \"jobs\", \"services\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n    # Rule 2: Allow viewing of pod logs\n    - apiGroups: [\"\"]\n      resources: [\"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n\n    # Rule 3: Allow viewing of HKS-specific resources\n    - apiGroups: [\"hks.io\"]\n      resources: [\"backups\", \"functions\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"rbac/permission-model/#common-verbs","title":"Common Verbs","text":"<p>These are the most common actions (verbs) you can assign in a permission.</p> Verb Description <code>get</code> Retrieve a single resource by name. <code>list</code> Retrieve a list of resources. <code>watch</code> \"Watch\" for changes to resources in real-time. <code>create</code> Create a new resource. <code>update</code> Modify an existing resource. <code>patch</code> Apply a partial modification to an existing resource. <code>delete</code> Delete a resource. <code>deletecollection</code> Delete multiple resources at once. <code>*</code> A wildcard that represents all verbs. Use with caution."},{"location":"rbac/permission-model/#resource-naming-and-sub-resources","title":"Resource Naming and Sub-resources","text":"<p>Some resources have sub-resources that can be controlled independently. The most common example is <code>pods/log</code>.</p> <ul> <li>To grant permission to view a pod, you need <code>get</code> on the <code>pods</code> resource.</li> <li>To grant permission to view a pod's logs, you need <code>get</code> on the <code>pods/log</code> sub-resource.</li> </ul> <p>This allows you to create roles for users who can see that a pod is running but cannot access the potentially sensitive information within its logs.</p>"},{"location":"rbac/permission-model/#aggregated-roles","title":"Aggregated Roles","text":"<p>Hexabase.AI makes use of Kubernetes's role aggregation feature. This means that some roles are composed of other roles.</p> <p>For example, the built-in <code>developer</code> role in HKS actually aggregates several smaller, more focused roles:</p> <ul> <li>A role for managing core workloads (<code>pods</code>, <code>deployments</code>).</li> <li>A role for managing networking (<code>services</code>, <code>ingresses</code>).</li> <li>A role for managing CI/CD resources within the workspace.</li> </ul> <p>This makes the system easier to manage and extend. When a new feature is added to HKS, a new granular role for that feature can be created and aggregated into the base roles (<code>admin</code>, <code>developer</code>, <code>viewer</code>) without modifying the base roles directly.</p>"},{"location":"rbac/permission-model/#viewing-raw-kubernetes-roles","title":"Viewing Raw Kubernetes Roles","text":"<p>If you have <code>workspace_admin</code> permissions, you can view the raw Kubernetes <code>Role</code> that HKS generates from its own <code>WorkspaceRole</code>.</p> <pre><code># First, find the name of the generated role\n# It will typically be prefixed with 'hks-'\nkubectl get roles -n &lt;your-workspace-namespace&gt;\n\n# Then, view the YAML definition of the role\nkubectl get role &lt;generated-role-name&gt; -o yaml\n</code></pre> <p>This can be a useful debugging tool for understanding the exact permissions being applied at the Kubernetes level.</p>"},{"location":"rbac/role-mappings/","title":"Role Mappings","text":"<p>Understanding how Hexabase.AI's built-in roles map to specific permissions is key to effective access management. This document details the permissions associated with the default roles at both the Organization and Workspace levels.</p>"},{"location":"rbac/role-mappings/#organization-level-roles","title":"Organization-Level Roles","text":"<p>These roles control access to the platform's administrative and management features.</p> Role Description Key Permissions <code>organization_admin</code> The highest level of access. Manages the entire organization. - Invite and manage users- Create, update, and delete workspaces- Configure Single Sign-On (SSO)- Manage billing and subscriptions- View organization-wide audit logs- Assign any role to any user <code>organization_user</code> The default role for a standard member of the organization. - View workspaces they have been invited to- Cannot manage users, billing, or workspaces- Can be assigned roles within specific workspaces"},{"location":"rbac/role-mappings/#workspace-level-roles","title":"Workspace-Level Roles","text":"<p>These roles control access to the Kubernetes resources inside a specific workspace. HKS provides three default roles, which cover most common use cases.</p>"},{"location":"rbac/role-mappings/#workspace_admin","title":"<code>workspace_admin</code>","text":"<ul> <li>Description: Full control over a specific workspace. This role is typically assigned to team leads or DevOps engineers responsible for an environment.</li> <li>Key HKS Permissions:</li> <li>Manage user access to the workspace (assign <code>developer</code> or <code>viewer</code> roles).</li> <li>Configure workspace settings, such as resource quotas and network policies.</li> <li>View all resources and settings within the workspace.</li> <li>Mapped Kubernetes Permissions:</li> <li><code>*</code> (All verbs) on <code>*</code> (All resources) within the workspace's namespace. This is equivalent to the built-in <code>admin</code> ClusterRole in Kubernetes, but scoped to the namespace.</li> </ul>"},{"location":"rbac/role-mappings/#developer","title":"<code>developer</code>","text":"<ul> <li>Description: Standard permissions for an application developer. Allows for the full lifecycle management of applications without granting access to sensitive security or user management settings.</li> <li>Key HKS Permissions:</li> <li>Create, update, and delete application workloads.</li> <li>View logs and exec into pods.</li> <li>Manage application configurations (ConfigMaps, Secrets).</li> <li>Mapped Kubernetes Permissions (Abbreviated):</li> <li><code>get</code>, <code>list</code>, <code>watch</code>, <code>create</code>, <code>update</code>, <code>patch</code>, <code>delete</code> on:<ul> <li><code>pods</code>, <code>deployments</code>, <code>statefulsets</code>, <code>daemonsets</code></li> <li><code>services</code>, <code>ingresses</code></li> <li><code>jobs</code>, <code>cronjobs</code></li> <li><code>configmaps</code>, <code>secrets</code></li> <li><code>persistentvolumeclaims</code></li> </ul> </li> <li><code>get</code>, <code>list</code>, <code>watch</code> on <code>pods/log</code>.</li> </ul>"},{"location":"rbac/role-mappings/#viewer","title":"<code>viewer</code>","text":"<ul> <li>Description: Read-only access to a workspace. Ideal for stakeholders, support staff, or junior developers who need to observe but not modify applications.</li> <li>Key HKS Permissions:</li> <li>View all resources and their configurations.</li> <li>View logs.</li> <li>Mapped Kubernetes Permissions:</li> <li><code>get</code>, <code>list</code>, <code>watch</code> on all resources within the workspace's namespace. This is equivalent to the built-in <code>view</code> ClusterRole in Kubernetes.</li> </ul>"},{"location":"rbac/role-mappings/#creating-custom-roles-enterprise-plan","title":"Creating Custom Roles (Enterprise Plan)","text":"<p>For organizations that need more granular control, the Enterprise Plan allows for the creation of custom workspace roles.</p> <p>Example: Creating a <code>db_operator</code> Role</p> <p>Imagine you want a role that can only manage StatefulSets (for databases) and their associated Secrets and PVCs.</p> <pre><code># custom-role-db-operator.yaml\napiVersion: hks.io/v1\nkind: WorkspaceRole\nmetadata:\n  name: db-operator\nspec:\n  # The permissions this role grants\n  permissions:\n    # Allow full control over StatefulSets\n    - resources: [\"statefulsets\"]\n      verbs: [\"*\"]\n    # Allow full control over secrets and PVCs\n    - resources: [\"secrets\", \"persistentvolumeclaims\"]\n      verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n    # Allow viewing of pods for debugging\n    - resources: [\"pods\", \"pods/log\"]\n      verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>After applying this manifest, you can assign the <code>db_operator</code> role to users in any workspace, just like the built-in roles. HKS will automatically generate the corresponding Kubernetes <code>Role</code> and <code>RoleBinding</code> in the background.</p>"},{"location":"registry/","title":"Container Registry Service","text":"<p>Hexabase.AI provides a comprehensive Container Registry Service that enables secure storage, management, and distribution of container images within your organization. Built on Harbor as the default registry platform, our service ensures enterprise-grade security, scalability, and seamless integration with your CI/CD workflows.</p>"},{"location":"registry/#overview","title":"Overview","text":"<p>The Container Registry Service acts as a centralized hub for all your container images, providing secure storage, vulnerability scanning, and access control. Whether you're deploying microservices, managing CI/CD pipelines, or distributing applications across multiple environments, our registry service ensures your container images are secure, accessible, and properly managed.</p>"},{"location":"registry/#key-features","title":"Key Features","text":"<ul> <li> Secure Image Storage</li> </ul> <p>Enterprise-grade security with role-based access control and image signing</p> <p> Security Features</p> <ul> <li> Vulnerability Scanning</li> </ul> <p>Automated security scanning with detailed vulnerability reports</p> <p> Security Scanning</p> <ul> <li> Multi-Registry Replication</li> </ul> <p>Cross-region replication and disaster recovery capabilities</p> <p> Replication</p> <ul> <li> API Integration</li> </ul> <p>RESTful APIs and webhook support for seamless CI/CD integration</p> <p> API Reference</p>"},{"location":"registry/#harbor-default-registry-platform","title":"Harbor: Default Registry Platform","text":"<p>Hexabase.AI uses Harbor as the default container registry platform, providing:</p>"},{"location":"registry/#core-harbor-features","title":"Core Harbor Features","text":"<ul> <li>Project-based Organization: Organize images by projects with granular access control</li> <li>Role-based Access Control (RBAC): Fine-grained permissions for users and groups</li> <li>Image Vulnerability Scanning: Built-in security scanning with Trivy and Clair</li> <li>Content Trust: Docker Content Trust and Notary for image signing</li> <li>Garbage Collection: Automated cleanup of unused images and layers</li> <li>Audit Logging: Comprehensive logging of all registry operations</li> </ul>"},{"location":"registry/#enterprise-enhancements","title":"Enterprise Enhancements","text":"<ul> <li>Multi-tenancy Support: Isolated registry spaces per workspace</li> <li>SSO Integration: Seamless integration with your identity providers</li> <li>High Availability: Clustered deployment with load balancing</li> <li>Backup and Recovery: Automated backup with point-in-time recovery</li> <li>Monitoring Integration: Built-in metrics and alerting</li> </ul>"},{"location":"registry/#registry-architecture","title":"Registry Architecture","text":""},{"location":"registry/#multi-tenant-architecture","title":"Multi-Tenant Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Hexabase.AI                          \u2502\n\u2502                 Container Registry                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 Workspace A \u2502  \u2502 Workspace B \u2502  \u2502 Workspace C \u2502     \u2502\n\u2502  \u2502  Registry   \u2502  \u2502  Registry   \u2502  \u2502  Registry   \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                   Harbor Platform                      \u2502\n\u2502              (Default Registry Engine)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Storage Backend (Object Storage + Database)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"registry/#service-components","title":"Service Components","text":"<ul> <li>Registry Core: Harbor registry engine with OCI compliance</li> <li>Database: PostgreSQL for metadata and configuration</li> <li>Redis Cache: High-performance caching layer</li> <li>Storage Backend: Object storage for container layers</li> <li>Security Scanner: Integrated vulnerability scanning engines</li> <li>Replication Controller: Cross-region synchronization</li> </ul>"},{"location":"registry/#getting-started","title":"Getting Started","text":""},{"location":"registry/#1-access-your-registry","title":"1. Access Your Registry","text":"<p>Each workspace gets its own dedicated registry endpoint:</p> <pre><code># Registry URL format\nhttps://&lt;workspace-id&gt;.registry.hexabase.ai\n\n# Example\nhttps://prod-workspace.registry.hexabase.ai\n</code></pre>"},{"location":"registry/#2-authentication","title":"2. Authentication","text":""},{"location":"registry/#using-docker-cli","title":"Using Docker CLI","text":"<pre><code># Login to your workspace registry\ndocker login prod-workspace.registry.hexabase.ai\n\n# Enter your Hexabase.AI credentials\nUsername: your-username\nPassword: your-token-or-password\n</code></pre>"},{"location":"registry/#using-robot-accounts","title":"Using Robot Accounts","text":"<p>For automated workflows, create robot accounts:</p> <pre><code># Create robot account via CLI\nhb registry robot create \\\n  --name ci-cd-bot \\\n  --workspace production \\\n  --permissions read,write \\\n  --description \"CI/CD automation account\"\n\n# Use robot credentials\ndocker login prod-workspace.registry.hexabase.ai \\\n  -u robot$ci-cd-bot \\\n  -p &lt;robot-token&gt;\n</code></pre>"},{"location":"registry/#3-basic-operations","title":"3. Basic Operations","text":""},{"location":"registry/#push-images","title":"Push Images","text":"<pre><code># Tag your image\ndocker tag myapp:latest prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# Push to registry\ndocker push prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"registry/#pull-images","title":"Pull Images","text":"<pre><code># Pull from registry\ndocker pull prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# Deploy to Kubernetes\nkubectl create deployment myapp \\\n  --image=prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"registry/#project-management","title":"Project Management","text":""},{"location":"registry/#creating-projects","title":"Creating Projects","text":"<p>Projects organize your container images and define access policies:</p> <pre><code># Create a new project\nhb registry project create \\\n  --name frontend-services \\\n  --workspace production \\\n  --visibility private \\\n  --description \"Frontend microservices\"\n\n# List projects\nhb registry project list --workspace production\n</code></pre>"},{"location":"registry/#project-configuration","title":"Project Configuration","text":""},{"location":"registry/#access-control","title":"Access Control","text":"<pre><code># Project RBAC configuration\nproject: frontend-services\nmembers:\n  - user: \"alice@company.com\"\n    role: \"ProjectAdmin\"\n  - user: \"bob@company.com\"\n    role: \"Developer\"\n  - group: \"frontend-team\"\n    role: \"Developer\"\n\npolicies:\n  vulnerability_scanning: true\n  content_trust: required\n  prevent_vulnerable_images: true\n  auto_scan_on_push: true\n</code></pre>"},{"location":"registry/#retention-policies","title":"Retention Policies","text":"<pre><code># Image retention configuration\nretention_policy:\n  rules:\n    - priority: 1\n      disabled: false\n      action: \"retain\"\n      template: \"latestPushedK\"\n      params:\n        latestPushedK: 10  # Keep latest 10 images\n      tag_selectors:\n        - kind: \"doublestar\"\n          decoration: \"matches\"\n          pattern: \"**\"\n      scope_selectors:\n        - repository:\n            - kind: \"doublestar\"\n              decoration: \"repoMatches\"\n              pattern: \"**\"\n</code></pre>"},{"location":"registry/#security-features","title":"Security Features","text":""},{"location":"registry/#vulnerability-scanning","title":"Vulnerability Scanning","text":""},{"location":"registry/#automated-scanning","title":"Automated Scanning","text":"<ul> <li>Scan on Push: Automatic vulnerability scanning when images are uploaded</li> <li>Scheduled Scans: Regular scanning of existing images for new vulnerabilities</li> <li>Multi-Scanner Support: Integration with Trivy, Clair, and other scanners</li> </ul>"},{"location":"registry/#vulnerability-reports","title":"Vulnerability Reports","text":"<pre><code># Get vulnerability report\nhb registry scan report \\\n  --image prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# Example output\nVulnerability Summary:\n  High: 2\n  Medium: 5\n  Low: 12\n  Unknown: 1\n\nCritical Vulnerabilities:\n  CVE-2023-12345: Remote Code Execution in libssl\n  CVE-2023-67890: Buffer Overflow in base image\n</code></pre>"},{"location":"registry/#security-policies","title":"Security Policies","text":"<pre><code># Security policy configuration\nsecurity_policy:\n  prevent_vulnerable_images:\n    enabled: true\n    severity_threshold: \"high\"\n\n  content_trust:\n    enabled: true\n    cosign_verification: true\n\n  image_scanning:\n    auto_scan: true\n    scan_on_push: true\n    scanner: \"trivy\"\n</code></pre>"},{"location":"registry/#content-trust-and-signing","title":"Content Trust and Signing","text":""},{"location":"registry/#docker-content-trust","title":"Docker Content Trust","text":"<pre><code># Enable content trust\nexport DOCKER_CONTENT_TRUST=1\nexport DOCKER_CONTENT_TRUST_SERVER=https://prod-workspace.registry.hexabase.ai:4443\n\n# Push signed image\ndocker push prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"registry/#cosign-integration","title":"Cosign Integration","text":"<pre><code># Sign image with Cosign\ncosign sign prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n\n# Verify signature\ncosign verify prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n</code></pre>"},{"location":"registry/#replication","title":"Replication","text":""},{"location":"registry/#cross-region-replication","title":"Cross-Region Replication","text":"<p>Set up replication for disaster recovery and global distribution:</p> <pre><code># Create replication endpoint\nhb registry replication endpoint create \\\n  --name disaster-recovery \\\n  --url https://dr-region.registry.hexabase.ai \\\n  --workspace production\n\n# Create replication rule\nhb registry replication rule create \\\n  --name prod-to-dr \\\n  --source-workspace production \\\n  --destination-endpoint disaster-recovery \\\n  --filter-pattern \"production/**\" \\\n  --trigger manual\n</code></pre>"},{"location":"registry/#replication-configuration","title":"Replication Configuration","text":"<pre><code># Replication rule configuration\nreplication_rule:\n  name: \"prod-to-dr\"\n  description: \"Production to disaster recovery replication\"\n  source_registry:\n    type: \"harbor\"\n    url: \"https://prod-workspace.registry.hexabase.ai\"\n  destination_registry:\n    type: \"harbor\"\n    url: \"https://dr-workspace.registry.hexabase.ai\"\n  filters:\n    - type: \"repository\"\n      value: \"production/**\"\n    - type: \"tag\"\n      value: \"v*\"\n  trigger:\n    type: \"scheduled\"\n    schedule: \"0 2 * * *\"  # Daily at 2 AM\n  settings:\n    override: false\n    deletion: false\n</code></pre>"},{"location":"registry/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"registry/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/build-and-push.yml\nname: Build and Push to Registry\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Login to Hexabase Registry\n        uses: docker/login-action@v2\n        with:\n          registry: prod-workspace.registry.hexabase.ai\n          username: ${{ secrets.REGISTRY_USERNAME }}\n          password: ${{ secrets.REGISTRY_PASSWORD }}\n\n      - name: Build and push\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          push: true\n          tags: |\n            prod-workspace.registry.hexabase.ai/myproject/myapp:latest\n            prod-workspace.registry.hexabase.ai/myproject/myapp:${{ github.sha }}\n\n      - name: Scan image\n        run: |\n          hb registry scan start \\\n            --image prod-workspace.registry.hexabase.ai/myproject/myapp:${{ github.sha }} \\\n            --wait\n</code></pre>"},{"location":"registry/#gitlab-ci","title":"GitLab CI","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - build\n  - scan\n  - deploy\n\nvariables:\n  REGISTRY: \"prod-workspace.registry.hexabase.ai\"\n  IMAGE_NAME: \"$REGISTRY/myproject/myapp\"\n\nbuild:\n  stage: build\n  script:\n    - docker login -u $REGISTRY_USERNAME -p $REGISTRY_PASSWORD $REGISTRY\n    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA .\n    - docker push $IMAGE_NAME:$CI_COMMIT_SHA\n\nsecurity_scan:\n  stage: scan\n  script:\n    - hb registry scan start --image $IMAGE_NAME:$CI_COMMIT_SHA --wait\n    - hb registry scan report --image $IMAGE_NAME:$CI_COMMIT_SHA --format json &gt; scan-results.json\n  artifacts:\n    reports:\n      vulnerability: scan-results.json\n</code></pre>"},{"location":"registry/#monitoring-and-analytics","title":"Monitoring and Analytics","text":""},{"location":"registry/#registry-metrics","title":"Registry Metrics","text":"<p>Monitor registry performance and usage:</p> <pre><code># Get registry statistics\nhb registry stats --workspace production\n\n# Example output\nRegistry Statistics:\n  Total Repositories: 156\n  Total Images: 1,247\n  Storage Used: 2.3 TB\n  Pulls (24h): 15,847\n  Pushes (24h): 234\n  Active Users: 45\n</code></pre>"},{"location":"registry/#common-metrics","title":"Common Metrics","text":"<ul> <li>Storage Usage: Track storage consumption by project</li> <li>Pull/Push Rates: Monitor registry traffic and usage patterns  </li> <li>Vulnerability Trends: Track security improvements over time</li> <li>User Activity: Monitor access patterns and usage</li> <li>Replication Status: Monitor cross-region sync health</li> </ul>"},{"location":"registry/#alerts-and-notifications","title":"Alerts and Notifications","text":"<pre><code># Alert configuration\nalerts:\n  - name: \"high_storage_usage\"\n    condition: \"storage_usage &gt; 80%\"\n    notification:\n      - webhook: \"https://hooks.slack.com/services/...\"\n      - email: \"ops-team@company.com\"\n\n  - name: \"vulnerability_detected\"\n    condition: \"new_critical_vulnerability == true\"\n    notification:\n      - webhook: \"https://hooks.teams.microsoft.com/...\"\n</code></pre>"},{"location":"registry/#best-practices","title":"Best Practices","text":""},{"location":"registry/#image-management","title":"Image Management","text":"<ol> <li>Use Semantic Versioning: Tag images with semantic versions (v1.2.3)</li> <li>Immutable Tags: Avoid overwriting existing tags</li> <li>Multi-Stage Builds: Optimize image size and security</li> <li>Base Image Updates: Regularly update base images for security patches</li> </ol>"},{"location":"registry/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Regular Scanning: Enable automatic vulnerability scanning</li> <li>Minimal Images: Use distroless or minimal base images</li> <li>Image Signing: Implement content trust and image signing</li> <li>Access Control: Follow principle of least privilege</li> <li>Secrets Management: Never include secrets in images</li> </ol>"},{"location":"registry/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Layer Caching: Optimize Dockerfile for layer reuse</li> <li>Registry Location: Use regional registries for faster pulls</li> <li>Cleanup Policies: Implement retention policies to manage storage</li> <li>Parallel Pulls: Configure concurrent layer downloads</li> </ol>"},{"location":"registry/#future-roadmap","title":"Future Roadmap","text":""},{"location":"registry/#alternative-registry-support","title":"Alternative Registry Support","text":"<p>While Harbor serves as our default platform, we're planning support for additional registry platforms:</p>"},{"location":"registry/#near-term-q1-q2","title":"Near-term (Q1-Q2)","text":"<ul> <li>AWS ECR Integration: Native support for Amazon Elastic Container Registry</li> <li>Azure ACR Support: Integration with Azure Container Registry</li> <li>Google GCR/Artifact Registry: Support for Google Cloud registry services</li> </ul>"},{"location":"registry/#medium-term-q3-q4","title":"Medium-term (Q3-Q4)","text":"<ul> <li>GitLab Container Registry: Direct integration with GitLab's registry</li> <li>JFrog Artifactory: Enterprise artifact management integration</li> <li>Nexus Repository: Sonatype Nexus support for enterprise customers</li> </ul>"},{"location":"registry/#long-term-next-year","title":"Long-term (Next Year)","text":"<ul> <li>Multi-Registry Federation: Unified view across multiple registry providers</li> <li>Registry Mesh: Distributed registry architecture</li> <li>AI-Powered Optimization: Intelligent image optimization and recommendations</li> <li>OCI Artifacts: Full support for OCI artifact types beyond container images</li> </ul>"},{"location":"registry/#enhanced-features","title":"Enhanced Features","text":"<ul> <li>Advanced Caching: Global content delivery network for images</li> <li>Build Caching: Registry-based build cache for faster CI/CD</li> <li>Image Promotion: Automated image promotion pipelines</li> <li>Compliance Scanning: Enhanced compliance and policy enforcement</li> </ul>"},{"location":"registry/#getting-help","title":"Getting Help","text":""},{"location":"registry/#documentation-and-support","title":"Documentation and Support","text":"<pre><code># Get help with registry commands\nhb registry help\n\n# Check registry service status\nhb registry status --workspace production\n\n# View registry logs\nhb registry logs --follow --workspace production\n</code></pre>"},{"location":"registry/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"registry/#authentication-problems","title":"Authentication Problems","text":"<pre><code># Clear Docker credentials\ndocker logout prod-workspace.registry.hexabase.ai\n\n# Re-authenticate\ndocker login prod-workspace.registry.hexabase.ai\n\n# Test connection\ndocker pull prod-workspace.registry.hexabase.ai/library/hello-world\n</code></pre>"},{"location":"registry/#network-issues","title":"Network Issues","text":"<pre><code># Test registry connectivity\ncurl -v https://prod-workspace.registry.hexabase.ai/v2/\n\n# Check DNS resolution\nnslookup prod-workspace.registry.hexabase.ai\n</code></pre>"},{"location":"registry/#related-documentation","title":"Related Documentation","text":"<ul> <li>Applications Deployment - Using registry images in deployments</li> <li>CI/CD Pipelines - Integrating registry with pipelines</li> <li>RBAC Configuration - Managing registry access permissions</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"security/","title":"Security","text":"<p>This section provides comprehensive security guidance for Hexabase.AI (HKS). Learn how to implement defense-in-depth strategies and maintain a secure Kubernetes environment.</p>"},{"location":"security/#what-youll-find-here","title":"What You'll Find Here","text":"<ul> <li>Security Architecture: Understanding HKS security layers and components</li> <li>Access Control: RBAC, authentication, and authorization configuration</li> <li>Network Security: Network policies, service mesh security, and encryption</li> <li>Compliance: Meeting industry standards and regulatory requirements</li> <li>Security Operations: Monitoring, incident response, and threat detection</li> </ul>"},{"location":"security/#key-topics","title":"Key Topics","text":"<ul> <li>Identity and Access Management (IAM)</li> <li>Role-Based Access Control (RBAC)</li> <li>Pod Security Standards and Policies</li> <li>Network policies and micro-segmentation</li> <li>Secrets management and encryption</li> <li>Container image security scanning</li> <li>Runtime security and threat detection</li> <li>SSL/TLS certificate management</li> <li>Security audit logging and monitoring</li> <li>Compliance frameworks (SOC2, HIPAA, PCI-DSS)</li> <li>AI-Ops security anomaly detection</li> <li>Zero-trust architecture implementation</li> <li>Security best practices and hardening guides</li> </ul> <p>From basic security hygiene to advanced threat protection, this section helps you build and maintain a secure HKS environment.</p>"},{"location":"security/architecture/","title":"Security Architecture","text":"<p>The security architecture of Hexabase.AI is built on a defense-in-depth strategy, integrating security into every layer of the platform, from the underlying infrastructure to the application workloads. This document provides an overview of the key architectural components that contribute to the platform's security posture.</p> <p>For a more detailed breakdown of the overall system architecture, please see the main System Architecture document.</p>"},{"location":"security/architecture/#core-principles","title":"Core Principles","text":"<ul> <li>Zero Trust: No user or service is trusted by default. All access must be authenticated and authorized.</li> <li>Isolation: Workspaces, tenants, and workloads are isolated from each other at multiple levels (network, compute, and control plane).</li> <li>Immutability: Infrastructure and application configurations are treated as immutable, managed via code and version control.</li> <li>Automation: Security controls, policy enforcement, and monitoring are automated to reduce human error and ensure consistency.</li> </ul>"},{"location":"security/architecture/#architectural-layers-and-their-security-controls","title":"Architectural Layers and Their Security Controls","text":"<p>The diagram below illustrates the key security layers within the HKS platform.</p> <pre><code>graph TD\n    subgraph \"User/Client\"\n        A[Users] --&gt;|mTLS, OIDC/SSO| B(HKS API Gateway);\n        C[CI/CD] --&gt;|mTLS, JWT| B;\n    end\n\n    subgraph \"Hexabase.AI Control Plane\"\n        B --&gt; D{AuthN/AuthZ Service};\n        D --&gt; E[RBAC Policy Store];\n        D --&gt; F[AIOps Security Engine];\n        B --&gt; G[Workspace &amp; Tenant Manager];\n    end\n\n    subgraph \"Kubernetes Data Plane (Per Tenant)\"\n        G --&gt; H(Kubernetes API Server);\n        F --&gt; I(Security Agents);\n\n        subgraph \"Workspace (Namespace)\"\n            J[Pod]\n            K[Pod]\n            L[Network Policy]\n            M[Service Mesh Proxy]\n            I --&gt; J;\n            I --&gt; K;\n        end\n        H -.-&gt; L;\n        H -.-&gt; J;\n        H -.-&gt; K;\n        M &lt;--&gt; J;\n        M &lt;--&gt; K;\n    end\n\n    style B fill:#00C6AB,stroke:#333,stroke-width:2px\n    style F fill:#FF346B,stroke:#333,stroke-width:2px</code></pre>"},{"location":"security/architecture/#1-api-gateway","title":"1. API Gateway","text":"<ul> <li>Role: The single entry point for all requests to the Hexabase.AI platform.</li> <li>Security Controls:</li> <li>mTLS Termination: Enforces mutual TLS for all incoming connections, ensuring both client and server are authenticated.</li> <li>Authentication: Validates OIDC tokens from users and JWTs from service accounts.</li> <li>WAF Integration: Applies Web Application Firewall policies to inspect traffic for common exploits.</li> <li>Rate Limiting: Protects backend services from denial-of-service attacks.</li> </ul>"},{"location":"security/architecture/#2-authentication-and-authorization-service","title":"2. Authentication and Authorization Service","text":"<ul> <li>Role: The central authority for all access control decisions.</li> <li>Security Controls:</li> <li>OIDC/SSO Integration: Manages connections to external identity providers.</li> <li>Token Issuance: Issues short-lived, scoped tokens for internal service-to-service communication.</li> <li>Policy Decision Point (PDP): Evaluates every request against the RBAC policies stored in the policy store.</li> </ul>"},{"location":"security/architecture/#3-aiops-security-engine","title":"3. AIOps Security Engine","text":"<ul> <li>Role: Provides intelligent, real-time security analysis and automation.</li> <li>Security Controls:</li> <li>Threat Detection: Analyzes audit logs and network flows to detect anomalous behavior (e.g., potential data exfiltration, brute-force attempts).</li> <li>Vulnerability Management: Manages the image scanning process and enforces <code>ImagePolicy</code>.</li> <li>Automated Response: Can automatically trigger actions in response to threats, such as isolating a compromised pod or notifying an administrator.</li> </ul>"},{"location":"security/architecture/#4-workspace-isolation-data-plane","title":"4. Workspace Isolation (Data Plane)","text":"<ul> <li>Role: The tenant's dedicated Kubernetes environment.</li> <li>Security Controls:</li> <li>Namespace Isolation: The fundamental unit of multi-tenancy.</li> <li>Kubernetes API Server: Each tenant or group of tenants has a logically or physically isolated API server.</li> <li>NetworkPolicy Enforcement: The CNI (Container Network Interface) enforces <code>NetworkPolicy</code> resources to control traffic flow.</li> <li>Service Mesh (Sidecar Proxies): When enabled, sidecar proxies are injected into every pod. They enforce mTLS, collect detailed telemetry, and apply fine-grained traffic policies.</li> <li>Security Agents: A lightweight agent runs on each node to enforce pod security standards, collect security-related metrics, and provide runtime security monitoring.</li> </ul>"},{"location":"security/architecture/#data-flow-example-secure-api-request","title":"Data Flow Example: Secure API Request","text":"<ol> <li>A developer runs <code>hb get pods -w my-prod-space</code>.</li> <li>The HKS CLI, using its OIDC token, establishes an mTLS connection to the API Gateway.</li> <li>The Gateway validates the token with the AuthN/AuthZ Service.</li> <li>The AuthZ service checks its policy store and confirms the user has <code>get pod</code> permissions for <code>my-prod-space</code>.</li> <li>The request is approved and forwarded to the Workspace Manager.</li> <li>The Workspace Manager proxies the request to the correct Kubernetes API Server for that tenant.</li> <li>The Kubernetes API server returns the list of pods.</li> <li>The response flows back to the user.</li> <li>The entire transaction is logged by the AIOps Security Engine for auditing.</li> </ol>"},{"location":"security/auth/","title":"Authentication and Authorization","text":"<p>Security is paramount in a multi-tenant environment. Hexabase.AI implements robust, standards-based authentication and authorization mechanisms to ensure that only legitimate users and services can access your resources.</p>"},{"location":"security/auth/#authentication-authn-who-are-you","title":"Authentication (AuthN) - Who are you?","text":"<p>Authentication is the process of verifying the identity of a user or service. HKS supports multiple authentication methods.</p>"},{"location":"security/auth/#1-user-authentication-via-oauth-20-and-oidc","title":"1. User Authentication via OAuth 2.0 and OIDC","text":"<ul> <li>Mechanism: All user-facing interactions with HKS (UI and CLI) are authenticated using the OAuth 2.0 Authorization Code Flow with PKCE. HKS acts as an OAuth 2.0 client, and it integrates with an OIDC (OpenID Connect) provider for identity verification.</li> <li>Default Provider: Hexabase.AI provides a built-in OIDC provider for new organizations.</li> <li>Single Sign-On (SSO): For Enterprise plans, you can integrate your own identity provider (IdP) like Okta, Azure Active Directory, or Google Workspace. This allows your users to log in using their existing corporate credentials.</li> </ul> <p>SSO Configuration Example (for Org Admins):</p> <pre><code>apiVersion: hks.io/v1\nkind: AuthProvider\nmetadata:\n  name: okta-sso\nspec:\n  type: oidc\n  config:\n    issuerUrl: \"https://my-org.okta.com\"\n    clientId: \"hks-client-id\"\n    clientSecretRef:\n      name: okta-secret\n      key: clientSecret\n    scopes:\n      - openid\n      - profile\n      - email\n      - groups\n    groupClaim: \"groups\"\n</code></pre>"},{"location":"security/auth/#2-service-account-authentication-for-machines","title":"2. Service Account Authentication (for Machines)","text":"<ul> <li>Mechanism: For programmatic access (e.g., in CI/CD pipelines or scripts), HKS uses Service Accounts. These are non-user accounts that can be granted specific permissions.</li> <li>Authentication Method: Service Accounts authenticate using signed JSON Web Tokens (JWTs). These tokens are short-lived for enhanced security.</li> </ul> <p>Creating a Service Account and API Key:</p> <pre><code># Create a service account\nhb create service-account cicd-agent --description \"For CI/CD pipeline\"\n\n# Create an API key (JWT) for the service account\nhb create api-key --service-account cicd-agent --duration 24h\n</code></pre> <p>The output of this command is a JWT that can be used as a Bearer token in API requests.</p>"},{"location":"security/auth/#authorization-authz-what-can-you-do","title":"Authorization (AuthZ) - What can you do?","text":"<p>Authorization is the process of determining what an authenticated user or service is allowed to do. HKS uses a sophisticated Role-Based Access Control (RBAC) model.</p>"},{"location":"security/auth/#the-hks-rbac-model","title":"The HKS RBAC Model","text":"<p>The authorization model has two main layers:</p> <ol> <li>Organization RBAC: Defines roles at the organization level (<code>org_admin</code>, <code>org_user</code>). Org Admins can manage billing, users, and workspaces.</li> <li>Workspace RBAC: Defines roles within a specific workspace (<code>workspace_admin</code>, <code>developer</code>, <code>viewer</code>). These roles grant permissions to interact with Kubernetes resources (Deployments, Pods, etc.) within that workspace.</li> </ol> <p>For more details, see the dedicated RBAC documentation.</p>"},{"location":"security/auth/#how-authorization-works","title":"How Authorization Works","text":"<ol> <li>A user or service makes a request to the HKS API with a valid JWT.</li> <li>The API gateway validates the token.</li> <li>The AuthZ service extracts the user/service identity and their associated roles/groups from the token.</li> <li>It checks the requested action (e.g., <code>create Deployment in 'prod-workspace'</code>) against the RBAC policies defined for that user/role.</li> <li>If the policy allows the action, the request is forwarded to the appropriate backend service.</li> <li>If not, a <code>403 Forbidden</code> error is returned.</li> </ol>"},{"location":"security/auth/#kubernetes-rbac-integration","title":"Kubernetes RBAC Integration","text":"<ul> <li>HKS RBAC seamlessly integrates with the underlying Kubernetes RBAC.</li> <li>When you assign a user the <code>developer</code> role in a workspace, HKS automatically creates a corresponding <code>Role</code> and <code>RoleBinding</code> in the underlying Kubernetes namespace for that workspace.</li> <li>This ensures that when the user interacts with the Kubernetes API server directly (e.g., via <code>kubectl</code>), the same permissions are enforced.</li> </ul> <p>Example of a generated Kubernetes Role:</p> <pre><code># This role is automatically created and managed by HKS\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: hks-developer-role\n  namespace: prod-workspace-ns\nrules:\n  - apiGroups: [\"\", \"apps\", \"batch\"]\n    resources: [\"pods\", \"deployments\", \"services\", \"jobs\", \"cronjobs\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n  - apiGroups: [\"\"]\n    resources: [\"pods/log\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"security/auth/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Principle of Least Privilege: Always grant users and service accounts the minimum permissions they need to perform their jobs. Avoid using highly privileged roles like <code>workspace_admin</code> for daily tasks.</li> <li>Use SSO: For organizations, always integrate your corporate IdP using SSO. This centralizes user management and enforces your company's authentication policies (like MFA).</li> <li>Short-Lived Tokens: For service accounts, generate short-lived API keys (e.g., <code>1h</code> or <code>8h</code>) specific to the task at hand, especially in automated environments like CI/CD.</li> <li>Regularly Audit Permissions: Org Admins should regularly review user roles and permissions to remove stale access.</li> <li>Secure <code>clientSecret</code>: When configuring an SSO provider, store the <code>clientSecret</code> in a secure Kubernetes secret, not in plain text.</li> </ol>"},{"location":"security/best-practices/","title":"Security Best Practices","text":"<p>This document provides a consolidated list of security best practices for using Hexabase.AI. While other documents cover specific features, this guide serves as a checklist to ensure you are operating in the most secure manner possible.</p>"},{"location":"security/best-practices/#1-identity-and-access-management","title":"1. Identity and Access Management","text":"<ul> <li>Enforce MFA: For the built-in HKS identity provider, ensure all users have Multi-Factor Authentication (MFA) enabled.</li> <li>Use SSO for Enterprises: Integrate your corporate identity provider (Okta, Azure AD) to centralize user management and enforce your organization's authentication policies.</li> <li>Principle of Least Privilege (PoLP):</li> <li>Assign users the most restrictive role that still allows them to perform their duties (e.g., prefer <code>developer</code> over <code>workspace_admin</code>).</li> <li>Create custom, fine-grained roles for specific tasks if needed.</li> <li>Regularly Audit Permissions: Periodically review who has access to what. Remove stale user accounts and permissions promptly.</li> <li>Use Service Accounts for Automation:</li> <li>Never use a human user's credentials in scripts or CI/CD pipelines.</li> <li>Create dedicated <code>ServiceAccount</code>s with the minimum required permissions.</li> <li>Generate short-lived API keys for these accounts.</li> </ul>"},{"location":"security/best-practices/#2-network-security","title":"2. Network Security","text":"<ul> <li>Start with \"Default Deny\": Apply a default-deny <code>NetworkPolicy</code> to all production namespaces. This blocks all pod-to-pod traffic by default, forcing you to explicitly allow necessary communication paths.</li> <li>Micro-segment Your Applications: Create granular <code>NetworkPolicy</code> resources that only allow required traffic between application components.</li> <li>Control Egress Traffic: Do not allow unrestricted outbound internet access from your pods. Use an <code>EgressGateway</code> to filter and monitor outbound traffic. Whitelist only the external IPs and domains your application needs to access.</li> <li>Encrypt All Traffic:</li> <li>Terminate TLS at the Ingress for all external traffic.</li> <li>Enable <code>STRICT</code> mTLS for all internal service-to-service traffic using the integrated service mesh.</li> </ul>"},{"location":"security/best-practices/#3-workload-and-pod-security","title":"3. Workload and Pod Security","text":"<ul> <li>Use Minimal, Secure Base Images: Build your container images from trusted, minimal base images (like <code>distroless</code> or <code>alpine</code>) to reduce the attack surface.</li> <li>Run as Non-Root: Never run your container processes as the <code>root</code> user. Use a <code>securityContext</code> to specify a non-root user.</li> <li>Read-Only Root Filesystem: Where possible, run your containers with a read-only root filesystem to prevent an attacker from modifying the container's contents.   <pre><code>securityContext:\n  readOnlyRootFilesystem: true\n</code></pre></li> <li>Apply Pod Security Standards: Use <code>WorkspacePolicy</code> to enforce <code>baseline</code> or <code>restricted</code> pod security standards on your production workspaces, preventing the use of privileged containers.</li> <li>Automate Vulnerability Scanning:</li> <li>Integrate image scanning into your CI/CD pipeline to catch vulnerabilities before deployment.</li> <li>Use HKS <code>ImagePolicy</code> to block deployments that contain critical vulnerabilities.</li> </ul>"},{"location":"security/best-practices/#4-data-and-storage-security","title":"4. Data and Storage Security","text":"<ul> <li>Encrypt Data at Rest: Ensure that your <code>StorageClass</code> is configured to encrypt persistent volumes at rest using the underlying cloud provider's encryption mechanisms.</li> <li>Secure Backups:</li> <li>Encrypt backups both in transit and at rest.</li> <li>Use a dedicated, access-restricted bucket for your backup storage location.</li> <li>Use separate storage locations for your primary and disaster recovery backups, preferably in different geographic regions.</li> <li>Manage Secrets Securely:</li> <li>Use HKS or Kubernetes <code>Secrets</code> for all sensitive data like passwords, API keys, and certificates.</li> <li>Do not store secrets in environment variables, ConfigMaps, or container images.</li> <li>Use a secret management solution like HashiCorp Vault for enhanced security, and integrate it with HKS.</li> </ul>"},{"location":"security/best-practices/#5-auditing-and-monitoring","title":"5. Auditing and Monitoring","text":"<ul> <li>Enable Comprehensive Auditing: Ensure audit logging is enabled for all your production workspaces.</li> <li>Integrate with SIEM: Stream audit logs to your central SIEM for analysis and long-term retention.</li> <li>Monitor for Anomalies: Configure AIOps alerts to notify you of unusual activity, such as a spike in <code>403 Forbidden</code> errors, unexpected egress traffic, or anomalous API calls.</li> <li>Log Everything: Configure your applications to log to <code>stdout</code>/<code>stderr</code> in a structured format (like JSON) so HKS can aggregate and analyze the logs effectively.</li> </ul>"},{"location":"security/best-practices/#6-general-best-practices","title":"6. General Best Practices","text":"<ul> <li>Infrastructure as Code (IaC): Define all your resources\u2014from applications to security policies\u2014as code (YAML) and store it in a version control system like Git. This makes your configuration auditable and repeatable.</li> <li>Automate Compliance: Leverage HKS <code>CompliancePacks</code> to automate the enforcement of security controls required by standards like HIPAA or PCI-DSS.</li> <li>Regularly Test Your Security:</li> <li>Periodically run penetration tests against your applications.</li> <li>Regularly test your disaster recovery and restore procedures.</li> </ul>"},{"location":"security/compliance/","title":"Compliance","text":"<p>For organizations operating in regulated industries, meeting compliance standards like PCI-DSS, HIPAA, or SOC 2 is a critical requirement. Hexabase.AI is designed with compliance in mind, providing tools and features that help you enforce policies, audit your environment, and demonstrate adherence to various regulatory frameworks.</p>"},{"location":"security/compliance/#how-hexabaseai-helps-with-compliance","title":"How Hexabase.AI Helps with Compliance","text":"<ul> <li>Secure by Default: The platform provides a secure foundation, with features like workspace isolation, mTLS, and RBAC that align with the security principles of most compliance standards.</li> <li>Policy Enforcement: HKS allows you to programmatically enforce security and configuration policies across your environment.</li> <li>Comprehensive Auditing: Immutable, long-term audit logs provide a detailed record of all activities, which is essential for compliance reporting.</li> <li>Automation: Automate compliance checks and evidence gathering to reduce the manual burden of audits.</li> </ul>"},{"location":"security/compliance/#compliance-packs","title":"Compliance Packs","text":"<p>Compliance Packs are pre-configured sets of policies, security controls, and monitoring rules tailored for specific regulatory standards. These are available on the Enterprise Plan.</p>"},{"location":"security/compliance/#enabling-a-compliance-pack","title":"Enabling a Compliance Pack","text":"<p>An Org Admin can enable a Compliance Pack for a specific workspace.</p> <pre><code># Enable the HIPAA compliance pack for the 'healthcare-data' workspace\nhb workspace configure healthcare-data --compliance-pack hipaa\n</code></pre> <p>When a pack is enabled, HKS automatically:</p> <ol> <li>Applies a strict set of <code>NetworkPolicy</code> resources.</li> <li>Enforces <code>STRICT</code> mTLS for all service communication.</li> <li>Applies pod security standards to prevent privileged containers.</li> <li>Configures fine-grained audit logging for all resources in the workspace.</li> <li>Enables vulnerability scanning for all container images deployed to the workspace.</li> </ol>"},{"location":"security/compliance/#available-compliance-packs","title":"Available Compliance Packs","text":"<ul> <li>PCI-DSS: For handling credit card and payment information.</li> <li>HIPAA: For managing protected health information (PHI).</li> <li>SOC 2: For service organizations requiring reports on security, availability, and confidentiality.</li> <li>CIS Benchmarks: Enforces configuration best practices based on the Center for Internet Security benchmarks for Kubernetes.</li> </ul>"},{"location":"security/compliance/#pod-security-standards","title":"Pod Security Standards","text":"<p>Hexabase.AI enforces Kubernetes Pod Security Standards to ensure that workloads run securely. You can apply different levels of security to your workspaces.</p> <pre><code>apiVersion: hks.io/v1\nkind: WorkspacePolicy\nmetadata:\n  name: production-pod-security\nspec:\n  # Applies to workspaces with this label\n  workspaceSelector:\n    environment: production\n  # Enforce the 'baseline' or 'restricted' Kubernetes standard\n  podSecurityStandard: \"baseline\"\n</code></pre> <ul> <li>Privileged: Unrestricted, for trusted workloads only.</li> <li>Baseline: Minimally restrictive, prevents known privilege escalations.</li> <li>Restricted: Heavily restricted, follows current pod hardening best practices.</li> </ul>"},{"location":"security/compliance/#audit-logs-for-compliance","title":"Audit Logs for Compliance","text":"<p>Detailed audit logs are a cornerstone of any compliance strategy.</p>"},{"location":"security/compliance/#accessing-audit-logs","title":"Accessing Audit Logs","text":"<p>Enterprise Plan users have access to long-term, immutable audit logs.</p> <pre><code># Query audit logs for a specific workspace and time range\nhb audit-logs query \\\n  --workspace sensitive-data \\\n  --start-time \"2025-06-01T00:00:00Z\" \\\n  --end-time \"2025-06-15T00:00:00Z\" \\\n  --filter \"event.type=resource.delete\"\n</code></pre>"},{"location":"security/compliance/#siem-integration","title":"SIEM Integration","text":"<p>You can stream audit logs directly to your organization's Security Information and Event Management (SIEM) system (e.g., Splunk, Datadog, ELK).</p> <pre><code>apiVersion: hks.io/v1\nkind: AuditLogSink\nmetadata:\n  name: splunk-integration\nspec:\n  type: splunk\n  config:\n    endpoint: \"https://http-inputs-my-org.splunkcloud.com\"\n    tokenSecretRef:\n      name: splunk-hec-token\n      key: token\n  filter:\n    # Only send critical events to the SIEM\n    minSeverity: \"warning\"\n</code></pre>"},{"location":"security/compliance/#vulnerability-management","title":"Vulnerability Management","text":"<p>Continuously scanning for vulnerabilities is a key compliance requirement.</p>"},{"location":"security/compliance/#automated-image-scanning","title":"Automated Image Scanning","text":"<p>HKS automatically scans all container images upon deployment to a workspace.</p> <pre><code># Policy to block deployments with critical vulnerabilities\napiVersion: hks.io/v1\nkind: ImagePolicy\nmetadata:\n  name: block-critical-vulns\nspec:\n  workspaceSelector:\n    environment: production\n  scan:\n    failOn:\n      severity: \"CRITICAL\"\n      # Optionally, fail if a fix is available\n      fixAvailable: true\n</code></pre>"},{"location":"security/compliance/#viewing-vulnerability-reports","title":"Viewing Vulnerability Reports","text":"<p>You can view vulnerability reports for your running applications at any time.</p> <pre><code># Get a vulnerability report for a deployment\nhb get vulnerabilities --deployment myapp-deployment\n</code></pre>"},{"location":"security/compliance/#best-practices-for-maintaining-compliance","title":"Best Practices for Maintaining Compliance","text":"<ol> <li>Engage Your Security Team: Work with your organization's security and compliance teams to map regulatory requirements to HKS features.</li> <li>Use Compliance Packs: If you are on the Enterprise Plan, leverage Compliance Packs to automate the enforcement of baseline controls.</li> <li>Automate Evidence Gathering: Use the <code>hb audit-logs</code> CLI and SIEM integration to automate the collection of evidence required for audits.</li> <li>Least Privilege: Apply the principle of least privilege not just to users, but to all resources. Use strict network policies and pod security standards.</li> <li>Stay Updated: Regularly review and apply updates to your applications and the HKS platform to patch vulnerabilities.</li> <li>Documentation: Keep internal documentation that maps each compliance requirement to the specific control or policy you have implemented in Hexabase.AI.</li> </ol>"},{"location":"security/network-security/","title":"Network Security","text":"<p>Network security in Hexabase.AI is a multi-layered strategy designed to protect your applications from unauthorized access and to control the flow of traffic within and between your workspaces.</p>"},{"location":"security/network-security/#layers-of-network-security","title":"Layers of Network Security","text":"<ol> <li>Workspace Isolation: Each workspace is backed by a dedicated Kubernetes namespace, providing a primary boundary for network policies.</li> <li>Network Policies: Kubernetes NetworkPolicies are used to control traffic between pods within a workspace.</li> <li>Ingress Control: Ingress controllers and API gateways manage and secure all traffic entering the cluster from the outside.</li> <li>Egress Control: Egress gateways control and monitor all traffic leaving the cluster.</li> <li>Service Mesh Security: For fine-grained control, a service mesh (like Istio) provides mutual TLS (mTLS) for all service-to-service communication.</li> </ol>"},{"location":"security/network-security/#workspace-network-isolation","title":"Workspace Network Isolation","text":"<p>By default, workspaces are isolated from each other at the network level. Pods in <code>workspace-a</code> cannot directly communicate with pods in <code>workspace-b</code> unless explicitly allowed by an administrator.</p>"},{"location":"security/network-security/#kubernetes-network-policies","title":"Kubernetes Network Policies","text":"<p>NetworkPolicies are the primary tool for implementing micro-segmentation within a workspace.</p>"},{"location":"security/network-security/#default-deny-policy","title":"Default Deny Policy","text":"<p>It is a best practice to start with a \"default deny\" policy for your production workspaces. This policy blocks all pod-to-pod traffic unless it is explicitly allowed by another policy.</p> <pre><code># policy-default-deny.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\nspec:\n  podSelector: {} # Selects all pods in the namespace\n  policyTypes:\n    - Ingress\n    - Egress\n</code></pre> <p>Applying this policy will immediately block all traffic. You must then create specific \"allow\" policies.</p>"},{"location":"security/network-security/#allowing-traffic-between-pods","title":"Allowing Traffic Between Pods","text":"<p>This example allows pods with the label <code>role: frontend</code> to connect to pods with the label <code>role: backend</code> on port 8080.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-frontend-to-backend\nspec:\n  podSelector:\n    matchLabels:\n      role: backend\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              role: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n</code></pre>"},{"location":"security/network-security/#limiting-egress-traffic","title":"Limiting Egress Traffic","text":"<p>This policy only allows pods with <code>role: backend</code> to initiate connections to an external database IP.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-backend-to-db\nspec:\n  podSelector:\n    matchLabels:\n      role: backend\n  policyTypes:\n    - Egress\n  egress:\n    - to:\n        - ipBlock:\n            cidr: 192.168.100.10/32 # External DB IP\n      ports:\n        - protocol: TCP\n          port: 5432\n</code></pre>"},{"location":"security/network-security/#securing-ingress-traffic","title":"Securing Ingress Traffic","text":"<p>All external traffic should pass through a secure Ingress gateway.</p>"},{"location":"security/network-security/#tls-termination","title":"TLS Termination","text":"<p>Terminate TLS at the edge using certificates managed by HKS.</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    hks.io/tls-certificate: \"my-app-cert\"\nspec:\n  tls:\n    - hosts:\n        - myapp.example.com\n      secretName: myapp-tls # HKS manages this secret\n  rules:\n    - host: myapp.example.com\n      http:\n        paths:\n        # ...\n</code></pre>"},{"location":"security/network-security/#web-application-firewall-waf","title":"Web Application Firewall (WAF)","text":"<p>Enable the WAF on your Ingress to protect against common web exploits (like SQL injection and XSS).</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ingress\n  annotations:\n    hks.io/waf-policy: \"level-2-standard\"\n    hks.io/rate-limit: \"100-per-minute\"\n# ...\n</code></pre>"},{"location":"security/network-security/#controlling-egress-traffic","title":"Controlling Egress Traffic","text":"<p>By default, pods can send traffic to any external destination. For a secure environment, this should be restricted.</p>"},{"location":"security/network-security/#egress-gateway","title":"Egress Gateway","text":"<p>Configure a dedicated egress gateway to route all outbound traffic through a single, monitored point.</p> <pre><code>apiVersion: hks.io/v1\nkind: EgressGateway\nmetadata:\n  name: main-egress-gw\nspec:\n  # Route all outbound traffic from this namespace through the gateway\n  selector: {}\n  # Assign a static IP for whitelisting by external services\n  staticIp: true\n  # Log all outbound connections\n  logging:\n    enabled: true\n</code></pre> <p>You can then create <code>NetworkPolicy</code> resources that only allow egress to the egress gateway itself.</p>"},{"location":"security/network-security/#service-mesh-security-with-mtls","title":"Service Mesh Security with mTLS","text":"<p>For the highest level of security (zero-trust networking), enable mutual TLS (mTLS) for all traffic inside your workspace.</p>"},{"location":"security/network-security/#enabling-mtls","title":"Enabling mTLS","text":"<p>With HKS's integrated service mesh, enabling mTLS is a single command or annotation.</p> <pre><code># Enable mTLS for the entire 'production' workspace\nhb mesh mtls enable --workspace production\n</code></pre> <p>Or via a policy:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default-mtls\n  namespace: production\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>With <code>STRICT</code> mTLS, all service-to-service communication is automatically encrypted, and services must present a valid certificate to communicate, preventing spoofing and man-in-the-middle attacks within the cluster.</p>"},{"location":"security/network-security/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Start with Default Deny: Always apply a default-deny network policy to production namespaces and explicitly allow required traffic.</li> <li>Micro-segmentation: Create fine-grained network policies that only allow pods to communicate with the specific services they need.</li> <li>Control Egress: Don't allow unrestricted outbound access from your pods. Use an egress gateway and network policies to limit what your applications can connect to externally.</li> <li>Encrypt Everywhere: Use TLS for all ingress traffic and enable mTLS for all internal service-to-service traffic.</li> <li>Audit Network Policies: Regularly review and audit your network policies to ensure they are still correct and not overly permissive.</li> <li>Log Network Traffic: Enable flow logging on your egress gateway and service mesh to get visibility into your network traffic patterns, which is invaluable for security audits and troubleshooting.</li> </ol>"},{"location":"usecases/","title":"Use Cases","text":"<p>Discover how organizations are leveraging Hexabase.AI to transform their Kubernetes operations and accelerate their cloud-native journey.</p>"},{"location":"usecases/#1-overview","title":"1. Overview","text":"<p>Hexabase.AI serves diverse use cases across industries, from startups deploying their first microservices to enterprises managing complex multi-cluster environments. This section explores common scenarios and best practices for getting the most value from the platform.</p>"},{"location":"usecases/#2-key-benefits","title":"2. Key Benefits","text":"<ul> <li> Application Modernization</li> </ul> <p>Migrate legacy applications to Kubernetes with minimal complexity</p> <p> Explore Modernization</p> <ul> <li> Multi-Environment Management</li> </ul> <p>Manage development, staging, and production environments efficiently</p> <p> Learn Multi-Environment</p> <ul> <li> Team Collaboration</li> </ul> <p>Enable multiple teams to work independently on shared infrastructure</p> <p> Team Collaboration Guide</p> <ul> <li> Cost Optimization</li> </ul> <p>Reduce infrastructure costs with AI-powered resource optimization</p> <p> Cost Optimization Strategies</p>"},{"location":"usecases/#3-plans-to-go","title":"3. Plans to Go","text":"<p>Hexabase.AI is designed to grow with you. Whether you're an individual developer starting a new project or a large enterprise with complex security and governance needs, there's a plan that fits your use case. Follow the journey to see how you can start small and scale up seamlessly.</p> <ul> <li> Single User/Hobby Plan</li> </ul> <p>Start your journey with a personal, isolated workspace. Deploy applications, set up a simple CI/CD pipeline, and get a feel for the platform's power. This plan is perfect for personal projects and learning.</p> <p> See the Single User Scenario</p> <ul> <li> Single User/Pro Plan</li> </ul> <p>As your project grows and requires more performance or resource guarantees, you can seamlessly upgrade to the Pro Plan with powerful dedicated nodes for your production workloads.</p> <p> Learn about Pro Features</p> <ul> <li> Team Plan</li> </ul> <p>Bring your team onboard. Collaborate in a shared organization with multiple workspaces, advanced CI/CD, and more powerful AIOps features. Ideal for startups and small-to-medium businesses.</p> <p> See the Team Scenario</p> <ul> <li> Enterprise Plan</li> </ul> <p>Unlock the full power of Hexabase.AI for your organization. Get enterprise-grade security, compliance packs, multi-region deployments, budget planning, and premium support.</p> <p> See the Enterprise Scenario</p>"},{"location":"usecases/#4-who-are-we-serving","title":"4. Who are we serving?","text":""},{"location":"usecases/#software-development-teams","title":"Software Development Teams","text":"<ul> <li>Challenge: Complex Kubernetes setup and maintenance</li> <li>Solution: Self-service deployment with built-in best practices</li> <li>Benefits: 80% reduction in deployment time, focus on code not infrastructure</li> </ul>"},{"location":"usecases/#enterprise-it","title":"Enterprise IT","text":"<ul> <li>Challenge: Managing multiple teams and environments securely</li> <li>Solution: Multi-tenant architecture with RBAC and resource quotas</li> <li>Benefits: Centralized governance with team autonomy</li> </ul>"},{"location":"usecases/#saas-providers","title":"SaaS Providers","text":"<ul> <li>Challenge: Scaling infrastructure with customer growth</li> <li>Solution: AI-powered autoscaling and resource optimization</li> <li>Benefits: 40% cost reduction while improving performance</li> </ul>"},{"location":"usecases/#educational-institutions","title":"Educational Institutions","text":"<ul> <li>Challenge: Providing isolated environments for students</li> <li>Solution: Workspace-based isolation with resource limits</li> <li>Benefits: Secure, cost-effective learning environments</li> </ul>"},{"location":"usecases/#5-best-practice","title":"5. Best Practice","text":""},{"location":"usecases/#1-start-small-scale-smart","title":"1. Start Small, Scale Smart","text":"<p>Begin with a pilot project in a single workspace, then expand based on learnings.</p>"},{"location":"usecases/#2-leverage-ai-insights","title":"2. Leverage AI Insights","text":"<p>Use AIOps recommendations to optimize resource allocation and reduce costs.</p>"},{"location":"usecases/#3-automate-everything","title":"3. Automate Everything","text":"<p>Integrate with CI/CD pipelines using our comprehensive APIs.</p>"},{"location":"usecases/#4-monitor-and-iterate","title":"4. Monitor and Iterate","text":"<p>Use built-in observability to continuously improve your deployments.</p>"},{"location":"usecases/#6-are-you-ready","title":"6. Are you ready?","text":"<p>Ready to explore how Hexabase.AI can transform your Kubernetes journey?</p> <ol> <li>Identify Your Use Case: Match your needs with the scenarios above</li> <li>Start a Trial: Experience the platform with a free trial</li> <li>Follow Best Practices: Use our guides for optimal results</li> <li>Get Support: Our team is here to help you succeed</li> </ol>"},{"location":"usecases/#related-resources","title":"Related Resources","text":"<ul> <li>Architecture Overview</li> <li>Getting Started Guide</li> <li>API Documentation</li> <li>Best Practices</li> </ul>"},{"location":"usecases/enterprise-plan/","title":"Enterprise Plan Scenario","text":"<p>The Enterprise Plan is the premier offering from Hexabase.AI, designed for large organizations with stringent security, compliance, scalability, and governance requirements. This plan provides the most comprehensive AI-oriented Kubernetes platform for enterprises managing complex, multi-tenant infrastructures.</p>"},{"location":"usecases/enterprise-plan/#enterprise-features-overview","title":"Enterprise Features Overview","text":"<p>Hexabase.AI Enterprise Plan addresses the unique needs of large organizations through advanced governance, security, and operational capabilities that enable both cloud and on-premises deployments.</p>"},{"location":"usecases/enterprise-plan/#enterprise-grade-ai-operations","title":"Enterprise-Grade AI Operations","text":"<ul> <li>Full AIOps Suite: Complete AI-powered operations including predictive scaling, automated root cause analysis, and intelligent security threat detection</li> <li>Custom AI Models: Train organization-specific models for specialized workloads and compliance requirements</li> <li>Advanced Analytics: Deep insights into resource utilization, cost optimization, and performance trends across all business units</li> </ul>"},{"location":"usecases/enterprise-plan/#centralized-management-governance","title":"Centralized Management &amp; Governance","text":"<ul> <li>Multi-Cluster Orchestration: Manage hundreds of clusters across multiple regions and cloud providers</li> <li>Enterprise SSO Integration: Seamless integration with existing identity providers (Okta, Azure AD, LDAP)</li> <li>Advanced RBAC: Fine-grained role-based access control mapping to corporate organizational structures</li> <li>Policy Enforcement: Centralized governance with automated compliance checking across all environments</li> </ul>"},{"location":"usecases/enterprise-plan/#use-case-scenarios","title":"Use Case Scenarios","text":""},{"location":"usecases/enterprise-plan/#scenario-1-global-financial-services-institution","title":"Scenario 1: Global Financial Services Institution","text":"<p>Organization: Large multinational bank with operations across 15 countries</p> <p>Requirements: - GDPR, PCI-DSS, and SOX compliance across all regions - Zero-downtime trading systems during market hours - Real-time fraud detection for millions of transactions - Strict data residency requirements</p> <p>Implementation:</p>"},{"location":"usecases/enterprise-plan/#multi-region-architecture","title":"Multi-Region Architecture","text":"<ul> <li>Americas: Primary data centers in New York and S\u00e3o Paulo</li> <li>EMEA: Primary data centers in London and Frankfurt  </li> <li>APAC: Primary data centers in Singapore and Tokyo</li> <li>Hybrid Cloud: On-premises for regulated data, cloud for analytics workloads</li> </ul>"},{"location":"usecases/enterprise-plan/#advanced-security-compliance","title":"Advanced Security &amp; Compliance","text":"<ul> <li>Immutable Audit Logs: All API calls, deployments, and data access logged with cryptographic integrity</li> <li>Zero-Trust Networking: End-to-end encryption, identity verification for every request</li> <li>Compliance Automation: PCI-DSS policies automatically applied to payment processing workspaces</li> <li>Data Classification: AI-powered data discovery and automatic classification</li> </ul>"},{"location":"usecases/enterprise-plan/#ai-powered-operations","title":"AI-Powered Operations","text":"<ul> <li>Predictive Scaling: AI predicts trading volume spikes and pre-scales infrastructure</li> <li>Fraud Detection: Real-time ML models detect anomalous transaction patterns</li> <li>Automated Compliance: AI continuously monitors for policy violations and auto-remediates</li> </ul>"},{"location":"usecases/enterprise-plan/#scenario-2-healthcare-research-organization","title":"Scenario 2: Healthcare Research Organization","text":"<p>Organization: Global pharmaceutical company with R&amp;D facilities worldwide</p> <p>Requirements: - HIPAA compliance for patient data - High-performance computing for drug discovery - Secure collaboration between global research teams - FDA validation requirements for clinical trial platforms</p> <p>Implementation:</p>"},{"location":"usecases/enterprise-plan/#secure-multi-tenancy","title":"Secure Multi-Tenancy","text":"<ul> <li>Research Units: Isolated workspaces per therapeutic area</li> <li>Data Isolation: Complete separation of competing research programs</li> <li>Collaboration Spaces: Secure environments for external research partnerships</li> <li>Regulatory Environments: Dedicated clusters for FDA-validated workloads</li> </ul>"},{"location":"usecases/enterprise-plan/#advanced-ai-integration","title":"Advanced AI Integration","text":"<ul> <li>Drug Discovery: GPU-accelerated AI workloads for molecular modeling</li> <li>Clinical Analytics: ML pipelines for patient outcome prediction</li> <li>Research Optimization: AI-driven resource allocation for compute-intensive tasks</li> </ul>"},{"location":"usecases/enterprise-plan/#scenario-3-manufacturing-supply-chain","title":"Scenario 3: Manufacturing &amp; Supply Chain","text":"<p>Organization: Global manufacturing conglomerate with smart factories</p> <p>Requirements: - Edge computing for factory automation - Supply chain optimization with AI - Predictive maintenance for industrial equipment - Integration with legacy industrial systems</p> <p>Implementation:</p>"},{"location":"usecases/enterprise-plan/#edge-hybrid-architecture","title":"Edge &amp; Hybrid Architecture","text":"<ul> <li>Factory Edge: K3s clusters in manufacturing facilities</li> <li>Supply Chain Analytics: Cloud-based AI for demand forecasting</li> <li>Predictive Maintenance: IoT data processing with ML models</li> <li>Digital Twin: Real-time simulation of manufacturing processes</li> </ul>"},{"location":"usecases/enterprise-plan/#enterprise-deployment-options","title":"Enterprise Deployment Options","text":""},{"location":"usecases/enterprise-plan/#cloud-enterprise","title":"Cloud Enterprise","text":""},{"location":"usecases/enterprise-plan/#multi-cloud-strategy","title":"Multi-Cloud Strategy","text":"<ul> <li>AWS: Primary compute and data services</li> <li>Google Cloud: AI/ML workloads and analytics</li> <li>Azure: Office 365 integration and hybrid connectivity</li> <li>Oracle Cloud: SAP and ERP system integration</li> </ul>"},{"location":"usecases/enterprise-plan/#advanced-networking","title":"Advanced Networking","text":"<ul> <li>Dedicated Interconnects: High-bandwidth, low-latency connections</li> <li>Global Load Balancing: Intelligent traffic routing across regions</li> <li>Private Network: Dedicated network segments for sensitive workloads</li> </ul>"},{"location":"usecases/enterprise-plan/#on-premises-enterprise","title":"On-Premises Enterprise","text":""},{"location":"usecases/enterprise-plan/#data-center-integration","title":"Data Center Integration","text":"<ul> <li>Proxmox Virtualization: VM-based infrastructure management</li> <li>Bare Metal Deployment: Direct K3s installation on physical servers</li> <li>Hybrid Connectivity: Secure connections to cloud resources</li> <li>Air-Gapped Environments: Completely isolated installations for maximum security</li> </ul>"},{"location":"usecases/enterprise-plan/#enterprise-hardware-support","title":"Enterprise Hardware Support","text":"<ul> <li>NVIDIA GPU: Accelerated AI/ML workloads</li> <li>High-Performance Storage: NVMe, parallel file systems</li> <li>Network Acceleration: DPDK, SR-IOV for high-throughput applications</li> </ul>"},{"location":"usecases/enterprise-plan/#advanced-security-features","title":"Advanced Security Features","text":""},{"location":"usecases/enterprise-plan/#enterprise-identity-access-management","title":"Enterprise Identity &amp; Access Management","text":""},{"location":"usecases/enterprise-plan/#advanced-authentication","title":"Advanced Authentication","text":"<ul> <li>Multi-Factor Authentication: Hardware tokens, biometric authentication</li> <li>Certificate-Based Authentication: X.509 client certificates</li> <li>Risk-Based Authentication: AI-powered authentication decisions</li> <li>Session Management: Advanced session controls and timeout policies</li> </ul>"},{"location":"usecases/enterprise-plan/#privileged-access-management","title":"Privileged Access Management","text":"<ul> <li>Just-in-Time Access: Temporary privilege elevation</li> <li>Break-Glass Procedures: Emergency access with full audit trails</li> <li>Privileged Session Recording: Complete session capture for auditing</li> <li>Automated Access Reviews: AI-assisted access certification</li> </ul>"},{"location":"usecases/enterprise-plan/#data-protection-privacy","title":"Data Protection &amp; Privacy","text":""},{"location":"usecases/enterprise-plan/#advanced-encryption","title":"Advanced Encryption","text":"<ul> <li>Encryption at Rest: AES-256 encryption for all stored data</li> <li>Encryption in Transit: TLS 1.3 for all network communications</li> <li>Key Management: Hardware Security Module (HSM) integration</li> <li>Homomorphic Encryption: Process encrypted data without decryption</li> </ul>"},{"location":"usecases/enterprise-plan/#privacy-controls","title":"Privacy Controls","text":"<ul> <li>Data Residency: Guarantee data stays within specified geographic regions</li> <li>Right to be Forgotten: Automated data deletion capabilities</li> <li>Data Lineage: Track data flow and transformations</li> <li>Consent Management: Automated privacy consent tracking</li> </ul>"},{"location":"usecases/enterprise-plan/#enterprise-support-services","title":"Enterprise Support &amp; Services","text":""},{"location":"usecases/enterprise-plan/#dedicated-support-team","title":"Dedicated Support Team","text":""},{"location":"usecases/enterprise-plan/#technical-account-management","title":"Technical Account Management","text":"<ul> <li>Dedicated TAM: Single point of contact for all technical needs</li> <li>Quarterly Business Reviews: Strategic planning and optimization recommendations</li> <li>Architecture Reviews: Regular assessment of deployment architecture</li> <li>Performance Optimization: Ongoing tuning and optimization services</li> </ul>"},{"location":"usecases/enterprise-plan/#premium-sla","title":"Premium SLA","text":"<ul> <li>24/7 Support: Round-the-clock expert assistance</li> <li>15-minute Response: Critical issue response time guarantee</li> <li>99.99% Uptime SLA: Service level guarantee with penalties</li> <li>Escalation Procedures: Direct access to engineering team</li> </ul>"},{"location":"usecases/enterprise-plan/#summary-of-features-used","title":"Summary of Features Used","text":"Feature Enterprise Plan Usage Governance SSO integration, custom RBAC, and centralized policy management. Cost Management Budget planning per workspace, detailed cost allocation, and fixed-price contracts. Audit Logs Complete, immutable audit logs with long-term retention and SIEM integration. Security Compliance packs (PCI, HIPAA), private networking, and advanced threat detection. Scalability Multi-region, multi-cloud deployments with automated scale-out plans. Backups &amp; DR Advanced, application-aware backup strategies and automated DR testing. AIOps Full suite including predictive scaling, automated root cause analysis, and AI-driven security. Support Dedicated TAM, premium support, and custom SLAs."},{"location":"usecases/on-premise-deployment/","title":"On-Premise Deployment","text":""},{"location":"usecases/on-premise-deployment/#overview","title":"Overview","text":"<p>Hexabase.AI On-Premise deployment enables organizations to run the complete AI-oriented Kubernetes platform within their own data centers, providing maximum control, security, and compliance capabilities. This deployment model is ideal for organizations with strict data sovereignty requirements, regulatory constraints, or security policies that mandate on-premises infrastructure.</p>"},{"location":"usecases/on-premise-deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"usecases/on-premise-deployment/#hardware-requirements","title":"Hardware Requirements","text":""},{"location":"usecases/on-premise-deployment/#minimum-configuration","title":"Minimum Configuration","text":"<p>Control Plane Nodes (3 nodes recommended for HA): - CPU: 8 cores per node - RAM: 32 GB per node - Storage: 500 GB SSD per node - Network: 10 Gbps network interface</p> <p>Worker Nodes (minimum 3 nodes): - CPU: 16 cores per node - RAM: 64 GB per node - Storage: 1 TB NVMe SSD per node - Network: 10 Gbps network interface</p>"},{"location":"usecases/on-premise-deployment/#recommended-production-configuration","title":"Recommended Production Configuration","text":"<p>Control Plane Nodes (3 nodes): - CPU: 16 cores per node - RAM: 64 GB per node - Storage: 1 TB NVMe SSD per node - Network: 25 Gbps network interface</p> <p>Worker Nodes (5+ nodes): - CPU: 32 cores per node - RAM: 128 GB per node - Storage: 2 TB NVMe SSD per node + separate storage network - Network: 25 Gbps network interface</p> <p>GPU Nodes (for AI workloads): - CPU: 32 cores per node - RAM: 256 GB per node - GPU: NVIDIA A100 or H100 series - Storage: 4 TB NVMe SSD per node - Network: 100 Gbps network interface</p>"},{"location":"usecases/on-premise-deployment/#software-requirements","title":"Software Requirements","text":""},{"location":"usecases/on-premise-deployment/#operating-system","title":"Operating System","text":"<ul> <li>Ubuntu: 22.04 LTS or later</li> <li>RHEL/CentOS: 8.x or later</li> <li>SUSE Linux: 15.x or later</li> </ul>"},{"location":"usecases/on-premise-deployment/#required-software","title":"Required Software","text":"<ul> <li>Docker: 24.0+ or containerd 1.7+</li> <li>Kubernetes: 1.28+ (installed via K3s)</li> <li>Helm: 3.12+</li> <li>PostgreSQL: 15+ (can be external)</li> <li>Redis: 7.0+ (can be external)</li> </ul>"},{"location":"usecases/on-premise-deployment/#network-requirements","title":"Network Requirements","text":""},{"location":"usecases/on-premise-deployment/#network-topology","title":"Network Topology","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         DMZ Network                 \u2502\n\u2502    (Load Balancers, Ingress)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Management Network             \u2502\n\u2502   (Control Plane, Monitoring)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Cluster Network               \u2502\n\u2502    (Worker Nodes, Storage)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"usecases/on-premise-deployment/#required-ports","title":"Required Ports","text":"<p>Control Plane: - 6443: Kubernetes API Server - 2379-2380: etcd - 10250: kubelet - 10259: kube-scheduler - 10257: kube-controller-manager</p> <p>Worker Nodes: - 10250: kubelet - 30000-32767: NodePort services - 179: BGP (if using Calico)</p> <p>Hexabase.AI Specific: - 8080: Hexabase.AI API - 5432: PostgreSQL - 6379: Redis - 4222: NATS</p>"},{"location":"usecases/on-premise-deployment/#storage-requirements","title":"Storage Requirements","text":""},{"location":"usecases/on-premise-deployment/#persistent-storage","title":"Persistent Storage","text":"<ul> <li>Distributed Storage: Rook/Ceph or similar</li> <li>NFS: For shared storage requirements</li> <li>Local Storage: NVMe SSDs for high-performance workloads</li> </ul>"},{"location":"usecases/on-premise-deployment/#backup-storage","title":"Backup Storage","text":"<ul> <li>Network Storage: NAS or SAN for backup retention</li> <li>Object Storage: MinIO or external S3-compatible storage</li> </ul>"},{"location":"usecases/on-premise-deployment/#installation-guide","title":"Installation Guide","text":""},{"location":"usecases/on-premise-deployment/#phase-1-infrastructure-preparation","title":"Phase 1: Infrastructure Preparation","text":""},{"location":"usecases/on-premise-deployment/#1-prepare-physical-infrastructure","title":"1. Prepare Physical Infrastructure","text":"<pre><code># Configure network bonding for redundancy\nsudo modprobe bonding\necho \"alias bond0 bonding\" &gt;&gt; /etc/modprobe.conf\n\n# Set up network configuration\ncat &gt; /etc/netplan/01-network.yaml &lt;&lt; EOF\nnetwork:\n  version: 2\n  bonds:\n    bond0:\n      interfaces: [enp1s0, enp2s0]\n      parameters:\n        mode: 802.3ad\n        mii-monitor-interval: 100\n      addresses: [192.168.1.10/24]\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\nEOF\n\nsudo netplan apply\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-configure-storage","title":"2. Configure Storage","text":"<pre><code># Set up Ceph cluster for distributed storage\n# Install cephadm\ncurl --silent --remote-name --location https://github.com/ceph/ceph/raw/quincy/src/cephadm/cephadm\nchmod +x cephadm\nsudo ./cephadm add-repo --release quincy\nsudo ./cephadm install\n\n# Bootstrap Ceph cluster\nsudo cephadm bootstrap --mon-ip 192.168.1.10\n</code></pre>"},{"location":"usecases/on-premise-deployment/#3-load-balancer-setup","title":"3. Load Balancer Setup","text":"<pre><code># Install and configure HAProxy for control plane HA\nsudo apt update &amp;&amp; sudo apt install -y haproxy\n\ncat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOF\nglobal\n    chroot /var/lib/haproxy\n    stats socket /run/haproxy/admin.sock mode 660 level admin\n    stats timeout 30s\n    user haproxy\n    group haproxy\n    daemon\n\ndefaults\n    mode http\n    timeout connect 5000ms\n    timeout client 50000ms\n    timeout server 50000ms\n\nfrontend kubernetes-frontend\n    bind *:6443\n    mode tcp\n    option tcplog\n    default_backend kubernetes-backend\n\nbackend kubernetes-backend\n    mode tcp\n    balance roundrobin\n    server control1 192.168.1.10:6443 check\n    server control2 192.168.1.11:6443 check\n    server control3 192.168.1.12:6443 check\n\nfrontend hexabase-frontend\n    bind *:8080\n    mode tcp\n    option tcplog\n    default_backend hexabase-backend\n\nbackend hexabase-backend\n    mode tcp\n    balance roundrobin\n    server api1 192.168.1.20:8080 check\n    server api2 192.168.1.21:8080 check\n    server api3 192.168.1.22:8080 check\nEOF\n\nsudo systemctl enable haproxy\nsudo systemctl start haproxy\n</code></pre>"},{"location":"usecases/on-premise-deployment/#phase-2-kubernetes-cluster-installation","title":"Phase 2: Kubernetes Cluster Installation","text":""},{"location":"usecases/on-premise-deployment/#1-install-k3s-control-plane","title":"1. Install K3s Control Plane","text":"<pre><code># On first control plane node\ncurl -sfL https://get.k3s.io | sh -s - server \\\n  --cluster-init \\\n  --disable traefik \\\n  --disable servicelb \\\n  --disable metrics-server \\\n  --node-ip=192.168.1.10 \\\n  --cluster-cidr=10.42.0.0/16 \\\n  --service-cidr=10.43.0.0/16 \\\n  --flannel-backend=none\n\n# Get the node token\nsudo cat /var/lib/rancher/k3s/server/node-token\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-join-additional-control-plane-nodes","title":"2. Join Additional Control Plane Nodes","text":"<pre><code># On additional control plane nodes\ncurl -sfL https://get.k3s.io | sh -s - server \\\n  --server https://192.168.1.10:6443 \\\n  --token &lt;NODE_TOKEN&gt; \\\n  --disable traefik \\\n  --disable servicelb \\\n  --disable metrics-server \\\n  --node-ip=192.168.1.11\n\n# Repeat for control plane node 3 with IP 192.168.1.12\n</code></pre>"},{"location":"usecases/on-premise-deployment/#3-join-worker-nodes","title":"3. Join Worker Nodes","text":"<pre><code># On worker nodes\ncurl -sfL https://get.k3s.io | sh -s - agent \\\n  --server https://192.168.1.10:6443 \\\n  --token &lt;NODE_TOKEN&gt; \\\n  --node-ip=192.168.1.20\n\n# Configure kubectl on control plane\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml\nkubectl get nodes\n</code></pre>"},{"location":"usecases/on-premise-deployment/#phase-3-network-and-storage-setup","title":"Phase 3: Network and Storage Setup","text":""},{"location":"usecases/on-premise-deployment/#1-install-calico-cni","title":"1. Install Calico CNI","text":"<pre><code># Install Calico for advanced networking\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml\n\ncat &gt; calico-config.yaml &lt;&lt; EOF\napiVersion: operator.tigera.io/v1\nkind: Installation\nmetadata:\n  name: default\nspec:\n  calicoNetwork:\n    ipPools:\n    - blockSize: 26\n      cidr: 10.42.0.0/16\n      encapsulation: VXLANCrossSubnet\n      natOutgoing: Enabled\n      nodeSelector: all()\nEOF\n\nkubectl apply -f calico-config.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-install-rookceph-storage","title":"2. Install Rook/Ceph Storage","text":"<pre><code># Install Rook operator\nkubectl apply -f https://raw.githubusercontent.com/rook/rook/v1.12.3/deploy/examples/crds.yaml\nkubectl apply -f https://raw.githubusercontent.com/rook/rook/v1.12.3/deploy/examples/common.yaml\nkubectl apply -f https://raw.githubusercontent.com/rook/rook/v1.12.3/deploy/examples/operator.yaml\n\n# Create Ceph cluster\ncat &gt; ceph-cluster.yaml &lt;&lt; EOF\napiVersion: ceph.rook.io/v1\nkind: CephCluster\nmetadata:\n  name: rook-ceph\n  namespace: rook-ceph\nspec:\n  cephVersion:\n    image: quay.io/ceph/ceph:v17.2.6\n  dataDirHostPath: /var/lib/rook\n  skipUpgradeChecks: false\n  continueUpgradeAfterChecksEvenIfNotHealthy: false\n  waitTimeoutForHealthyOSDInMinutes: 10\n  mon:\n    count: 3\n    allowMultiplePerNode: false\n  mgr:\n    count: 2\n    allowMultiplePerNode: false\n  dashboard:\n    enabled: true\n    ssl: true\n  storage:\n    useAllNodes: true\n    useAllDevices: true\n    config:\n      osdsPerDevice: \"1\"\nEOF\n\nkubectl apply -f ceph-cluster.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#phase-4-hexabaseai-platform-installation","title":"Phase 4: Hexabase.AI Platform Installation","text":""},{"location":"usecases/on-premise-deployment/#1-install-postgresql","title":"1. Install PostgreSQL","text":"<pre><code># Create PostgreSQL deployment\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm install postgresql bitnami/postgresql \\\n  --set auth.postgresPassword=hexabase-secure-password \\\n  --set auth.database=hexabase \\\n  --set primary.persistence.size=100Gi \\\n  --set primary.resources.requests.memory=8Gi \\\n  --set primary.resources.requests.cpu=2000m \\\n  --namespace hexabase-system \\\n  --create-namespace\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-install-redis","title":"2. Install Redis","text":"<pre><code># Install Redis for caching and sessions\nhelm install redis bitnami/redis \\\n  --set auth.password=redis-secure-password \\\n  --set master.persistence.size=20Gi \\\n  --set replica.replicaCount=2 \\\n  --namespace hexabase-system\n</code></pre>"},{"location":"usecases/on-premise-deployment/#3-install-nats","title":"3. Install NATS","text":"<pre><code># Install NATS for messaging\nhelm repo add nats https://nats-io.github.io/k8s/helm/charts/\nhelm install nats nats/nats \\\n  --set config.cluster.enabled=true \\\n  --set config.cluster.replicas=3 \\\n  --namespace hexabase-system\n</code></pre>"},{"location":"usecases/on-premise-deployment/#4-install-hexabaseai-platform","title":"4. Install Hexabase.AI Platform","text":"<pre><code># Add Hexabase.AI Helm repository\nhelm repo add hexabase https://charts.hexabase.ai\nhelm repo update\n\n# Create configuration values\ncat &gt; hexabase-values.yaml &lt;&lt; EOF\nglobal:\n  environment: production\n\napi:\n  replicaCount: 3\n  image:\n    repository: hexabase/api\n    tag: \"v1.0.0\"\n  resources:\n    requests:\n      memory: 2Gi\n      cpu: 1000m\n    limits:\n      memory: 4Gi\n      cpu: 2000m\n\nui:\n  replicaCount: 2\n  image:\n    repository: hexabase/ui\n    tag: \"v1.0.0\"\n\npostgres:\n  host: postgresql.hexabase-system.svc.cluster.local\n  database: hexabase\n  username: postgres\n  password: hexabase-secure-password\n\nredis:\n  host: redis-master.hexabase-system.svc.cluster.local\n  password: redis-secure-password\n\nnats:\n  url: nats://nats.hexabase-system.svc.cluster.local:4222\n\nstorage:\n  storageClass: rook-ceph-block\n\nmonitoring:\n  enabled: true\n  grafana:\n    enabled: true\n  prometheus:\n    enabled: true\n\ningress:\n  enabled: true\n  hostname: hexabase.example.com\n  tls:\n    enabled: true\n    secretName: hexabase-tls\nEOF\n\n# Install Hexabase.AI\nhelm install hexabase hexabase/hexabase-ai \\\n  --values hexabase-values.yaml \\\n  --namespace hexabase-system\n</code></pre>"},{"location":"usecases/on-premise-deployment/#phase-5-security-and-ssl-configuration","title":"Phase 5: Security and SSL Configuration","text":""},{"location":"usecases/on-premise-deployment/#1-install-cert-manager","title":"1. Install cert-manager","text":"<pre><code># Install cert-manager for TLS certificate management\nkubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.1/cert-manager.yaml\n\n# Create Let's Encrypt ClusterIssuer\ncat &gt; letsencrypt-issuer.yaml &lt;&lt; EOF\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@example.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\nEOF\n\nkubectl apply -f letsencrypt-issuer.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-configure-network-policies","title":"2. Configure Network Policies","text":"<pre><code># Create network policies for security\ncat &gt; network-policies.yaml &lt;&lt; EOF\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: hexabase-api-policy\n  namespace: hexabase-system\nspec:\n  podSelector:\n    matchLabels:\n      app: hexabase-api\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: hexabase-ui\n    - podSelector:\n        matchLabels:\n          app: nginx-ingress\n    ports:\n    - protocol: TCP\n      port: 8080\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: postgresql\n    ports:\n    - protocol: TCP\n      port: 5432\n  - to:\n    - podSelector:\n        matchLabels:\n          app: redis\n    ports:\n    - protocol: TCP\n      port: 6379\nEOF\n\nkubectl apply -f network-policies.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"usecases/on-premise-deployment/#1-initialize-hexabaseai","title":"1. Initialize Hexabase.AI","text":"<pre><code># Get admin credentials\nkubectl get secret hexabase-admin-credentials \\\n  -n hexabase-system \\\n  -o jsonpath='{.data.username}' | base64 -d\n\nkubectl get secret hexabase-admin-credentials \\\n  -n hexabase-system \\\n  -o jsonpath='{.data.password}' | base64 -d\n\n# Access the platform\necho \"https://hexabase.example.com\"\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-configure-organization-and-workspaces","title":"2. Configure Organization and Workspaces","text":"<pre><code># Use Hexabase CLI to set up initial configuration\ncurl -L https://github.com/hexabase/cli/releases/latest/download/hks-linux-amd64.tar.gz | tar xz\nsudo mv hb /usr/local/bin/\n\n# Configure CLI\nhb config init \\\n  --api-url https://hexabase.example.com \\\n  --username admin \\\n  --password &lt;ADMIN_PASSWORD&gt;\n\n# Create organization\nhb organization create \"My Enterprise\" \\\n  --plan enterprise \\\n  --admin-email admin@example.com\n\n# Create workspace\nhb workspace create production \\\n  --organization \"My Enterprise\" \\\n  --plan dedicated \\\n  --region on-premise\n</code></pre>"},{"location":"usecases/on-premise-deployment/#3-backup-configuration","title":"3. Backup Configuration","text":"<pre><code># Configure automated backups\ncat &gt; backup-config.yaml &lt;&lt; EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: backup-config\n  namespace: hexabase-system\ndata:\n  backup.yaml: |\n    schedule: \"0 2 * * *\"  # Daily at 2 AM\n    retention: \"30d\"\n    destinations:\n      - type: s3\n        endpoint: backup.example.com\n        bucket: hexabase-backups\n        region: us-east-1\n    components:\n      - postgresql\n      - etcd\n      - application-data\nEOF\n\nkubectl apply -f backup-config.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"usecases/on-premise-deployment/#health-checks","title":"Health Checks","text":"<pre><code># Check cluster health\nkubectl get nodes\nkubectl get pods -A\nkubectl top nodes\nkubectl top pods -A\n\n# Check Hexabase.AI specific components\nkubectl get pods -n hexabase-system\nkubectl logs -f deployment/hexabase-api -n hexabase-system\n</code></pre>"},{"location":"usecases/on-premise-deployment/#regular-maintenance-tasks","title":"Regular Maintenance Tasks","text":""},{"location":"usecases/on-premise-deployment/#weekly-tasks","title":"Weekly Tasks","text":"<ul> <li>Review system logs for errors</li> <li>Check resource utilization</li> <li>Verify backup completion</li> <li>Update security patches</li> </ul>"},{"location":"usecases/on-premise-deployment/#monthly-tasks","title":"Monthly Tasks","text":"<ul> <li>Review and rotate credentials</li> <li>Capacity planning assessment</li> <li>Performance optimization</li> <li>Security vulnerability scanning</li> </ul>"},{"location":"usecases/on-premise-deployment/#quarterly-tasks","title":"Quarterly Tasks","text":"<ul> <li>Kubernetes version updates</li> <li>Hexabase.AI platform updates</li> <li>Disaster recovery testing</li> <li>Architecture review</li> </ul>"},{"location":"usecases/on-premise-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usecases/on-premise-deployment/#common-issues","title":"Common Issues","text":""},{"location":"usecases/on-premise-deployment/#1-pod-scheduling-issues","title":"1. Pod Scheduling Issues","text":"<pre><code># Check node resources\nkubectl describe nodes\n\n# Check taints and tolerations\nkubectl describe node &lt;node-name&gt;\n\n# Check resource quotas\nkubectl describe resourcequota -A\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-storage-issues","title":"2. Storage Issues","text":"<pre><code># Check Ceph cluster health\nkubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph status\n\n# Check PVC status\nkubectl get pvc -A\nkubectl describe pvc &lt;pvc-name&gt;\n</code></pre>"},{"location":"usecases/on-premise-deployment/#3-network-connectivity-issues","title":"3. Network Connectivity Issues","text":"<pre><code># Check Calico status\nkubectl get pods -n calico-system\n\n# Test pod-to-pod connectivity\nkubectl run test-pod --image=busybox --rm -it -- /bin/sh\n# Inside pod: ping &lt;target-ip&gt;\n\n# Check network policies\nkubectl get networkpolicies -A\n</code></pre>"},{"location":"usecases/on-premise-deployment/#security-considerations","title":"Security Considerations","text":""},{"location":"usecases/on-premise-deployment/#1-air-gapped-deployment","title":"1. Air-Gapped Deployment","text":"<p>For maximum security, Hexabase.AI can be deployed in completely air-gapped environments:</p> <pre><code># Create local container registry\ndocker run -d -p 5000:5000 --name registry registry:2\n\n# Push Hexabase.AI images to local registry\ndocker tag hexabase/api:v1.0.0 localhost:5000/hexabase/api:v1.0.0\ndocker push localhost:5000/hexabase/api:v1.0.0\n\n# Update Helm values to use local registry\ncat &gt; air-gapped-values.yaml &lt;&lt; EOF\nglobal:\n  imageRegistry: localhost:5000\n\napi:\n  image:\n    repository: localhost:5000/hexabase/api\n    tag: \"v1.0.0\"\nEOF\n</code></pre>"},{"location":"usecases/on-premise-deployment/#2-hardware-security-module-integration","title":"2. Hardware Security Module Integration","text":"<pre><code># Configure HSM for key management\ncat &gt; hsm-config.yaml &lt;&lt; EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hsm-config\n  namespace: hexabase-system\ntype: Opaque\ndata:\n  hsm-endpoint: &lt;base64-encoded-endpoint&gt;\n  hsm-token: &lt;base64-encoded-token&gt;\n  hsm-pin: &lt;base64-encoded-pin&gt;\nEOF\n\nkubectl apply -f hsm-config.yaml\n</code></pre>"},{"location":"usecases/on-premise-deployment/#related-topics","title":"Related Topics","text":"<ul> <li>Enterprise Plan Features - Complete enterprise capabilities</li> <li>Security Architecture - Comprehensive security overview</li> <li>RBAC Configuration - Role-based access control setup</li> <li>Monitoring Setup - Complete observability stack</li> </ul>"},{"location":"usecases/single-user-plan/","title":"Single User Plan Scenarios","text":"<p>This use case outlines the journey of a single developer using Hexabase.AI. We offer two plans for individual developers: Hobby Plan for personal projects and learning, and Pro Plan for production workloads requiring dedicated resources.</p>"},{"location":"usecases/single-user-plan/#goal","title":"Goal","text":"<p>The goal of the Single User Plan is to provide an individual developer with a powerful, cost-effective, and reliable platform to build, test, and deploy applications. It's ideal for personal projects, freelance work, or prototyping a new startup idea without the complexity of managing infrastructure.</p>"},{"location":"usecases/single-user-plan/#1-first-login-and-workspace-setup","title":"1. First Login and Workspace Setup","text":"<ul> <li>Upon signing up, a developer logs in for the first time.</li> <li>A personal workspace, such as <code>dev-workspace</code>, is automatically created.</li> <li>This workspace is a fully isolated environment, providing the developer with a private Kubernetes namespace.</li> </ul>"},{"location":"usecases/single-user-plan/#2-deploying-the-application","title":"2. Deploying the Application","text":"<ul> <li>A developer's application might consist of a Node.js backend and a React frontend.</li> <li>Using the HKS CLI, the developer deploys application containers to the shared node pool. This is a cost-effective option perfect for development and staging.</li> <li>If a database is needed, a PostgreSQL instance can be provisioned from the HKS marketplace, which uses a persistent storage volume. The plan includes a limited amount of high-speed storage.</li> </ul>"},{"location":"usecases/single-user-plan/#3-setting-up-cicd","title":"3. Setting up CI/CD","text":"<ul> <li>The developer connects a personal GitHub repository to the project.</li> <li>A simple CI/CD pipeline is configured using a template:</li> <li>On every <code>git push</code>, the pipeline automatically builds the container images.</li> <li>It runs unit tests.</li> <li>It deploys the new version to a staging environment within the workspace.</li> </ul>"},{"location":"usecases/single-user-plan/#4-leveraging-serverless-and-scheduled-jobs","title":"4. Leveraging Serverless and Scheduled Jobs","text":"<ul> <li>To handle a task like sending a daily summary email, the developer creates a CronJob that triggers a serverless Function once a day.</li> <li>The Function contains the business logic, making it a highly efficient way to run scheduled tasks.</li> </ul>"},{"location":"usecases/single-user-plan/#5-aiops-assistance","title":"5. AIOps Assistance","text":"<ul> <li>If the application experiences a performance issue, the integrated AIOps assistant can detect the anomaly (e.g., a memory leak).</li> <li>It can proactively notify the developer via Slack with a detailed report and a suggestion for remediation, saving hours of troubleshooting.</li> <li>The AIOps features on this plan are focused on core monitoring and anomaly detection.</li> </ul>"},{"location":"usecases/single-user-plan/#6-scaling-up-dedicated-node","title":"6. Scaling Up: Dedicated Node","text":"<ul> <li>As the application gets ready for production, it may require more performance and resource guarantees.</li> <li>The developer can upgrade the plan to include a dedicated node.</li> <li>From the UI, a new dedicated node is provisioned and added to the workspace, allowing the production deployment to be moved for higher performance and isolation.</li> </ul>"},{"location":"usecases/single-user-plan/#summary-of-features","title":"Summary of Features","text":""},{"location":"usecases/single-user-plan/#hobby-plan-features","title":"Hobby Plan Features","text":"Feature Hobby Plan Usage Workspace 1 personal, isolated workspace Nodes Shared node pool only CI/CD Basic template-based pipelines Functions Up to 5 serverless functions CronJobs Up to 10 scheduled jobs Storage 10GB persistent storage AIOps Basic monitoring and alerts Support Community support"},{"location":"usecases/single-user-plan/#pro-plan-features","title":"Pro Plan Features","text":"<p>When you're ready to take your project to production, upgrade to the Pro Plan for enhanced capabilities:</p> Feature Pro Plan Usage Workspace 1 personal workspace with production-grade isolation Nodes 1 dedicated node included (upgradeable) CI/CD Advanced pipelines with parallel builds Functions Unlimited serverless functions CronJobs Unlimited scheduled jobs Storage 100GB high-performance SSD storage AIOps Full AIOps suite: anomaly detection, predictive scaling, cost optimization Backup Automated daily backups with 7-day retention Support Priority email support with 24-hour response time"},{"location":"usecases/single-user-plan/#upgrading-from-hobby-to-pro","title":"Upgrading from Hobby to Pro","text":"<p>The upgrade process is seamless:</p> <ol> <li>Click \"Upgrade to Pro\" in your dashboard</li> <li>Your existing workloads continue running without interruption</li> <li>A dedicated node is provisioned within minutes</li> <li>Migrate critical workloads to the dedicated node for better performance</li> <li>Enjoy enhanced features and support immediately</li> </ol>"},{"location":"usecases/team-plan/","title":"Team Plan Scenario","text":"<p>This use case describes a development team leveraging the Team Plan on Hexabase.AI. This plan is ideal for startups and small-to-medium-sized businesses that need to collaborate on multiple projects with shared infrastructure and governance.</p>"},{"location":"usecases/team-plan/#goal","title":"Goal","text":"<p>The goal of the Team Plan is to provide a collaborative, secure, and governed platform for startups and development teams. It is designed for teams who need to manage multiple projects across different environments (e.g., development, staging, production) with shared infrastructure and clear, role-based access control.</p>"},{"location":"usecases/team-plan/#1-organization-and-team-setup","title":"1. Organization and Team Setup","text":"<ul> <li>An administrator signs up for the Team Plan and creates an organization (e.g., <code>MyStartupInc</code>).</li> <li>The administrator invites DevOps engineers as Org Admins and other team members as Org Users.</li> <li>This role-based access control (RBAC) ensures that only Org Admins can manage billing, create new workspaces, and set organization-wide policies.</li> </ul>"},{"location":"usecases/team-plan/#2-workspace-creation","title":"2. Workspace Creation","text":"<ul> <li>The Org Admins create multiple workspaces to separate environments, such as:</li> <li><code>SaaS-Product-Dev</code>: For daily development and testing.</li> <li><code>SaaS-Product-Staging</code>: A more stable environment for pre-production testing.</li> <li>Admins assign teams and users to these workspaces, granting them appropriate permissions (e.g., <code>workspace-admin</code>, <code>developer</code>).</li> </ul>"},{"location":"usecases/team-plan/#3-resource-management-and-infrastructure","title":"3. Resource Management and Infrastructure","text":"<ul> <li>To support the team's needs, Org Admins provision several dedicated nodes for the organization, which can be shared across workspaces.</li> <li>They also attach high-performance block storage for databases and a separate object storage bucket for automated backups.</li> <li>Resource quotas are set on the development workspace to prevent any single user from consuming excessive resources.</li> </ul>"},{"location":"usecases/team-plan/#4-collaborative-development-and-cicd","title":"4. Collaborative Development and CI/CD","text":"<ul> <li>The team's projects are hosted in a central Git repository like GitLab or GitHub.</li> <li>DevOps engineers set up advanced CI/CD pipelines:</li> <li>Feature branches are automatically deployed to isolated preview environments.</li> <li>Merges to a <code>main</code> branch trigger deployments to the <code>SaaS-Product-Dev</code> workspace.</li> <li>Promotions to staging require a manual approval step from a workspace admin.</li> </ul>"},{"location":"usecases/team-plan/#5-advanced-aiops-and-observability","title":"5. Advanced AIOps and Observability","text":"<ul> <li>The staging and production workspaces have full-featured AIOps enabled.</li> <li>The AIOps assistant analyzes logs, traces, and metrics to provide insights into application performance and potential bottlenecks.</li> <li>It also offers cost-optimization recommendations, suggesting rightsizing for over-provisioned resources.</li> <li>While the team has access to powerful observability tools, this plan has some limitations on the retention period for audit logs compared to the Enterprise plan.</li> </ul>"},{"location":"usecases/team-plan/#6-disaster-recovery-dr-and-backups","title":"6. Disaster Recovery (DR) and Backups","text":"<ul> <li>Org Admins configure a basic disaster recovery plan.</li> <li>Daily snapshots of critical database volumes are automatically taken and stored in a secure, geo-redundant location.</li> <li>The team can easily restore from these backups in case of data loss.</li> </ul>"},{"location":"usecases/team-plan/#summary-of-features-used","title":"Summary of Features Used","text":"Feature Team Plan Usage Organization Centralized management of users, billing, and resources. RBAC Roles for Org Admins and Org Users, providing clear separation of duties. Workspaces Multiple workspaces for different environments (dev, staging). Nodes Ability to provision and share dedicated nodes across workspaces. Storage &amp; Backups Support for advanced storage solutions and automated backup configurations. Disaster Recovery Basic disaster recovery options available. CI/CD Fully functional pipelines with approvals and multi-environment deployments. AIOps Advanced AIOps capabilities for performance tuning and cost optimization. Audit &amp; Security Access to audit logs and security features, with some limitations on retention and scope."},{"location":"usecases-description/common/external-auth-signup/","title":"Sign Up to Hexabase.AI with External Authentication","text":""},{"location":"usecases-description/common/external-auth-signup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Sign Up to Hexabase.AI with External Authentication</p>"},{"location":"usecases-description/common/external-auth-signup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: New User</li> <li>Secondary Actors: Hexabase.AI System, External Authentication Provider (GitHub, Google)</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>User has an account with external authentication provider (GitHub or Google)</li> <li>Internet connection is available</li> <li>User does not have a Hexabase.AI account</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>User accesses the Hexabase.AI official website</li> <li>User clicks the authentication provider's sign-up button</li> <li>The system redirects user to external authentication provider</li> <li>User authenticates with external authentication provider</li> <li>User approves access permissions to Hexabase.AI</li> <li>The system returns user to Hexabase.AI site</li> <li>The system displays account setup screen</li> <li>User selects usage plan</li> <li>User agrees to terms of service and privacy policy</li> <li>The system creates the account</li> <li>The system guides user to dashboard</li> </ol>"},{"location":"usecases-description/common/external-auth-signup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":""},{"location":"usecases-description/common/external-auth-signup/#51-duplicate-with-existing-account","title":"5.1 Duplicate with Existing Account","text":"<ul> <li>7.1a. Email address is already registered</li> <li>7.1b. The system displays \"This account is already registered\"</li> <li>7.1c. User navigates to login page</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#52-authentication-denial-or-cancellation","title":"5.2 Authentication Denial or Cancellation","text":"<ul> <li>5.2a. User cancels authentication with external authentication provider</li> <li>5.2b. The system displays \"Authentication was cancelled\"</li> <li>5.2c. User returns to sign-up page</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#53-external-authentication-service-failure","title":"5.3 External Authentication Service Failure","text":"<ul> <li>3.3a. External authentication provider service is unavailable</li> <li>3.3b. The system displays \"Authentication service is temporarily unavailable\"</li> <li>3.3c. User retries later or selects different authentication provider</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>New user account is created in Hexabase.AI</li> <li>User is logged in</li> <li>Selected plan is applied</li> <li>Integration with external authentication provider is enabled</li> <li>User can access dashboard</li> </ul>"},{"location":"usecases-description/common/external-auth-signup/#7-additional-notes","title":"7. Additional Notes","text":"<ul> <li>For GitHub: Additional steps may occur due to two-factor authentication or private email settings</li> <li>For Google: Additional confirmation may be required for multiple account selection or corporate restrictions </li> </ul>"},{"location":"usecases-description/enterprise/cost-management/","title":"Execute Cost Management and Budget Planning","text":""},{"location":"usecases-description/enterprise/cost-management/#1-use-case-name","title":"1. Use Case Name","text":"<p>Execute Cost Management and Budget Planning</p>"},{"location":"usecases-description/enterprise/cost-management/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Financial Administrator</li> <li>Secondary Actors: IT Department Administrator, Hexabase.AI System, Business Unit Managers</li> </ul>"},{"location":"usecases-description/enterprise/cost-management/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Enterprise plan is already contracted</li> <li>Multiple business unit workspaces exist</li> <li>Company's budget cycle and approval process are defined</li> <li>Cost allocation criteria (business unit, project, labels) are determined</li> </ul>"},{"location":"usecases-description/enterprise/cost-management/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>Financial administrator accesses the \"Cost Management\" dashboard</li> <li>The system displays current overall resource usage and costs</li> <li>Financial administrator navigates to \"Budget Planning\" section</li> <li>Financial administrator starts new fiscal year budget planning</li> <li>Financial administrator sets budget allocation by business unit (Finance-BU: $50,000, Healthcare-Analytics: $80,000)</li> <li>Financial administrator sets resource quotas per workspace based on budget</li> <li>Financial administrator sets alert thresholds (80%, 90% of budget)</li> <li>The system applies budget plan to each workspace</li> <li>Financial administrator navigates to \"Cost Allocation Report\" configuration screen</li> <li>Financial administrator sets cost analysis axes (by business unit, by project, by resource type)</li> <li>Financial administrator enables label-based cost tracking</li> <li>The system generates cost analysis report for the past 3 months</li> <li>Financial administrator configures automatic report delivery (monthly, to each business unit manager)</li> <li>Financial administrator reviews \"Fixed Price Contract\" option and considers migration to annual contract</li> <li>The system enables budget monitoring and alert functions</li> <li>Financial administrator records configuration completion confirmation and next review schedule</li> </ol>"},{"location":"usecases-description/enterprise/cost-management/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Budget Exceeded Alert - 15a. Healthcare-Analytics business unit reaches 80% of budget - 15b. The system sends alerts to financial administrator and business unit manager - 15c. Business unit manager reviews resource usage or requests additional budget - 15d. Financial administrator approves budget adjustment if necessary</p> <p>5b. Resource Quota Shortage - 6a. Resource quotas are insufficient for the set budget - 6b. The system presents recommended resource allocation - 6c. Financial administrator adjusts budget allocation or corrects resource quotas</p> <p>5c. Report Generation Failure - 12a. Report generation fails due to past data inconsistency - 12b. The system identifies data problem areas and displays error report - 12c. IT department administrator executes data correction - 12d. Financial administrator re-executes report generation</p> <p>5d. Approval Process Delay - 14a. Budget approval from business unit managers is not obtained within deadline - 14b. The system displays pending approval status and deadline - 14c. Financial administrator decides on approval reminder or provisional budget application</p>"},{"location":"usecases-description/enterprise/cost-management/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>Annual budget is allocated to each business unit</li> <li>Resource quotas are set for each workspace</li> <li>Budget exceeded alert function is enabled</li> <li>Detailed cost allocation reports are generated regularly</li> <li>Cost tracking by business unit and project is achieved</li> <li>Label-based cost analysis is enabled</li> <li>Financial governance and control are established</li> <li>Fixed price contract option is evaluated and applied if necessary </li> </ul>"},{"location":"usecases-description/enterprise/governance-setup/","title":"Setup Centralized Governance and SSO Integration","text":""},{"location":"usecases-description/enterprise/governance-setup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Setup Centralized Governance and SSO Integration</p>"},{"location":"usecases-description/enterprise/governance-setup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: IT Department Administrator</li> <li>Secondary Actors: Hexabase.AI System, SSO Provider (Okta/Azure AD), Enterprise Users</li> </ul>"},{"location":"usecases-description/enterprise/governance-setup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Enterprise plan is already contracted</li> <li>Existing SSO provider (Okta, Azure AD, etc.) is operational</li> <li>Company's internal organizational structure and role definitions are clarified</li> <li>Personnel with understanding of SAML/OIDC technical specifications are available</li> </ul>"},{"location":"usecases-description/enterprise/governance-setup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>IT department administrator logs into Hexabase.AI enterprise dashboard</li> <li>Administrator accesses \"Organization Settings\" \u2192 \"SSO Integration\" section</li> <li>The system displays SSO configuration wizard</li> <li>Administrator selects SSO provider type (Okta)</li> <li>Administrator enters Okta metadata URL, Entity ID, and certificate information</li> <li>The system executes SSO configuration verification</li> <li>Administrator tests SSO authentication with test user</li> <li>The system confirms SSO authentication success</li> <li>Administrator navigates to \"Custom Role Management\" section</li> <li>Administrator creates custom roles based on company's organizational structure</li> <li>Administrator defines roles corresponding to each department (Finance, Engineering, Operations)</li> <li>Administrator sets detailed permissions (resource creation, deletion, viewing, etc.) for each role</li> <li>The system applies role configuration to RBAC system</li> <li>Administrator configures SSO attribute mapping, mapping Okta group information to Hexabase roles</li> <li>Administrator configures \"Organization Policy\" settings including password requirements, session management, etc.</li> <li>The system saves all configurations and enables SSO integration</li> </ol>"},{"location":"usecases-description/enterprise/governance-setup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. SSO Authentication Failure - 7a. SSO authentication with test user fails - 7b. The system displays detailed error logs (certificate, metadata errors, etc.) - 7c. Administrator reviews and corrects SSO provider settings - 7d. Administrator retests SSO configuration</p> <p>5b. Attribute Mapping Error - 14a. SSO attribute mapping does not work correctly - 14b. User is not authenticated with expected role - 14c. Administrator reviews Okta group settings and mapping configuration - 14d. Administrator corrects attribute mapping and retests</p> <p>5c. Permission Configuration Conflict - 12a. Contradictions or conflicts exist in configured permissions - 12b. The system displays permission conflict warnings - 12c. Administrator reviews permission settings and resolves conflicts</p> <p>5d. Existing User Migration Issues - 16a. After SSO enablement, existing non-SSO users cannot access - 16b. The system presents migration guide and temporary access methods - 16c. Administrator executes phased migration plan</p>"},{"location":"usecases-description/enterprise/governance-setup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>SSO provider and Hexabase.AI are properly integrated</li> <li>Custom roles corresponding to company's internal organizational structure are configured</li> <li>Users can seamlessly authenticate with company's ID provider</li> <li>Fine-grained RBAC permissions are enabled</li> <li>Organization-wide security policies are applied</li> <li>Centralized organizational management is achieved</li> <li>Audit logs are enabled and all activities are recorded </li> </ul>"},{"location":"usecases-description/single-user/application-deployment/","title":"Deploy Application","text":""},{"location":"usecases-description/single-user/application-deployment/#1-use-case-name","title":"1. Use Case Name","text":"<p>Deploy Application</p>"},{"location":"usecases-description/single-user/application-deployment/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: HKS CLI, Hexabase.AI System, Container Registry</li> </ul>"},{"location":"usecases-description/single-user/application-deployment/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer owns a workspace</li> <li>Application (Node.js backend, React frontend) is developed</li> <li>HKS CLI is installed and authentication configuration is completed</li> <li>Docker container image is created</li> </ul>"},{"location":"usecases-description/single-user/application-deployment/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer executes deployment command using HKS CLI</li> <li>The system places the application container in the shared node pool</li> <li>The system pulls the container image from the private registry</li> <li>The system creates Kubernetes deployment and service</li> <li>The developer confirms that a database is needed</li> <li>The developer selects a PostgreSQL instance from the HKS marketplace</li> <li>The system creates persistent storage volume and provisions PostgreSQL</li> <li>The system configures connection between application and database</li> <li>The system displays application URL and access information</li> <li>The developer verifies application operation</li> </ol>"},{"location":"usecases-description/single-user/application-deployment/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Deployment Failure - 4a. Container image pull fails - 4b. The system displays error logs - 4c. The developer checks image existence and access permissions - 4d. The developer executes redeployment after correction</p> <p>5b. Resource Shortage - 2a. Resources are insufficient in the shared node pool - 2b. The system displays waiting status message - 2c. The system automatically continues deployment when resources become available</p> <p>5c. Storage Limit Exceeded - 7a. Persistent storage limit is exceeded - 7b. The system displays limit exceeded error message - 7c. The developer deletes unnecessary data or upgrades the plan</p>"},{"location":"usecases-description/single-user/application-deployment/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>Application is running in the shared node pool</li> <li>PostgreSQL database is provisioned and connected to the application</li> <li>Application is accessible via public URL</li> <li>Resource usage is being monitored </li> </ul>"},{"location":"usecases-description/single-user/cicd-setup/","title":"Setup CI/CD Pipeline","text":""},{"location":"usecases-description/single-user/cicd-setup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Setup CI/CD Pipeline</p>"},{"location":"usecases-description/single-user/cicd-setup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: GitHub Repository, Hexabase.AI System, Container Registry</li> </ul>"},{"location":"usecases-description/single-user/cicd-setup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer owns a workspace</li> <li>Application code exists in a GitHub repository</li> <li>The developer has administrator permissions to the GitHub repository</li> <li>Hexabase.AI account and GitHub account can be linked</li> </ul>"},{"location":"usecases-description/single-user/cicd-setup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer accesses the CI/CD setup screen in the Hexabase.AI dashboard</li> <li>The developer clicks the \"Connect GitHub Repository\" button</li> <li>The system redirects to the GitHub authentication screen</li> <li>The developer approves access permissions on GitHub</li> <li>The system displays a list of available repositories</li> <li>The developer selects the target repository</li> <li>The system displays the CI/CD template selection screen</li> <li>The developer selects the \"Node.js + React\" template</li> <li>The system displays the pipeline configuration details screen</li> <li>The developer reviews and adjusts build and deployment settings</li> <li>The developer clicks the \"Create Pipeline\" button</li> <li>The system configures webhooks in the GitHub repository</li> <li>The system starts the initial pipeline execution</li> <li>The system displays pipeline execution status</li> </ol>"},{"location":"usecases-description/single-user/cicd-setup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. GitHub Authentication Failure - 4a. An error occurs during GitHub authentication - 4b. The system displays an error message - 4c. The developer checks GitHub access permissions - 4d. The developer attempts re-authentication</p> <p>5b. Initial Build Failure - 13a. A build error occurs during initial pipeline execution - 13b. The system displays detailed error logs - 13c. The developer corrects build settings - 13d. The developer manually re-executes the pipeline</p> <p>5c. Repository Access Permission Insufficient - 6a. Access permissions to the selected repository are insufficient - 6b. The system displays a permission shortage message - 6c. The developer reviews and adjusts repository permission settings</p>"},{"location":"usecases-description/single-user/cicd-setup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>GitHub repository and Hexabase.AI are linked</li> <li>CI/CD pipeline is configured</li> <li>Pipeline is configured to automatically execute on <code>git push</code></li> <li>Automatic deployment to staging environment is enabled</li> <li>Pipeline execution history is available for review </li> </ul>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/","title":"Scale Up: Dedicated Node","text":""},{"location":"usecases-description/single-user/dedicated-node-scaleup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Scale Up: Dedicated Node</p>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: Hexabase.AI System, Kubernetes Cluster, Resource Provisioning Service</li> </ul>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer is using the Pro plan</li> <li>The application is ready for production environment</li> <li>More performance and resource guarantees are needed</li> <li>Migration from shared node pool to dedicated resources is being considered</li> </ul>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer accesses the \"Node Management\" section of the dashboard</li> <li>The system displays current resource usage and shared node pool limitations</li> <li>The developer clicks the \"Add Dedicated Node\" button</li> <li>The system displays the dedicated node configuration wizard</li> <li>The developer selects node size (CPU, memory, storage)</li> <li>The system displays estimated monthly cost and performance improvement description</li> <li>The developer confirms node configuration and clicks the \"Start Provisioning\" button</li> <li>The system begins provisioning the dedicated node</li> <li>The system displays provisioning progress in real-time</li> <li>The system displays dedicated node ready notification</li> <li>The developer accesses the \"Workload Migration\" screen</li> <li>The system displays a list of migratable applications and services</li> <li>The developer selects the production deployment</li> <li>The developer clicks the \"Migrate to Dedicated Node\" button</li> <li>The system performs zero-downtime migration</li> <li>The system confirms migration completion and performance improvement</li> <li>The developer verifies application performance on the new dedicated resources</li> </ol>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Dedicated Node Provisioning Failure - 8a. A resource constraint error occurs during dedicated node creation - 8b. The system displays error details and alternative options - 8c. The system suggests retry in a different region - 8d. The developer selects alternative configuration and executes provisioning again</p> <p>5b. Workload Migration Error - 15a. An error occurs during production deployment migration - 15b. The system automatically performs rollback - 15c. The system displays error cause and troubleshooting procedures - 15d. The developer reviews and corrects application configuration - 15e. The developer executes migration process again</p> <p>5c. Resource Shortage Warning - 5c1. The selected node size is insufficient for current workload - 5c2. The system displays recommended size and warning message - 5c3. The developer selects a larger node size - 5c4. Or creates a phased migration plan</p> <p>5d. Performance Issues During Migration - 5d1. Application response time increases during migration - 5d2. The system detects temporary performance degradation and notifies - 5d3. The system pauses the migration process - 5d4. The developer adjusts migration timing and resumes processing</p>"},{"location":"usecases-description/single-user/dedicated-node-scaleup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>A dedicated node is provisioned and available</li> <li>Production deployment is migrated to the dedicated node</li> <li>Application performance is improved</li> <li>Resource isolation is achieved</li> <li>Stable performance guarantee through dedicated resources is provided</li> <li>Higher performance and resource guarantees are available</li> <li>The developer has access to dedicated node monitoring and scaling options</li> <li>Complete isolation from the shared node pool is achieved </li> </ul>"},{"location":"usecases-description/single-user/initial-setup/","title":"First Login and Workspace Setup","text":""},{"location":"usecases-description/single-user/initial-setup/#1-use-case-name","title":"1. Use Case Name","text":"<p>First Login and Workspace Setup</p>"},{"location":"usecases-description/single-user/initial-setup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: Hexabase.AI System</li> </ul>"},{"location":"usecases-description/single-user/initial-setup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer has already signed up for a Hexabase.AI account</li> <li>Internet connection is available</li> <li>Browser or HKS CLI is available</li> </ul>"},{"location":"usecases-description/single-user/initial-setup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer logs into the Hexabase.AI platform</li> <li>The system detects that the user is a new user</li> <li>The system automatically creates a personal workspace (e.g., <code>dev-workspace</code>)</li> <li>The system assigns a private Kubernetes namespace to the developer</li> <li>The system displays the workspace initial setup screen</li> <li>The developer confirms or changes the workspace name</li> <li>The system completes workspace setup</li> <li>The system displays the dashboard and shows available resources and quotas</li> </ol>"},{"location":"usecases-description/single-user/initial-setup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Workspace Creation Failure - 4a. Workspace creation fails due to resource shortage in the system - 4b. The system displays an error message - 4c. The system provides a retry option - 4d. The developer retries or contacts support</p> <p>5b. Network Connection Issues - 1a. Network connection is lost during login - 1b. The system displays a timeout error - 1c. The developer checks connection and attempts login again</p>"},{"location":"usecases-description/single-user/initial-setup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>An isolated workspace dedicated to the developer is created</li> <li>A private Kubernetes namespace is assigned</li> <li>The developer can access the dashboard</li> <li>Resource quotas and limits are configured </li> </ul>"},{"location":"usecases-description/single-user/plan-upgrade/","title":"Upgrade Plan","text":""},{"location":"usecases-description/single-user/plan-upgrade/#1-use-case-name","title":"1. Use Case Name","text":"<p>Upgrade Plan</p>"},{"location":"usecases-description/single-user/plan-upgrade/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: Hexabase.AI System, Payment System, Kubernetes Cluster</li> </ul>"},{"location":"usecases-description/single-user/plan-upgrade/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer is using the Hobby plan</li> <li>The application is ready for production environment migration</li> <li>The developer has payment information (credit card, etc.)</li> <li>Existing workloads are running on shared node pool</li> </ul>"},{"location":"usecases-description/single-user/plan-upgrade/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer accesses the \"Plan\" section of the dashboard</li> <li>The system displays current Hobby plan usage and limitations</li> <li>The developer clicks the \"Upgrade to Pro\" button</li> <li>The system displays Pro plan feature comparison and pricing information</li> <li>The developer clicks the \"Start Upgrade\" button</li> <li>The system displays the payment information input screen</li> <li>The developer enters credit card information</li> <li>The system validates the payment information</li> <li>The developer reviews the terms of service and clicks the agreement checkbox</li> <li>The developer clicks the \"Execute Upgrade\" button</li> <li>The system executes payment processing</li> <li>The system starts the plan upgrade</li> <li>The system begins dedicated node provisioning</li> <li>The system displays upgrade progress</li> <li>The system displays upgrade completion notification</li> <li>The developer verifies enhanced features (unlimited Functions, advanced AIOps)</li> </ol>"},{"location":"usecases-description/single-user/plan-upgrade/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Payment Failure - 11a. Credit card payment fails - 11b. The system displays payment error message - 11c. The developer reviews and corrects payment information - 11d. The developer executes payment processing again</p> <p>5b. Dedicated Node Provisioning Failure - 13a. A resource shortage error occurs during dedicated node creation - 13b. The system displays error status on the dashboard - 13c. The system automatically executes retry - 13d. If retry fails, the support team manually handles the issue</p> <p>5c. Upgrade Interruption - 12a. Network connection is lost during upgrade processing - 12b. The system pauses the upgrade - 12c. After connection recovery, the system automatically resumes processing - 12d. The developer re-confirms the progress</p> <p>5d. Existing Workload Impact - 12a. Existing applications become temporarily inaccessible during upgrade - 12b. The system executes phased migration to minimize impact - 12c. The system restores application access after migration completion</p>"},{"location":"usecases-description/single-user/plan-upgrade/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>The account is changed to Pro plan</li> <li>A dedicated node is provisioned and available</li> <li>Existing workloads continue execution without interruption</li> <li>Unlimited Functions and CronJobs are available</li> <li>Advanced AIOps features (anomaly detection, predictive scaling) are enabled</li> <li>100GB high-performance SSD storage is available</li> <li>Automatic backup is configured</li> <li>99.9% uptime guarantee is applied</li> <li>Priority email support is available </li> </ul>"},{"location":"usecases-description/single-user/serverless-cronjob/","title":"Create Serverless Functions and CronJobs","text":""},{"location":"usecases-description/single-user/serverless-cronjob/#1-use-case-name","title":"1. Use Case Name","text":"<p>Create Serverless Functions and CronJobs</p>"},{"location":"usecases-description/single-user/serverless-cronjob/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Individual Developer</li> <li>Secondary Actors: Hexabase.AI System, Email Service, Kubernetes Scheduler</li> </ul>"},{"location":"usecases-description/single-user/serverless-cronjob/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>The developer owns a workspace</li> <li>The developer has Function creation permissions</li> <li>Business logic for summary email sending is prepared</li> <li>External service configuration for email sending (SMTP or API) is available</li> </ul>"},{"location":"usecases-description/single-user/serverless-cronjob/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>The developer accesses the \"Functions\" section of the Hexabase.AI dashboard</li> <li>The developer clicks the \"Create New Function\" button</li> <li>The system displays the Function creation screen</li> <li>The developer enters the Function name (e.g., <code>daily-summary-email</code>)</li> <li>The developer selects the runtime (Node.js)</li> <li>The developer enters the email sending business logic in the code editor</li> <li>The developer configures environment variables (SMTP settings, API keys, etc.)</li> <li>The developer clicks the \"Create Function\" button</li> <li>The system deploys the Function and makes it executable</li> <li>The developer navigates to the \"CronJobs\" section</li> <li>The developer clicks the \"Create New CronJob\" button</li> <li>The developer enters the schedule (e.g., daily at 9 AM) in cron format</li> <li>The developer selects the previously created Function as the Function to execute</li> <li>The developer clicks the \"Create CronJob\" button</li> <li>The system registers the CronJob with the scheduler</li> <li>The system displays setup completion message and next execution time</li> </ol>"},{"location":"usecases-description/single-user/serverless-cronjob/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Function Execution Error - 9a. An error occurs during Function deployment - 9b. The system displays detailed error logs - 9c. The developer checks code syntax errors or dependencies - 9d. The developer fixes the code and redeploys</p> <p>5b. Environment Variable Configuration Issue - 7a. Required environment variables are not configured - 7b. An error occurs during Function execution - 7c. The system displays environment variable-related error messages - 7d. The developer adds or corrects environment variables</p> <p>5c. CronJob Execution Failure - 15a. The Function fails during the first scheduled execution - 15b. The system logs the error in execution logs - 15c. The developer checks execution logs to identify the error cause - 15d. The developer fixes the Function or CronJob configuration</p> <p>5d. Schedule Format Error - 12a. The entered cron format is invalid - 12b. The system displays a validation error message - 12c. The developer re-enters in correct cron format</p>"},{"location":"usecases-description/single-user/serverless-cronjob/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>A serverless Function is created and deployed</li> <li>A CronJob is registered with the specified schedule</li> <li>The Function is configured to automatically execute at the specified time daily</li> <li>Function execution logs are available for review</li> <li>Alert settings for execution failures are enabled </li> </ul>"},{"location":"usecases-description/team/disaster-recovery-backup/","title":"Disaster Recovery (DR) and Backup User Operations","text":""},{"location":"usecases-description/team/disaster-recovery-backup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Disaster Recovery (DR) and Backup User Operations</p>"},{"location":"usecases-description/team/disaster-recovery-backup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Organization Administrator, DevOps Engineer</li> <li>Secondary Actors: Hexabase.AI System, Backup Service, Storage System</li> </ul>"},{"location":"usecases-description/team/disaster-recovery-backup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Team plan is configured</li> <li>Critical applications and databases are running</li> <li>Organization administrator has appropriate permissions</li> <li>Backup storage is configured</li> </ul>"},{"location":"usecases-description/team/disaster-recovery-backup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>Organization administrator accesses the \"Backup &amp; DR\" section of the organization dashboard</li> <li>The system displays current backup status and configuration options</li> <li>Organization administrator clicks the \"Setup Disaster Recovery Plan\" button</li> <li>The system displays the DR configuration wizard</li> <li>Organization administrator selects critical database volumes (PostgreSQL, MySQL, etc.)</li> <li>Organization administrator sets backup frequency (daily, weekly)</li> <li>Organization administrator selects geographically redundant backup storage location</li> <li>Organization administrator clicks the \"Create Backup Plan\" button</li> <li>The system creates and applies automatic backup schedule</li> <li>The system executes initial full backup</li> <li>Organization administrator monitors backup execution status in real-time</li> <li>The system sends backup completion notification</li> <li>Organization administrator accesses the \"Recovery Test\" function</li> <li>Organization administrator selects test recovery scenario</li> <li>The system executes data recovery test in isolated environment</li> <li>The system displays recovery test results and data integrity report</li> <li>Organization administrator reviews and approves backup configuration and DR plan</li> </ol>"},{"location":"usecases-description/team/disaster-recovery-backup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Backup Execution Failure - 10a. Storage capacity shortage error occurs during initial backup execution - 10b. The system displays error details and storage usage - 10c. Organization administrator upgrades storage plan - 10d. Or deletes unnecessary backup data - 10e. The system re-executes backup processing</p> <p>5b. Geographically Redundant Backup Configuration Error - 7a. Backup storage in the selected geographical location becomes unavailable - 7b. The system displays alternative backup location options - 7c. Organization administrator selects a different geographical location - 7d. The system configures backup settings in the new location</p> <p>5c. Recovery Test Failure - 15a. Data integrity error is detected during data recovery test - 15b. The system displays error details and recommended remediation - 15c. Organization administrator reviews backup configuration - 15d. Organization administrator sets more frequent backup schedule - 15e. The system re-applies improved backup plan</p> <p>5d. Actual Disaster Recovery Operation - Emergency recovery flow during disaster: - 1d. Organization administrator clicks the \"Emergency Recovery\" button - 2d. The system identifies the latest backup data - 3d. Organization administrator selects workspaces and services to recover - 4d. The system starts emergency recovery processing - 5d. The system displays recovery progress in real-time - 6d. The system notifies recovery completion and data integrity confirmation</p> <p>5e. Backup Configuration Change - 6a. Organization administrator wants to change existing backup frequency - 6b. Organization administrator clicks the \"Change Backup Configuration\" button - 6c. The system displays the impact scope of configuration changes - 6d. Organization administrator confirms and approves changes - 6e. The system applies new backup schedule</p>"},{"location":"usecases-description/team/disaster-recovery-backup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>Basic disaster recovery plan is configured</li> <li>Daily automatic backup of critical database volumes is configured</li> <li>Backup data is stored in geographically redundant secure locations</li> <li>Recovery test is successfully completed and data integrity is confirmed</li> <li>Recovery procedures for disaster situations are documented and accessible</li> <li>Backup monitoring and alert functions are enabled</li> <li>Organization members can check backup status</li> <li>System for rapid recovery during emergencies is established </li> </ul>"},{"location":"usecases-description/team/organization-setup/","title":"Setup Organization and Team","text":""},{"location":"usecases-description/team/organization-setup/#1-use-case-name","title":"1. Use Case Name","text":"<p>Setup Organization and Team</p>"},{"location":"usecases-description/team/organization-setup/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Organization Administrator</li> <li>Secondary Actors: Hexabase.AI System, Team Members, Email Delivery System</li> </ul>"},{"location":"usecases-description/team/organization-setup/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Organization administrator has signed up for the team plan</li> <li>Email address list of team members to invite is prepared</li> <li>Basic organization information (company name, industry, etc.) is determined</li> </ul>"},{"location":"usecases-description/team/organization-setup/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>Organization administrator logs into the Hexabase.AI platform</li> <li>The system displays the organization creation wizard</li> <li>Organization administrator enters organization name (e.g., <code>MyStartupInc</code>)</li> <li>Organization administrator selects organization industry and size</li> <li>The system creates the organization and grants organization administrator permissions to the administrator</li> <li>The system displays the team member invitation screen</li> <li>Organization administrator enters DevOps engineer's email address</li> <li>Organization administrator sets \"Organization Administrator\" role for DevOps engineer</li> <li>Organization administrator enters other team members' email addresses</li> <li>Organization administrator sets \"Organization User\" role for other members</li> <li>Organization administrator clicks the \"Send Invitations\" button</li> <li>The system sends invitation emails to each member</li> <li>Team members receive invitation emails and click invitation links</li> <li>Team members complete account creation or login</li> <li>The system adds team members to the organization and grants appropriate roles</li> <li>The system displays organization dashboard and confirms member list</li> </ol>"},{"location":"usecases-description/team/organization-setup/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Invitation Email Sending Failure - 12a. Invitation emails are not sent due to email delivery system issues - 12b. The system displays sending failure message - 12c. Organization administrator manually copies invitation links and shares with members - 12d. Or resends invitations later</p> <p>5b. Duplicate Organization Name - 5a. Entered organization name is already in use - 5b. The system displays error message and alternatives - 5c. Organization administrator enters a different organization name</p> <p>5c. Invitation Acceptance Expired - 14a. Team member does not access invitation link within validity period - 14b. Invitation link becomes invalid - 14c. Organization administrator sends invitation again</p> <p>5d. Permission Setting Error - 8a. Incorrect permissions are granted in role setting - 8b. Organization administrator corrects roles in organization settings screen - 8c. The system applies changed permissions</p>"},{"location":"usecases-description/team/organization-setup/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>Organization is created and organization administrator is configured</li> <li>DevOps engineer has organization administrator permissions</li> <li>Other team members have organization user permissions</li> <li>RBAC (Role-Based Access Control) is enabled</li> <li>All organization members can access the organization dashboard</li> <li>Billing management and resource management permissions are appropriately separated </li> </ul>"},{"location":"usecases-description/team/workspace-management/","title":"Create and Manage Multiple Workspaces","text":""},{"location":"usecases-description/team/workspace-management/#1-use-case-name","title":"1. Use Case Name","text":"<p>Create and Manage Multiple Workspaces</p>"},{"location":"usecases-description/team/workspace-management/#2-actors","title":"2. Actors","text":"<ul> <li>Primary Actor: Organization Administrator</li> <li>Secondary Actors: Hexabase.AI System, Team Members, Kubernetes Cluster</li> </ul>"},{"location":"usecases-description/team/workspace-management/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Organization and team are already configured</li> <li>Organization administrator has organization management permissions</li> <li>Environment separation strategy (development, staging) is planned</li> <li>Dedicated node resources are available</li> </ul>"},{"location":"usecases-description/team/workspace-management/#4-success-scenario-basic-flow","title":"4. Success Scenario (Basic Flow)","text":"<ol> <li>Organization administrator accesses the \"Workspaces\" section of the organization dashboard</li> <li>Organization administrator clicks the \"Create New Workspace\" button</li> <li>The system displays the workspace creation wizard</li> <li>Organization administrator enters workspace name (e.g., <code>SaaS-Product-Dev</code>)</li> <li>Organization administrator selects workspace purpose (development environment)</li> <li>Organization administrator sets resource quotas (CPU, memory, storage)</li> <li>Organization administrator clicks the \"Create Workspace\" button</li> <li>The system creates Kubernetes namespace and applies resource quotas</li> <li>Organization administrator navigates to team member assignment screen</li> <li>Organization administrator selects developers and grants <code>developer</code> permissions</li> <li>Organization administrator grants <code>workspace-admin</code> permissions to DevOps engineer</li> <li>The system applies permission settings and grants access rights to members</li> <li>Organization administrator creates a second workspace (<code>SaaS-Product-Staging</code>) using the same procedure</li> <li>Organization administrator sets higher resource quotas for staging</li> <li>The system confirms completion of both workspace creations</li> <li>Organization administrator navigates to the \"Dedicated Node Management\" screen</li> <li>Organization administrator provisions dedicated nodes</li> <li>The system creates dedicated nodes and configures them to be shareable between workspaces</li> </ol>"},{"location":"usecases-description/team/workspace-management/#5-alternative-scenarios-alternative-flows","title":"5. Alternative Scenarios (Alternative Flows)","text":"<p>5a. Resource Quota Exceeded - 6a. Set resource quotas exceed organization's available resources - 6b. The system displays limit exceeded error message - 6c. Organization administrator adjusts resource allocation - 6d. Or reviews existing workspace quotas</p> <p>5b. Workspace Name Duplication - 4a. Entered workspace name is already in use within the organization - 4b. The system displays duplication error and alternatives - 4c. Organization administrator enters a different workspace name</p> <p>5c. Dedicated Node Provisioning Failure - 17a. Infrastructure error occurs during dedicated node creation - 17b. The system displays error details and troubleshooting information - 17c. Organization administrator contacts support or retries later</p> <p>5d. Permission Grant Error - 11a. Permission grant to team member fails - 11b. The system displays permission error message - 11c. Organization administrator checks member's organization affiliation status - 11d. Organization administrator re-executes permission configuration</p>"},{"location":"usecases-description/team/workspace-management/#6-postconditions","title":"6. Postconditions","text":"<ul> <li>Development workspace (<code>SaaS-Product-Dev</code>) is created</li> <li>Staging workspace (<code>SaaS-Product-Staging</code>) is created</li> <li>Appropriate resource quotas are set for each workspace</li> <li>Team members are assigned to each workspace with appropriate permissions</li> <li>Dedicated nodes are provisioned and shareable between workspaces</li> <li>Environment isolation is achieved</li> <li>Each workspace is independently monitored </li> </ul>"},{"location":"users/cronjobs/examples/","title":"CronJob Examples","text":"<p>This guide provides practical examples of CronJobs for common use cases in Hexabase.AI. Each example includes the complete YAML configuration and explains the key components.</p>"},{"location":"users/cronjobs/examples/#database-backup-jobs","title":"Database Backup Jobs","text":""},{"location":"users/cronjobs/examples/#daily-postgresql-backup","title":"Daily PostgreSQL Backup","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgres-backup-daily\n  namespace: production\nspec:\n  schedule: \"0 2 * * *\" # 2 AM daily\n  concurrencyPolicy: Forbid\n  successfulJobsHistoryLimit: 7\n  failedJobsHistoryLimit: 3\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: postgres-backup\n              image: postgres:14-alpine\n              env:\n                - name: PGPASSWORD\n                  valueFrom:\n                    secretKeyRef:\n                      name: postgres-credentials\n                      key: password\n                - name: BACKUP_DATE\n                  value: $(date +%Y%m%d_%H%M%S)\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  pg_dump -h postgres-service -U postgres -d myapp &gt; /backup/db_${BACKUP_DATE}.sql\n                  gzip /backup/db_${BACKUP_DATE}.sql\n                  aws s3 cp /backup/db_${BACKUP_DATE}.sql.gz s3://my-backups/postgres/\n              volumeMounts:\n                - name: backup-storage\n                  mountPath: /backup\n              resources:\n                requests:\n                  memory: \"256Mi\"\n                  cpu: \"250m\"\n                limits:\n                  memory: \"512Mi\"\n                  cpu: \"500m\"\n          volumes:\n            - name: backup-storage\n              emptyDir: {}\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#mongodb-incremental-backup","title":"MongoDB Incremental Backup","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: mongodb-incremental-backup\n  namespace: production\nspec:\n  schedule: \"0 */6 * * *\" # Every 6 hours\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: mongodump\n              image: mongo:5.0\n              env:\n                - name: MONGO_URI\n                  valueFrom:\n                    secretKeyRef:\n                      name: mongodb-uri\n                      key: connection-string\n              command:\n                - /bin/bash\n                - -c\n                - |\n                  TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n                  mongodump --uri=\"$MONGO_URI\" --archive=/tmp/mongo_backup_${TIMESTAMP}.gz --gzip\n\n                  # Upload to Hexabase.AI object storage\n                  hxb storage upload \\\n                    --source=/tmp/mongo_backup_${TIMESTAMP}.gz \\\n                    --destination=backups/mongodb/${TIMESTAMP}/\n\n                  # Clean up local file\n                  rm /tmp/mongo_backup_${TIMESTAMP}.gz\n              resources:\n                requests:\n                  memory: \"512Mi\"\n                  cpu: \"500m\"\n                limits:\n                  memory: \"1Gi\"\n                  cpu: \"1\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#data-processing-jobs","title":"Data Processing Jobs","text":""},{"location":"users/cronjobs/examples/#etl-pipeline-job","title":"ETL Pipeline Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: etl-pipeline\n  namespace: data-processing\n  labels:\n    app: etl\n    team: data-engineering\nspec:\n  schedule: \"30 1 * * *\" # 1:30 AM daily\n  concurrencyPolicy: Replace\n  startingDeadlineSeconds: 300\n  jobTemplate:\n    spec:\n      activeDeadlineSeconds: 7200 # 2 hour timeout\n      parallelism: 3\n      template:\n        spec:\n          containers:\n            - name: etl-processor\n              image: myregistry/etl-processor:v2.1\n              env:\n                - name: SOURCE_DB\n                  value: \"postgres://source-db:5432/analytics\"\n                - name: TARGET_DB\n                  value: \"clickhouse://analytics-cluster:9000/warehouse\"\n                - name: PROCESSING_DATE\n                  value: \"$(date -d 'yesterday' +%Y-%m-%d)\"\n              command:\n                - python\n                - /app/etl_pipeline.py\n                - --date=$(PROCESSING_DATE)\n                - --mode=incremental\n              resources:\n                requests:\n                  memory: \"2Gi\"\n                  cpu: \"1\"\n                limits:\n                  memory: \"4Gi\"\n                  cpu: \"2\"\n          nodeSelector:\n            workload-type: batch-processing\n          tolerations:\n            - key: batch-processing\n              operator: Equal\n              value: \"true\"\n              effect: NoSchedule\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#data-aggregation-job","title":"Data Aggregation Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hourly-metrics-aggregation\n  namespace: analytics\nspec:\n  schedule: \"5 * * * *\" # 5 minutes past every hour\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: aggregator\n              image: analytics/aggregator:latest\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Calculate hourly metrics\n                  python /scripts/aggregate_metrics.py \\\n                    --start-time=\"$(date -d '1 hour ago' --iso-8601)\" \\\n                    --end-time=\"$(date --iso-8601)\" \\\n                    --output-table=hourly_metrics\n\n                  # Send completion notification\n                  curl -X POST $WEBHOOK_URL \\\n                    -H \"Content-Type: application/json\" \\\n                    -d '{\"status\": \"completed\", \"job\": \"hourly-metrics\"}'\n              env:\n                - name: WEBHOOK_URL\n                  valueFrom:\n                    configMapKeyRef:\n                      name: job-config\n                      key: webhook-url\n              resources:\n                requests:\n                  memory: \"1Gi\"\n                  cpu: \"500m\"\n          restartPolicy: Never\n</code></pre>"},{"location":"users/cronjobs/examples/#maintenance-jobs","title":"Maintenance Jobs","text":""},{"location":"users/cronjobs/examples/#log-cleanup-job","title":"Log Cleanup Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: log-cleanup\n  namespace: system-maintenance\nspec:\n  schedule: \"0 3 * * 0\" # 3 AM every Sunday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: log-cleaner\n          containers:\n            - name: cleanup\n              image: busybox:latest\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Clean up logs older than 30 days\n                  find /var/log/apps -name \"*.log\" -type f -mtime +30 -delete\n\n                  # Compress logs older than 7 days\n                  find /var/log/apps -name \"*.log\" -type f -mtime +7 -exec gzip {} \\;\n\n                  # Report disk usage\n                  df -h /var/log/apps\n              volumeMounts:\n                - name: app-logs\n                  mountPath: /var/log/apps\n              resources:\n                requests:\n                  memory: \"128Mi\"\n                  cpu: \"100m\"\n                limits:\n                  memory: \"256Mi\"\n                  cpu: \"200m\"\n          volumes:\n            - name: app-logs\n              persistentVolumeClaim:\n                claimName: app-logs-pvc\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#certificate-renewal-job","title":"Certificate Renewal Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cert-renewal\n  namespace: cert-manager\nspec:\n  schedule: \"0 0 1 * *\" # Monthly on the 1st\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: cert-renewer\n          containers:\n            - name: certbot\n              image: certbot/certbot:latest\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Check certificate expiration\n                  for domain in app.example.com api.example.com; do\n                    if openssl x509 -checkend 2592000 -noout -in /etc/letsencrypt/live/$domain/cert.pem; then\n                      echo \"Certificate for $domain is still valid\"\n                    else\n                      echo \"Renewing certificate for $domain\"\n                      certbot renew --cert-name $domain --non-interactive\n\n                      # Update Kubernetes secret\n                      kubectl create secret tls ${domain}-tls \\\n                        --cert=/etc/letsencrypt/live/$domain/fullchain.pem \\\n                        --key=/etc/letsencrypt/live/$domain/privkey.pem \\\n                        --dry-run=client -o yaml | kubectl apply -f -\n                    fi\n                  done\n              volumeMounts:\n                - name: letsencrypt\n                  mountPath: /etc/letsencrypt\n              resources:\n                requests:\n                  memory: \"128Mi\"\n                  cpu: \"100m\"\n          volumes:\n            - name: letsencrypt\n              persistentVolumeClaim:\n                claimName: letsencrypt-pvc\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#reporting-jobs","title":"Reporting Jobs","text":""},{"location":"users/cronjobs/examples/#daily-usage-report","title":"Daily Usage Report","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-usage-report\n  namespace: reporting\nspec:\n  schedule: \"0 6 * * *\" # 6 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: report-generator\n              image: reporting/usage-reporter:v1.2\n              env:\n                - name: REPORT_DATE\n                  value: \"$(date -d 'yesterday' +%Y-%m-%d)\"\n                - name: SMTP_HOST\n                  valueFrom:\n                    configMapKeyRef:\n                      name: smtp-config\n                      key: host\n                - name: RECIPIENTS\n                  value: \"team@example.com,manager@example.com\"\n              command:\n                - python\n                - /app/generate_report.py\n                - --date=$(REPORT_DATE)\n                - --format=pdf\n                - --send-email\n              resources:\n                requests:\n                  memory: \"512Mi\"\n                  cpu: \"250m\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#cost-analysis-report","title":"Cost Analysis Report","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: weekly-cost-analysis\n  namespace: finops\nspec:\n  schedule: \"0 9 * * 1\" # 9 AM every Monday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: cost-analyzer\n              image: finops/cost-analyzer:latest\n              command:\n                - /bin/bash\n                - -c\n                - |\n                  # Fetch usage data from Hexabase.AI API\n                  hxb usage export \\\n                    --start-date=\"$(date -d '7 days ago' +%Y-%m-%d)\" \\\n                    --end-date=\"$(date -d 'yesterday' +%Y-%m-%d)\" \\\n                    --format=json &gt; /tmp/usage.json\n\n                  # Generate cost report\n                  python /app/analyze_costs.py \\\n                    --input=/tmp/usage.json \\\n                    --output=/tmp/cost_report.html\n\n                  # Upload to shared storage\n                  hxb storage upload \\\n                    --source=/tmp/cost_report.html \\\n                    --destination=reports/costs/week_$(date +%Y%W).html\n\n                  # Send notification\n                  python /app/send_notification.py \\\n                    --report-url=\"https://storage.hexabase.ai/reports/costs/week_$(date +%Y%W).html\"\n              resources:\n                requests:\n                  memory: \"256Mi\"\n                  cpu: \"200m\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#integration-jobs","title":"Integration Jobs","text":""},{"location":"users/cronjobs/examples/#slack-notification-job","title":"Slack Notification Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-standup-reminder\n  namespace: notifications\nspec:\n  schedule: \"0 9 * * 1-5\" # 9 AM Monday-Friday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: slack-notifier\n              image: curlimages/curl:latest\n              env:\n                - name: SLACK_WEBHOOK\n                  valueFrom:\n                    secretKeyRef:\n                      name: slack-credentials\n                      key: webhook-url\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  curl -X POST $SLACK_WEBHOOK \\\n                    -H 'Content-Type: application/json' \\\n                    -d '{\n                      \"text\": \"\ud83c\udfc3 Daily Standup Reminder\",\n                      \"blocks\": [\n                        {\n                          \"type\": \"header\",\n                          \"text\": {\n                            \"type\": \"plain_text\",\n                            \"text\": \"Time for Daily Standup!\"\n                          }\n                        },\n                        {\n                          \"type\": \"section\",\n                          \"text\": {\n                            \"type\": \"mrkdwn\",\n                            \"text\": \"*Meeting Link:* &lt;https://meet.example.com/standup|Join Here&gt;\\n*Time:* 9:15 AM\"\n                          }\n                        }\n                      ]\n                    }'\n              resources:\n                requests:\n                  memory: \"32Mi\"\n                  cpu: \"50m\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#github-actions-trigger","title":"GitHub Actions Trigger","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: nightly-build-trigger\n  namespace: ci-cd\nspec:\n  schedule: \"0 0 * * *\" # Midnight daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: github-trigger\n              image: ghcr.io/github/gh:latest\n              env:\n                - name: GITHUB_TOKEN\n                  valueFrom:\n                    secretKeyRef:\n                      name: github-token\n                      key: token\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Trigger workflow dispatch\n                  gh workflow run nightly-build.yml \\\n                    --repo myorg/myrepo \\\n                    --ref main \\\n                    --field environment=production \\\n                    --field version=$(date +%Y%m%d)\n              resources:\n                requests:\n                  memory: \"64Mi\"\n                  cpu: \"50m\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#monitoring-jobs","title":"Monitoring Jobs","text":""},{"location":"users/cronjobs/examples/#health-check-job","title":"Health Check Job","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: endpoint-health-check\n  namespace: monitoring\nspec:\n  schedule: \"*/5 * * * *\" # Every 5 minutes\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: health-checker\n              image: monitoring/health-checker:v1.0\n              env:\n                - name: ENDPOINTS\n                  value: \"https://api.example.com/health,https://app.example.com/health\"\n                - name: ALERT_WEBHOOK\n                  valueFrom:\n                    secretKeyRef:\n                      name: alerting-config\n                      key: webhook-url\n              command:\n                - python\n                - /app/check_health.py\n                - --timeout=30\n                - --alert-on-failure\n              resources:\n                requests:\n                  memory: \"128Mi\"\n                  cpu: \"100m\"\n                limits:\n                  memory: \"256Mi\"\n                  cpu: \"200m\"\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#best-practices-examples","title":"Best Practices Examples","text":""},{"location":"users/cronjobs/examples/#job-with-init-container","title":"Job with Init Container","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: data-processor-with-init\n  namespace: batch-jobs\nspec:\n  schedule: \"0 */4 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          initContainers:\n            - name: wait-for-db\n              image: busybox:latest\n              command:\n                [\n                  \"sh\",\n                  \"-c\",\n                  \"until nc -z postgres-service 5432; do sleep 2; done\",\n                ]\n          containers:\n            - name: processor\n              image: data/processor:latest\n              command: [\"/app/process.sh\"]\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#job-with-multiple-containers","title":"Job with Multiple Containers","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: multi-container-job\n  namespace: complex-jobs\nspec:\n  schedule: \"30 2 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: data-fetcher\n              image: fetcher:latest\n              volumeMounts:\n                - name: shared-data\n                  mountPath: /data\n            - name: data-processor\n              image: processor:latest\n              volumeMounts:\n                - name: shared-data\n                  mountPath: /data\n          volumes:\n            - name: shared-data\n              emptyDir: {}\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"users/cronjobs/examples/#related-documentation","title":"Related Documentation","text":"<ul> <li>UI Configuration Guide</li> <li>Integration Patterns</li> <li>CronJob Best Practices</li> <li>Monitoring CronJobs</li> </ul>"},{"location":"users/cronjobs/integration-patterns/","title":"CronJob Integration Patterns","text":"<p>This guide covers common patterns for integrating CronJobs with other Hexabase.AI features and external systems.</p>"},{"location":"users/cronjobs/integration-patterns/#cicd-pipeline-integration","title":"CI/CD Pipeline Integration","text":""},{"location":"users/cronjobs/integration-patterns/#triggering-pipeline-builds","title":"Triggering Pipeline Builds","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: nightly-build-trigger\n  namespace: ci-cd\nspec:\n  schedule: \"0 2 * * *\" # 2 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: pipeline-trigger\n          containers:\n            - name: trigger\n              image: hexabase/cli:latest\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Trigger Hexabase.AI pipeline\n                  hxb pipeline trigger \\\n                    --name=nightly-build \\\n                    --branch=main \\\n                    --params='{\"build_type\": \"release\", \"run_tests\": \"true\"}'\n\n                  # Wait for pipeline to start\n                  PIPELINE_ID=$(hxb pipeline status --name=nightly-build --format=json | jq -r '.latest_run_id')\n\n                  # Monitor pipeline status\n                  hxb pipeline wait --id=$PIPELINE_ID --timeout=3600\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#post-deployment-verification","title":"Post-Deployment Verification","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: deployment-verifier\n  namespace: production\nspec:\n  schedule: \"*/30 * * * *\" # Every 30 minutes\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: verifier\n              image: verification/suite:latest\n              env:\n                - name: DEPLOYMENT_ENV\n                  value: \"production\"\n              command:\n                - python\n                - /app/verify_deployment.py\n                - --checks=health,performance,security\n                - --alert-on-failure\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#function-integration","title":"Function Integration","text":""},{"location":"users/cronjobs/integration-patterns/#scheduled-function-invocation","title":"Scheduled Function Invocation","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: data-processor-function\n  namespace: functions\nspec:\n  schedule: \"0 * * * *\" # Hourly\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: function-invoker\n              image: hexabase/function-runner:latest\n              env:\n                - name: FUNCTION_NAME\n                  value: \"process-hourly-data\"\n                - name: FUNCTION_NAMESPACE\n                  value: \"data-processing\"\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Prepare input data\n                  INPUT_DATA=$(cat &lt;&lt;EOF\n                  {\n                    \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\n                    \"data_source\": \"production-db\",\n                    \"processing_type\": \"incremental\"\n                  }\n                  EOF\n                  )\n\n                  # Invoke function\n                  hxb function invoke \\\n                    --name=$FUNCTION_NAME \\\n                    --namespace=$FUNCTION_NAMESPACE \\\n                    --data=\"$INPUT_DATA\" \\\n                    --wait\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#batch-function-processing","title":"Batch Function Processing","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: batch-function-processor\n  namespace: batch-jobs\nspec:\n  schedule: \"0 3 * * *\" # 3 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: batch-processor\n              image: batch/processor:latest\n              command:\n                - python\n                - -c\n                - |\n                  import json\n                  import subprocess\n                  from datetime import datetime, timedelta\n\n                  # Get items to process\n                  items = fetch_pending_items()\n\n                  # Process in batches\n                  batch_size = 100\n                  for i in range(0, len(items), batch_size):\n                      batch = items[i:i+batch_size]\n\n                      # Invoke function for each batch\n                      result = subprocess.run([\n                          'hxb', 'function', 'invoke',\n                          '--name=batch-processor',\n                          '--data', json.dumps({'items': batch}),\n                          '--async'\n                      ], capture_output=True)\n\n                      print(f\"Processed batch {i//batch_size + 1}\")\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#backup-system-integration","title":"Backup System Integration","text":""},{"location":"users/cronjobs/integration-patterns/#coordinated-backup-strategy","title":"Coordinated Backup Strategy","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: coordinated-backup\n  namespace: backup-system\nspec:\n  schedule: \"0 1 * * *\" # 1 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: backup-coordinator\n              image: backup/coordinator:latest\n              command:\n                - /bin/bash\n                - -c\n                - |\n                  # 1. Trigger application backup\n                  hxb backup create \\\n                    --type=application \\\n                    --name=daily-app-backup \\\n                    --retention=30d\n\n                  # 2. Backup persistent volumes\n                  for pvc in $(kubectl get pvc -o name); do\n                    hxb backup create \\\n                      --type=volume \\\n                      --source=$pvc \\\n                      --name=daily-${pvc##*/}-backup\n                  done\n\n                  # 3. Export configuration\n                  kubectl get all,cm,secret -o yaml &gt; /tmp/k8s-config-backup.yaml\n                  hxb storage upload \\\n                    --source=/tmp/k8s-config-backup.yaml \\\n                    --destination=backups/config/$(date +%Y%m%d).yaml\n\n                  # 4. Verify backups\n                  hxb backup verify --created-after=\"1 hour ago\"\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#cross-region-replication","title":"Cross-Region Replication","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: backup-replication\n  namespace: disaster-recovery\nspec:\n  schedule: \"0 4 * * *\" # 4 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: replicator\n              image: backup/replicator:latest\n              env:\n                - name: SOURCE_REGION\n                  value: \"us-east-1\"\n                - name: TARGET_REGIONS\n                  value: \"eu-west-1,ap-southeast-1\"\n              command:\n                - /app/replicate_backups.sh\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#monitoring-integration","title":"Monitoring Integration","text":""},{"location":"users/cronjobs/integration-patterns/#metrics-collection","title":"Metrics Collection","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: custom-metrics-collector\n  namespace: monitoring\nspec:\n  schedule: \"*/5 * * * *\" # Every 5 minutes\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: collector\n              image: monitoring/collector:latest\n              command:\n                - python\n                - /app/collect_metrics.py\n                - |\n                  # Collect custom metrics\n                  metrics = {\n                      \"active_users\": count_active_users(),\n                      \"api_usage\": get_api_usage_stats(),\n                      \"resource_utilization\": calculate_resource_usage()\n                  }\n\n                  # Push to monitoring system\n                  push_to_prometheus(metrics)\n\n                  # Store in ClickHouse for analytics\n                  store_in_clickhouse(metrics)\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#alert-aggregation","title":"Alert Aggregation","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: alert-digest\n  namespace: monitoring\nspec:\n  schedule: \"0 8 * * 1-5\" # 8 AM weekdays\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: alert-aggregator\n              image: monitoring/alert-digest:latest\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  # Fetch alerts from last 24 hours\n                  ALERTS=$(hxb monitoring alerts list \\\n                    --since=\"24h ago\" \\\n                    --format=json)\n\n                  # Generate digest\n                  python /app/generate_digest.py \\\n                    --alerts=\"$ALERTS\" \\\n                    --output=/tmp/alert_digest.html\n\n                  # Send digest email\n                  hxb notify send \\\n                    --type=email \\\n                    --recipients=ops-team@example.com \\\n                    --subject=\"Daily Alert Digest\" \\\n                    --body-file=/tmp/alert_digest.html\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#event-driven-patterns","title":"Event-Driven Patterns","text":""},{"location":"users/cronjobs/integration-patterns/#webhook-processor","title":"Webhook Processor","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: webhook-processor\n  namespace: integrations\nspec:\n  schedule: \"*/10 * * * *\" # Every 10 minutes\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: webhook-handler\n              image: integrations/webhook-processor:latest\n              env:\n                - name: WEBHOOK_QUEUE\n                  value: \"pending-webhooks\"\n              command:\n                - python\n                - /app/process_webhooks.py\n                - --batch-size=50\n                - --retry-failed=true\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#event-stream-consumer","title":"Event Stream Consumer","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: event-consumer\n  namespace: event-processing\nspec:\n  schedule: \"*/5 * * * *\" # Every 5 minutes\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: consumer\n              image: events/consumer:latest\n              command:\n                - /app/consume_events.sh\n                - --stream=application-events\n                - --checkpoint-interval=1000\n                - --max-runtime=280s # Stop before next run\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#external-service-integration","title":"External Service Integration","text":""},{"location":"users/cronjobs/integration-patterns/#slack-notifications","title":"Slack Notifications","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: slack-reporter\n  namespace: notifications\nspec:\n  schedule: \"0 9 * * 1\" # 9 AM every Monday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: slack-bot\n              image: notifications/slack-bot:latest\n              env:\n                - name: SLACK_WEBHOOK_URL\n                  valueFrom:\n                    secretKeyRef:\n                      name: slack-config\n                      key: webhook-url\n              command:\n                - python\n                - /app/weekly_report.py\n                - --format=slack\n                - --channel=#weekly-updates\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#email-reports","title":"Email Reports","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: email-reporter\n  namespace: reporting\nspec:\n  schedule: \"0 6 * * *\" # 6 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: emailer\n              image: reporting/emailer:latest\n              env:\n                - name: SMTP_CONFIG\n                  valueFrom:\n                    secretKeyRef:\n                      name: smtp-config\n                      key: connection-string\n              command:\n                - /app/send_daily_report.sh\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#data-pipeline-integration","title":"Data Pipeline Integration","text":""},{"location":"users/cronjobs/integration-patterns/#etl-orchestration","title":"ETL Orchestration","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: etl-orchestrator\n  namespace: data-pipelines\nspec:\n  schedule: \"0 2 * * *\" # 2 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: orchestrator\n              image: data/orchestrator:latest\n              command:\n                - python\n                - /app/orchestrate_etl.py\n                - |\n                  # Step 1: Extract data\n                  extract_job = trigger_job(\"data-extractor\")\n                  wait_for_completion(extract_job)\n\n                  # Step 2: Transform data\n                  transform_jobs = []\n                  for dataset in get_datasets():\n                      job = trigger_job(\"data-transformer\", params={\"dataset\": dataset})\n                      transform_jobs.append(job)\n\n                  wait_for_all(transform_jobs)\n\n                  # Step 3: Load data\n                  load_job = trigger_job(\"data-loader\")\n                  wait_for_completion(load_job)\n\n                  # Step 4: Validate\n                  validate_job = trigger_job(\"data-validator\")\n                  wait_for_completion(validate_job)\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#stream-processing-bridge","title":"Stream Processing Bridge","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: stream-batch-bridge\n  namespace: data-processing\nspec:\n  schedule: \"*/15 * * * *\" # Every 15 minutes\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: bridge\n              image: streaming/bridge:latest\n              command:\n                - /app/bridge.sh\n                - --source=kafka://streaming-cluster\n                - --destination=clickhouse://analytics-db\n                - --batch-window=15m\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#security-integration","title":"Security Integration","text":""},{"location":"users/cronjobs/integration-patterns/#certificate-rotation","title":"Certificate Rotation","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cert-rotator\n  namespace: security\nspec:\n  schedule: \"0 0 * * 0\" # Weekly on Sunday\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: cert-manager\n          containers:\n            - name: rotator\n              image: security/cert-rotator:latest\n              command:\n                - /app/rotate_certs.sh\n                - --check-expiry=30d\n                - --auto-renew=true\n                - --update-secrets=true\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#security-scanning","title":"Security Scanning","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: security-scanner\n  namespace: security\nspec:\n  schedule: \"0 3 * * *\" # 3 AM daily\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: scanner\n              image: security/scanner:latest\n              command:\n                - /app/scan.sh\n                - --scan-images=true\n                - --scan-configs=true\n                - --scan-secrets=true\n                - --report-critical=true\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#best-practices","title":"Best Practices","text":""},{"location":"users/cronjobs/integration-patterns/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: robust-job\n  namespace: production\nspec:\n  schedule: \"0 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: worker\n              image: myapp/worker:latest\n              command:\n                - /bin/bash\n                - -c\n                - |\n                  set -e  # Exit on error\n\n                  # Error handling function\n                  handle_error() {\n                      echo \"Error occurred: $1\"\n                      # Send alert\n                      curl -X POST $ALERT_WEBHOOK \\\n                        -d \"{\\\"error\\\": \\\"$1\\\", \\\"job\\\": \\\"$JOB_NAME\\\"}\"\n                      exit 1\n                  }\n\n                  # Set trap for errors\n                  trap 'handle_error \"Unexpected error\"' ERR\n\n                  # Main job logic\n                  process_data || handle_error \"Data processing failed\"\n                  validate_results || handle_error \"Validation failed\"\n\n                  echo \"Job completed successfully\"\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#idempotent-job-pattern","title":"Idempotent Job Pattern","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: idempotent-job\n  namespace: data-processing\nspec:\n  schedule: \"*/30 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: processor\n              image: data/processor:latest\n              command:\n                - python\n                - -c\n                - |\n                  # Check if job already ran\n                  last_run = get_last_successful_run()\n                  if last_run and last_run &gt; datetime.now() - timedelta(minutes=30):\n                      print(\"Job already completed in this window\")\n                      exit(0)\n\n                  # Process with idempotency key\n                  process_id = generate_idempotency_key()\n                  if not start_processing(process_id):\n                      print(\"Another instance is processing\")\n                      exit(0)\n\n                  # Perform work\n                  try:\n                      do_work()\n                      mark_success(process_id)\n                  except Exception as e:\n                      mark_failure(process_id, str(e))\n                      raise\n</code></pre>"},{"location":"users/cronjobs/integration-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>CronJob Examples</li> <li>UI Configuration</li> <li>Function Development</li> <li>Pipeline Configuration</li> </ul>"},{"location":"users/cronjobs/ui-configuration/","title":"CronJob UI Configuration","text":"<p>The Hexabase.AI platform provides an intuitive web interface for managing CronJobs without requiring direct YAML manipulation. This guide covers all aspects of configuring CronJobs through the UI.</p>"},{"location":"users/cronjobs/ui-configuration/#accessing-the-cronjob-interface","title":"Accessing the CronJob Interface","text":""},{"location":"users/cronjobs/ui-configuration/#navigation","title":"Navigation","text":"<ol> <li>Log in to the Hexabase.AI console</li> <li>Select your workspace</li> <li>Navigate to Workloads \u2192 CronJobs</li> </ol>"},{"location":"users/cronjobs/ui-configuration/#creating-a-new-cronjob","title":"Creating a New CronJob","text":""},{"location":"users/cronjobs/ui-configuration/#basic-configuration","title":"Basic Configuration","text":""},{"location":"users/cronjobs/ui-configuration/#1-job-identity","title":"1. Job Identity","text":"<ul> <li>Name: Unique identifier for your CronJob</li> <li>Namespace: Target namespace for execution</li> <li>Labels: Key-value pairs for organization</li> <li>Annotations: Metadata for integrations</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#2-schedule-configuration","title":"2. Schedule Configuration","text":"<p>The UI provides multiple ways to define schedules:</p> <p>Visual Schedule Builder</p> <ul> <li>Select frequency: Minutely, Hourly, Daily, Weekly, Monthly</li> <li>Choose specific times/days through dropdowns</li> <li>Preview the generated cron expression</li> </ul> <p>Cron Expression Editor</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6)\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre> <p>Common Schedules Quick Select</p> <ul> <li>Every hour: <code>0 * * * *</code></li> <li>Daily at midnight: <code>0 0 * * *</code></li> <li>Weekly on Sunday: <code>0 0 * * 0</code></li> <li>Monthly on the 1<sup>st</sup>: <code>0 0 1 * *</code></li> </ul>"},{"location":"users/cronjobs/ui-configuration/#job-template-configuration","title":"Job Template Configuration","text":""},{"location":"users/cronjobs/ui-configuration/#container-settings","title":"Container Settings","text":"<ol> <li> <p>Image Selection</p> </li> <li> <p>Repository browser</p> </li> <li>Tag selection with version history</li> <li> <p>Private registry support</p> </li> <li> <p>Command and Arguments</p> </li> </ol> <pre><code>Command: [\"/bin/sh\"]\nArgs: [\"-c\", \"echo 'Job executed at $(date)'\"]\n</code></pre> <ol> <li>Environment Variables</li> <li>Key-value editor</li> <li>Secret/ConfigMap references</li> <li>Import from existing deployments</li> </ol>"},{"location":"users/cronjobs/ui-configuration/#resource-management","title":"Resource Management","text":"<p>Plan-based Limits:</p> Plan CPU Request Memory Request CPU Limit Memory Limit Single 100m 128Mi 500m 512Mi Team 250m 256Mi 1 CPU 1Gi Enterprise Configurable Configurable Custom Custom <p>UI Resource Sliders:</p> <ul> <li>Visual representation of resource allocation</li> <li>Real-time cost impact display</li> <li>Recommendations based on job history</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"users/cronjobs/ui-configuration/#concurrency-policy","title":"Concurrency Policy","text":"<ul> <li>Allow (default): Run jobs concurrently</li> <li>Forbid: Skip if previous still running</li> <li>Replace: Cancel previous and start new</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#job-history-limits","title":"Job History Limits","text":"<ul> <li>Successful job history: 1-10 (default: 3)</li> <li>Failed job history: 1-10 (default: 1)</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#deadline-and-timeout","title":"Deadline and Timeout","text":"<ul> <li>Starting deadline seconds</li> <li>Active deadline seconds</li> <li>Backoff limit for retries</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#managing-existing-cronjobs","title":"Managing Existing CronJobs","text":""},{"location":"users/cronjobs/ui-configuration/#list-view-features","title":"List View Features","text":"<ul> <li>Status indicators (Active/Suspended)</li> <li>Last schedule time</li> <li>Next scheduled run</li> <li>Quick actions menu</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#filtering-and-search","title":"Filtering and Search","text":"<ul> <li>By name, namespace, labels</li> <li>By schedule frequency</li> <li>By job status</li> <li>By resource usage</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#bulk-operations","title":"Bulk Operations","text":"<ul> <li>Suspend/Resume multiple jobs</li> <li>Delete with confirmation</li> <li>Export configurations</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#job-execution-monitoring","title":"Job Execution Monitoring","text":""},{"location":"users/cronjobs/ui-configuration/#execution-history-view","title":"Execution History View","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Job Name: backup-database                   \u2502\n\u2502 Schedule: 0 2 * * *                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Execution \u2502 Start Time  \u2502 Duration \u2502 Status \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 #125      \u2502 2:00:03 AM  \u2502 5m 23s   \u2502 \u2713      \u2502\n\u2502 #124      \u2502 2:00:01 AM  \u2502 5m 19s   \u2502 \u2713      \u2502\n\u2502 #123      \u2502 2:00:05 AM  \u2502 --       \u2502 \u2717      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#live-job-monitoring","title":"Live Job Monitoring","text":"<ul> <li>Real-time log streaming</li> <li>Resource usage graphs</li> <li>Pod status tracking</li> <li>Event timeline</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#ui-workflows","title":"UI Workflows","text":""},{"location":"users/cronjobs/ui-configuration/#quick-create-wizard","title":"Quick Create Wizard","text":"<ol> <li> <p>Template Selection</p> </li> <li> <p>Database backup</p> </li> <li>Report generation</li> <li>Data synchronization</li> <li> <p>Cleanup tasks</p> </li> <li> <p>Customization</p> </li> <li> <p>Modify template parameters</p> </li> <li>Adjust schedule</li> <li> <p>Set notifications</p> </li> <li> <p>Review and Deploy</p> </li> <li>Configuration summary</li> <li>Validation warnings</li> <li>Cost estimation</li> </ol>"},{"location":"users/cronjobs/ui-configuration/#importexport-features","title":"Import/Export Features","text":"<p>Import Options:</p> <ul> <li>Upload YAML files</li> <li>Import from Git repository</li> <li>Copy from existing CronJob</li> </ul> <p>Export Formats:</p> <ul> <li>YAML configuration</li> <li>Helm chart values</li> <li>Terraform resources</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#notifications-and-alerts","title":"Notifications and Alerts","text":""},{"location":"users/cronjobs/ui-configuration/#email-notifications","title":"Email Notifications","text":"<p>Configure alerts for:</p> <ul> <li>Job failures</li> <li>Execution delays</li> <li>Success confirmations</li> <li>Resource limit warnings</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#webhook-integration","title":"Webhook Integration","text":"<pre><code>{\n  \"webhook_url\": \"https://hooks.slack.com/services/...\",\n  \"events\": [\"failure\", \"success\"],\n  \"include_logs\": true\n}\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#best-practices-for-ui-configuration","title":"Best Practices for UI Configuration","text":""},{"location":"users/cronjobs/ui-configuration/#1-use-descriptive-names","title":"1. Use Descriptive Names","text":"<pre><code>Good: daily-user-report-generator\nBad: cronjob-1\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#2-label-consistently","title":"2. Label Consistently","text":"<pre><code>app: reporting\nenvironment: production\nschedule: daily\nowner: data-team\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#3-set-appropriate-timeouts","title":"3. Set Appropriate Timeouts","text":"<ul> <li>Short jobs: 300 seconds</li> <li>Medium jobs: 1800 seconds</li> <li>Long-running jobs: 3600+ seconds</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#4-configure-history-limits","title":"4. Configure History Limits","text":"<ul> <li>Keep more failed job history for debugging</li> <li>Limit successful job history to save resources</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#5-test-schedules","title":"5. Test Schedules","text":"<p>Use the \"Run Now\" button to test jobs before scheduling</p>"},{"location":"users/cronjobs/ui-configuration/#troubleshooting-ui-issues","title":"Troubleshooting UI Issues","text":""},{"location":"users/cronjobs/ui-configuration/#common-problems","title":"Common Problems","text":"<ol> <li> <p>Schedule Not Triggering</p> </li> <li> <p>Verify timezone settings</p> </li> <li>Check cron expression syntax</li> <li> <p>Ensure CronJob is not suspended</p> </li> <li> <p>Resource Allocation Errors</p> </li> <li> <p>Review namespace quotas</p> </li> <li>Check node availability</li> <li> <p>Verify plan limits</p> </li> <li> <p>Image Pull Failures</p> </li> <li>Confirm registry credentials</li> <li>Verify image exists</li> <li>Check network policies</li> </ol>"},{"location":"users/cronjobs/ui-configuration/#ui-performance-tips","title":"UI Performance Tips","text":"<ul> <li>Use pagination for large job lists</li> <li>Apply filters to reduce data load</li> <li>Export configurations for bulk editing</li> </ul>"},{"location":"users/cronjobs/ui-configuration/#integration-with-other-features","title":"Integration with Other Features","text":""},{"location":"users/cronjobs/ui-configuration/#cicd-pipeline-triggers","title":"CI/CD Pipeline Triggers","text":"<p>Create CronJobs that trigger pipeline runs:</p> <pre><code>Container Command:\n  - curl\n  - -X\n  - POST\n  - https://api.hexabase.ai/pipelines/trigger\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#function-invocation","title":"Function Invocation","text":"<p>Schedule serverless function execution:</p> <pre><code>Container Command:\n  - hxb\n  - function\n  - invoke\n  - --name=process-daily-data\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#backup-integration","title":"Backup Integration","text":"<p>Coordinate with Hexabase.AI backup system:</p> <pre><code>Container Command:\n  - hxb\n  - backup\n  - create\n  - --type=incremental\n</code></pre>"},{"location":"users/cronjobs/ui-configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>CronJob Examples</li> <li>Integration Patterns</li> <li>Monitoring CronJobs</li> <li>RBAC for CronJobs</li> </ul>"},{"location":"users/functions/ai-agent-functions/","title":"AI Agent Functions","text":"<p>Hexabase.AI's AI Agent Functions enable intelligent automation and decision-making within your serverless functions. This guide covers the integration of AI capabilities into your function workflows.</p>"},{"location":"users/functions/ai-agent-functions/#overview","title":"Overview","text":"<p>AI Agent Functions combine the power of serverless computing with large language models (LLMs) and intelligent agents to:</p> <ul> <li>Process natural language inputs</li> <li>Make context-aware decisions</li> <li>Automate complex workflows</li> <li>Generate dynamic responses</li> <li>Integrate with external AI services</li> </ul>"},{"location":"users/functions/ai-agent-functions/#ai-agent-types","title":"AI Agent Types","text":""},{"location":"users/functions/ai-agent-functions/#1-task-automation-agents","title":"1. Task Automation Agents","text":""},{"location":"users/functions/ai-agent-functions/#code-generation-agent","title":"Code Generation Agent","text":"<pre><code>// functions/code-generator/index.js\nconst { AIAgent } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new AIAgent({\n    type: \"code-generator\",\n    model: \"gpt-4\",\n    temperature: 0.7,\n  });\n\n  const { description, language, framework } = event.body;\n\n  const prompt = `\n    Generate ${language} code using ${framework} that:\n    ${description}\n\n    Include error handling and comments.\n  `;\n\n  const response = await agent.generate({\n    prompt,\n    maxTokens: 2000,\n    stopSequences: [\"```\"],\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      code: response.content,\n      language,\n      framework,\n      suggestions: response.metadata.suggestions,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#data-processing-agent","title":"Data Processing Agent","text":"<pre><code># functions/data-processor/main.py\nfrom hexabase.agents import DataAgent\nimport pandas as pd\n\ndef handler(event, context):\n    agent = DataAgent(\n        capabilities=['analyze', 'transform', 'summarize']\n    )\n\n    # Process incoming data\n    data = pd.DataFrame(event['data'])\n\n    # AI-powered analysis\n    analysis = agent.analyze(data, {\n        'identify': ['patterns', 'anomalies', 'trends'],\n        'generate': ['insights', 'recommendations']\n    })\n\n    # Transform data based on AI insights\n    transformed = agent.transform(data, analysis['recommendations'])\n\n    return {\n        'statusCode': 200,\n        'body': {\n            'analysis': analysis,\n            'transformed_data': transformed.to_dict(),\n            'summary': agent.summarize(analysis)\n        }\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#2-conversational-agents","title":"2. Conversational Agents","text":""},{"location":"users/functions/ai-agent-functions/#customer-support-agent","title":"Customer Support Agent","text":"<pre><code>// functions/support-agent/index.js\nconst { ConversationalAgent } = require(\"@hexabase/ai-agents\");\nconst { KnowledgeBase } = require(\"@hexabase/knowledge\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new ConversationalAgent({\n    personality: \"helpful, professional\",\n    knowledgeBase: new KnowledgeBase(\"support-docs\"),\n    contextWindow: 10,\n  });\n\n  const { message, conversationId, userId } = event.body;\n\n  // Load conversation history\n  const history = await agent.loadHistory(conversationId);\n\n  // Generate contextual response\n  const response = await agent.respond({\n    message,\n    history,\n    context: {\n      userId,\n      userTier: event.headers[\"x-user-tier\"],\n      timestamp: new Date().toISOString(),\n    },\n  });\n\n  // Store conversation\n  await agent.saveInteraction(conversationId, {\n    user: message,\n    assistant: response.message,\n    metadata: response.metadata,\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      message: response.message,\n      suggestions: response.suggestions,\n      confidence: response.confidence,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#interactive-assistant","title":"Interactive Assistant","text":"<pre><code># functions/interactive-assistant/main.py\nfrom hexabase.agents import InteractiveAgent\nfrom hexabase.tools import ToolRegistry\n\ndef handler(event, context):\n    # Initialize agent with tools\n    tools = ToolRegistry()\n    tools.register('search_database', search_db)\n    tools.register('send_email', send_email)\n    tools.register('create_ticket', create_ticket)\n\n    agent = InteractiveAgent(\n        tools=tools,\n        planning_enabled=True\n    )\n\n    query = event['body']['query']\n\n    # Agent plans and executes actions\n    plan = agent.plan(query)\n    results = []\n\n    for step in plan.steps:\n        result = agent.execute(step)\n        results.append(result)\n\n        # Dynamic replanning based on results\n        if result.requires_replanning:\n            plan = agent.replan(query, results)\n\n    return {\n        'statusCode': 200,\n        'body': {\n            'query': query,\n            'plan': plan.to_dict(),\n            'results': results,\n            'summary': agent.summarize_actions(results)\n        }\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#3-decision-making-agents","title":"3. Decision-Making Agents","text":""},{"location":"users/functions/ai-agent-functions/#approval-workflow-agent","title":"Approval Workflow Agent","text":"<pre><code>// functions/approval-agent/index.js\nconst { DecisionAgent } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new DecisionAgent({\n    rules: \"approval-policies\",\n    model: \"gpt-4\",\n    confidence_threshold: 0.85,\n  });\n\n  const request = event.body;\n\n  // Analyze request\n  const analysis = await agent.analyze({\n    request,\n    historicalData: await fetchHistoricalData(request.type),\n    policies: await loadPolicies(request.department),\n  });\n\n  // Make decision\n  const decision = await agent.decide({\n    factors: analysis.factors,\n    risk_score: analysis.risk,\n    compliance: analysis.compliance_check,\n  });\n\n  // Generate explanation\n  const explanation = await agent.explain(decision);\n\n  // Auto-approve if confidence is high\n  if (decision.confidence &gt;= 0.85) {\n    await processApproval(request, decision);\n  } else {\n    await escalateToHuman(request, decision, explanation);\n  }\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      decision: decision.outcome,\n      confidence: decision.confidence,\n      explanation: explanation.summary,\n      factors: explanation.key_factors,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#resource-optimization-agent","title":"Resource Optimization Agent","text":"<pre><code># functions/resource-optimizer/main.py\nfrom hexabase.agents import OptimizationAgent\nimport numpy as np\n\ndef handler(event, context):\n    agent = OptimizationAgent(\n        objectives=['cost', 'performance', 'reliability']\n    )\n\n    # Current resource state\n    resources = event['resources']\n    constraints = event['constraints']\n    metrics = event['current_metrics']\n\n    # AI-powered optimization\n    optimization = agent.optimize({\n        'resources': resources,\n        'constraints': constraints,\n        'historical_performance': metrics,\n        'prediction_window': '7d'\n    })\n\n    # Generate recommendations\n    recommendations = []\n    for resource in optimization.changes:\n        if resource.benefit_score &gt; 0.7:\n            recommendations.append({\n                'resource': resource.name,\n                'action': resource.action,\n                'expected_benefit': resource.benefit_score,\n                'implementation': resource.steps\n            })\n\n    return {\n        'statusCode': 200,\n        'body': {\n            'current_efficiency': metrics['efficiency'],\n            'predicted_efficiency': optimization.predicted_efficiency,\n            'recommendations': recommendations,\n            'estimated_savings': optimization.cost_savings\n        }\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#integration-patterns","title":"Integration Patterns","text":""},{"location":"users/functions/ai-agent-functions/#1-chain-of-agents","title":"1. Chain of Agents","text":"<pre><code>// functions/agent-chain/index.js\nconst { AgentChain } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const chain = new AgentChain();\n\n  // Add agents to the chain\n  chain\n    .add(\"validator\", new ValidationAgent())\n    .add(\"processor\", new ProcessingAgent())\n    .add(\"analyzer\", new AnalysisAgent())\n    .add(\"reporter\", new ReportingAgent());\n\n  // Execute chain\n  const result = await chain.execute(event.body, {\n    stopOnError: false,\n    parallel: [\"processor\", \"analyzer\"],\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      success: result.success,\n      steps: result.steps,\n      finalOutput: result.output,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#2-agent-orchestration","title":"2. Agent Orchestration","text":"<pre><code># functions/agent-orchestrator/main.py\nfrom hexabase.agents import Orchestrator, Agent\n\ndef handler(event, context):\n    orchestrator = Orchestrator()\n\n    # Register specialized agents\n    orchestrator.register('classifier', ClassifierAgent())\n    orchestrator.register('extractor', DataExtractorAgent())\n    orchestrator.register('enricher', EnrichmentAgent())\n    orchestrator.register('validator', ValidationAgent())\n\n    # Define workflow\n    workflow = {\n        'steps': [\n            {'agent': 'classifier', 'input': 'raw_data'},\n            {\n                'parallel': [\n                    {'agent': 'extractor', 'input': 'classified_data'},\n                    {'agent': 'enricher', 'input': 'classified_data'}\n                ]\n            },\n            {'agent': 'validator', 'input': 'all_outputs'}\n        ]\n    }\n\n    # Execute orchestrated workflow\n    result = orchestrator.run(workflow, event['data'])\n\n    return {\n        'statusCode': 200,\n        'body': result.to_dict()\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#advanced-features","title":"Advanced Features","text":""},{"location":"users/functions/ai-agent-functions/#1-context-management","title":"1. Context Management","text":"<pre><code>// functions/context-aware-agent/index.js\nconst { ContextAwareAgent } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new ContextAwareAgent({\n    contextSources: [\"user-history\", \"system-state\", \"external-apis\"],\n  });\n\n  // Build rich context\n  const context = await agent.buildContext({\n    userId: event.userId,\n    sessionId: event.sessionId,\n    includeHistory: true,\n    timeWindow: \"30d\",\n  });\n\n  // Context-aware processing\n  const response = await agent.process({\n    input: event.body,\n    context,\n    adaptToContext: true,\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      response: response.content,\n      contextFactors: response.influential_context,\n      confidence: response.context_confidence,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#2-learning-and-adaptation","title":"2. Learning and Adaptation","text":"<pre><code># functions/adaptive-agent/main.py\nfrom hexabase.agents import AdaptiveAgent\nfrom hexabase.learning import FeedbackLoop\n\ndef handler(event, context):\n    agent = AdaptiveAgent(\n        learning_rate=0.1,\n        feedback_threshold=100\n    )\n\n    # Process with current knowledge\n    result = agent.process(event['input'])\n\n    # Collect feedback if available\n    if 'feedback' in event:\n        agent.learn({\n            'input': event['input'],\n            'output': result,\n            'feedback': event['feedback']\n        })\n\n    # Adapt behavior based on patterns\n    if agent.should_adapt():\n        agent.adapt_behavior()\n\n    return {\n        'statusCode': 200,\n        'body': {\n            'result': result,\n            'model_version': agent.version,\n            'confidence': agent.confidence,\n            'learning_progress': agent.learning_stats()\n        }\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#3-multi-modal-processing","title":"3. Multi-Modal Processing","text":"<pre><code>// functions/multimodal-agent/index.js\nconst { MultiModalAgent } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new MultiModalAgent({\n    modalities: [\"text\", \"image\", \"audio\"],\n    fusion_strategy: \"attention-based\",\n  });\n\n  const inputs = {\n    text: event.body.text,\n    image: event.body.image_url,\n    audio: event.body.audio_data,\n  };\n\n  // Process multiple modalities\n  const analysis = await agent.analyze(inputs);\n\n  // Generate unified response\n  const response = await agent.synthesize({\n    analysis,\n    outputFormat: event.body.preferred_format || \"text\",\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      analysis: analysis.summary,\n      response: response.content,\n      modality_contributions: analysis.contributions,\n      confidence_scores: analysis.confidence,\n    }),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#best-practices","title":"Best Practices","text":""},{"location":"users/functions/ai-agent-functions/#1-error-handling","title":"1. Error Handling","text":"<pre><code>// Robust error handling for AI agents\nexports.handler = async (event) =&gt; {\n  const agent = new AIAgent({\n    retryStrategy: \"exponential\",\n    maxRetries: 3,\n  });\n\n  try {\n    const result = await agent.process(event.body);\n\n    // Validate AI output\n    if (!agent.validateOutput(result)) {\n      throw new Error(\"Invalid AI output\");\n    }\n\n    return {\n      statusCode: 200,\n      body: JSON.stringify(result),\n    };\n  } catch (error) {\n    // Fallback logic\n    if (error.code === \"MODEL_OVERLOADED\") {\n      return await fallbackProcessor(event);\n    }\n\n    // Log for monitoring\n    await logError(error, {\n      functionName: context.functionName,\n      requestId: context.requestId,\n    });\n\n    return {\n      statusCode: 500,\n      body: JSON.stringify({\n        error: \"Processing failed\",\n        fallbackUsed: true,\n      }),\n    };\n  }\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#2-performance-optimization","title":"2. Performance Optimization","text":"<pre><code># Optimize AI agent performance\nfrom hexabase.agents import CachedAgent\nfrom hexabase.optimization import ResponseCache\n\ndef handler(event, context):\n    # Use caching for repeated queries\n    cache = ResponseCache(ttl=3600)\n    agent = CachedAgent(cache=cache)\n\n    # Check cache first\n    cache_key = agent.generate_cache_key(event['input'])\n    cached_result = cache.get(cache_key)\n\n    if cached_result:\n        return {\n            'statusCode': 200,\n            'body': cached_result,\n            'headers': {'X-Cache': 'HIT'}\n        }\n\n    # Process and cache\n    result = agent.process(event['input'])\n    cache.set(cache_key, result)\n\n    return {\n        'statusCode': 200,\n        'body': result,\n        'headers': {'X-Cache': 'MISS'}\n    }\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#3-security-considerations","title":"3. Security Considerations","text":"<pre><code>// Secure AI agent implementation\nconst { SecureAgent } = require(\"@hexabase/ai-agents\");\n\nexports.handler = async (event) =&gt; {\n  const agent = new SecureAgent({\n    inputSanitization: true,\n    outputFiltering: true,\n    piiDetection: true,\n  });\n\n  // Sanitize input\n  const sanitized = agent.sanitize(event.body);\n\n  // Process with security constraints\n  const result = await agent.process(sanitized, {\n    forbidden_topics: [\"sensitive_data\"],\n    max_output_length: 1000,\n    strip_pii: true,\n  });\n\n  // Audit log\n  await agent.audit({\n    action: \"ai_processing\",\n    user: event.userId,\n    timestamp: new Date(),\n    data_categories: result.detected_categories,\n  });\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify(result.safe_output),\n  };\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"users/functions/ai-agent-functions/#agent-metrics","title":"Agent Metrics","text":"<pre><code># Function configuration for AI agent monitoring\nfunctions:\n  ai-support-agent:\n    handler: support-agent.handler\n    environment:\n      ENABLE_METRICS: true\n      METRICS_NAMESPACE: AIAgents\n    metrics:\n      - name: response_time\n        unit: Milliseconds\n      - name: token_usage\n        unit: Count\n      - name: confidence_score\n        unit: None\n      - name: fallback_rate\n        unit: Percent\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#logging-configuration","title":"Logging Configuration","text":"<pre><code>// Structured logging for AI agents\nconst { Logger } = require(\"@hexabase/logging\");\n\nconst logger = new Logger({\n  service: \"ai-agent-function\",\n  level: \"info\",\n});\n\nexports.handler = async (event) =&gt; {\n  const requestId = context.requestId;\n\n  logger.info(\"AI agent invoked\", {\n    requestId,\n    functionName: context.functionName,\n    inputSize: JSON.stringify(event.body).length,\n  });\n\n  const agent = new AIAgent({\n    onTokenUsage: (usage) =&gt; {\n      logger.metric(\"token_usage\", usage, { requestId });\n    },\n  });\n\n  const result = await agent.process(event.body);\n\n  logger.info(\"AI agent completed\", {\n    requestId,\n    responseTime: context.getRemainingTimeInMillis(),\n    outputTokens: result.usage.output_tokens,\n    confidence: result.confidence,\n  });\n\n  return result;\n};\n</code></pre>"},{"location":"users/functions/ai-agent-functions/#related-documentation","title":"Related Documentation","text":"<ul> <li>Function Development</li> <li>Function Deployment</li> <li>Function Runtime</li> <li>AIOps Integration</li> </ul>"},{"location":"users/functions/deployment/","title":"Function Deployment","text":"<p>This guide covers the deployment process for serverless functions on the Hexabase.AI platform, including configuration, optimization, and best practices.</p>"},{"location":"users/functions/deployment/#deployment-methods","title":"Deployment Methods","text":""},{"location":"users/functions/deployment/#1-cli-deployment","title":"1. CLI Deployment","text":""},{"location":"users/functions/deployment/#quick-deploy","title":"Quick Deploy","text":"<pre><code># Deploy a single function\nhxb function deploy --name my-function --runtime nodejs18.x\n\n# Deploy with configuration\nhxb function deploy \\\n  --name my-function \\\n  --runtime python3.9 \\\n  --memory 512 \\\n  --timeout 30 \\\n  --env-file .env.production\n</code></pre>"},{"location":"users/functions/deployment/#batch-deployment","title":"Batch Deployment","text":"<pre><code># Deploy all functions in a directory\nhxb function deploy-all --path ./functions\n\n# Deploy with specific pattern\nhxb function deploy-all --path ./functions --pattern \"api-*\"\n</code></pre>"},{"location":"users/functions/deployment/#2-ui-deployment","title":"2. UI Deployment","text":"<p>The Hexabase.AI console provides a visual deployment interface:</p> <ol> <li>Navigate to Functions \u2192 Deploy</li> <li>Upload your function code (ZIP or link to repository)</li> <li>Configure runtime settings</li> <li>Set environment variables</li> <li>Review and deploy</li> </ol>"},{"location":"users/functions/deployment/#3-gitops-deployment","title":"3. GitOps Deployment","text":""},{"location":"users/functions/deployment/#function-configuration-file","title":"Function Configuration File","text":"<pre><code># functions.yaml\nfunctions:\n  user-api:\n    runtime: nodejs18.x\n    handler: index.handler\n    memory: 256\n    timeout: 10\n    environment:\n      DATABASE_URL: ${secrets.database_url}\n      API_KEY: ${secrets.api_key}\n    triggers:\n      - type: http\n        path: /api/users/*\n        methods: [GET, POST, PUT, DELETE]\n\n  data-processor:\n    runtime: python3.9\n    handler: main.process\n    memory: 1024\n    timeout: 300\n    layers:\n      - arn:aws:lambda:layer:numpy-scipy:1\n    triggers:\n      - type: schedule\n        expression: \"rate(5 minutes)\"\n      - type: queue\n        queue: data-processing-queue\n</code></pre>"},{"location":"users/functions/deployment/#automated-deployment","title":"Automated Deployment","text":"<pre><code># .github/workflows/deploy-functions.yml\nname: Deploy Functions\n\non:\n  push:\n    branches: [main]\n    paths:\n      - \"functions/**\"\n      - \"functions.yaml\"\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Hexabase CLI\n        run: |\n          curl -sL https://cli.hexabase.ai/install.sh | bash\n          hxb auth login --token ${{ secrets.HXB_TOKEN }}\n\n      - name: Validate Functions\n        run: hxb function validate --config functions.yaml\n\n      - name: Deploy Functions\n        run: hxb function deploy-all --config functions.yaml --env production\n</code></pre>"},{"location":"users/functions/deployment/#deployment-configuration","title":"Deployment Configuration","text":""},{"location":"users/functions/deployment/#runtime-configuration","title":"Runtime Configuration","text":""},{"location":"users/functions/deployment/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Version Features Node.js 18.x, 16.x Full ES6+, native modules Python 3.9, 3.8 Scientific libraries, ML frameworks Go 1.19 Fast cold starts, efficient memory Java 11, 8 Enterprise frameworks .NET 6.0 C#, F# support Ruby 3.0 Rails compatibility"},{"location":"users/functions/deployment/#runtime-selection","title":"Runtime Selection","text":"<pre><code>// package.json for Node.js\n{\n  \"name\": \"my-function\",\n  \"version\": \"1.0.0\",\n  \"main\": \"index.js\",\n  \"engines\": {\n    \"node\": \"18.x\"\n  },\n  \"dependencies\": {\n    \"@hexabase/sdk\": \"^2.0.0\"\n  }\n}\n</code></pre> <pre><code># requirements.txt for Python\nhexabase-sdk&gt;=2.0.0\nnumpy==1.21.0\npandas==1.3.0\nrequests==2.26.0\n</code></pre>"},{"location":"users/functions/deployment/#resource-configuration","title":"Resource Configuration","text":""},{"location":"users/functions/deployment/#memory-and-cpu-allocation","title":"Memory and CPU Allocation","text":"<pre><code># Plan-based limits\nresources:\n  single_user:\n    memory_min: 128\n    memory_max: 512\n    cpu_shares: 0.25\n\n  team:\n    memory_min: 128\n    memory_max: 2048\n    cpu_shares: 1\n\n  enterprise:\n    memory_min: 128\n    memory_max: 10240\n    cpu_shares: 4\n</code></pre>"},{"location":"users/functions/deployment/#function-sizing-guide","title":"Function Sizing Guide","text":"<pre><code>// Memory configuration examples\nconst functionConfigs = {\n  // Lightweight API endpoint\n  minimal: {\n    memory: 128,\n    timeout: 10,\n    use_cases: [\"Simple API responses\", \"Webhooks\"],\n  },\n\n  // Standard processing\n  standard: {\n    memory: 512,\n    timeout: 30,\n    use_cases: [\"Data transformation\", \"API integrations\"],\n  },\n\n  // Heavy processing\n  intensive: {\n    memory: 2048,\n    timeout: 300,\n    use_cases: [\"Image processing\", \"ML inference\", \"Large data sets\"],\n  },\n};\n</code></pre>"},{"location":"users/functions/deployment/#environment-configuration","title":"Environment Configuration","text":""},{"location":"users/functions/deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># Set via CLI\nhxb function env set MY_FUNCTION \\\n  --var DATABASE_URL=postgres://... \\\n  --var API_KEY=secret123 \\\n  --encrypt API_KEY\n\n# Set via configuration file\ncat &gt; function.env &lt;&lt;EOF\nNODE_ENV=production\nLOG_LEVEL=info\nFEATURE_FLAGS={\"newUI\":true,\"betaFeatures\":false}\nEOF\n\nhxb function env import MY_FUNCTION --file function.env\n</code></pre>"},{"location":"users/functions/deployment/#secrets-management","title":"Secrets Management","text":"<pre><code># function-config.yaml\nfunction:\n  name: secure-function\n  environment:\n    # Plain text variables\n    APP_NAME: MyApp\n    LOG_LEVEL: info\n\n    # Encrypted secrets\n    DATABASE_URL:\n      encrypted: true\n      value: ${vault.database_url}\n\n    API_KEY:\n      encrypted: true\n      value: ${vault.api_key}\n\n    # Runtime injection\n    AWS_ACCESS_KEY_ID:\n      from_secret: aws-credentials\n      key: access_key_id\n</code></pre>"},{"location":"users/functions/deployment/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"users/functions/deployment/#1-blue-green-deployment","title":"1. Blue-Green Deployment","text":"<pre><code>deployment:\n  strategy: blue-green\n  settings:\n    traffic_shift:\n      type: gradual\n      duration: 30m\n      intervals:\n        - weight: 10\n          duration: 5m\n        - weight: 50\n          duration: 10m\n        - weight: 100\n          duration: 15m\n    rollback:\n      automatic: true\n      error_threshold: 5%\n</code></pre>"},{"location":"users/functions/deployment/#2-canary-deployment","title":"2. Canary Deployment","text":"<pre><code># Deploy new version as canary\nhxb function deploy my-function \\\n  --version v2 \\\n  --canary \\\n  --traffic 10\n\n# Monitor metrics\nhxb function metrics my-function --version v2\n\n# Promote canary to production\nhxb function promote my-function --version v2\n\n# Or rollback\nhxb function rollback my-function\n</code></pre>"},{"location":"users/functions/deployment/#3-feature-flag-deployment","title":"3. Feature Flag Deployment","text":"<pre><code>// Function with feature flags\nexports.handler = async (event) =&gt; {\n  const features = await getFeatureFlags(event.userId);\n\n  if (features.newAlgorithm) {\n    return await newProcessingLogic(event);\n  } else {\n    return await legacyProcessingLogic(event);\n  }\n};\n</code></pre>"},{"location":"users/functions/deployment/#layer-management","title":"Layer Management","text":""},{"location":"users/functions/deployment/#creating-layers","title":"Creating Layers","text":"<pre><code># Create a layer for shared dependencies\nmkdir nodejs\ncd nodejs\nnpm install shared-utils aws-sdk moment\ncd ..\nzip -r shared-layer.zip nodejs\n\n# Upload layer\nhxb function layer create \\\n  --name shared-utils \\\n  --zip shared-layer.zip \\\n  --compatible-runtimes nodejs18.x nodejs16.x\n</code></pre>"},{"location":"users/functions/deployment/#using-layers","title":"Using Layers","text":"<pre><code>function:\n  name: api-handler\n  runtime: nodejs18.x\n  layers:\n    - name: shared-utils\n      version: 3\n    - arn: arn:hexabase:layer:region:account:layer:name:version\n</code></pre>"},{"location":"users/functions/deployment/#trigger-configuration","title":"Trigger Configuration","text":""},{"location":"users/functions/deployment/#http-triggers","title":"HTTP Triggers","text":"<pre><code>triggers:\n  - type: http\n    path: /api/v1/users/{userId}\n    methods: [GET, PUT, DELETE]\n    auth:\n      type: jwt\n      issuer: https://auth.hexabase.ai\n    cors:\n      origins: [\"https://app.example.com\"]\n      credentials: true\n    rate_limit:\n      requests_per_second: 100\n      burst: 200\n</code></pre>"},{"location":"users/functions/deployment/#event-triggers","title":"Event Triggers","text":"<pre><code>triggers:\n  - type: event\n    source: user-service\n    events:\n      - user.created\n      - user.updated\n    filters:\n      - attribute: user.plan\n        values: [premium, enterprise]\n\n  - type: queue\n    queue: processing-queue\n    batch_size: 10\n    visibility_timeout: 300\n</code></pre>"},{"location":"users/functions/deployment/#schedule-triggers","title":"Schedule Triggers","text":"<pre><code>triggers:\n  - type: schedule\n    expression: \"cron(0 8 * * MON-FRI)\"\n    timezone: \"America/New_York\"\n    input:\n      type: \"daily-report\"\n      recipients: [\"team@example.com\"]\n</code></pre>"},{"location":"users/functions/deployment/#monitoring-deployment","title":"Monitoring Deployment","text":""},{"location":"users/functions/deployment/#health-checks","title":"Health Checks","text":"<pre><code>// Health check endpoint\nexports.health = async (event) =&gt; {\n  const checks = {\n    function: \"healthy\",\n    dependencies: await checkDependencies(),\n    version: process.env.FUNCTION_VERSION,\n  };\n\n  return {\n    statusCode: 200,\n    body: JSON.stringify(checks),\n  };\n};\n</code></pre>"},{"location":"users/functions/deployment/#deployment-metrics","title":"Deployment Metrics","text":"<pre><code># Monitor deployment\nmetrics:\n  deployment:\n    - success_rate\n    - deployment_duration\n    - rollback_count\n\n  function:\n    - invocation_count\n    - error_rate\n    - cold_start_duration\n    - concurrent_executions\n</code></pre>"},{"location":"users/functions/deployment/#best-practices","title":"Best Practices","text":""},{"location":"users/functions/deployment/#1-package-optimization","title":"1. Package Optimization","text":"<pre><code>// webpack.config.js for bundling\nmodule.exports = {\n  target: \"node\",\n  mode: \"production\",\n  entry: \"./src/index.js\",\n  output: {\n    filename: \"index.js\",\n    libraryTarget: \"commonjs2\",\n  },\n  externals: {\n    // Don't bundle AWS SDK (provided by runtime)\n    \"aws-sdk\": \"aws-sdk\",\n  },\n  optimization: {\n    minimize: true,\n  },\n};\n</code></pre>"},{"location":"users/functions/deployment/#2-dependency-management","title":"2. Dependency Management","text":"<pre><code>// Separate dev and production dependencies\n{\n  \"dependencies\": {\n    \"express\": \"^4.18.0\",\n    \"axios\": \"^0.27.0\"\n  },\n  \"devDependencies\": {\n    \"jest\": \"^28.0.0\",\n    \"eslint\": \"^8.0.0\",\n    \"webpack\": \"^5.0.0\"\n  }\n}\n</code></pre>"},{"location":"users/functions/deployment/#3-version-management","title":"3. Version Management","text":"<pre><code># Tag versions\nhxb function version create my-function \\\n  --tag v1.2.3 \\\n  --description \"Added caching support\"\n\n# Deploy specific version\nhxb function deploy my-function --version v1.2.3\n\n# List versions\nhxb function versions my-function\n</code></pre>"},{"location":"users/functions/deployment/#4-rollback-strategy","title":"4. Rollback Strategy","text":"<pre><code>rollback:\n  automatic:\n    enabled: true\n    conditions:\n      - error_rate: 5%\n        window: 5m\n      - latency_p99: 1000ms\n        window: 5m\n\n  manual:\n    preserve_data: true\n    notification:\n      channels: [slack, email]\n</code></pre>"},{"location":"users/functions/deployment/#troubleshooting-deployment","title":"Troubleshooting Deployment","text":""},{"location":"users/functions/deployment/#common-issues","title":"Common Issues","text":"<ol> <li>Deployment Timeout</li> </ol> <pre><code># Increase timeout for large functions\nhxb function deploy my-function \\\n  --deployment-timeout 600 \\\n  --package-size-limit 250MB\n</code></pre> <ol> <li>Permission Errors</li> </ol> <pre><code># Check and fix permissions\nhxb function permissions my-function --check\nhxb function permissions my-function --fix\n</code></pre> <ol> <li>Package Size Issues</li> </ol> <pre><code># Use layers for large dependencies\nhxb function analyze my-function --show-size\n\n# Optimize package\nnpm prune --production\nnpm dedupe\n</code></pre>"},{"location":"users/functions/deployment/#deployment-logs","title":"Deployment Logs","text":"<pre><code># View deployment logs\nhxb function logs my-function --deployment\n\n# Stream logs during deployment\nhxb function deploy my-function --stream-logs\n\n# Debug deployment\nhxb function deploy my-function --debug --verbose\n</code></pre>"},{"location":"users/functions/deployment/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"users/functions/deployment/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/function-deploy.yml\nname: Deploy Function\n\non:\n  push:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: npm test\n\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to Hexabase\n        uses: hexabase/function-deploy-action@v1\n        with:\n          function-name: ${{ github.event.repository.name }}\n          runtime: nodejs18.x\n          environment: production\n          auth-token: ${{ secrets.HXB_DEPLOY_TOKEN }}\n</code></pre>"},{"location":"users/functions/deployment/#gitlab-ci","title":"GitLab CI","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - test\n  - deploy\n\ntest:\n  stage: test\n  script:\n    - npm install\n    - npm test\n\ndeploy:\n  stage: deploy\n  only:\n    - main\n  script:\n    - curl -sL https://cli.hexabase.ai/install.sh | bash\n    - hxb auth login --token $HXB_DEPLOY_TOKEN\n    - hxb function deploy --name $CI_PROJECT_NAME --env production\n</code></pre>"},{"location":"users/functions/deployment/#related-documentation","title":"Related Documentation","text":"<ul> <li>Function Development</li> <li>Function Runtime</li> <li>AI Agent Functions</li> <li>CI/CD Integration</li> </ul>"},{"location":"users/functions/development/","title":"Function Development","text":"<p>This comprehensive guide covers developing serverless functions for the Hexabase.AI platform, including local development, testing, and best practices.</p>"},{"location":"users/functions/development/#getting-started","title":"Getting Started","text":""},{"location":"users/functions/development/#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"users/functions/development/#install-hexabase-cli","title":"Install Hexabase CLI","text":"<pre><code># macOS/Linux\ncurl -sL https://cli.hexabase.ai/install.sh | bash\n\n# Windows\niwr -useb https://cli.hexabase.ai/install.ps1 | iex\n\n# Verify installation\nhxb --version\n</code></pre>"},{"location":"users/functions/development/#initialize-project","title":"Initialize Project","text":"<pre><code># Create new function project\nhxb function init my-function --runtime nodejs18.x\n\n# Project structure created:\n# my-function/\n# \u251c\u2500\u2500 src/\n# \u2502   \u2514\u2500\u2500 index.js\n# \u251c\u2500\u2500 test/\n# \u2502   \u2514\u2500\u2500 index.test.js\n# \u251c\u2500\u2500 package.json\n# \u251c\u2500\u2500 .env.example\n# \u251c\u2500\u2500 .gitignore\n# \u2514\u2500\u2500 hexabase.yaml\n</code></pre>"},{"location":"users/functions/development/#function-structure","title":"Function Structure","text":""},{"location":"users/functions/development/#nodejs-function","title":"Node.js Function","text":"<pre><code>// src/index.js\nconst { Logger } = require(\"@hexabase/functions\");\n\nconst logger = new Logger();\n\n/**\n * Main handler function\n * @param {Object} event - The event object\n * @param {Object} context - The context object\n * @returns {Object} - Response object\n */\nexports.handler = async (event, context) =&gt; {\n  logger.info(\"Function invoked\", {\n    requestId: context.requestId,\n    functionName: context.functionName,\n  });\n\n  try {\n    // Your business logic here\n    const result = await processRequest(event);\n\n    return {\n      statusCode: 200,\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"X-Request-ID\": context.requestId,\n      },\n      body: JSON.stringify({\n        success: true,\n        data: result,\n      }),\n    };\n  } catch (error) {\n    logger.error(\"Function error\", { error: error.message });\n\n    return {\n      statusCode: error.statusCode || 500,\n      body: JSON.stringify({\n        success: false,\n        error: error.message,\n      }),\n    };\n  }\n};\n\nasync function processRequest(event) {\n  // Implementation\n  return { message: \"Hello from Hexabase Function!\" };\n}\n</code></pre>"},{"location":"users/functions/development/#python-function","title":"Python Function","text":"<pre><code># src/main.py\nimport json\nimport logging\nfrom hexabase.functions import Logger\n\nlogger = Logger()\n\ndef handler(event, context):\n    \"\"\"\n    Main handler function\n\n    Args:\n        event (dict): The event object\n        context (object): The context object\n\n    Returns:\n        dict: Response object\n    \"\"\"\n    logger.info('Function invoked', {\n        'request_id': context.request_id,\n        'function_name': context.function_name\n    })\n\n    try:\n        # Your business logic here\n        result = process_request(event)\n\n        return {\n            'statusCode': 200,\n            'headers': {\n                'Content-Type': 'application/json',\n                'X-Request-ID': context.request_id\n            },\n            'body': json.dumps({\n                'success': True,\n                'data': result\n            })\n        }\n    except Exception as error:\n        logger.error('Function error', {'error': str(error)})\n\n        return {\n            'statusCode': getattr(error, 'status_code', 500),\n            'body': json.dumps({\n                'success': False,\n                'error': str(error)\n            })\n        }\n\ndef process_request(event):\n    # Implementation\n    return {'message': 'Hello from Hexabase Function!'}\n</code></pre>"},{"location":"users/functions/development/#local-development","title":"Local Development","text":""},{"location":"users/functions/development/#local-runtime-environment","title":"Local Runtime Environment","text":""},{"location":"users/functions/development/#using-function-emulator","title":"Using Function Emulator","text":"<pre><code># Start local emulator\nhxb function serve --port 3000\n\n# In another terminal, invoke function\nhxb function invoke my-function --local --data '{\"name\":\"test\"}'\n\n# Or use curl\ncurl -X POST http://localhost:3000/functions/my-function \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\":\"test\"}'\n</code></pre>"},{"location":"users/functions/development/#docker-development","title":"Docker Development","text":"<pre><code># Dockerfile.dev\nFROM hexabase/function-runtime:nodejs18.x\n\nWORKDIR /function\n\n# Copy dependencies\nCOPY package*.json ./\nRUN npm ci\n\n# Copy source\nCOPY src/ ./src/\n\n# Development mode\nENV NODE_ENV=development\nENV LOG_LEVEL=debug\n\n# Hot reload support\nCMD [\"npm\", \"run\", \"dev\"]\n</code></pre> <pre><code># docker-compose.yml\nversion: '3.8'\nservices:\n  function:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    ports:\n      - \"9000:9000\"\n    volumes:\n      - ./src:/function/src\n      - ./test:/function/test\n    environment:\n      - LOCAL_DEVELOPMENT=true\n      - AWS_LAMBDA_FUNCTION_NAME=my-function\n    command: npm run watch\n</code></pre>"},{"location":"users/functions/development/#environment-variables","title":"Environment Variables","text":""},{"location":"users/functions/development/#local-configuration","title":"Local Configuration","text":"<pre><code># .env.local\nNODE_ENV=development\nLOG_LEVEL=debug\nDATABASE_URL=postgres://localhost:5432/dev_db\nAPI_KEY=dev_api_key_12345\nFEATURE_FLAGS={\"newFeature\":true}\n</code></pre>"},{"location":"users/functions/development/#loading-environment","title":"Loading Environment","text":"<pre><code>// src/config.js\nconst dotenv = require(\"dotenv\");\n\n// Load environment-specific config\nconst environment = process.env.NODE_ENV || \"development\";\ndotenv.config({ path: `.env.${environment}` });\n\nmodule.exports = {\n  database: {\n    url: process.env.DATABASE_URL,\n    poolSize: parseInt(process.env.DB_POOL_SIZE || \"10\"),\n  },\n  api: {\n    key: process.env.API_KEY,\n    timeout: parseInt(process.env.API_TIMEOUT || \"30000\"),\n  },\n  features: JSON.parse(process.env.FEATURE_FLAGS || \"{}\"),\n};\n</code></pre>"},{"location":"users/functions/development/#testing","title":"Testing","text":""},{"location":"users/functions/development/#unit-testing","title":"Unit Testing","text":""},{"location":"users/functions/development/#jest-configuration","title":"Jest Configuration","text":"<pre><code>// jest.config.js\nmodule.exports = {\n  testEnvironment: \"node\",\n  coverageDirectory: \"coverage\",\n  collectCoverageFrom: [\"src/**/*.js\", \"!src/**/*.test.js\"],\n  testMatch: [\"**/test/**/*.test.js\"],\n  setupFilesAfterEnv: [\"./test/setup.js\"],\n};\n</code></pre>"},{"location":"users/functions/development/#test-examples","title":"Test Examples","text":"<pre><code>// test/handler.test.js\nconst { handler } = require(\"../src/index\");\n\ndescribe(\"Function Handler\", () =&gt; {\n  const mockContext = {\n    requestId: \"test-request-id\",\n    functionName: \"my-function\",\n    getRemainingTimeInMillis: () =&gt; 30000,\n  };\n\n  test(\"should handle valid request\", async () =&gt; {\n    const event = {\n      body: JSON.stringify({ name: \"test\" }),\n      headers: { \"content-type\": \"application/json\" },\n    };\n\n    const response = await handler(event, mockContext);\n\n    expect(response.statusCode).toBe(200);\n    expect(JSON.parse(response.body)).toMatchObject({\n      success: true,\n      data: expect.any(Object),\n    });\n  });\n\n  test(\"should handle errors gracefully\", async () =&gt; {\n    const event = {\n      body: \"invalid-json\",\n    };\n\n    const response = await handler(event, mockContext);\n\n    expect(response.statusCode).toBe(400);\n    expect(JSON.parse(response.body)).toMatchObject({\n      success: false,\n      error: expect.any(String),\n    });\n  });\n});\n</code></pre>"},{"location":"users/functions/development/#integration-testing","title":"Integration Testing","text":""},{"location":"users/functions/development/#test-harness","title":"Test Harness","text":"<pre><code>// test/integration/api.test.js\nconst { FunctionTestHarness } = require(\"@hexabase/testing\");\n\ndescribe(\"API Integration\", () =&gt; {\n  let harness;\n\n  beforeAll(async () =&gt; {\n    harness = new FunctionTestHarness({\n      functionName: \"my-function\",\n      environment: {\n        DATABASE_URL: \"postgres://test:5432/test_db\",\n      },\n    });\n    await harness.start();\n  });\n\n  afterAll(async () =&gt; {\n    await harness.stop();\n  });\n\n  test(\"should process API request\", async () =&gt; {\n    const response = await harness.invoke({\n      path: \"/api/users\",\n      method: \"GET\",\n      headers: {\n        Authorization: \"Bearer test-token\",\n      },\n    });\n\n    expect(response.statusCode).toBe(200);\n    expect(response.body).toHaveProperty(\"users\");\n  });\n});\n</code></pre>"},{"location":"users/functions/development/#performance-testing","title":"Performance Testing","text":"<pre><code>// test/performance/load.test.js\nconst { PerformanceTest } = require(\"@hexabase/testing\");\n\ndescribe(\"Performance Tests\", () =&gt; {\n  test(\"should handle concurrent requests\", async () =&gt; {\n    const test = new PerformanceTest({\n      function: \"my-function\",\n      duration: 60, // seconds\n      concurrency: 100,\n      rampUp: 10,\n    });\n\n    const results = await test.run();\n\n    expect(results.successRate).toBeGreaterThan(0.99);\n    expect(results.p99Latency).toBeLessThan(1000);\n    expect(results.throughput).toBeGreaterThan(500);\n  });\n});\n</code></pre>"},{"location":"users/functions/development/#advanced-development","title":"Advanced Development","text":""},{"location":"users/functions/development/#middleware-pattern","title":"Middleware Pattern","text":"<pre><code>// src/middleware/auth.js\nexports.authenticate = async (event) =&gt; {\n  const token = event.headers.authorization?.replace(\"Bearer \", \"\");\n\n  if (!token) {\n    throw new UnauthorizedError(\"No token provided\");\n  }\n\n  const user = await verifyToken(token);\n  event.user = user;\n  return event;\n};\n\n// src/middleware/validation.js\nconst Joi = require(\"joi\");\n\nexports.validate = (schema) =&gt; async (event) =&gt; {\n  const body = JSON.parse(event.body || \"{}\");\n  const { error, value } = schema.validate(body);\n\n  if (error) {\n    throw new ValidationError(error.details[0].message);\n  }\n\n  event.validatedBody = value;\n  return event;\n};\n\n// src/index.js\nconst { compose } = require(\"@hexabase/functions\");\nconst { authenticate } = require(\"./middleware/auth\");\nconst { validate } = require(\"./middleware/validation\");\n\nconst schema = Joi.object({\n  name: Joi.string().required(),\n  email: Joi.string().email().required(),\n});\n\nexports.handler = compose(\n  authenticate,\n  validate(schema),\n  async (event, context) =&gt; {\n    // Main handler with authenticated user and validated body\n    const { user, validatedBody } = event;\n\n    return {\n      statusCode: 200,\n      body: JSON.stringify({\n        message: `Hello ${user.name}`,\n        data: validatedBody,\n      }),\n    };\n  }\n);\n</code></pre>"},{"location":"users/functions/development/#database-connections","title":"Database Connections","text":"<pre><code>// src/db/connection.js\nconst { Pool } = require(\"pg\");\n\nlet pool;\n\nexports.getConnection = () =&gt; {\n  if (!pool) {\n    pool = new Pool({\n      connectionString: process.env.DATABASE_URL,\n      max: 10,\n      idleTimeoutMillis: 30000,\n      connectionTimeoutMillis: 2000,\n    });\n\n    // Handle cleanup\n    process.on(\"SIGTERM\", async () =&gt; {\n      await pool.end();\n    });\n  }\n\n  return pool;\n};\n\n// src/db/queries.js\nconst { getConnection } = require(\"./connection\");\n\nexports.getUser = async (userId) =&gt; {\n  const pool = getConnection();\n  const result = await pool.query(\"SELECT * FROM users WHERE id = $1\", [\n    userId,\n  ]);\n  return result.rows[0];\n};\n\n// Prepared statements for better performance\nexports.createUser = async (userData) =&gt; {\n  const pool = getConnection();\n  const query = {\n    name: \"create-user\",\n    text: \"INSERT INTO users(name, email) VALUES($1, $2) RETURNING *\",\n    values: [userData.name, userData.email],\n  };\n  const result = await pool.query(query);\n  return result.rows[0];\n};\n</code></pre>"},{"location":"users/functions/development/#external-api-integration","title":"External API Integration","text":"<pre><code>// src/services/external-api.js\nconst axios = require(\"axios\");\nconst CircuitBreaker = require(\"opossum\");\n\nclass ExternalAPIService {\n  constructor() {\n    this.client = axios.create({\n      baseURL: process.env.EXTERNAL_API_URL,\n      timeout: 5000,\n      headers: {\n        \"X-API-Key\": process.env.EXTERNAL_API_KEY,\n      },\n    });\n\n    // Circuit breaker configuration\n    this.breaker = new CircuitBreaker(this.makeRequest.bind(this), {\n      timeout: 3000,\n      errorThresholdPercentage: 50,\n      resetTimeout: 30000,\n    });\n  }\n\n  async makeRequest(config) {\n    return this.client.request(config);\n  }\n\n  async getResource(id) {\n    try {\n      const response = await this.breaker.fire({\n        method: \"GET\",\n        url: `/resources/${id}`,\n      });\n      return response.data;\n    } catch (error) {\n      if (error.code === \"EOPENBREAKER\") {\n        // Circuit is open, use fallback\n        return this.getFallbackResource(id);\n      }\n      throw error;\n    }\n  }\n\n  getFallbackResource(id) {\n    // Return cached or default data\n    return { id, status: \"fallback\" };\n  }\n}\n\nmodule.exports = new ExternalAPIService();\n</code></pre>"},{"location":"users/functions/development/#debugging","title":"Debugging","text":""},{"location":"users/functions/development/#local-debugging","title":"Local Debugging","text":""},{"location":"users/functions/development/#vs-code-configuration","title":"VS Code Configuration","text":"<pre><code>// .vscode/launch.json\n{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"type\": \"node\",\n      \"request\": \"launch\",\n      \"name\": \"Debug Function\",\n      \"program\": \"${workspaceFolder}/node_modules/.bin/hxb\",\n      \"args\": [\"function\", \"invoke\", \"my-function\", \"--local\", \"--debug\"],\n      \"env\": {\n        \"NODE_ENV\": \"development\",\n        \"DEBUG\": \"*\"\n      },\n      \"console\": \"integratedTerminal\"\n    }\n  ]\n}\n</code></pre>"},{"location":"users/functions/development/#remote-debugging","title":"Remote Debugging","text":"<pre><code># Enable debug logs\nhxb function update my-function --env LOG_LEVEL=debug\n\n# View real-time logs\nhxb function logs my-function --follow\n\n# Get detailed error traces\nhxb function logs my-function --filter ERROR --include-traces\n</code></pre>"},{"location":"users/functions/development/#monitoring-development","title":"Monitoring Development","text":"<pre><code>// src/monitoring.js\nconst { Metrics } = require(\"@hexabase/functions\");\n\nconst metrics = new Metrics();\n\n// Custom metrics\nexports.recordMetric = (name, value, unit = \"Count\") =&gt; {\n  metrics.putMetric(name, value, unit);\n};\n\n// Performance tracking\nexports.trackPerformance = async (operation, fn) =&gt; {\n  const start = Date.now();\n  try {\n    const result = await fn();\n    const duration = Date.now() - start;\n\n    metrics.putMetric(`${operation}.duration`, duration, \"Milliseconds\");\n    metrics.putMetric(`${operation}.success`, 1, \"Count\");\n\n    return result;\n  } catch (error) {\n    const duration = Date.now() - start;\n\n    metrics.putMetric(`${operation}.duration`, duration, \"Milliseconds\");\n    metrics.putMetric(`${operation}.error`, 1, \"Count\");\n\n    throw error;\n  }\n};\n</code></pre>"},{"location":"users/functions/development/#development-tools","title":"Development Tools","text":""},{"location":"users/functions/development/#code-generation","title":"Code Generation","text":"<pre><code># Generate function from template\nhxb function generate api-endpoint \\\n  --template rest-api \\\n  --method GET,POST \\\n  --path /users\n\n# Generate test files\nhxb function generate-tests my-function \\\n  --framework jest \\\n  --coverage 80\n</code></pre>"},{"location":"users/functions/development/#hot-reload-development","title":"Hot Reload Development","text":"<pre><code>// dev-server.js\nconst chokidar = require(\"chokidar\");\nconst { spawn } = require(\"child_process\");\n\nlet functionProcess;\n\nfunction startFunction() {\n  if (functionProcess) {\n    functionProcess.kill();\n  }\n\n  functionProcess = spawn(\"hxb\", [\"function\", \"serve\"], {\n    stdio: \"inherit\",\n  });\n}\n\n// Watch for changes\nchokidar.watch(\"src/**/*.js\").on(\"change\", () =&gt; {\n  console.log(\"Reloading function...\");\n  startFunction();\n});\n\nstartFunction();\n</code></pre>"},{"location":"users/functions/development/#best-practices","title":"Best Practices","text":""},{"location":"users/functions/development/#1-error-handling","title":"1. Error Handling","text":"<pre><code>// src/errors.js\nclass ApplicationError extends Error {\n  constructor(message, statusCode = 500, code = \"INTERNAL_ERROR\") {\n    super(message);\n    this.statusCode = statusCode;\n    this.code = code;\n  }\n}\n\nclass ValidationError extends ApplicationError {\n  constructor(message) {\n    super(message, 400, \"VALIDATION_ERROR\");\n  }\n}\n\nclass NotFoundError extends ApplicationError {\n  constructor(resource) {\n    super(`${resource} not found`, 404, \"NOT_FOUND\");\n  }\n}\n\n// Global error handler\nexports.errorHandler = (fn) =&gt; async (event, context) =&gt; {\n  try {\n    return await fn(event, context);\n  } catch (error) {\n    console.error(\"Function error:\", error);\n\n    return {\n      statusCode: error.statusCode || 500,\n      body: JSON.stringify({\n        error: {\n          message: error.message,\n          code: error.code || \"INTERNAL_ERROR\",\n        },\n      }),\n    };\n  }\n};\n</code></pre>"},{"location":"users/functions/development/#2-input-validation","title":"2. Input Validation","text":"<pre><code>// src/validation.js\nconst validator = require(\"validator\");\n\nexports.validateEmail = (email) =&gt; {\n  if (!validator.isEmail(email)) {\n    throw new ValidationError(\"Invalid email format\");\n  }\n  return validator.normalizeEmail(email);\n};\n\nexports.sanitizeInput = (input) =&gt; {\n  if (typeof input === \"string\") {\n    return validator.escape(input);\n  }\n  return input;\n};\n</code></pre>"},{"location":"users/functions/development/#3-performance-optimization","title":"3. Performance Optimization","text":"<pre><code>// Reuse connections\nconst connections = new Map();\n\nexports.getOptimizedConnection = (key, factory) =&gt; {\n  if (!connections.has(key)) {\n    connections.set(key, factory());\n  }\n  return connections.get(key);\n};\n\n// Lazy loading\nlet heavyModule;\nexports.getHeavyModule = () =&gt; {\n  if (!heavyModule) {\n    heavyModule = require(\"heavy-computation-lib\");\n  }\n  return heavyModule;\n};\n</code></pre>"},{"location":"users/functions/development/#related-documentation","title":"Related Documentation","text":"<ul> <li>Function Deployment</li> <li>Function Runtime</li> <li>AI Agent Functions</li> <li>CLI Documentation</li> </ul>"},{"location":"users/functions/runtime/","title":"Function Runtime","text":"<p>This guide provides detailed information about the Hexabase.AI serverless function runtime environment, including capabilities, limitations, and optimization strategies.</p>"},{"location":"users/functions/runtime/#runtime-architecture","title":"Runtime Architecture","text":""},{"location":"users/functions/runtime/#execution-environment","title":"Execution Environment","text":"<p>The Hexabase.AI function runtime provides:</p> <ul> <li>Isolated execution environments</li> <li>Automatic scaling based on demand</li> <li>Built-in security and sandboxing</li> <li>Language-specific optimizations</li> </ul> <pre><code>graph TD\n    A[HTTP Request] --&gt; B[API Gateway]\n    B --&gt; C[Load Balancer]\n    C --&gt; D[Function Router]\n    D --&gt; E[Runtime Pool]\n    E --&gt; F[Function Instance]\n    F --&gt; G[Execution Context]\n    G --&gt; H[User Code]\n    H --&gt; I[Response]</code></pre>"},{"location":"users/functions/runtime/#supported-runtimes","title":"Supported Runtimes","text":"Runtime Versions Cold Start Memory Range Max Timeout Node.js 18.x, 16.x, 14.x ~100ms 128MB-10GB 15 min Python 3.9, 3.8, 3.7 ~150ms 128MB-10GB 15 min Go 1.19, 1.18 ~50ms 128MB-10GB 15 min Java 11, 8 ~300ms 512MB-10GB 15 min .NET 6.0, 3.1 ~250ms 512MB-10GB 15 min Ruby 3.0, 2.7 ~200ms 128MB-10GB 15 min"},{"location":"users/functions/runtime/#runtime-features","title":"Runtime Features","text":""},{"location":"users/functions/runtime/#environment-variables","title":"Environment Variables","text":"<p>System-provided variables:</p> <pre><code>process.env.HXB_FUNCTION_NAME; // Function name\nprocess.env.HXB_FUNCTION_VERSION; // Function version\nprocess.env.HXB_WORKSPACE; // Workspace identifier\nprocess.env.HXB_REGION; // Deployment region\nprocess.env.HXB_MEMORY_SIZE; // Allocated memory\nprocess.env.HXB_TIMEOUT; // Function timeout\nprocess.env.HXB_LOG_LEVEL; // Logging level\n</code></pre>"},{"location":"users/functions/runtime/#file-system","title":"File System","text":""},{"location":"users/functions/runtime/#temporary-storage","title":"Temporary Storage","text":"<pre><code>const fs = require(\"fs\").promises;\nconst path = require(\"path\");\n\n// /tmp is writable with 512MB space\nconst tempFile = path.join(\"/tmp\", \"processing-data.json\");\n\n// Write temporary data\nawait fs.writeFile(tempFile, JSON.stringify(data));\n\n// Read temporary data\nconst savedData = await fs.readFile(tempFile, \"utf8\");\n\n// Clean up (automatic on function end)\nawait fs.unlink(tempFile);\n</code></pre>"},{"location":"users/functions/runtime/#read-only-directories","title":"Read-only Directories","text":"<ul> <li><code>/var/task</code> - Function code</li> <li><code>/opt</code> - Layers and runtime</li> <li><code>/var/runtime</code> - Runtime libraries</li> </ul>"},{"location":"users/functions/runtime/#network-access","title":"Network Access","text":""},{"location":"users/functions/runtime/#outbound-connections","title":"Outbound Connections","text":"<pre><code>// HTTP/HTTPS requests allowed\nconst axios = require(\"axios\");\nconst response = await axios.get(\"https://api.example.com/data\");\n\n// Database connections\nconst { Client } = require(\"pg\");\nconst client = new Client({\n  connectionString: process.env.DATABASE_URL,\n});\nawait client.connect();\n</code></pre>"},{"location":"users/functions/runtime/#network-restrictions","title":"Network Restrictions","text":"<ul> <li>No inbound connections</li> <li>Outbound connections through NAT</li> <li>VPC integration available for private resources</li> </ul>"},{"location":"users/functions/runtime/#process-capabilities","title":"Process Capabilities","text":""},{"location":"users/functions/runtime/#child-processes","title":"Child Processes","text":"<pre><code>const { exec } = require(\"child_process\");\nconst util = require(\"util\");\nconst execPromise = util.promisify(exec);\n\n// Execute shell commands\nconst { stdout, stderr } = await execPromise(\"ls -la /tmp\");\n\n// Spawn processes\nconst { spawn } = require(\"child_process\");\nconst python = spawn(\"python3\", [\"script.py\"]);\n</code></pre>"},{"location":"users/functions/runtime/#binary-execution","title":"Binary Execution","text":"<pre><code>// Include binaries in deployment package\nconst pathToBinary = path.join(__dirname, \"bin\", \"custom-tool\");\n\n// Make executable\nawait fs.chmod(pathToBinary, \"755\");\n\n// Execute\nconst { stdout } = await execPromise(pathToBinary);\n</code></pre>"},{"location":"users/functions/runtime/#context-object","title":"Context Object","text":""},{"location":"users/functions/runtime/#properties","title":"Properties","text":"<pre><code>exports.handler = async (event, context) =&gt; {\n  // Context properties\n  console.log({\n    requestId: context.requestId, // Unique request ID\n    functionName: context.functionName, // Function name\n    functionVersion: context.functionVersion, // Version or $LATEST\n    invokedFunctionArn: context.invokedFunctionArn, // Full ARN\n    memoryLimitInMB: context.memoryLimitInMB, // Memory allocation\n    logGroupName: context.logGroupName, // CloudWatch log group\n    logStreamName: context.logStreamName, // CloudWatch log stream\n    identity: context.identity, // Caller identity\n    clientContext: context.clientContext, // Client application info\n  });\n\n  // Timing information\n  const remainingTime = context.getRemainingTimeInMillis();\n  console.log(`Time remaining: ${remainingTime}ms`);\n};\n</code></pre>"},{"location":"users/functions/runtime/#callback-pattern-legacy","title":"Callback Pattern (Legacy)","text":"<pre><code>// Still supported but async/await preferred\nexports.handler = (event, context, callback) =&gt; {\n  // Success\n  callback(null, {\n    statusCode: 200,\n    body: JSON.stringify({ message: \"Success\" }),\n  });\n\n  // Error\n  callback(new Error(\"Something went wrong\"));\n};\n</code></pre>"},{"location":"users/functions/runtime/#performance-optimization","title":"Performance Optimization","text":""},{"location":"users/functions/runtime/#cold-start-mitigation","title":"Cold Start Mitigation","text":""},{"location":"users/functions/runtime/#1-code-optimization","title":"1. Code Optimization","text":"<pre><code>// Move requires outside handler\nconst AWS = require(\"aws-sdk\");\nconst axios = require(\"axios\");\n\n// Initialize connections outside handler\nconst dynamodb = new AWS.DynamoDB.DocumentClient();\nlet dbConnection;\n\nexports.handler = async (event) =&gt; {\n  // Reuse connections\n  if (!dbConnection) {\n    dbConnection = await createConnection();\n  }\n\n  // Handler logic\n};\n</code></pre>"},{"location":"users/functions/runtime/#2-provisioned-concurrency","title":"2. Provisioned Concurrency","text":"<pre><code># hexabase.yaml\nfunction:\n  name: critical-api\n  provisioned_concurrency:\n    single_user: 0 # Not available\n    team: 2 # 2 warm instances\n    enterprise: 10 # 10 warm instances\n</code></pre>"},{"location":"users/functions/runtime/#3-runtime-selection","title":"3. Runtime Selection","text":"<pre><code>// Go for minimal cold starts\npackage main\n\nimport (\n    \"context\"\n    \"github.com/hexabase/functions-go\"\n)\n\nfunc handler(ctx context.Context, event Event) (Response, error) {\n    // Go functions have ~50ms cold starts\n    return Response{\n        StatusCode: 200,\n        Body: \"Fast response\",\n    }, nil\n}\n\nfunc main() {\n    functions.Start(handler)\n}\n</code></pre>"},{"location":"users/functions/runtime/#memory-optimization","title":"Memory Optimization","text":""},{"location":"users/functions/runtime/#memory-to-cpu-ratio","title":"Memory to CPU Ratio","text":"<pre><code>// CPU scales with memory\nconst memoryConfigs = {\n  128: { cpu: 0.08, network: \"250 Mbps\" },\n  512: { cpu: 0.33, network: \"500 Mbps\" },\n  1024: { cpu: 0.66, network: \"750 Mbps\" },\n  1769: { cpu: 1.0, network: \"1 Gbps\" },\n  3008: { cpu: 2.0, network: \"2 Gbps\" },\n  10240: { cpu: 6.0, network: \"10 Gbps\" },\n};\n\n// Profile memory usage\nexports.handler = async (event) =&gt; {\n  const startMemory = process.memoryUsage();\n\n  // Process data\n  const result = await processLargeDataset(event.data);\n\n  const endMemory = process.memoryUsage();\n  console.log(\"Memory used:\", {\n    heap: (endMemory.heapUsed - startMemory.heapUsed) / 1024 / 1024,\n    external: endMemory.external / 1024 / 1024,\n  });\n\n  return result;\n};\n</code></pre>"},{"location":"users/functions/runtime/#concurrency-management","title":"Concurrency Management","text":""},{"location":"users/functions/runtime/#reserved-concurrency","title":"Reserved Concurrency","text":"<pre><code># Prevent throttling\nfunction:\n  name: batch-processor\n  reserved_concurrency: 50 # Max 50 concurrent executions\n</code></pre>"},{"location":"users/functions/runtime/#concurrency-limits-by-plan","title":"Concurrency Limits by Plan","text":"Plan Default Concurrency Reserved Concurrency Burst Concurrency Single 10 Not available 50 Team 100 Up to 50 500 Enterprise 1000 Up to 500 3000"},{"location":"users/functions/runtime/#runtime-limits","title":"Runtime Limits","text":""},{"location":"users/functions/runtime/#execution-limits","title":"Execution Limits","text":"Resource Limit Notes Timeout 15 minutes Configurable per function Memory 128 MB - 10 GB CPU scales with memory Temp storage 512 MB /tmp directory Environment variables 4 KB Total size Payload size 6 MB (sync), 256 KB (async) Request/response File descriptors 1024 Open files/sockets Processes/threads 1024 Combined limit"},{"location":"users/functions/runtime/#package-size-limits","title":"Package Size Limits","text":"<pre><code># Deployment package limits\nDirect upload: 50 MB (zipped)\nS3 upload: 250 MB (zipped)\nUnzipped size: 250 MB\n\n# Including layers\nTotal unzipped: 250 MB\nIndividual layer: 50 MB\nNumber of layers: 5\n</code></pre>"},{"location":"users/functions/runtime/#security-context","title":"Security Context","text":""},{"location":"users/functions/runtime/#iam-permissions","title":"IAM Permissions","text":"<pre><code>// Function has execution role with permissions\nconst AWS = require(\"aws-sdk\");\n\n// Access Hexabase resources\nconst storage = new AWS.S3();\nconst result = await storage\n  .getObject({\n    Bucket: \"hexabase-workspace-bucket\",\n    Key: \"data/file.json\",\n  })\n  .promise();\n\n// Access controlled by execution role\n</code></pre>"},{"location":"users/functions/runtime/#network-security","title":"Network Security","text":"<pre><code># VPC configuration\nfunction:\n  name: secure-function\n  vpc:\n    security_groups:\n      - sg-12345678\n    subnets:\n      - subnet-12345678\n      - subnet-87654321\n</code></pre>"},{"location":"users/functions/runtime/#secrets-access","title":"Secrets Access","text":"<pre><code>// Access secrets securely\nconst { SecretsManager } = require(\"@hexabase/sdk\");\n\nconst secrets = new SecretsManager();\nconst apiKey = await secrets.getSecret(\"external-api-key\");\n\n// Use in function\nconst response = await fetch(\"https://api.example.com\", {\n  headers: {\n    Authorization: `Bearer ${apiKey}`,\n  },\n});\n</code></pre>"},{"location":"users/functions/runtime/#logging-and-monitoring","title":"Logging and Monitoring","text":""},{"location":"users/functions/runtime/#structured-logging","title":"Structured Logging","text":"<pre><code>const { Logger } = require(\"@hexabase/functions\");\nconst logger = new Logger();\n\nexports.handler = async (event, context) =&gt; {\n  // Logs automatically include context\n  logger.info(\"Processing request\", {\n    userId: event.userId,\n    action: event.action,\n  });\n\n  try {\n    const result = await processData(event);\n    logger.info(\"Success\", {\n      resultSize: result.length,\n      duration: Date.now() - startTime,\n    });\n    return result;\n  } catch (error) {\n    logger.error(\"Processing failed\", {\n      error: error.message,\n      stack: error.stack,\n      input: event,\n    });\n    throw error;\n  }\n};\n</code></pre>"},{"location":"users/functions/runtime/#metrics-collection","title":"Metrics Collection","text":"<pre><code>const { Metrics } = require(\"@hexabase/functions\");\nconst metrics = new Metrics();\n\n// Built-in metrics\n// - Invocations\n// - Errors\n// - Duration\n// - Throttles\n// - ConcurrentExecutions\n\n// Custom metrics\nmetrics.putMetric(\"ItemsProcessed\", items.length, \"Count\");\nmetrics.putMetric(\"ProcessingTime\", duration, \"Milliseconds\");\n</code></pre>"},{"location":"users/functions/runtime/#tracing","title":"Tracing","text":"<pre><code>const { Tracer } = require(\"@hexabase/functions\");\nconst tracer = new Tracer();\n\nexports.handler = async (event) =&gt; {\n  const segment = tracer.getSegment();\n\n  // Add custom annotations\n  segment.addAnnotation(\"userId\", event.userId);\n  segment.addAnnotation(\"requestType\", event.type);\n\n  // Trace subsegments\n  const subsegment = segment.addNewSubsegment(\"database-query\");\n  try {\n    const result = await queryDatabase();\n    subsegment.close();\n    return result;\n  } catch (error) {\n    subsegment.addError(error);\n    subsegment.close();\n    throw error;\n  }\n};\n</code></pre>"},{"location":"users/functions/runtime/#runtime-extensions","title":"Runtime Extensions","text":""},{"location":"users/functions/runtime/#custom-layers","title":"Custom Layers","text":"<pre><code># Create layer structure\nmkdir -p nodejs/node_modules\ncd nodejs\nnpm install shared-library\n\n# Package layer\ncd ..\nzip -r layer.zip nodejs\n\n# Deploy layer\nhxb function layer create \\\n  --name shared-utils \\\n  --zip layer.zip \\\n  --compatible-runtimes nodejs18.x nodejs16.x\n</code></pre>"},{"location":"users/functions/runtime/#runtime-hooks","title":"Runtime Hooks","text":"<pre><code>// Initialization code (runs once)\nlet initialized = false;\nlet sharedResource;\n\nasync function initialize() {\n  if (!initialized) {\n    sharedResource = await setupResource();\n    initialized = true;\n  }\n}\n\n// Cleanup hook\nprocess.on(\"SIGTERM\", async () =&gt; {\n  console.log(\"Function terminating, cleanup...\");\n  await sharedResource?.close();\n});\n\nexports.handler = async (event) =&gt; {\n  await initialize();\n  // Use sharedResource\n};\n</code></pre>"},{"location":"users/functions/runtime/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/functions/runtime/#common-runtime-issues","title":"Common Runtime Issues","text":""},{"location":"users/functions/runtime/#1-out-of-memory","title":"1. Out of Memory","text":"<pre><code>// Monitor memory usage\nexports.handler = async (event) =&gt; {\n  const usage = process.memoryUsage();\n  console.log(\"Memory usage:\", {\n    rss: Math.round(usage.rss / 1024 / 1024) + \" MB\",\n    heapTotal: Math.round(usage.heapTotal / 1024 / 1024) + \" MB\",\n    heapUsed: Math.round(usage.heapUsed / 1024 / 1024) + \" MB\",\n  });\n\n  // Increase function memory if consistently high\n};\n</code></pre>"},{"location":"users/functions/runtime/#2-timeout-issues","title":"2. Timeout Issues","text":"<pre><code>// Check remaining time\nexports.handler = async (event, context) =&gt; {\n  const timeout = context.getRemainingTimeInMillis();\n\n  // Long-running process with timeout check\n  for (const item of largeDataset) {\n    if (context.getRemainingTimeInMillis() &lt; 5000) {\n      // Less than 5 seconds remaining\n      await saveProgress(processedItems);\n      return {\n        statusCode: 202,\n        body: JSON.stringify({\n          message: \"Partial completion\",\n          processed: processedItems.length,\n          remaining: largeDataset.length - processedItems.length,\n        }),\n      };\n    }\n\n    await processItem(item);\n  }\n};\n</code></pre>"},{"location":"users/functions/runtime/#3-connection-pool-exhaustion","title":"3. Connection Pool Exhaustion","text":"<pre><code>// Proper connection management\nconst pool = new Pool({\n  max: 10, // Don't exceed runtime limits\n  idleTimeoutMillis: 30000,\n  connectionTimeoutMillis: 2000,\n});\n\n// Ensure cleanup\nexports.handler = async (event) =&gt; {\n  try {\n    const client = await pool.connect();\n    try {\n      return await client.query(\"SELECT * FROM users\");\n    } finally {\n      client.release();\n    }\n  } catch (error) {\n    console.error(\"Database error:\", error);\n    throw error;\n  }\n};\n</code></pre>"},{"location":"users/functions/runtime/#best-practices","title":"Best Practices","text":""},{"location":"users/functions/runtime/#1-efficient-initialization","title":"1. Efficient Initialization","text":"<pre><code>// Good: Initialize once\nconst heavyLibrary = require(\"heavy-library\");\nconst connection = createConnection();\n\nexports.handler = async (event) =&gt; {\n  // Reuse initialized resources\n};\n\n// Bad: Initialize on every invocation\nexports.handler = async (event) =&gt; {\n  const heavyLibrary = require(\"heavy-library\");\n  const connection = createConnection();\n};\n</code></pre>"},{"location":"users/functions/runtime/#2-error-handling","title":"2. Error Handling","text":"<pre><code>// Proper error handling with context\nexports.handler = async (event, context) =&gt; {\n  const logger = new Logger({ requestId: context.requestId });\n\n  try {\n    return await processRequest(event);\n  } catch (error) {\n    logger.error(\"Handler error\", {\n      error: error.message,\n      stack: error.stack,\n      event: JSON.stringify(event),\n    });\n\n    // Return appropriate error response\n    return {\n      statusCode: error.statusCode || 500,\n      body: JSON.stringify({\n        error: \"Internal server error\",\n        requestId: context.requestId,\n      }),\n    };\n  }\n};\n</code></pre>"},{"location":"users/functions/runtime/#3-resource-cleanup","title":"3. Resource Cleanup","text":"<pre><code>// Ensure resources are released\nconst resources = [];\n\nfunction addResource(resource) {\n  resources.push(resource);\n}\n\n// Cleanup on termination\nprocess.on(\"SIGTERM\", async () =&gt; {\n  for (const resource of resources) {\n    try {\n      await resource.close();\n    } catch (error) {\n      console.error(\"Cleanup error:\", error);\n    }\n  }\n});\n</code></pre>"},{"location":"users/functions/runtime/#related-documentation","title":"Related Documentation","text":"<ul> <li>Function Development</li> <li>Function Deployment</li> <li>Performance Optimization</li> <li>Monitoring Functions</li> </ul>"},{"location":"users/nodes/configuration/","title":"Node Configuration","text":"<p>This guide covers the configuration and management of nodes in the Hexabase.AI platform, including shared and dedicated node setups, resource allocation, and optimization.</p>"},{"location":"users/nodes/configuration/#node-architecture","title":"Node Architecture","text":""},{"location":"users/nodes/configuration/#node-types","title":"Node Types","text":"<pre><code>graph TD\n    A[Hexabase.AI Nodes] --&gt; B[Shared Nodes]\n    A --&gt; C[Dedicated Nodes]\n    A --&gt; D[Edge Nodes]\n\n    B --&gt; E[Multi-tenant]\n    B --&gt; F[Resource Pooling]\n    B --&gt; G[Cost Effective]\n\n    C --&gt; H[Single-tenant]\n    C --&gt; I[Guaranteed Resources]\n    C --&gt; J[Full Control]\n\n    D --&gt; K[Low Latency]\n    D --&gt; L[Edge Computing]\n    D --&gt; M[IoT Support]</code></pre>"},{"location":"users/nodes/configuration/#plan-based-node-access","title":"Plan-based Node Access","text":"Plan Shared Nodes Dedicated Nodes Edge Nodes Custom Hardware Single \u2713 - - - Team \u2713 \u2713 (Limited) - - Enterprise \u2713 \u2713 (Unlimited) \u2713 \u2713"},{"location":"users/nodes/configuration/#initial-node-setup","title":"Initial Node Setup","text":""},{"location":"users/nodes/configuration/#shared-node-configuration","title":"Shared Node Configuration","text":"<p>Shared nodes are pre-configured and managed by Hexabase.AI:</p> <pre><code># View available shared nodes\nhxb node list --type shared\n\n# Get node details\nhxb node describe shared-node-1\n\n# Check resource availability\nhxb node resources shared-node-1\n</code></pre>"},{"location":"users/nodes/configuration/#dedicated-node-setup","title":"Dedicated Node Setup","text":""},{"location":"users/nodes/configuration/#1-provisioning-a-dedicated-node","title":"1. Provisioning a Dedicated Node","text":"<pre><code># Request dedicated node\nhxb node provision \\\n  --type dedicated \\\n  --name prod-node-1 \\\n  --cpu 64 \\\n  --memory 256GB \\\n  --storage 4TB \\\n  --location us-east-1\n\n# Monitor provisioning\nhxb node status prod-node-1 --watch\n</code></pre>"},{"location":"users/nodes/configuration/#2-initial-configuration","title":"2. Initial Configuration","text":"<pre><code># node-config.yaml\napiVersion: infrastructure/v1\nkind: NodeConfiguration\nmetadata:\n  name: prod-node-1\nspec:\n  hardware:\n    cpu:\n      cores: 64\n      threads: 128\n      governor: performance\n    memory:\n      size: 256GB\n      hugepages: enabled\n    storage:\n      - device: /dev/nvme0n1\n        size: 2TB\n        type: system\n        filesystem: ext4\n      - device: /dev/nvme1n1\n        size: 2TB\n        type: data\n        filesystem: xfs\n\n  network:\n    interfaces:\n      - name: eth0\n        type: public\n        speed: 10Gbps\n        mtu: 9000\n      - name: eth1\n        type: private\n        speed: 25Gbps\n        mtu: 9000\n\n    bonding:\n      enabled: true\n      mode: active-backup\n      interfaces: [eth0, eth1]\n\n  virtualization:\n    hypervisor: kvm\n    nested: enabled\n    iommu: enabled\n\n  security:\n    firewall: enabled\n    selinux: enforcing\n    encryption: at-rest\n</code></pre>"},{"location":"users/nodes/configuration/#resource-configuration","title":"Resource Configuration","text":""},{"location":"users/nodes/configuration/#cpu-management","title":"CPU Management","text":""},{"location":"users/nodes/configuration/#cpu-allocation","title":"CPU Allocation","text":"<pre><code>cpu:\n  allocation:\n    reserved_system: 4 # Cores reserved for system\n    available_compute: 60 # Cores for workloads\n\n  pinning:\n    enabled: true\n    policy: strict # strict, preferred, none\n\n  features:\n    hyperthreading: enabled\n    numa_aware: true\n    cpu_manager_policy: static\n</code></pre>"},{"location":"users/nodes/configuration/#numa-configuration","title":"NUMA Configuration","text":"<pre><code># View NUMA topology\nhxb node numa-topology prod-node-1\n\n# Configure NUMA pinning\nhxb node configure prod-node-1 \\\n  --numa-pin vm-1:0,1 \\\n  --numa-pin vm-2:2,3\n</code></pre>"},{"location":"users/nodes/configuration/#memory-configuration","title":"Memory Configuration","text":""},{"location":"users/nodes/configuration/#memory-allocation","title":"Memory Allocation","text":"<pre><code>memory:\n  allocation:\n    system_reserved: 16GB\n    hugepages:\n      size_2MB: 8192 # 16GB in 2MB pages\n      size_1GB: 128 # 128GB in 1GB pages\n\n    overcommit:\n      enabled: false # Single user: false\n      ratio: 1.0 # Team: 1.5, Enterprise: configurable\n\n  swap:\n    enabled: true\n    size: 32GB\n    swappiness: 10\n</code></pre>"},{"location":"users/nodes/configuration/#memory-optimization","title":"Memory Optimization","text":"<pre><code># Enable transparent huge pages\nhxb node tune prod-node-1 --thp always\n\n# Configure memory limits\nhxb node limits prod-node-1 \\\n  --memory-hard 240GB \\\n  --memory-soft 220GB\n</code></pre>"},{"location":"users/nodes/configuration/#storage-configuration","title":"Storage Configuration","text":""},{"location":"users/nodes/configuration/#storage-layout","title":"Storage Layout","text":"<pre><code>storage:\n  volumes:\n    - name: system\n      path: /\n      size: 500GB\n      type: ssd\n      raid: mirror\n\n    - name: data\n      path: /var/lib/hexabase\n      size: 3.5TB\n      type: nvme\n      raid: stripe\n      cache: enabled\n\n  lvm:\n    enabled: true\n    volume_groups:\n      - name: vg_data\n        devices: [/dev/nvme1n1, /dev/nvme2n1]\n\n  filesystem:\n    defaults:\n      type: xfs\n      mount_options: \"noatime,nodiratime\"\n</code></pre>"},{"location":"users/nodes/configuration/#storage-performance-tuning","title":"Storage Performance Tuning","text":"<pre><code># Configure I/O scheduler\nhxb node storage tune prod-node-1 \\\n  --scheduler noop \\\n  --read-ahead 4096 \\\n  --nr-requests 256\n\n# Enable storage cache\nhxb node storage cache prod-node-1 \\\n  --type writeback \\\n  --size 16GB\n</code></pre>"},{"location":"users/nodes/configuration/#network-configuration","title":"Network Configuration","text":""},{"location":"users/nodes/configuration/#network-interfaces","title":"Network Interfaces","text":"<pre><code>network:\n  interfaces:\n    - name: eth0\n      type: physical\n      speed: 10Gbps\n      offload:\n        tso: enabled\n        gso: enabled\n        gro: enabled\n\n    - name: br0\n      type: bridge\n      members: [eth0]\n      stp: disabled\n\n    - name: vlan100\n      type: vlan\n      parent: eth0\n      vlan_id: 100\n\n  routing:\n    tables:\n      - name: main\n        routes:\n          - dst: 0.0.0.0/0\n            via: 192.168.1.1\n            dev: eth0\n\n  firewall:\n    zones:\n      - name: public\n        interfaces: [eth0]\n        services: [ssh, https]\n      - name: internal\n        interfaces: [br0]\n        services: [all]\n</code></pre>"},{"location":"users/nodes/configuration/#network-performance","title":"Network Performance","text":"<pre><code># Optimize network stack\nhxb node network tune prod-node-1 \\\n  --tcp-congestion bbr \\\n  --tcp-fastopen 3 \\\n  --net-core-rmem \"4096 87380 134217728\" \\\n  --net-core-wmem \"4096 65536 134217728\"\n\n# Configure network queues\nhxb node network queues prod-node-1 \\\n  --rx-queues 16 \\\n  --tx-queues 16 \\\n  --xps enabled\n</code></pre>"},{"location":"users/nodes/configuration/#service-configuration","title":"Service Configuration","text":""},{"location":"users/nodes/configuration/#container-runtime","title":"Container Runtime","text":"<pre><code># container-runtime.yaml\ncontainerRuntime:\n  type: containerd\n  version: 1.7.x\n\n  config:\n    default_runtime: runc\n    snapshotter: overlayfs\n\n    registries:\n      - mirror: registry.hexabase.ai\n        endpoints:\n          - https://registry.hexabase.ai\n\n    plugins:\n      cri:\n        sandbox_image: pause:3.9\n        max_container_log_line_size: 16384\n\n  resources:\n    cpu_manager: true\n    topology_manager: true\n    memory_manager: true\n</code></pre>"},{"location":"users/nodes/configuration/#kubernetes-configuration","title":"Kubernetes Configuration","text":"<pre><code># kubelet-config.yaml\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nclusterDNS:\n  - 10.96.0.10\ncpuManagerPolicy: static\nsystemReserved:\n  cpu: 2\n  memory: 4Gi\nkubeReserved:\n  cpu: 2\n  memory: 4Gi\nevictionHard:\n  memory.available: 1Gi\n  nodefs.available: 10%\n  imagefs.available: 15%\nmaxPods: 250\n</code></pre>"},{"location":"users/nodes/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"users/nodes/configuration/#metrics-collection","title":"Metrics Collection","text":"<pre><code>monitoring:\n  metrics:\n    enabled: true\n    interval: 30s\n    retention: 30d\n\n  exporters:\n    node_exporter:\n      enabled: true\n      port: 9100\n\n    custom_metrics:\n      - name: gpu_utilization\n        command: nvidia-smi\n        interval: 60s\n\n  alerts:\n    - name: high_cpu_usage\n      condition: cpu_usage &gt; 90\n      duration: 5m\n      severity: warning\n\n    - name: disk_space_low\n      condition: disk_free &lt; 10%\n      duration: 1m\n      severity: critical\n</code></pre>"},{"location":"users/nodes/configuration/#logging-configuration","title":"Logging Configuration","text":"<pre><code>logging:\n  drivers:\n    - type: journald\n      config:\n        max_size: 1G\n        max_files: 10\n\n    - type: fluentd\n      config:\n        endpoint: logs.hexabase.ai:24224\n        buffer_size: 32MB\n\n  levels:\n    system: info\n    application: debug\n    security: info\n</code></pre>"},{"location":"users/nodes/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"users/nodes/configuration/#access-control","title":"Access Control","text":"<pre><code>security:\n  ssh:\n    port: 22\n    permit_root_login: no\n    password_authentication: no\n    allowed_users:\n      - hexabase-admin\n      - node-operator\n\n  sudo:\n    passwordless:\n      - hexabase-admin\n    require_password:\n      - node-operator\n\n  selinux:\n    mode: enforcing\n    policy: targeted\n</code></pre>"},{"location":"users/nodes/configuration/#firewall-rules","title":"Firewall Rules","text":"<pre><code># Configure firewall\nhxb node firewall prod-node-1 \\\n  --zone public \\\n  --add-service ssh \\\n  --add-port 6443/tcp \\\n  --add-port 10250/tcp\n\n# Add custom rules\nhxb node firewall rule prod-node-1 \\\n  --add \"allow from 10.0.0.0/8 to any port 22\" \\\n  --add \"allow from any to any port 443\"\n</code></pre>"},{"location":"users/nodes/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"users/nodes/configuration/#kernel-parameters","title":"Kernel Parameters","text":"<pre><code># Apply performance tuning\nhxb node tune prod-node-1 --profile high-performance\n\n# Custom kernel parameters\ncat &gt; /etc/sysctl.d/99-hexabase.conf &lt;&lt; EOF\n# Network performance\nnet.core.rmem_max = 134217728\nnet.core.wmem_max = 134217728\nnet.ipv4.tcp_rmem = 4096 87380 134217728\nnet.ipv4.tcp_wmem = 4096 65536 134217728\n\n# VM settings\nvm.swappiness = 10\nvm.dirty_ratio = 15\nvm.dirty_background_ratio = 5\n\n# File system\nfs.file-max = 2097152\nfs.aio-max-nr = 1048576\nEOF\n</code></pre>"},{"location":"users/nodes/configuration/#power-management","title":"Power Management","text":"<pre><code>power:\n  governor: performance\n  c_states:\n    enabled: false # Disable for low latency\n  turbo:\n    enabled: true\n  frequency:\n    min: 2.4GHz\n    max: 3.8GHz\n</code></pre>"},{"location":"users/nodes/configuration/#maintenance-mode","title":"Maintenance Mode","text":""},{"location":"users/nodes/configuration/#entering-maintenance","title":"Entering Maintenance","text":"<pre><code># Drain workloads\nhxb node drain prod-node-1 --grace-period 300\n\n# Enter maintenance mode\nhxb node maintenance enter prod-node-1 \\\n  --reason \"Hardware upgrade\" \\\n  --estimated-duration 2h\n\n# Perform maintenance tasks\nhxb node update prod-node-1 --all\nhxb node firmware update prod-node-1\n</code></pre>"},{"location":"users/nodes/configuration/#exiting-maintenance","title":"Exiting Maintenance","text":"<pre><code># Run health checks\nhxb node health-check prod-node-1 --comprehensive\n\n# Exit maintenance mode\nhxb node maintenance exit prod-node-1\n\n# Uncordon node\nhxb node uncordon prod-node-1\n</code></pre>"},{"location":"users/nodes/configuration/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"users/nodes/configuration/#configuration-backup","title":"Configuration Backup","text":"<pre><code># Backup node configuration\nhxb node backup config prod-node-1 \\\n  --output /backup/node-config-$(date +%Y%m%d).tar.gz\n\n# Schedule automatic backups\nhxb node backup schedule prod-node-1 \\\n  --type config \\\n  --frequency daily \\\n  --retention 30\n</code></pre>"},{"location":"users/nodes/configuration/#disaster-recovery","title":"Disaster Recovery","text":"<pre><code># dr-config.yaml\ndisasterRecovery:\n  backup:\n    configuration: enabled\n    system_state: enabled\n    frequency: daily\n\n  replication:\n    target_node: prod-node-2\n    sync_interval: 15m\n\n  recovery:\n    rto: 4h\n    rpo: 1h\n</code></pre>"},{"location":"users/nodes/configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/nodes/configuration/#common-issues","title":"Common Issues","text":""},{"location":"users/nodes/configuration/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Analyze memory usage\nhxb node analyze prod-node-1 --memory\n\n# Clear caches\nhxb node clear-cache prod-node-1 --type all\n\n# Restart memory-intensive services\nhxb node service restart prod-node-1 kubelet\n</code></pre>"},{"location":"users/nodes/configuration/#network-performance_1","title":"Network Performance","text":"<pre><code># Test network throughput\nhxb node network test prod-node-1 \\\n  --type throughput \\\n  --duration 60\n\n# Check for packet loss\nhxb node network diagnose prod-node-1\n</code></pre>"},{"location":"users/nodes/configuration/#storage-issues","title":"Storage Issues","text":"<pre><code># Check disk health\nhxb node storage health prod-node-1\n\n# Run filesystem check\nhxb node storage fsck prod-node-1 --device /dev/nvme1n1\n\n# Analyze I/O patterns\nhxb node storage analyze prod-node-1 --duration 10m\n</code></pre>"},{"location":"users/nodes/configuration/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Regular Maintenance</p> </li> <li> <p>Weekly health checks</p> </li> <li>Monthly firmware updates</li> <li> <p>Quarterly performance reviews</p> </li> <li> <p>Resource Planning</p> </li> <li> <p>Monitor usage trends</p> </li> <li>Plan for growth</li> <li> <p>Maintain 20% headroom</p> </li> <li> <p>Security Hardening</p> </li> <li> <p>Regular security updates</p> </li> <li>Audit access logs</li> <li> <p>Review firewall rules</p> </li> <li> <p>Documentation</p> </li> <li>Document all changes</li> <li>Maintain runbooks</li> <li>Update disaster recovery plans</li> </ol>"},{"location":"users/nodes/configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>VM Management</li> <li>Node Scaling</li> <li>Health Monitoring</li> <li>Performance Optimization</li> </ul>"},{"location":"users/nodes/health-monitoring/","title":"Node Health Monitoring","text":"<p>This comprehensive guide covers health monitoring for nodes in the Hexabase.AI platform, including metrics collection, alerting, diagnostics, and preventive maintenance.</p>"},{"location":"users/nodes/health-monitoring/#health-monitoring-overview","title":"Health Monitoring Overview","text":""},{"location":"users/nodes/health-monitoring/#monitoring-architecture","title":"Monitoring Architecture","text":"<pre><code>graph TD\n    A[Node Health Monitoring] --&gt; B[Metrics Collection]\n    A --&gt; C[Health Checks]\n    A --&gt; D[Alerting]\n    A --&gt; E[Diagnostics]\n\n    B --&gt; F[System Metrics]\n    B --&gt; G[Application Metrics]\n    B --&gt; H[Custom Metrics]\n\n    C --&gt; I[Liveness Probes]\n    C --&gt; J[Readiness Checks]\n    C --&gt; K[Comprehensive Tests]\n\n    D --&gt; L[Threshold Alerts]\n    D --&gt; M[Anomaly Detection]\n    D --&gt; N[Predictive Alerts]</code></pre>"},{"location":"users/nodes/health-monitoring/#monitoring-coverage-by-plan","title":"Monitoring Coverage by Plan","text":"Plan Basic Monitoring Advanced Analytics AI-Powered Insights Custom Dashboards Single \u2713 - - - Team \u2713 \u2713 - Limited Enterprise \u2713 \u2713 \u2713 Unlimited"},{"location":"users/nodes/health-monitoring/#metrics-collection","title":"Metrics Collection","text":""},{"location":"users/nodes/health-monitoring/#system-metrics","title":"System Metrics","text":""},{"location":"users/nodes/health-monitoring/#cpu-metrics","title":"CPU Metrics","text":"<pre><code># cpu-metrics.yaml\nmetrics:\n  - name: node_cpu_utilization\n    type: gauge\n    unit: percent\n    collection_interval: 30s\n\n  - name: node_cpu_load_average\n    type: gauge\n    dimensions: [1m, 5m, 15m]\n\n  - name: node_cpu_temperature\n    type: gauge\n    unit: celsius\n    alert_threshold: 80\n\n  - name: node_cpu_throttling\n    type: counter\n    description: \"CPU throttling events\"\n</code></pre>"},{"location":"users/nodes/health-monitoring/#memory-metrics","title":"Memory Metrics","text":"<pre><code># memory-metrics.yaml\nmetrics:\n  - name: node_memory_used\n    type: gauge\n    unit: bytes\n\n  - name: node_memory_available\n    type: gauge\n    unit: bytes\n\n  - name: node_memory_pressure\n    type: gauge\n    unit: percent\n\n  - name: node_swap_usage\n    type: gauge\n    unit: bytes\n\n  - name: node_oom_kills\n    type: counter\n    description: \"Out of memory kill events\"\n</code></pre>"},{"location":"users/nodes/health-monitoring/#storage-metrics","title":"Storage Metrics","text":"<pre><code># storage-metrics.yaml\nmetrics:\n  - name: node_disk_usage\n    type: gauge\n    unit: bytes\n    labels: [device, mountpoint]\n\n  - name: node_disk_io_rate\n    type: gauge\n    unit: bytes_per_second\n    dimensions: [read, write]\n\n  - name: node_disk_iops\n    type: gauge\n    unit: operations_per_second\n\n  - name: node_disk_latency\n    type: histogram\n    unit: milliseconds\n    buckets: [1, 5, 10, 25, 50, 100]\n</code></pre>"},{"location":"users/nodes/health-monitoring/#application-metrics","title":"Application Metrics","text":"<pre><code># Configure application metrics collection\nhxb monitoring configure \\\n  --node prod-node-1 \\\n  --enable-app-metrics \\\n  --endpoints kubernetes,docker,custom\n\n# Add custom application endpoint\nhxb monitoring add-endpoint \\\n  --node prod-node-1 \\\n  --name myapp \\\n  --url http://localhost:9090/metrics \\\n  --format prometheus\n</code></pre>"},{"location":"users/nodes/health-monitoring/#custom-metrics","title":"Custom Metrics","text":"<pre><code># custom-metrics-collector.py\nfrom hexabase.monitoring import MetricsCollector\n\ncollector = MetricsCollector(node=\"prod-node-1\")\n\n# Define custom metric\n@collector.gauge(\"custom_queue_depth\", \"items\")\ndef get_queue_depth():\n    return measure_queue_depth()\n\n@collector.histogram(\"custom_processing_time\", \"seconds\",\n                    buckets=[0.1, 0.5, 1.0, 2.0, 5.0])\ndef track_processing_time(duration):\n    return duration\n\n# Start collection\ncollector.start(interval=60)\n</code></pre>"},{"location":"users/nodes/health-monitoring/#health-checks","title":"Health Checks","text":""},{"location":"users/nodes/health-monitoring/#liveness-probes","title":"Liveness Probes","text":"<pre><code># liveness-checks.yaml\napiVersion: monitoring/v1\nkind: LivenessProbe\nmetadata:\n  name: node-liveness\nspec:\n  checks:\n    - name: system-responsive\n      command: \"echo 'alive'\"\n      timeout: 5s\n\n    - name: kernel-not-panicked\n      command: \"dmesg | grep -i panic | wc -l\"\n      expectedOutput: \"0\"\n\n    - name: critical-services\n      command: \"systemctl is-active kubelet docker\"\n      expectedOutput: \"active\\nactive\"\n\n  interval: 60s\n  failureThreshold: 3\n  action:\n    type: restart\n    gracePeriod: 300s\n</code></pre>"},{"location":"users/nodes/health-monitoring/#readiness-checks","title":"Readiness Checks","text":"<pre><code># readiness-checks.yaml\napiVersion: monitoring/v1\nkind: ReadinessProbe\nmetadata:\n  name: node-readiness\nspec:\n  checks:\n    - name: cpu-available\n      metric: node_cpu_utilization\n      condition: \"&lt; 90\"\n\n    - name: memory-available\n      metric: node_memory_available\n      condition: \"&gt; 1Gi\"\n\n    - name: disk-space\n      metric: node_disk_usage\n      condition: \"&lt; 85%\"\n\n    - name: network-connectivity\n      http:\n        url: http://registry.hexabase.ai/health\n        timeout: 10s\n\n  interval: 30s\n  successThreshold: 2\n</code></pre>"},{"location":"users/nodes/health-monitoring/#comprehensive-health-tests","title":"Comprehensive Health Tests","text":"<pre><code># Run comprehensive health check\nhxb node health-check prod-node-1 --comprehensive\n\n# Specific component checks\nhxb node health-check prod-node-1 \\\n  --components cpu,memory,disk,network,kubernetes\n\n# Generate health report\nhxb node health-report prod-node-1 \\\n  --format pdf \\\n  --output node-health-$(date +%Y%m%d).pdf\n</code></pre>"},{"location":"users/nodes/health-monitoring/#alerting-configuration","title":"Alerting Configuration","text":""},{"location":"users/nodes/health-monitoring/#alert-rules","title":"Alert Rules","text":"<pre><code># alert-rules.yaml\napiVersion: monitoring/v1\nkind: AlertRules\nmetadata:\n  name: node-alerts\nspec:\n  groups:\n    - name: critical\n      rules:\n        - alert: NodeDown\n          expr: up{job=\"node\"} == 0\n          for: 2m\n          severity: critical\n          annotations:\n            summary: \"Node {{ $labels.node }} is down\"\n\n        - alert: HighCPUUsage\n          expr: node_cpu_utilization &gt; 90\n          for: 5m\n          severity: warning\n          annotations:\n            summary: \"CPU usage above 90% on {{ $labels.node }}\"\n\n        - alert: DiskSpaceLow\n          expr: node_disk_free_percent &lt; 10\n          for: 5m\n          severity: critical\n          annotations:\n            summary: \"Less than 10% disk space on {{ $labels.node }}\"\n\n    - name: performance\n      rules:\n        - alert: HighMemoryPressure\n          expr: node_memory_pressure &gt; 80\n          for: 10m\n          severity: warning\n\n        - alert: NetworkLatencyHigh\n          expr: node_network_latency_ms &gt; 100\n          for: 5m\n          severity: warning\n</code></pre>"},{"location":"users/nodes/health-monitoring/#alert-channels","title":"Alert Channels","text":"<pre><code># Configure email alerts\nhxb alerts configure email \\\n  --smtp-server smtp.gmail.com:587 \\\n  --from alerts@example.com \\\n  --to ops-team@example.com\n\n# Configure Slack alerts\nhxb alerts configure slack \\\n  --webhook-url https://hooks.slack.com/services/xxx \\\n  --channel #alerts \\\n  --mention @oncall\n\n# Configure PagerDuty\nhxb alerts configure pagerduty \\\n  --integration-key xxx \\\n  --severity-mapping critical=P1,warning=P3\n</code></pre>"},{"location":"users/nodes/health-monitoring/#alert-suppression","title":"Alert Suppression","text":"<pre><code># alert-suppression.yaml\nsuppressions:\n  - name: maintenance-window\n    match:\n      alertname: \".*\"\n      node: \"prod-node-1\"\n    time_periods:\n      - start: \"2024-01-15T02:00:00Z\"\n        end: \"2024-01-15T04:00:00Z\"\n\n  - name: known-issue\n    match:\n      alertname: \"DiskIOHigh\"\n      device: \"/dev/sdb\"\n    until: \"2024-01-20T00:00:00Z\"\n    comment: \"Known issue with backup disk\"\n</code></pre>"},{"location":"users/nodes/health-monitoring/#diagnostics-tools","title":"Diagnostics Tools","text":""},{"location":"users/nodes/health-monitoring/#built-in-diagnostics","title":"Built-in Diagnostics","text":"<pre><code># System diagnostics\nhxb node diagnose prod-node-1 --system\n\n# Network diagnostics\nhxb node diagnose prod-node-1 --network \\\n  --tests connectivity,bandwidth,latency,packet-loss\n\n# Storage diagnostics\nhxb node diagnose prod-node-1 --storage \\\n  --deep-scan \\\n  --check-smart\n</code></pre>"},{"location":"users/nodes/health-monitoring/#performance-analysis","title":"Performance Analysis","text":"<pre><code># CPU performance analysis\nhxb node analyze prod-node-1 --cpu \\\n  --duration 10m \\\n  --profile \\\n  --output cpu-analysis.html\n\n# Memory analysis\nhxb node analyze prod-node-1 --memory \\\n  --check-leaks \\\n  --heap-dump \\\n  --output memory-analysis.tar.gz\n\n# I/O analysis\nhxb node analyze prod-node-1 --io \\\n  --trace \\\n  --duration 5m\n</code></pre>"},{"location":"users/nodes/health-monitoring/#log-analysis","title":"Log Analysis","text":"<pre><code># log-analysis.yaml\napiVersion: monitoring/v1\nkind: LogAnalysis\nmetadata:\n  name: node-logs\nspec:\n  sources:\n    - path: /var/log/messages\n      parser: syslog\n\n    - path: /var/log/kern.log\n      parser: kernel\n\n    - path: /var/log/hexabase/*.log\n      parser: json\n\n  patterns:\n    - name: errors\n      regex: \"(ERROR|FATAL|CRITICAL)\"\n      severity: high\n\n    - name: warnings\n      regex: \"(WARN|WARNING)\"\n      severity: medium\n\n    - name: oom_killer\n      regex: \"Out of memory: Kill process\"\n      severity: critical\n      alert: immediate\n</code></pre>"},{"location":"users/nodes/health-monitoring/#dashboard-configuration","title":"Dashboard Configuration","text":""},{"location":"users/nodes/health-monitoring/#system-overview-dashboard","title":"System Overview Dashboard","text":"<pre><code># system-dashboard.yaml\napiVersion: monitoring/v1\nkind: Dashboard\nmetadata:\n  name: node-health-overview\nspec:\n  refresh: 30s\n  time_range: 1h\n\n  panels:\n    - title: \"Node Status\"\n      type: stat\n      targets:\n        - expr: up{node=\"$node\"}\n          legend: \"Status\"\n\n    - title: \"CPU Usage\"\n      type: graph\n      targets:\n        - expr: node_cpu_utilization{node=\"$node\"}\n          legend: \"CPU %\"\n\n    - title: \"Memory Usage\"\n      type: gauge\n      targets:\n        - expr: node_memory_used{node=\"$node\"} / node_memory_total{node=\"$node\"} * 100\n          legend: \"Memory %\"\n\n    - title: \"Disk I/O\"\n      type: graph\n      targets:\n        - expr: rate(node_disk_read_bytes{node=\"$node\"}[5m])\n          legend: \"Read\"\n        - expr: rate(node_disk_written_bytes{node=\"$node\"}[5m])\n          legend: \"Write\"\n</code></pre>"},{"location":"users/nodes/health-monitoring/#custom-dashboards","title":"Custom Dashboards","text":"<pre><code># Create custom dashboard\nhxb dashboard create \\\n  --name \"Application Performance\" \\\n  --template app-performance \\\n  --customize\n\n# Import Grafana dashboard\nhxb dashboard import \\\n  --source grafana \\\n  --id 12345 \\\n  --adapt-queries\n\n# Share dashboard\nhxb dashboard share node-health-overview \\\n  --public-read \\\n  --embed-allowed\n</code></pre>"},{"location":"users/nodes/health-monitoring/#preventive-maintenance","title":"Preventive Maintenance","text":""},{"location":"users/nodes/health-monitoring/#automated-health-remediation","title":"Automated Health Remediation","text":"<pre><code># auto-remediation.yaml\napiVersion: monitoring/v1\nkind: RemediationPolicy\nmetadata:\n  name: auto-fix\nspec:\n  rules:\n    - condition: node_disk_usage &gt; 90\n      actions:\n        - name: cleanup-logs\n          command: \"find /var/log -type f -name '*.log' -mtime +30 -delete\"\n        - name: cleanup-tmp\n          command: \"find /tmp -type f -atime +7 -delete\"\n\n    - condition: node_memory_pressure &gt; 85\n      actions:\n        - name: clear-caches\n          command: \"sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches\"\n        - name: restart-heavy-services\n          command: \"systemctl restart kubelet\"\n          after: 300s\n\n    - condition: node_load_average_5m &gt; 10\n      actions:\n        - name: identify-top-processes\n          command: \"ps aux --sort=-%cpu | head -20\"\n          log: true\n        - name: limit-resources\n          command: \"cpulimit -l 50 -p $(pgrep -f heavy_process)\"\n</code></pre>"},{"location":"users/nodes/health-monitoring/#predictive-maintenance","title":"Predictive Maintenance","text":"<pre><code># predictive-maintenance.py\nfrom hexabase.aiops import PredictiveAnalyzer\n\nanalyzer = PredictiveAnalyzer(node=\"prod-node-1\")\n\n# Train model on historical data\nanalyzer.train(\n    metrics=[\"cpu\", \"memory\", \"disk_io\", \"network\"],\n    period=\"90d\",\n    anomaly_detection=True\n)\n\n# Get predictions\npredictions = analyzer.predict(horizon=\"7d\")\n\nfor prediction in predictions:\n    if prediction.probability &gt; 0.8:\n        print(f\"Predicted issue: {prediction.issue}\")\n        print(f\"Time to failure: {prediction.ttf}\")\n        print(f\"Recommended action: {prediction.action}\")\n</code></pre>"},{"location":"users/nodes/health-monitoring/#integration-with-aiops","title":"Integration with AIOps","text":""},{"location":"users/nodes/health-monitoring/#ai-powered-analysis","title":"AI-Powered Analysis","text":"<pre><code># aiops-integration.yaml\napiVersion: aiops/v1\nkind: HealthAnalyzer\nmetadata:\n  name: intelligent-monitoring\nspec:\n  models:\n    - type: anomaly-detection\n      algorithm: isolation-forest\n      training_window: 30d\n\n    - type: root-cause-analysis\n      algorithm: decision-tree\n      features: [\"metrics\", \"logs\", \"events\"]\n\n    - type: capacity-prediction\n      algorithm: prophet\n      forecast_horizon: 30d\n\n  actions:\n    anomaly_detected:\n      - notify: ops-team\n      - create_incident: true\n      - gather_diagnostics: true\n\n    capacity_threshold:\n      - alert: capacity-planning-team\n      - recommend_scaling: true\n</code></pre>"},{"location":"users/nodes/health-monitoring/#intelligent-alerting","title":"Intelligent Alerting","text":"<pre><code># Configure AI-powered alerting\nhxb aiops configure alerts \\\n  --enable-smart-grouping \\\n  --enable-noise-reduction \\\n  --learning-period 14d\n\n# Train on historical alerts\nhxb aiops train \\\n  --type alert-correlation \\\n  --data-source historical-alerts \\\n  --period 90d\n\n# Enable predictive alerts\nhxb aiops enable predictive-alerts \\\n  --confidence-threshold 0.85 \\\n  --advance-warning 2h\n</code></pre>"},{"location":"users/nodes/health-monitoring/#troubleshooting-monitoring-issues","title":"Troubleshooting Monitoring Issues","text":""},{"location":"users/nodes/health-monitoring/#common-problems","title":"Common Problems","text":""},{"location":"users/nodes/health-monitoring/#missing-metrics","title":"Missing Metrics","text":"<pre><code># Debug metric collection\nhxb monitoring debug \\\n  --node prod-node-1 \\\n  --component prometheus \\\n  --verbose\n\n# Verify endpoints\nhxb monitoring test-endpoint \\\n  --node prod-node-1 \\\n  --url http://localhost:9100/metrics\n\n# Restart collectors\nhxb monitoring restart \\\n  --node prod-node-1 \\\n  --collectors node-exporter,custom-metrics\n</code></pre>"},{"location":"users/nodes/health-monitoring/#alert-fatigue","title":"Alert Fatigue","text":"<pre><code># Analyze alert patterns\nhxb alerts analyze \\\n  --period 30d \\\n  --identify-noisy\n\n# Tune alert thresholds\nhxb alerts tune \\\n  --auto-adjust \\\n  --target-precision 0.95\n\n# Configure alert deduplication\nhxb alerts configure dedup \\\n  --window 5m \\\n  --group-by node,alertname\n</code></pre>"},{"location":"users/nodes/health-monitoring/#dashboard-performance","title":"Dashboard Performance","text":"<pre><code># Optimize slow dashboards\nhxb dashboard optimize node-health-overview \\\n  --analyze-queries \\\n  --suggest-improvements\n\n# Cache frequently accessed data\nhxb dashboard cache enable \\\n  --dashboard node-health-overview \\\n  --ttl 5m\n</code></pre>"},{"location":"users/nodes/health-monitoring/#best-practices","title":"Best Practices","text":""},{"location":"users/nodes/health-monitoring/#1-monitoring-strategy","title":"1. Monitoring Strategy","text":"<ul> <li>Define clear SLIs and SLOs</li> <li>Implement defense-in-depth monitoring</li> <li>Balance coverage with overhead</li> <li>Regular review and tuning</li> </ul>"},{"location":"users/nodes/health-monitoring/#2-alert-design","title":"2. Alert Design","text":"<ul> <li>Alert on symptoms, not causes</li> <li>Include clear remediation steps</li> <li>Set appropriate severity levels</li> <li>Implement escalation policies</li> </ul>"},{"location":"users/nodes/health-monitoring/#3-data-retention","title":"3. Data Retention","text":"<ul> <li>Keep high-resolution data short-term</li> <li>Downsample for long-term storage</li> <li>Archive critical incident data</li> <li>Comply with regulatory requirements</li> </ul>"},{"location":"users/nodes/health-monitoring/#4-performance-impact","title":"4. Performance Impact","text":"<ul> <li>Monitor the monitors</li> <li>Optimize collection intervals</li> <li>Use sampling for high-volume metrics</li> <li>Implement circuit breakers</li> </ul>"},{"location":"users/nodes/health-monitoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Node Configuration</li> <li>Performance Optimization</li> <li>AIOps Integration</li> <li>Incident Management</li> </ul>"},{"location":"users/nodes/scaling/","title":"Node Scaling","text":"<p>This guide covers scaling strategies for nodes in the Hexabase.AI platform, including horizontal and vertical scaling, auto-scaling configurations, and capacity planning.</p>"},{"location":"users/nodes/scaling/#scaling-overview","title":"Scaling Overview","text":""},{"location":"users/nodes/scaling/#scaling-dimensions","title":"Scaling Dimensions","text":"<pre><code>graph TD\n    A[Node Scaling] --&gt; B[Vertical Scaling]\n    A --&gt; C[Horizontal Scaling]\n    A --&gt; D[Auto Scaling]\n\n    B --&gt; E[CPU/Memory Upgrade]\n    B --&gt; F[Storage Expansion]\n    B --&gt; G[Network Bandwidth]\n\n    C --&gt; H[Add Nodes]\n    C --&gt; I[Geographic Distribution]\n    C --&gt; J[Load Distribution]\n\n    D --&gt; K[Metric-based]\n    D --&gt; L[Schedule-based]\n    D --&gt; M[Predictive]</code></pre>"},{"location":"users/nodes/scaling/#plan-based-scaling-limits","title":"Plan-based Scaling Limits","text":"Plan Max Nodes Vertical Limit Auto-scaling Multi-region Single 1 (shared) Limited - - Team 5 Moderate Basic - Enterprise Unlimited No limit Advanced \u2713"},{"location":"users/nodes/scaling/#vertical-scaling","title":"Vertical Scaling","text":""},{"location":"users/nodes/scaling/#cpu-and-memory-scaling","title":"CPU and Memory Scaling","text":""},{"location":"users/nodes/scaling/#online-scaling-hot-add","title":"Online Scaling (Hot-add)","text":"<pre><code># Check if hot-add is supported\nhxb node capabilities prod-node-1\n\n# Add CPU resources (if supported)\nhxb node scale prod-node-1 \\\n  --cpu-add 16 \\\n  --online\n\n# Add memory (if supported)\nhxb node scale prod-node-1 \\\n  --memory-add 64GB \\\n  --online\n</code></pre>"},{"location":"users/nodes/scaling/#offline-scaling","title":"Offline Scaling","text":"<pre><code># Schedule maintenance window\nhxb node maintenance schedule prod-node-1 \\\n  --start \"2024-01-15 02:00\" \\\n  --duration 2h \\\n  --reason \"Vertical scaling\"\n\n# Drain workloads\nhxb node drain prod-node-1 --delete-local-data\n\n# Perform scaling\nhxb node scale prod-node-1 \\\n  --cpu 64 \\\n  --memory 512GB \\\n  --reboot\n</code></pre>"},{"location":"users/nodes/scaling/#storage-scaling","title":"Storage Scaling","text":""},{"location":"users/nodes/scaling/#dynamic-storage-expansion","title":"Dynamic Storage Expansion","text":"<pre><code># Expand existing volume\nhxb node storage expand prod-node-1 \\\n  --volume /dev/vg_data/lv_apps \\\n  --size +500GB\n\n# Add new storage device\nhxb node storage add prod-node-1 \\\n  --device /dev/nvme2n1 \\\n  --size 2TB \\\n  --type nvme \\\n  --mount /data2\n</code></pre>"},{"location":"users/nodes/scaling/#storage-tiering","title":"Storage Tiering","text":"<pre><code># storage-tiers.yaml\napiVersion: storage/v1\nkind: StorageTiering\nmetadata:\n  name: prod-node-1-tiers\nspec:\n  tiers:\n    - name: hot\n      type: nvme\n      size: 1TB\n      policy:\n        age: \"&lt; 7d\"\n        access_frequency: \"&gt; 10/day\"\n\n    - name: warm\n      type: ssd\n      size: 4TB\n      policy:\n        age: \"7d-30d\"\n        access_frequency: \"1-10/day\"\n\n    - name: cold\n      type: hdd\n      size: 10TB\n      policy:\n        age: \"&gt; 30d\"\n        access_frequency: \"&lt; 1/day\"\n</code></pre>"},{"location":"users/nodes/scaling/#network-bandwidth-scaling","title":"Network Bandwidth Scaling","text":"<pre><code># Upgrade network interface\nhxb node network upgrade prod-node-1 \\\n  --interface eth0 \\\n  --speed 25Gbps\n\n# Add network interface\nhxb node network add-interface prod-node-1 \\\n  --type ethernet \\\n  --speed 10Gbps \\\n  --name eth2\n\n# Configure bonding for increased bandwidth\nhxb node network bond prod-node-1 \\\n  --name bond0 \\\n  --slaves eth0,eth1,eth2 \\\n  --mode 802.3ad\n</code></pre>"},{"location":"users/nodes/scaling/#horizontal-scaling","title":"Horizontal Scaling","text":""},{"location":"users/nodes/scaling/#adding-nodes","title":"Adding Nodes","text":""},{"location":"users/nodes/scaling/#quick-node-addition","title":"Quick Node Addition","text":"<pre><code># Clone existing node configuration\nhxb node clone prod-node-1 \\\n  --target prod-node-2 \\\n  --modify cpu=32,memory=256GB\n\n# Join to cluster\nhxb cluster join prod-node-2 \\\n  --cluster prod-cluster \\\n  --role worker\n</code></pre>"},{"location":"users/nodes/scaling/#batch-node-provisioning","title":"Batch Node Provisioning","text":"<pre><code># nodes-scaling.yaml\napiVersion: infrastructure/v1\nkind: NodePool\nmetadata:\n  name: web-tier-pool\nspec:\n  count: 5\n  template:\n    spec:\n      cpu: 16\n      memory: 64GB\n      storage: 500GB\n      labels:\n        tier: web\n        scalable: \"true\"\n\n  placement:\n    strategy: spread\n    zones:\n      - us-east-1a\n      - us-east-1b\n      - us-east-1c\n</code></pre>"},{"location":"users/nodes/scaling/#geographic-distribution","title":"Geographic Distribution","text":"<pre><code># multi-region-scaling.yaml\napiVersion: infrastructure/v1\nkind: RegionalScaling\nmetadata:\n  name: global-scaling\nspec:\n  regions:\n    - name: us-east\n      nodes: 10\n      primary: true\n\n    - name: eu-west\n      nodes: 8\n      latency_target: \"&lt; 50ms\"\n\n    - name: ap-south\n      nodes: 6\n      backup: true\n\n  replication:\n    mode: active-active\n    consistency: eventual\n</code></pre>"},{"location":"users/nodes/scaling/#load-distribution","title":"Load Distribution","text":"<pre><code># Configure load balancing\nhxb load-balancer create \\\n  --name prod-lb \\\n  --algorithm round-robin \\\n  --health-check http:8080/health\n\n# Add nodes to load balancer\nhxb load-balancer add-backend prod-lb \\\n  --nodes prod-node-1,prod-node-2,prod-node-3 \\\n  --weight 1:2:1\n</code></pre>"},{"location":"users/nodes/scaling/#auto-scaling-configuration","title":"Auto-scaling Configuration","text":""},{"location":"users/nodes/scaling/#metric-based-auto-scaling","title":"Metric-based Auto-scaling","text":"<pre><code># autoscaling-policy.yaml\napiVersion: autoscaling/v2\nkind: AutoScalingPolicy\nmetadata:\n  name: node-autoscaler\nspec:\n  target:\n    kind: NodePool\n    name: web-tier-pool\n\n  minNodes: 3\n  maxNodes: 20\n\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 80\n\n    - type: Custom\n      custom:\n        name: request_rate\n        target:\n          type: AverageValue\n          averageValue: \"1000\"\n\n  behavior:\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n        - type: Pods\n          value: 2\n          periodSeconds: 60\n\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n        - type: Pods\n          value: 1\n          periodSeconds: 180\n</code></pre>"},{"location":"users/nodes/scaling/#schedule-based-scaling","title":"Schedule-based Scaling","text":"<pre><code># scheduled-scaling.yaml\napiVersion: scaling/v1\nkind: ScheduledScaling\nmetadata:\n  name: business-hours-scaling\nspec:\n  schedules:\n    - name: weekday-peak\n      schedule: \"0 8 * * 1-5\" # 8 AM weekdays\n      minNodes: 10\n      desiredNodes: 15\n\n    - name: weekday-normal\n      schedule: \"0 18 * * 1-5\" # 6 PM weekdays\n      minNodes: 5\n      desiredNodes: 8\n\n    - name: weekend\n      schedule: \"0 0 * * 0,6\" # Weekends\n      minNodes: 3\n      desiredNodes: 5\n\n  timezone: \"America/New_York\"\n</code></pre>"},{"location":"users/nodes/scaling/#predictive-scaling","title":"Predictive Scaling","text":"<pre><code># predictive-scaling.yaml\napiVersion: aiops/v1\nkind: PredictiveScaling\nmetadata:\n  name: ml-based-scaling\nspec:\n  model:\n    type: prophet\n    training_window: 30d\n    forecast_horizon: 24h\n\n  features:\n    - historical_load\n    - time_of_day\n    - day_of_week\n    - special_events\n\n  actions:\n    scale_up_threshold: 0.8\n    scale_down_threshold: 0.3\n\n  constraints:\n    min_nodes: 5\n    max_nodes: 50\n    budget_limit: 10000 # Monthly USD\n</code></pre>"},{"location":"users/nodes/scaling/#capacity-planning","title":"Capacity Planning","text":""},{"location":"users/nodes/scaling/#resource-forecasting","title":"Resource Forecasting","text":"<pre><code># Analyze historical usage\nhxb capacity analyze \\\n  --period 90d \\\n  --resource cpu,memory,storage\n\n# Generate capacity report\nhxb capacity forecast \\\n  --horizon 6m \\\n  --growth-rate 20% \\\n  --confidence 95%\n\n# Get recommendations\nhxb capacity recommend \\\n  --target-utilization 70% \\\n  --buffer 30%\n</code></pre>"},{"location":"users/nodes/scaling/#capacity-monitoring-dashboard","title":"Capacity Monitoring Dashboard","text":"<pre><code># capacity-dashboard.yaml\napiVersion: monitoring/v1\nkind: Dashboard\nmetadata:\n  name: capacity-planning\nspec:\n  panels:\n    - title: \"CPU Capacity\"\n      metrics:\n        - node_cpu_total\n        - node_cpu_used\n        - node_cpu_available\n      visualization: timeseries\n\n    - title: \"Memory Capacity\"\n      metrics:\n        - node_memory_total\n        - node_memory_used\n        - node_memory_available\n      visualization: gauge\n\n    - title: \"Growth Projection\"\n      query: |\n        predict_linear(\n          node_cpu_used[30d], \n          86400 * 30\n        )\n      visualization: line\n</code></pre>"},{"location":"users/nodes/scaling/#scaling-strategies","title":"Scaling Strategies","text":""},{"location":"users/nodes/scaling/#reactive-scaling","title":"Reactive Scaling","text":"<pre><code># reactive-scaling.yaml\ntriggers:\n  - name: cpu-spike\n    condition: \"cpu_usage &gt; 90%\"\n    duration: 5m\n    action:\n      type: scale-out\n      nodes: 2\n\n  - name: memory-pressure\n    condition: \"memory_available &lt; 10%\"\n    duration: 2m\n    action:\n      type: scale-up\n      memory: \"+50%\"\n</code></pre>"},{"location":"users/nodes/scaling/#proactive-scaling","title":"Proactive Scaling","text":"<pre><code># Pre-scale for expected load\nhxb node scale-schedule \\\n  --name black-friday-prep \\\n  --start \"2024-11-28 00:00\" \\\n  --nodes 50 \\\n  --preemptive\n\n# Configure burst capacity\nhxb node burst-config \\\n  --pool prod-pool \\\n  --burst-limit 200% \\\n  --duration 4h\n</code></pre>"},{"location":"users/nodes/scaling/#cost-optimized-scaling","title":"Cost-Optimized Scaling","text":"<pre><code># cost-optimization.yaml\napiVersion: finops/v1\nkind: CostOptimizedScaling\nmetadata:\n  name: budget-aware-scaling\nspec:\n  budget:\n    monthly_limit: 50000\n    currency: USD\n\n  preferences:\n    - use_spot_instances: true\n      spot_percentage: 60\n\n    - use_reserved_capacity: true\n      reservation_term: 1y\n\n    - rightsizing:\n        enabled: true\n        check_interval: weekly\n\n  constraints:\n    min_performance: \"baseline\"\n    availability: \"99.9%\"\n</code></pre>"},{"location":"users/nodes/scaling/#scaling-automation","title":"Scaling Automation","text":""},{"location":"users/nodes/scaling/#gitops-based-scaling","title":"GitOps-based Scaling","text":"<pre><code># .github/workflows/scale-infrastructure.yml\nname: Infrastructure Scaling\n\non:\n  repository_dispatch:\n    types: [scale-request]\n\njobs:\n  scale:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Validate scaling request\n        run: |\n          hxb capacity check \\\n            --requested-nodes ${{ github.event.client_payload.nodes }} \\\n            --budget-check\n\n      - name: Apply scaling\n        run: |\n          hxb node scale \\\n            --pool ${{ github.event.client_payload.pool }} \\\n            --count ${{ github.event.client_payload.nodes }} \\\n            --approve\n</code></pre>"},{"location":"users/nodes/scaling/#api-driven-scaling","title":"API-driven Scaling","text":"<pre><code># scaling-api.py\nfrom hexabase import ScalingClient\n\nclient = ScalingClient(api_key=\"...\")\n\n# Get current capacity\ncapacity = client.get_capacity(\"prod-pool\")\n\n# Calculate required nodes\nrequired = calculate_required_nodes(\n    current_load=capacity.current_load,\n    predicted_load=capacity.predicted_load,\n    sla_target=0.99\n)\n\n# Scale if needed\nif required &gt; capacity.node_count:\n    client.scale_out(\n        pool=\"prod-pool\",\n        count=required - capacity.node_count,\n        reason=\"Predicted load increase\"\n    )\n</code></pre>"},{"location":"users/nodes/scaling/#monitoring-scaling-operations","title":"Monitoring Scaling Operations","text":""},{"location":"users/nodes/scaling/#scaling-events","title":"Scaling Events","text":"<pre><code># Monitor scaling events\nhxb events watch --type scaling\n\n# Get scaling history\nhxb scaling history \\\n  --pool prod-pool \\\n  --period 30d\n\n# Analyze scaling efficiency\nhxb scaling analyze \\\n  --metric response-time \\\n  --compare before-after\n</code></pre>"},{"location":"users/nodes/scaling/#scaling-metrics","title":"Scaling Metrics","text":"<pre><code># scaling-metrics.yaml\nmetrics:\n  - name: scaling_operations_total\n    type: counter\n    labels: [pool, direction, trigger]\n\n  - name: scaling_duration_seconds\n    type: histogram\n    buckets: [30, 60, 120, 300, 600]\n\n  - name: nodes_current\n    type: gauge\n    labels: [pool, state]\n\n  - name: scaling_efficiency_ratio\n    type: gauge\n    description: \"Performance gain / Resource increase\"\n</code></pre>"},{"location":"users/nodes/scaling/#troubleshooting-scaling-issues","title":"Troubleshooting Scaling Issues","text":""},{"location":"users/nodes/scaling/#common-problems","title":"Common Problems","text":""},{"location":"users/nodes/scaling/#scale-out-failures","title":"Scale-out Failures","text":"<pre><code># Debug scale-out issues\nhxb scaling debug \\\n  --operation scale-out \\\n  --pool prod-pool \\\n  --verbose\n\n# Check constraints\nhxb constraints check \\\n  --type node-limit \\\n  --type budget \\\n  --type availability-zone\n</code></pre>"},{"location":"users/nodes/scaling/#performance-degradation-after-scaling","title":"Performance Degradation After Scaling","text":"<pre><code># Analyze performance impact\nhxb performance compare \\\n  --before \"2024-01-10\" \\\n  --after \"2024-01-11\" \\\n  --metrics latency,throughput\n\n# Rebalance workloads\nhxb workload rebalance \\\n  --pool prod-pool \\\n  --strategy even-distribution\n</code></pre>"},{"location":"users/nodes/scaling/#best-practices","title":"Best Practices","text":""},{"location":"users/nodes/scaling/#1-gradual-scaling","title":"1. Gradual Scaling","text":"<ul> <li>Scale in small increments</li> <li>Monitor impact between changes</li> <li>Use canary deployments</li> </ul>"},{"location":"users/nodes/scaling/#2-right-sizing","title":"2. Right-sizing","text":"<ul> <li>Regular utilization reviews</li> <li>Avoid over-provisioning</li> <li>Use appropriate instance types</li> </ul>"},{"location":"users/nodes/scaling/#3-cost-management","title":"3. Cost Management","text":"<ul> <li>Set budget alerts</li> <li>Use spot instances where appropriate</li> <li>Implement automatic cleanup</li> </ul>"},{"location":"users/nodes/scaling/#4-testing","title":"4. Testing","text":"<ul> <li>Load test scaling policies</li> <li>Simulate failure scenarios</li> <li>Validate rollback procedures</li> </ul>"},{"location":"users/nodes/scaling/#related-documentation","title":"Related Documentation","text":"<ul> <li>Node Configuration</li> <li>Health Monitoring</li> <li>Performance Optimization</li> <li>Cost Management</li> </ul>"},{"location":"users/nodes/vm-management/","title":"VM Management","text":"<p>This guide covers virtual machine management within the Hexabase.AI platform, including provisioning, lifecycle management, and optimization strategies.</p>"},{"location":"users/nodes/vm-management/#overview","title":"Overview","text":"<p>Hexabase.AI provides comprehensive VM management capabilities across shared and dedicated node infrastructures, enabling flexible compute resource allocation based on your plan level.</p>"},{"location":"users/nodes/vm-management/#vm-provisioning","title":"VM Provisioning","text":""},{"location":"users/nodes/vm-management/#quick-provisioning-via-ui","title":"Quick Provisioning via UI","text":"<ol> <li>Navigate to Nodes \u2192 Virtual Machines</li> <li>Click Create VM</li> <li>Configure:</li> <li>Name: Descriptive identifier</li> <li>Node: Select target node (shared/dedicated)</li> <li>Resources: CPU, Memory, Storage</li> <li>OS: Select from available images</li> <li>Network: Configure networking</li> <li>Review and create</li> </ol>"},{"location":"users/nodes/vm-management/#cli-provisioning","title":"CLI Provisioning","text":"<pre><code># Create a basic VM\nhxb vm create \\\n  --name web-server-01 \\\n  --node shared-node-1 \\\n  --cpu 2 \\\n  --memory 4096 \\\n  --disk 50 \\\n  --image ubuntu-22.04\n\n# Create VM with advanced options\nhxb vm create \\\n  --name database-server \\\n  --node dedicated-node-1 \\\n  --cpu 8 \\\n  --memory 16384 \\\n  --disk 200 \\\n  --image centos-8 \\\n  --network-mode bridge \\\n  --ssh-key ~/.ssh/id_rsa.pub \\\n  --startup-script /path/to/init.sh\n</code></pre>"},{"location":"users/nodes/vm-management/#programmatic-provisioning","title":"Programmatic Provisioning","text":"<pre><code># vm-config.yaml\napiVersion: compute/v1\nkind: VirtualMachine\nmetadata:\n  name: app-server\n  namespace: production\nspec:\n  node: dedicated-node-2\n  resources:\n    cpu: 4\n    memory: 8192\n    disk:\n      size: 100\n      type: ssd\n  image:\n    name: ubuntu-22.04\n    version: latest\n  network:\n    mode: bridge\n    interfaces:\n      - name: eth0\n        type: public\n        ipv4: auto\n  userData: |\n    #!/bin/bash\n    apt-get update\n    apt-get install -y docker.io\n    systemctl start docker\n</code></pre>"},{"location":"users/nodes/vm-management/#vm-templates","title":"VM Templates","text":""},{"location":"users/nodes/vm-management/#creating-templates","title":"Creating Templates","text":"<pre><code># Create template from existing VM\nhxb vm template create \\\n  --source-vm web-server-01 \\\n  --name web-server-template \\\n  --description \"Optimized web server configuration\"\n\n# List available templates\nhxb vm template list\n</code></pre>"},{"location":"users/nodes/vm-management/#using-templates","title":"Using Templates","text":"<pre><code># Deploy VM from template\nhxb vm create-from-template \\\n  --template web-server-template \\\n  --name web-server-02 \\\n  --customize cpu=4,memory=8192\n</code></pre>"},{"location":"users/nodes/vm-management/#template-library","title":"Template Library","text":"Template OS Pre-installed Use Case web-server Ubuntu 22.04 Nginx, PHP Web applications database Ubuntu 20.04 PostgreSQL, Redis Database servers kubernetes-node Ubuntu 22.04 Docker, kubelet K8s worker nodes dev-environment Ubuntu 22.04 Dev tools, Docker Development"},{"location":"users/nodes/vm-management/#lifecycle-management","title":"Lifecycle Management","text":""},{"location":"users/nodes/vm-management/#vm-states","title":"VM States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Creating\n    Creating --&gt; Running\n    Running --&gt; Stopping\n    Stopping --&gt; Stopped\n    Stopped --&gt; Starting\n    Starting --&gt; Running\n    Running --&gt; Rebooting\n    Rebooting --&gt; Running\n    Stopped --&gt; Deleting\n    Deleting --&gt; [*]</code></pre>"},{"location":"users/nodes/vm-management/#state-management-commands","title":"State Management Commands","text":"<pre><code># Start VM\nhxb vm start web-server-01\n\n# Stop VM (graceful)\nhxb vm stop web-server-01\n\n# Force stop VM\nhxb vm stop web-server-01 --force\n\n# Reboot VM\nhxb vm reboot web-server-01\n\n# Delete VM\nhxb vm delete web-server-01 --confirm\n</code></pre>"},{"location":"users/nodes/vm-management/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Stop all VMs with label\nhxb vm stop --selector env=development\n\n# Start multiple VMs\nhxb vm start web-server-01 web-server-02 web-server-03\n\n# Reboot all VMs on a node\nhxb vm reboot --node shared-node-1 --all\n</code></pre>"},{"location":"users/nodes/vm-management/#resource-management","title":"Resource Management","text":""},{"location":"users/nodes/vm-management/#dynamic-resource-allocation","title":"Dynamic Resource Allocation","text":"<pre><code># Resize VM (requires stop/start)\nhxb vm resize web-server-01 \\\n  --cpu 4 \\\n  --memory 8192\n\n# Add storage\nhxb vm disk attach web-server-01 \\\n  --size 100 \\\n  --type ssd \\\n  --mount /data\n\n# Modify network\nhxb vm network add web-server-01 \\\n  --interface eth1 \\\n  --type private \\\n  --vlan 100\n</code></pre>"},{"location":"users/nodes/vm-management/#resource-limits-by-plan","title":"Resource Limits by Plan","text":"Plan Max CPU/VM Max Memory/VM Max Disk/VM Total VMs Single 2 cores 4 GB 50 GB 3 Team 8 cores 32 GB 500 GB 20 Enterprise 32 cores 128 GB 2 TB Unlimited"},{"location":"users/nodes/vm-management/#resource-monitoring","title":"Resource Monitoring","text":"<pre><code># View VM resource usage\nhxb vm stats web-server-01\n\n# Get detailed metrics\nhxb vm metrics web-server-01 \\\n  --metric cpu,memory,disk,network \\\n  --period 1h\n\n# Export resource report\nhxb vm report \\\n  --format csv \\\n  --output vm-usage-report.csv\n</code></pre>"},{"location":"users/nodes/vm-management/#snapshots-and-backups","title":"Snapshots and Backups","text":""},{"location":"users/nodes/vm-management/#creating-snapshots","title":"Creating Snapshots","text":"<pre><code># Create snapshot\nhxb vm snapshot create web-server-01 \\\n  --name pre-upgrade-snapshot \\\n  --description \"Before system upgrade\"\n\n# List snapshots\nhxb vm snapshot list web-server-01\n\n# Schedule automatic snapshots\nhxb vm snapshot schedule web-server-01 \\\n  --frequency daily \\\n  --retention 7 \\\n  --time 02:00\n</code></pre>"},{"location":"users/nodes/vm-management/#restoring-from-snapshots","title":"Restoring from Snapshots","text":"<pre><code># Restore VM to snapshot\nhxb vm snapshot restore web-server-01 \\\n  --snapshot pre-upgrade-snapshot\n\n# Create new VM from snapshot\nhxb vm create-from-snapshot \\\n  --snapshot web-server-01/pre-upgrade-snapshot \\\n  --name web-server-restored\n</code></pre>"},{"location":"users/nodes/vm-management/#backup-integration","title":"Backup Integration","text":"<pre><code># backup-policy.yaml\napiVersion: backup/v1\nkind: BackupPolicy\nmetadata:\n  name: vm-backup-policy\nspec:\n  targets:\n    - type: vm\n      selector:\n        labels:\n          backup: enabled\n  schedule: \"0 2 * * *\"\n  retention:\n    daily: 7\n    weekly: 4\n    monthly: 12\n  destination:\n    type: s3\n    bucket: hexabase-vm-backups\n</code></pre>"},{"location":"users/nodes/vm-management/#network-configuration","title":"Network Configuration","text":""},{"location":"users/nodes/vm-management/#network-modes","title":"Network Modes","text":""},{"location":"users/nodes/vm-management/#bridge-mode","title":"Bridge Mode","text":"<pre><code># Create VM with bridge networking\nhxb vm create web-server \\\n  --network-mode bridge \\\n  --bridge br0 \\\n  --ip 192.168.1.100/24 \\\n  --gateway 192.168.1.1\n</code></pre>"},{"location":"users/nodes/vm-management/#nat-mode","title":"NAT Mode","text":"<pre><code># Create VM with NAT networking\nhxb vm create app-server \\\n  --network-mode nat \\\n  --port-forward 80:8080,443:8443\n</code></pre>"},{"location":"users/nodes/vm-management/#private-network","title":"Private Network","text":"<pre><code># Create private network\nhxb network create private-net \\\n  --subnet 10.0.0.0/24 \\\n  --vlan 100\n\n# Attach VM to private network\nhxb vm network attach app-server \\\n  --network private-net \\\n  --ip 10.0.0.10\n</code></pre>"},{"location":"users/nodes/vm-management/#advanced-networking","title":"Advanced Networking","text":"<pre><code># network-config.yaml\nnetworking:\n  interfaces:\n    - name: eth0\n      type: public\n      ipv4:\n        method: static\n        address: 203.0.113.10\n        netmask: 255.255.255.0\n        gateway: 203.0.113.1\n      ipv6:\n        method: auto\n\n    - name: eth1\n      type: private\n      vlan: 100\n      ipv4:\n        method: static\n        address: 10.0.0.10\n        netmask: 255.255.255.0\n\n  dns:\n    nameservers:\n      - 8.8.8.8\n      - 8.8.4.4\n    search:\n      - internal.example.com\n\n  routes:\n    - destination: 10.1.0.0/16\n      gateway: 10.0.0.1\n      metric: 100\n</code></pre>"},{"location":"users/nodes/vm-management/#security-management","title":"Security Management","text":""},{"location":"users/nodes/vm-management/#security-groups","title":"Security Groups","text":"<pre><code># Create security group\nhxb security-group create web-sg \\\n  --description \"Web server security group\"\n\n# Add rules\nhxb security-group rule add web-sg \\\n  --direction ingress \\\n  --protocol tcp \\\n  --port 80,443 \\\n  --source 0.0.0.0/0\n\nhxb security-group rule add web-sg \\\n  --direction ingress \\\n  --protocol tcp \\\n  --port 22 \\\n  --source 10.0.0.0/8\n\n# Attach to VM\nhxb vm security-group attach web-server-01 web-sg\n</code></pre>"},{"location":"users/nodes/vm-management/#ssh-key-management","title":"SSH Key Management","text":"<pre><code># Add SSH key to VM\nhxb vm ssh-key add web-server-01 \\\n  --key-file ~/.ssh/id_rsa.pub \\\n  --user ubuntu\n\n# Rotate SSH keys\nhxb vm ssh-key rotate web-server-01 \\\n  --new-key ~/.ssh/new_key.pub \\\n  --remove-old\n</code></pre>"},{"location":"users/nodes/vm-management/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"users/nodes/vm-management/#built-in-monitoring","title":"Built-in Monitoring","text":"<pre><code># Enable detailed monitoring\nhxb vm monitoring enable web-server-01 \\\n  --metrics all \\\n  --interval 60\n\n# Set up alerts\nhxb vm alert create \\\n  --vm web-server-01 \\\n  --metric cpu \\\n  --threshold 80 \\\n  --duration 300 \\\n  --action email:ops@example.com\n</code></pre>"},{"location":"users/nodes/vm-management/#custom-metrics","title":"Custom Metrics","text":"<pre><code># monitoring-config.yaml\nmonitoring:\n  custom_metrics:\n    - name: application_response_time\n      command: /usr/local/bin/check_response.sh\n      interval: 60\n      unit: milliseconds\n\n    - name: database_connections\n      command: /usr/local/bin/check_db.sh\n      interval: 30\n      unit: count\n\n  alerts:\n    - metric: application_response_time\n      condition: gt\n      threshold: 1000\n      window: 300\n      severity: warning\n\n    - metric: database_connections\n      condition: gt\n      threshold: 100\n      window: 60\n      severity: critical\n</code></pre>"},{"location":"users/nodes/vm-management/#automation","title":"Automation","text":""},{"location":"users/nodes/vm-management/#cloud-init-integration","title":"Cloud-Init Integration","text":"<pre><code># cloud-init.yaml\n#cloud-config\nusers:\n  - name: admin\n    groups: sudo\n    shell: /bin/bash\n    sudo: ALL=(ALL) NOPASSWD:ALL\n    ssh_authorized_keys:\n      - ssh-rsa AAAAB3NzaC1yc2EAAA...\n\npackages:\n  - docker.io\n  - nginx\n  - postgresql-client\n\nruncmd:\n  - systemctl start docker\n  - docker run -d -p 8080:80 my-app:latest\n  - curl -X POST https://api.hexabase.ai/vm/ready\n</code></pre>"},{"location":"users/nodes/vm-management/#ansible-integration","title":"Ansible Integration","text":"<pre><code># ansible-playbook.yml\n---\n- hosts: hexabase_vms\n  vars:\n    ansible_ssh_common_args: '-o ProxyCommand=\"hxb vm ssh-proxy %h\"'\n\n  tasks:\n    - name: Update system packages\n      apt:\n        update_cache: yes\n        upgrade: dist\n\n    - name: Install required packages\n      package:\n        name:\n          - docker.io\n          - python3-pip\n          - git\n        state: present\n\n    - name: Configure application\n      template:\n        src: app.conf.j2\n        dest: /etc/app/app.conf\n      notify: restart application\n</code></pre>"},{"location":"users/nodes/vm-management/#terraform-provider","title":"Terraform Provider","text":"<pre><code># main.tf\nterraform {\n  required_providers {\n    hexabase = {\n      source = \"hexabase/hexabase\"\n      version = \"~&gt; 1.0\"\n    }\n  }\n}\n\nresource \"hexabase_vm\" \"web_servers\" {\n  count = 3\n\n  name = \"web-server-${count.index + 1}\"\n  node = \"shared-node-1\"\n\n  resources {\n    cpu    = 2\n    memory = 4096\n    disk   = 50\n  }\n\n  image = \"ubuntu-22.04\"\n\n  network {\n    mode = \"bridge\"\n    ip   = \"192.168.1.${100 + count.index}\"\n  }\n\n  user_data = file(\"cloud-init.yaml\")\n\n  tags = {\n    environment = \"production\"\n    role        = \"web\"\n  }\n}\n</code></pre>"},{"location":"users/nodes/vm-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/nodes/vm-management/#common-issues","title":"Common Issues","text":""},{"location":"users/nodes/vm-management/#vm-wont-start","title":"VM Won't Start","text":"<pre><code># Check VM status\nhxb vm status web-server-01 --detailed\n\n# View console output\nhxb vm console web-server-01\n\n# Check event logs\nhxb vm events web-server-01 --tail 50\n\n# Verify resources\nhxb node resources shared-node-1\n</code></pre>"},{"location":"users/nodes/vm-management/#network-connectivity-issues","title":"Network Connectivity Issues","text":"<pre><code># Test network configuration\nhxb vm network test web-server-01\n\n# Check routing table\nhxb vm exec web-server-01 -- ip route\n\n# Verify security groups\nhxb vm security-group list web-server-01\n</code></pre>"},{"location":"users/nodes/vm-management/#performance-issues","title":"Performance Issues","text":"<pre><code># Analyze performance\nhxb vm analyze web-server-01 \\\n  --check cpu,memory,disk,network\n\n# Get recommendations\nhxb vm optimize web-server-01 --suggest\n</code></pre>"},{"location":"users/nodes/vm-management/#recovery-procedures","title":"Recovery Procedures","text":"<pre><code># Emergency console access\nhxb vm console web-server-01 --emergency\n\n# Boot in rescue mode\nhxb vm rescue web-server-01 \\\n  --image rescue-ubuntu-22.04\n\n# Rebuild from backup\nhxb vm rebuild web-server-01 \\\n  --from-backup latest\n</code></pre>"},{"location":"users/nodes/vm-management/#best-practices","title":"Best Practices","text":""},{"location":"users/nodes/vm-management/#1-resource-planning","title":"1. Resource Planning","text":"<ul> <li>Monitor usage patterns before resizing</li> <li>Use templates for consistent deployments</li> <li>Implement resource quotas per project</li> </ul>"},{"location":"users/nodes/vm-management/#2-security-hardening","title":"2. Security Hardening","text":"<ul> <li>Disable root login</li> <li>Use key-based authentication only</li> <li>Regular security updates</li> <li>Implement network segmentation</li> </ul>"},{"location":"users/nodes/vm-management/#3-backup-strategy","title":"3. Backup Strategy","text":"<ul> <li>Regular automated snapshots</li> <li>Test restore procedures</li> <li>Off-site backup replication</li> <li>Document recovery procedures</li> </ul>"},{"location":"users/nodes/vm-management/#4-performance-optimization","title":"4. Performance Optimization","text":"<ul> <li>Right-size VM resources</li> <li>Use SSD for I/O intensive workloads</li> <li>Implement monitoring and alerting</li> <li>Regular performance reviews</li> </ul>"},{"location":"users/nodes/vm-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Node Configuration</li> <li>VM Scaling</li> <li>Health Monitoring</li> <li>Security Best Practices</li> </ul>"},{"location":"users/observability/clickhouse-analytics/","title":"ClickHouse Analytics","text":"<p>This guide covers advanced analytics capabilities using ClickHouse in Hexabase.AI, enabling real-time analysis of logs, metrics, and events at scale.</p>"},{"location":"users/observability/clickhouse-analytics/#clickhouse-overview","title":"ClickHouse Overview","text":""},{"location":"users/observability/clickhouse-analytics/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[Data Sources] --&gt; B[Ingestion Layer]\n    B --&gt; C[ClickHouse Cluster]\n\n    D[Logs] --&gt; B\n    E[Metrics] --&gt; B\n    F[Events] --&gt; B\n    G[Traces] --&gt; B\n\n    C --&gt; H[Distributed Tables]\n    C --&gt; I[Replicated Tables]\n    C --&gt; J[Materialized Views]\n\n    K[Query Layer] --&gt; C\n    L[Analytics Tools] --&gt; K\n    M[Dashboards] --&gt; K\n    N[API] --&gt; K</code></pre>"},{"location":"users/observability/clickhouse-analytics/#clickhouse-features-by-plan","title":"ClickHouse Features by Plan","text":"Plan Storage Query Performance Distributed Queries Custom Functions Single 100GB Standard - - Team 1TB Optimized Limited - Enterprise Unlimited High Performance Full \u2713"},{"location":"users/observability/clickhouse-analytics/#data-schema-design","title":"Data Schema Design","text":""},{"location":"users/observability/clickhouse-analytics/#time-series-tables","title":"Time-Series Tables","text":"<pre><code>-- Metrics table optimized for time-series queries\nCREATE TABLE metrics.raw_metrics\n(\n    timestamp DateTime64(3) CODEC(DoubleDelta),\n    metric_name LowCardinality(String),\n    service LowCardinality(String),\n    environment LowCardinality(String),\n    labels Nested(\n        key LowCardinality(String),\n        value String\n    ),\n    value Float64 CODEC(Gorilla),\n\n    INDEX idx_metric_service (metric_name, service) TYPE bloom_filter GRANULARITY 4,\n    INDEX idx_timestamp timestamp TYPE minmax GRANULARITY 1\n)\nENGINE = MergeTree()\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (metric_name, service, timestamp)\nTTL timestamp + INTERVAL 30 DAY\nSETTINGS index_granularity = 8192;\n\n-- Distributed wrapper for cluster deployments\nCREATE TABLE metrics.metrics AS metrics.raw_metrics\nENGINE = Distributed('metrics_cluster', 'metrics', 'raw_metrics', cityHash64(service));\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#event-storage","title":"Event Storage","text":"<pre><code>-- Flexible event storage with JSON support\nCREATE TABLE events.raw_events\n(\n    event_id UUID DEFAULT generateUUIDv4(),\n    timestamp DateTime64(3),\n    event_type LowCardinality(String),\n    user_id String,\n    session_id String,\n    properties JSON,\n\n    -- Computed columns from JSON\n    country String MATERIALIZED JSONExtractString(properties, 'geo.country'),\n    device_type LowCardinality(String) MATERIALIZED JSONExtractString(properties, 'device.type'),\n    revenue Decimal(10, 2) MATERIALIZED JSONExtractFloat(properties, 'revenue'),\n\n    INDEX idx_user user_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_session session_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_event_type event_type TYPE minmax GRANULARITY 1\n)\nENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/events', '{replica}')\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (event_type, timestamp, user_id)\nSAMPLE BY cityHash64(user_id)\nTTL timestamp + toIntervalDay(JSONExtractUInt(properties, 'retention_days'));\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#log-analytics-schema","title":"Log Analytics Schema","text":"<pre><code>-- Optimized log storage with full-text search\nCREATE TABLE logs.raw_logs\n(\n    timestamp DateTime64(3),\n    level Enum8('DEBUG' = 1, 'INFO' = 2, 'WARN' = 3, 'ERROR' = 4, 'FATAL' = 5),\n    service LowCardinality(String),\n    hostname LowCardinality(String),\n    message String,\n    trace_id FixedString(16) DEFAULT '',\n    span_id FixedString(8) DEFAULT '',\n\n    -- Full-text search tokens\n    message_tokens Array(String) MATERIALIZED splitByRegexp('[^a-zA-Z0-9]+', lower(message)),\n\n    INDEX idx_level level TYPE minmax GRANULARITY 1,\n    INDEX idx_trace trace_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_message message TYPE tokenbf_v1(32768, 3, 0) GRANULARITY 1,\n    INDEX idx_tokens message_tokens TYPE bloom_filter GRANULARITY 1\n)\nENGINE = MergeTree()\nPARTITION BY toDate(timestamp)\nORDER BY (service, level, timestamp)\nTTL timestamp + INTERVAL 7 DAY TO VOLUME 'cold_storage';\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#materialized-views","title":"Materialized Views","text":""},{"location":"users/observability/clickhouse-analytics/#real-time-aggregations","title":"Real-time Aggregations","text":"<pre><code>-- Service metrics aggregation\nCREATE MATERIALIZED VIEW metrics.service_metrics_5m\nENGINE = SummingMergeTree()\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (timestamp, service, metric_name)\nPOPULATE AS\nSELECT\n    toStartOfFiveMinute(timestamp) as timestamp,\n    service,\n    metric_name,\n    count() as sample_count,\n    sum(value) as sum_value,\n    min(value) as min_value,\n    max(value) as max_value,\n    quantilesState(0.5, 0.95, 0.99)(value) as quantiles_state\nFROM metrics.raw_metrics\nGROUP BY timestamp, service, metric_name;\n\n-- User behavior aggregation\nCREATE MATERIALIZED VIEW events.user_sessions_mv\nENGINE = AggregatingMergeTree()\nPARTITION BY toYYYYMM(session_start)\nORDER BY (user_id, session_start)\nPOPULATE AS\nSELECT\n    user_id,\n    session_id,\n    min(timestamp) as session_start,\n    max(timestamp) as session_end,\n    count() as event_count,\n    countDistinct(event_type) as unique_events,\n    sumIf(revenue, event_type = 'purchase') as session_revenue,\n    groupArrayArray(100)(event_type) as event_sequence\nFROM events.raw_events\nGROUP BY user_id, session_id;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#pre-computed-reports","title":"Pre-computed Reports","text":"<pre><code>-- Daily active users with retention cohorts\nCREATE MATERIALIZED VIEW analytics.daily_active_users\nENGINE = SummingMergeTree()\nPARTITION BY toYYYYMM(date)\nORDER BY (date, cohort_date)\nPOPULATE AS\nWITH user_cohorts AS (\n    SELECT\n        user_id,\n        toDate(min(timestamp)) as cohort_date\n    FROM events.raw_events\n    GROUP BY user_id\n)\nSELECT\n    toDate(timestamp) as date,\n    cohort_date,\n    count(DISTINCT user_id) as active_users,\n    count(DISTINCT session_id) as sessions,\n    sum(revenue) as daily_revenue\nFROM events.raw_events\nINNER JOIN user_cohorts USING (user_id)\nGROUP BY date, cohort_date;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#query-optimization","title":"Query Optimization","text":""},{"location":"users/observability/clickhouse-analytics/#efficient-queries","title":"Efficient Queries","text":"<pre><code>-- Optimized time-series query with pre-aggregation\nWITH intervals AS (\n    SELECT toStartOfMinute(now() - INTERVAL number MINUTE) as minute\n    FROM numbers(60)\n)\nSELECT\n    intervals.minute as timestamp,\n    ifNull(m.avg_value, 0) as value,\n    ifNull(m.sample_count, 0) as samples\nFROM intervals\nLEFT JOIN (\n    SELECT\n        toStartOfMinute(timestamp) as minute,\n        avg(value) as avg_value,\n        count() as sample_count\n    FROM metrics.raw_metrics\n    WHERE metric_name = 'cpu_usage'\n        AND service = 'api-gateway'\n        AND timestamp &gt;= now() - INTERVAL 1 HOUR\n    GROUP BY minute\n) m ON intervals.minute = m.minute\nORDER BY timestamp;\n\n-- Funnel analysis with arrayJoin\nWITH funnel_events AS (\n    SELECT\n        user_id,\n        groupArray(10)(\n            tuple(timestamp, event_type)\n        ) as events\n    FROM events.raw_events\n    WHERE timestamp &gt;= today() - 7\n        AND event_type IN ('page_view', 'add_to_cart', 'checkout', 'purchase')\n    GROUP BY user_id\n)\nSELECT\n    arrayJoin([1, 2, 3, 4]) as step,\n    arrayElement(['page_view', 'add_to_cart', 'checkout', 'purchase'], step) as event,\n    countIf(\n        arrayExists(\n            x -&gt; x.2 = arrayElement(['page_view', 'add_to_cart', 'checkout', 'purchase'], step),\n            events\n        )\n    ) as users,\n    if(step = 1, 100, users / lag(users) OVER (ORDER BY step) * 100) as conversion_rate\nFROM funnel_events\nGROUP BY step\nORDER BY step;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#query-performance-tips","title":"Query Performance Tips","text":"<pre><code>-- Use PREWHERE for early filtering\nSELECT *\nFROM logs.raw_logs\nPREWHERE level = 'ERROR'  -- Filter before reading all columns\nWHERE timestamp &gt;= now() - INTERVAL 1 HOUR\n    AND message LIKE '%database%'\nLIMIT 100;\n\n-- Optimize JOIN order and conditions\nSELECT\n    l.timestamp,\n    l.message,\n    m.value as memory_usage\nFROM logs.raw_logs l\nINNER JOIN metrics.raw_metrics m\n    ON l.service = m.service\n    AND m.metric_name = 'memory_usage'\n    AND m.timestamp BETWEEN l.timestamp - INTERVAL 1 MINUTE\n                        AND l.timestamp + INTERVAL 1 MINUTE\nWHERE l.level = 'ERROR'\n    AND l.timestamp &gt;= now() - INTERVAL 1 HOUR\nSETTINGS join_algorithm = 'partial_merge';\n\n-- Use sampling for approximate queries\nSELECT\n    approx_count_distinct(user_id) as unique_users,\n    approx_percentile(0.95)(revenue) as p95_revenue\nFROM events.raw_events SAMPLE 0.1  -- Sample 10% of data\nWHERE timestamp &gt;= today() - 30;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#advanced-analytics","title":"Advanced Analytics","text":""},{"location":"users/observability/clickhouse-analytics/#window-functions","title":"Window Functions","text":"<pre><code>-- Moving averages and trend detection\nWITH time_series AS (\n    SELECT\n        toStartOfHour(timestamp) as hour,\n        avg(value) as hourly_avg\n    FROM metrics.raw_metrics\n    WHERE metric_name = 'request_rate'\n        AND timestamp &gt;= now() - INTERVAL 7 DAY\n    GROUP BY hour\n)\nSELECT\n    hour,\n    hourly_avg,\n    avg(hourly_avg) OVER (\n        ORDER BY hour\n        ROWS BETWEEN 23 PRECEDING AND CURRENT ROW\n    ) as moving_avg_24h,\n    hourly_avg - lag(hourly_avg, 24) OVER (ORDER BY hour) as hour_over_hour_change,\n    (hourly_avg - moving_avg_24h) / moving_avg_24h * 100 as deviation_percent\nFROM time_series\nORDER BY hour DESC;\n\n-- Percentile rankings\nSELECT\n    service,\n    p95_latency,\n    percent_rank() OVER (ORDER BY p95_latency) as latency_percentile,\n    CASE\n        WHEN latency_percentile &gt;= 0.9 THEN 'Critical'\n        WHEN latency_percentile &gt;= 0.75 THEN 'Warning'\n        ELSE 'Healthy'\n    END as health_status\nFROM (\n    SELECT\n        service,\n        quantile(0.95)(value) as p95_latency\n    FROM metrics.raw_metrics\n    WHERE metric_name = 'response_time'\n        AND timestamp &gt;= now() - INTERVAL 1 HOUR\n    GROUP BY service\n);\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#machine-learning-integration","title":"Machine Learning Integration","text":"<pre><code>-- Anomaly detection using statistical methods\nWITH baseline AS (\n    SELECT\n        service,\n        metric_name,\n        avg(value) as mean_value,\n        stddevPop(value) as std_dev\n    FROM metrics.raw_metrics\n    WHERE timestamp &gt;= now() - INTERVAL 24 HOUR\n        AND timestamp &lt; now() - INTERVAL 1 HOUR\n    GROUP BY service, metric_name\n),\nrecent_data AS (\n    SELECT\n        service,\n        metric_name,\n        timestamp,\n        value\n    FROM metrics.raw_metrics\n    WHERE timestamp &gt;= now() - INTERVAL 1 HOUR\n)\nSELECT\n    r.timestamp,\n    r.service,\n    r.metric_name,\n    r.value,\n    b.mean_value,\n    b.std_dev,\n    abs(r.value - b.mean_value) / b.std_dev as z_score,\n    CASE\n        WHEN z_score &gt; 3 THEN 'Anomaly'\n        WHEN z_score &gt; 2 THEN 'Warning'\n        ELSE 'Normal'\n    END as status\nFROM recent_data r\nINNER JOIN baseline b USING (service, metric_name)\nWHERE z_score &gt; 2\nORDER BY z_score DESC;\n\n-- Time series forecasting preparation\nSELECT\n    toStartOfHour(timestamp) as hour,\n    avg(value) as value,\n    -- Features for ML model\n    hour() as hour_of_day,\n    dayOfWeek(hour) as day_of_week,\n    if(day_of_week IN [6, 7], 1, 0) as is_weekend,\n    -- Lag features\n    lag(value, 1) OVER w as lag_1h,\n    lag(value, 24) OVER w as lag_24h,\n    lag(value, 168) OVER w as lag_1w,\n    -- Rolling statistics\n    avg(value) OVER (w ROWS BETWEEN 23 PRECEDING AND CURRENT ROW) as rolling_avg_24h,\n    stddevPop(value) OVER (w ROWS BETWEEN 23 PRECEDING AND CURRENT ROW) as rolling_std_24h\nFROM metrics.raw_metrics\nWHERE metric_name = 'active_users'\n    AND timestamp &gt;= now() - INTERVAL 30 DAY\nGROUP BY hour\nWINDOW w AS (ORDER BY hour)\nORDER BY hour\nFORMAT JSONEachRow;  -- Export for ML training\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#data-pipeline-integration","title":"Data Pipeline Integration","text":""},{"location":"users/observability/clickhouse-analytics/#kafka-integration","title":"Kafka Integration","text":"<pre><code>-- Create Kafka engine table for real-time ingestion\nCREATE TABLE events.kafka_events\n(\n    raw String\n)\nENGINE = Kafka()\nSETTINGS\n    kafka_broker_list = 'kafka1:9092,kafka2:9092',\n    kafka_topic_list = 'events',\n    kafka_group_name = 'clickhouse-consumer',\n    kafka_format = 'JSONAsString',\n    kafka_num_consumers = 4;\n\n-- Materialized view to parse and store Kafka data\nCREATE MATERIALIZED VIEW events.kafka_events_mv TO events.raw_events AS\nSELECT\n    JSONExtractString(raw, 'timestamp') as timestamp,\n    JSONExtractString(raw, 'event_type') as event_type,\n    JSONExtractString(raw, 'user_id') as user_id,\n    JSONExtractString(raw, 'session_id') as session_id,\n    raw as properties\nFROM events.kafka_events\nWHERE JSONHas(raw, 'event_type');\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#data-export","title":"Data Export","text":"<pre><code>-- Export query results to S3\nINSERT INTO FUNCTION\ns3(\n    'https://s3.amazonaws.com/analytics-export/daily_report_{date}.parquet',\n    'AWS_ACCESS_KEY_ID',\n    'AWS_SECRET_ACCESS_KEY',\n    'Parquet'\n)\nSELECT\n    toDate(timestamp) as date,\n    service,\n    count() as request_count,\n    avg(value) as avg_response_time,\n    quantile(0.95)(value) as p95_response_time\nFROM metrics.raw_metrics\nWHERE metric_name = 'response_time'\n    AND timestamp &gt;= today() - 1\n    AND timestamp &lt; today()\nGROUP BY date, service;\n\n-- Create external table for data lake integration\nCREATE TABLE analytics.external_events\n(\n    timestamp DateTime,\n    event_type String,\n    user_id String,\n    properties String\n)\nENGINE = S3(\n    'https://datalake.example.com/events/year={year}/month={month}/day={day}/*.parquet',\n    'access_key',\n    'secret_key',\n    'Parquet'\n)\nSETTINGS\n    schema_inference_hints = 'timestamp DateTime, event_type String, user_id String, properties String';\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#performance-tuning","title":"Performance Tuning","text":""},{"location":"users/observability/clickhouse-analytics/#table-optimization","title":"Table Optimization","text":"<pre><code>-- Analyze table statistics\nSELECT\n    table,\n    formatReadableSize(sum(bytes)) as size,\n    sum(rows) as rows,\n    max(modification_time) as latest_modification,\n    any(engine) as engine\nFROM system.parts\nWHERE database = 'metrics'\nGROUP BY table\nORDER BY sum(bytes) DESC;\n\n-- Optimize table partitions\nOPTIMIZE TABLE metrics.raw_metrics PARTITION '202401' FINAL;\n\n-- Configure TTL for automatic data management\nALTER TABLE logs.raw_logs\nMODIFY TTL\n    timestamp + INTERVAL 7 DAY TO DISK 'cold_storage',\n    timestamp + INTERVAL 30 DAY DELETE;\n\n-- Add projection for common queries\nALTER TABLE metrics.raw_metrics\nADD PROJECTION projection_service_metrics\n(\n    SELECT\n        service,\n        metric_name,\n        toStartOfMinute(timestamp) as minute,\n        avg(value) as avg_value,\n        count() as count\n    GROUP BY service, metric_name, minute\n);\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#query-optimization_1","title":"Query Optimization","text":"<pre><code>-- Use EXPLAIN to analyze query plans\nEXPLAIN SYNTAX\nSELECT\n    service,\n    avg(value) as avg_value\nFROM metrics.raw_metrics\nWHERE timestamp &gt;= now() - INTERVAL 1 HOUR\nGROUP BY service;\n\n-- Enable query profiling\nSET query_profiler_real_time_period_ns = 100000000;\nSET query_profiler_cpu_time_period_ns = 100000000;\n\n-- Analyze slow queries\nSELECT\n    query,\n    query_duration_ms,\n    read_rows,\n    read_bytes,\n    memory_usage,\n    ProfileEvents['RealTimeMicroseconds'] / 1000 as real_time_ms\nFROM system.query_log\nWHERE query_duration_ms &gt; 1000\n    AND type = 'QueryFinish'\n    AND query_start_time &gt;= now() - INTERVAL 1 HOUR\nORDER BY query_duration_ms DESC\nLIMIT 10;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#security-and-access-control","title":"Security and Access Control","text":""},{"location":"users/observability/clickhouse-analytics/#row-level-security","title":"Row-Level Security","text":"<pre><code>-- Create view with row-level security\nCREATE VIEW events.user_events AS\nSELECT *\nFROM events.raw_events\nWHERE user_id = currentUser();\n\n-- Grant permissions\nGRANT SELECT ON events.user_events TO analytics_users;\n\n-- Column-level security\nCREATE VIEW metrics.public_metrics AS\nSELECT\n    timestamp,\n    metric_name,\n    service,\n    value\nFROM metrics.raw_metrics\nWHERE service NOT IN ('payment', 'auth');  -- Exclude sensitive services\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#audit-logging","title":"Audit Logging","text":"<pre><code>-- Enable query logging for audit\nSET log_queries = 1;\nSET log_query_threads = 1;\n\n-- Query audit log\nSELECT\n    user,\n    query,\n    query_start_time,\n    query_duration_ms,\n    read_rows,\n    written_rows,\n    result_rows,\n    exception\nFROM system.query_log\nWHERE user != 'default'\n    AND query NOT LIKE '%system.query_log%'\n    AND query_start_time &gt;= today()\nORDER BY query_start_time DESC;\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#best-practices","title":"Best Practices","text":""},{"location":"users/observability/clickhouse-analytics/#1-schema-design","title":"1. Schema Design","text":"<ul> <li>Use appropriate data types and codecs</li> <li>Design for your query patterns</li> <li>Implement proper partitioning strategy</li> <li>Use materialized views for frequent aggregations</li> </ul>"},{"location":"users/observability/clickhouse-analytics/#2-query-performance","title":"2. Query Performance","text":"<ul> <li>Filter early with PREWHERE</li> <li>Use appropriate JOIN algorithms</li> <li>Leverage indexes effectively</li> <li>Monitor and optimize slow queries</li> </ul>"},{"location":"users/observability/clickhouse-analytics/#3-data-management","title":"3. Data Management","text":"<ul> <li>Implement TTL policies</li> <li>Use tiered storage effectively</li> <li>Regular maintenance with OPTIMIZE</li> <li>Monitor disk usage and performance</li> </ul>"},{"location":"users/observability/clickhouse-analytics/#4-high-availability","title":"4. High Availability","text":"<ul> <li>Use replicated tables</li> <li>Implement proper backup strategies</li> <li>Monitor cluster health</li> <li>Plan for disaster recovery</li> </ul>"},{"location":"users/observability/clickhouse-analytics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/observability/clickhouse-analytics/#common-issues","title":"Common Issues","text":"<pre><code># Check cluster status\nclickhouse-client --query \"SELECT * FROM system.clusters\"\n\n# Monitor memory usage\nclickhouse-client --query \"SELECT formatReadableSize(memory_usage) FROM system.processes\"\n\n# Check replication lag\nclickhouse-client --query \"\n    SELECT\n        database,\n        table,\n        is_leader,\n        absolute_delay,\n        total_replicas,\n        active_replicas\n    FROM system.replicas\n    WHERE absolute_delay &gt; 10\n\"\n\n# Analyze merge performance\nclickhouse-client --query \"\n    SELECT\n        database,\n        table,\n        elapsed,\n        progress,\n        formatReadableSize(total_size_bytes_compressed) as size\n    FROM system.merges\n    WHERE elapsed &gt; 60\n\"\n</code></pre>"},{"location":"users/observability/clickhouse-analytics/#related-documentation","title":"Related Documentation","text":"<ul> <li>Logging Architecture</li> <li>Dashboards and Alerts</li> <li>Performance Monitoring</li> <li>Data Pipeline Integration</li> </ul>"},{"location":"users/observability/dashboards-alerts/","title":"Dashboards and Alerts","text":"<p>This comprehensive guide covers creating and managing dashboards and alerts in Hexabase.AI, enabling effective monitoring and proactive incident response.</p>"},{"location":"users/observability/dashboards-alerts/#dashboard-overview","title":"Dashboard Overview","text":""},{"location":"users/observability/dashboards-alerts/#dashboard-architecture","title":"Dashboard Architecture","text":"<pre><code>graph TD\n    A[Data Sources] --&gt; B[Query Engine]\n    B --&gt; C[Visualization Engine]\n    C --&gt; D[Dashboard Renderer]\n\n    E[Metrics] --&gt; A\n    F[Logs] --&gt; A\n    G[Traces] --&gt; A\n    H[Events] --&gt; A\n\n    D --&gt; I[Web UI]\n    D --&gt; J[Mobile App]\n    D --&gt; K[TV Mode]\n    D --&gt; L[API/Embed]</code></pre>"},{"location":"users/observability/dashboards-alerts/#dashboard-features-by-plan","title":"Dashboard Features by Plan","text":"Plan Pre-built Dashboards Custom Dashboards Sharing Advanced Visualizations Single 5 2 - Basic Team 20 10 Team only Standard Enterprise Unlimited Unlimited Public/Embed Advanced + Custom"},{"location":"users/observability/dashboards-alerts/#creating-dashboards","title":"Creating Dashboards","text":""},{"location":"users/observability/dashboards-alerts/#dashboard-configuration","title":"Dashboard Configuration","text":"<pre><code># dashboard-config.yaml\napiVersion: observability/v1\nkind: Dashboard\nmetadata:\n  name: application-overview\n  labels:\n    team: platform\n    environment: production\nspec:\n  title: \"Application Performance Overview\"\n  description: \"Real-time monitoring of application health and performance\"\n\n  variables:\n    - name: environment\n      type: query\n      query: \"SELECT DISTINCT environment FROM metrics\"\n      default: \"production\"\n\n    - name: service\n      type: query\n      query: \"SELECT DISTINCT service FROM metrics WHERE environment = '$environment'\"\n      multi: true\n      includeAll: true\n\n    - name: timeRange\n      type: interval\n      default: \"1h\"\n      options: [\"5m\", \"15m\", \"1h\", \"6h\", \"24h\", \"7d\"]\n\n  refresh: \"30s\"\n  timezone: \"browser\"\n\n  layout:\n    type: grid\n    columns: 12\n    rowHeight: 60\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#panel-types","title":"Panel Types","text":""},{"location":"users/observability/dashboards-alerts/#time-series-panel","title":"Time Series Panel","text":"<pre><code>{\n  \"type\": \"timeseries\",\n  \"title\": \"Request Rate\",\n  \"gridPos\": {\n    \"x\": 0,\n    \"y\": 0,\n    \"w\": 6,\n    \"h\": 8\n  },\n  \"targets\": [\n    {\n      \"datasource\": \"prometheus\",\n      \"expr\": \"sum(rate(http_requests_total{environment=\\\"$environment\\\", service=~\\\"$service\\\"}[5m])) by (service)\",\n      \"legendFormat\": \"{{service}}\"\n    }\n  ],\n  \"options\": {\n    \"tooltip\": {\n      \"mode\": \"multi\"\n    },\n    \"legend\": {\n      \"displayMode\": \"table\",\n      \"placement\": \"bottom\",\n      \"calcs\": [\"mean\", \"max\", \"lastNotNull\"]\n    }\n  },\n  \"fieldConfig\": {\n    \"defaults\": {\n      \"unit\": \"reqps\",\n      \"thresholds\": {\n        \"mode\": \"absolute\",\n        \"steps\": [\n          { \"value\": 0, \"color\": \"green\" },\n          { \"value\": 1000, \"color\": \"yellow\" },\n          { \"value\": 5000, \"color\": \"red\" }\n        ]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#stat-panel","title":"Stat Panel","text":"<pre><code>{\n  \"type\": \"stat\",\n  \"title\": \"Error Rate\",\n  \"gridPos\": {\n    \"x\": 6,\n    \"y\": 0,\n    \"w\": 3,\n    \"h\": 4\n  },\n  \"targets\": [\n    {\n      \"datasource\": \"prometheus\",\n      \"expr\": \"sum(rate(http_requests_total{status=~\\\"5..\\\"}[5m])) / sum(rate(http_requests_total[5m])) * 100\"\n    }\n  ],\n  \"options\": {\n    \"reduceOptions\": {\n      \"calcs\": [\"lastNotNull\"]\n    },\n    \"orientation\": \"horizontal\",\n    \"textMode\": \"value_and_name\",\n    \"colorMode\": \"background\",\n    \"graphMode\": \"area\"\n  },\n  \"fieldConfig\": {\n    \"defaults\": {\n      \"unit\": \"percent\",\n      \"decimals\": 2,\n      \"thresholds\": {\n        \"mode\": \"absolute\",\n        \"steps\": [\n          { \"value\": 0, \"color\": \"green\" },\n          { \"value\": 1, \"color\": \"yellow\" },\n          { \"value\": 5, \"color\": \"red\" }\n        ]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#heatmap-panel","title":"Heatmap Panel","text":"<pre><code>{\n  \"type\": \"heatmap\",\n  \"title\": \"Response Time Distribution\",\n  \"gridPos\": {\n    \"x\": 0,\n    \"y\": 8,\n    \"w\": 12,\n    \"h\": 8\n  },\n  \"targets\": [\n    {\n      \"datasource\": \"prometheus\",\n      \"expr\": \"sum(rate(http_request_duration_seconds_bucket{environment=\\\"$environment\\\"}[5m])) by (le)\",\n      \"format\": \"heatmap\"\n    }\n  ],\n  \"options\": {\n    \"calculate\": false,\n    \"yAxis\": {\n      \"axisPlacement\": \"left\",\n      \"unit\": \"s\",\n      \"decimals\": 3\n    },\n    \"color\": {\n      \"mode\": \"spectrum\",\n      \"scheme\": \"Oranges\"\n    }\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#advanced-visualizations","title":"Advanced Visualizations","text":""},{"location":"users/observability/dashboards-alerts/#service-map","title":"Service Map","text":"<pre><code>// service-map-panel.js\nclass ServiceMapPanel {\n  constructor(config) {\n    this.datasource = config.datasource;\n    this.query = config.query;\n    this.refreshInterval = config.refreshInterval || 30000;\n  }\n\n  async render(container) {\n    const data = await this.fetchServiceDependencies();\n\n    const graph = {\n      nodes: this.createNodes(data.services),\n      edges: this.createEdges(data.dependencies),\n    };\n\n    // Initialize D3.js force-directed graph\n    const simulation = d3\n      .forceSimulation(graph.nodes)\n      .force(\n        \"link\",\n        d3.forceLink(graph.edges).id((d) =&gt; d.id)\n      )\n      .force(\"charge\", d3.forceManyBody().strength(-300))\n      .force(\"center\", d3.forceCenter(width / 2, height / 2));\n\n    // Render nodes with health status\n    const nodes = svg\n      .selectAll(\".node\")\n      .data(graph.nodes)\n      .enter()\n      .append(\"g\")\n      .attr(\"class\", \"node\")\n      .call(\n        d3\n          .drag()\n          .on(\"start\", this.dragStarted)\n          .on(\"drag\", this.dragged)\n          .on(\"end\", this.dragEnded)\n      );\n\n    nodes\n      .append(\"circle\")\n      .attr(\"r\", (d) =&gt; Math.sqrt(d.requestRate) * 5)\n      .attr(\"fill\", (d) =&gt; this.getHealthColor(d.errorRate));\n\n    // Render edges with traffic volume\n    const edges = svg\n      .selectAll(\".edge\")\n      .data(graph.edges)\n      .enter()\n      .append(\"line\")\n      .attr(\"class\", \"edge\")\n      .attr(\"stroke-width\", (d) =&gt; Math.log(d.traffic) + 1)\n      .attr(\"opacity\", 0.6);\n  }\n\n  getHealthColor(errorRate) {\n    if (errorRate &lt; 0.01) return \"#52c41a\"; // Green\n    if (errorRate &lt; 0.05) return \"#faad14\"; // Yellow\n    return \"#f5222d\"; // Red\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#custom-chart","title":"Custom Chart","text":"<pre><code>// custom-chart.ts\nimport { PanelPlugin } from \"@hexabase/dashboard-sdk\";\n\nexport const customChartPlugin = new PanelPlugin({\n  id: \"custom-3d-scatter\",\n  name: \"3D Scatter Plot\",\n\n  editor: {\n    fields: [\n      { name: \"xAxis\", type: \"field-select\", label: \"X Axis\" },\n      { name: \"yAxis\", type: \"field-select\", label: \"Y Axis\" },\n      { name: \"zAxis\", type: \"field-select\", label: \"Z Axis\" },\n      { name: \"colorBy\", type: \"field-select\", label: \"Color By\" },\n    ],\n  },\n\n  render: async (context) =&gt; {\n    const { data, options, width, height } = context;\n\n    // Transform data for 3D visualization\n    const points = data.series.map((series) =&gt; ({\n      x: series.fields.find((f) =&gt; f.name === options.xAxis).values,\n      y: series.fields.find((f) =&gt; f.name === options.yAxis).values,\n      z: series.fields.find((f) =&gt; f.name === options.zAxis).values,\n      color: series.fields.find((f) =&gt; f.name === options.colorBy).values,\n    }));\n\n    // Render using Three.js or similar\n    const scene = new THREE.Scene();\n    const camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);\n    const renderer = new THREE.WebGLRenderer();\n\n    // Add points to scene\n    points.forEach((point) =&gt; {\n      const geometry = new THREE.SphereGeometry(0.1);\n      const material = new THREE.MeshBasicMaterial({\n        color: this.scaleColor(point.color),\n      });\n      const sphere = new THREE.Mesh(geometry, material);\n      sphere.position.set(point.x, point.y, point.z);\n      scene.add(sphere);\n    });\n\n    return renderer.domElement;\n  },\n});\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-configuration","title":"Alert Configuration","text":""},{"location":"users/observability/dashboards-alerts/#alert-rules","title":"Alert Rules","text":""},{"location":"users/observability/dashboards-alerts/#prometheus-style-alerts","title":"Prometheus-style Alerts","text":"<pre><code># alert-rules.yaml\ngroups:\n  - name: application\n    interval: 30s\n    rules:\n      - alert: HighErrorRate\n        expr: |\n          (\n            sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (service)\n            /\n            sum(rate(http_requests_total[5m])) by (service)\n          ) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n          team: platform\n        annotations:\n          summary: \"High error rate detected for {{ $labels.service }}\"\n          description: \"Error rate is {{ $value | humanizePercentage }} for service {{ $labels.service }}\"\n          runbook_url: \"https://wiki.example.com/runbooks/high-error-rate\"\n          dashboard_url: \"https://dashboards.hexabase.ai/d/app-overview?var-service={{ $labels.service }}\"\n\n      - alert: HighLatency\n        expr: |\n          histogram_quantile(0.95,\n            sum(rate(http_request_duration_seconds_bucket[5m])) by (service, le)\n          ) &gt; 1\n        for: 10m\n        labels:\n          severity: warning\n          team: platform\n        annotations:\n          summary: \"High latency for {{ $labels.service }}\"\n          description: \"95th percentile latency is {{ $value | humanizeDuration }}\"\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#log-based-alerts","title":"Log-based Alerts","text":"<pre><code># log-alerts.yaml\napiVersion: monitoring/v1\nkind: LogAlert\nmetadata:\n  name: security-alerts\nspec:\n  datasource: logs\n\n  rules:\n    - name: suspicious-login-pattern\n      query: |\n        SELECT \n          user_id,\n          count() as attempts,\n          uniq(ip_address) as unique_ips,\n          groupArray(country) as countries\n        FROM logs\n        WHERE \n          action = 'login'\n          AND status = 'failed'\n          AND timestamp &gt; now() - INTERVAL 5 MINUTE\n        GROUP BY user_id\n        HAVING attempts &gt; 5 OR unique_ips &gt; 3\n\n      severity: high\n\n      annotations:\n        summary: \"Suspicious login pattern for user {{ .user_id }}\"\n        details: |\n          Failed attempts: {{ .attempts }}\n          From IPs: {{ .unique_ips }}\n          Countries: {{ .countries }}\n\n    - name: application-errors-spike\n      query: |\n        WITH current_errors AS (\n          SELECT count() as current_count\n          FROM logs\n          WHERE level = 'ERROR'\n            AND timestamp &gt; now() - INTERVAL 5 MINUTE\n        ),\n        baseline AS (\n          SELECT avg(count) as avg_count\n          FROM (\n            SELECT toStartOfFiveMinute(timestamp) as bucket,\n                   count() as count\n            FROM logs\n            WHERE level = 'ERROR'\n              AND timestamp BETWEEN now() - INTERVAL 1 DAY AND now() - INTERVAL 5 MINUTE\n            GROUP BY bucket\n          )\n        )\n        SELECT \n          current_count,\n          avg_count,\n          current_count / avg_count as ratio\n        FROM current_errors, baseline\n        WHERE ratio &gt; 3\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-routing","title":"Alert Routing","text":"<pre><code># alert-routing.yaml\napiVersion: monitoring/v1\nkind: AlertmanagerConfig\nmetadata:\n  name: main-routing\nspec:\n  route:\n    group_by: [alertname, cluster, service]\n    group_wait: 30s\n    group_interval: 5m\n    repeat_interval: 12h\n    receiver: default\n\n    routes:\n      - match:\n          severity: critical\n        receiver: pagerduty-critical\n        continue: true\n\n      - match:\n          severity: critical\n          team: platform\n        receiver: platform-oncall\n\n      - match_re:\n          service: \"payment-.*\"\n        receiver: finance-team\n        routes:\n          - match:\n              severity: critical\n            receiver: finance-emergency\n\n      - match:\n          alertname: DeadManSwitch\n        receiver: monitoring-team\n        repeat_interval: 1m\n\n  receivers:\n    - name: default\n      slack_configs:\n        - api_url: ${SLACK_WEBHOOK_URL}\n          channel: \"#alerts\"\n          title: \"Alert: {{ .GroupLabels.alertname }}\"\n          text: \"{{ range .Alerts }}{{ .Annotations.description }}{{ end }}\"\n\n    - name: pagerduty-critical\n      pagerduty_configs:\n        - service_key: ${PAGERDUTY_KEY}\n          severity: critical\n          client: \"Hexabase.AI\"\n          client_url: \"https://dashboards.hexabase.ai\"\n          details:\n            firing: \"{{ .Alerts.Firing | len }}\"\n            resolved: \"{{ .Alerts.Resolved | len }}\"\n\n    - name: platform-oncall\n      webhook_configs:\n        - url: \"https://oncall.hexabase.ai/webhook\"\n          send_resolved: true\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-templates","title":"Alert Templates","text":"<pre><code># alert-templates.yaml\ntemplates:\n  - name: slack-message\n    template: |\n      {{ define \"slack.title\" }}\n      [{{ .Status | toUpper }}{{ if eq .Status \"firing\" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}\n      {{ end }}\n\n      {{ define \"slack.text\" }}\n      {{ range .Alerts }}\n      *Alert:* {{ .Labels.alertname }} - {{ .Labels.severity }}\n      *Service:* {{ .Labels.service }}\n      *Description:* {{ .Annotations.description }}\n      *Started:* {{ .StartsAt | humanizeTimestamp }}\n      {{ if .Labels.runbook_url }}*Runbook:* &lt;{{ .Labels.runbook_url }}|View Runbook&gt;{{ end }}\n      {{ if .Labels.dashboard_url }}*Dashboard:* &lt;{{ .Labels.dashboard_url }}|View Dashboard&gt;{{ end }}\n      {{ end }}\n      {{ end }}\n\n  - name: email-html\n    template: |\n      {{ define \"email.html\" }}\n      &lt;!DOCTYPE html&gt;\n      &lt;html&gt;\n      &lt;head&gt;\n        &lt;style&gt;\n          .alert-critical { background-color: #f44336; }\n          .alert-warning { background-color: #ff9800; }\n          .alert-info { background-color: #2196f3; }\n          .alert-resolved { background-color: #4caf50; }\n        &lt;/style&gt;\n      &lt;/head&gt;\n      &lt;body&gt;\n        &lt;h2&gt;{{ .GroupLabels.alertname }}&lt;/h2&gt;\n        {{ range .Alerts }}\n        &lt;div class=\"alert alert-{{ .Labels.severity }}\"&gt;\n          &lt;h3&gt;{{ .Labels.service }} - {{ .Labels.severity | toUpper }}&lt;/h3&gt;\n          &lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt; {{ .Annotations.description }}&lt;/p&gt;\n          &lt;p&gt;&lt;strong&gt;Started:&lt;/strong&gt; {{ .StartsAt | humanizeTimestamp }}&lt;/p&gt;\n          {{ if .EndsAt }}\n          &lt;p&gt;&lt;strong&gt;Ended:&lt;/strong&gt; {{ .EndsAt | humanizeTimestamp }}&lt;/p&gt;\n          {{ end }}\n          &lt;p&gt;\n            {{ if .Annotations.runbook_url }}\n            &lt;a href=\"{{ .Annotations.runbook_url }}\"&gt;View Runbook&lt;/a&gt; |\n            {{ end }}\n            {{ if .Annotations.dashboard_url }}\n            &lt;a href=\"{{ .Annotations.dashboard_url }}\"&gt;View Dashboard&lt;/a&gt;\n            {{ end }}\n          &lt;/p&gt;\n        &lt;/div&gt;\n        {{ end }}\n      &lt;/body&gt;\n      &lt;/html&gt;\n      {{ end }}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#dashboard-management","title":"Dashboard Management","text":""},{"location":"users/observability/dashboards-alerts/#version-control","title":"Version Control","text":"<pre><code># dashboard-versioning.yaml\napiVersion: dashboards/v1\nkind: DashboardVersion\nmetadata:\n  name: app-overview-v2\nspec:\n  dashboard: application-overview\n  version: 2.0.0\n  changes:\n    - type: panel_added\n      description: \"Added memory usage panel\"\n\n    - type: query_modified\n      panel: request-rate\n      description: \"Optimized query for better performance\"\n\n    - type: variable_added\n      name: region\n      description: \"Added region filter\"\n\n  author: platform-team\n  timestamp: 2024-01-15T10:30:00Z\n\n  rollback:\n    enabled: true\n    previous_version: 1.9.0\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#dashboard-as-code","title":"Dashboard as Code","text":"<pre><code>// dashboard-generator.ts\nimport { DashboardBuilder } from \"@hexabase/dashboard-sdk\";\n\nexport function generateServiceDashboard(serviceName: string) {\n  const builder = new DashboardBuilder()\n    .title(`${serviceName} Service Dashboard`)\n    .uid(`service-${serviceName}`)\n    .tags([\"generated\", \"service\", serviceName]);\n\n  // Add standard panels\n  builder\n    .addRow(\"Overview\")\n    .addPanel({\n      title: \"Request Rate\",\n      type: \"graph\",\n      span: 4,\n      query: `sum(rate(http_requests_total{service=\"${serviceName}\"}[5m])) by (method)`,\n    })\n    .addPanel({\n      title: \"Error Rate\",\n      type: \"stat\",\n      span: 2,\n      query: `sum(rate(http_requests_total{service=\"${serviceName}\",status=~\"5..\"}[5m]))`,\n    })\n    .addPanel({\n      title: \"P95 Latency\",\n      type: \"gauge\",\n      span: 2,\n      query: `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{service=\"${serviceName}\"}[5m])) by (le))`,\n    });\n\n  // Add SLO panel\n  builder.addRow(\"SLOs\").addPanel({\n    title: \"Availability SLO\",\n    type: \"slo\",\n    span: 6,\n    config: {\n      objective: 99.9,\n      window: \"30d\",\n      query: `1 - (sum(rate(http_requests_total{service=\"${serviceName}\",status=~\"5..\"}[5m])) / sum(rate(http_requests_total{service=\"${serviceName}\"}[5m])))`,\n    },\n  });\n\n  return builder.build();\n}\n\n// Generate dashboards for all services\nasync function generateAllServiceDashboards() {\n  const services = await getServiceList();\n\n  for (const service of services) {\n    const dashboard = generateServiceDashboard(service);\n    await saveDashboard(dashboard);\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-management","title":"Alert Management","text":""},{"location":"users/observability/dashboards-alerts/#alert-silencing","title":"Alert Silencing","text":"<pre><code># silence-config.yaml\napiVersion: monitoring/v1\nkind: Silence\nmetadata:\n  name: maintenance-window\nspec:\n  matchers:\n    - name: alertname\n      value: HighCPU\n      regex: false\n\n    - name: environment\n      value: staging\n      regex: false\n\n  startsAt: 2024-01-15T02:00:00Z\n  endsAt: 2024-01-15T04:00:00Z\n\n  createdBy: platform-team\n  comment: \"Scheduled maintenance for staging environment\"\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-analytics","title":"Alert Analytics","text":"<pre><code>-- Alert frequency analysis\nSELECT\n    alertname,\n    severity,\n    count(*) as alert_count,\n    avg(duration_minutes) as avg_duration,\n    max(duration_minutes) as max_duration,\n    countIf(acknowledged) as acknowledged_count,\n    avg(time_to_acknowledge_minutes) as avg_tta\nFROM alerts.history\nWHERE timestamp &gt; now() - INTERVAL 30 DAY\nGROUP BY alertname, severity\nORDER BY alert_count DESC;\n\n-- Alert correlation\nWITH alert_pairs AS (\n    SELECT\n        a1.alertname as alert1,\n        a2.alertname as alert2,\n        count(*) as co_occurrence_count\n    FROM alerts.history a1\n    INNER JOIN alerts.history a2\n        ON a1.fingerprint != a2.fingerprint\n        AND a1.timestamp BETWEEN a2.timestamp - INTERVAL 5 MINUTE\n                            AND a2.timestamp + INTERVAL 5 MINUTE\n    WHERE a1.timestamp &gt; now() - INTERVAL 7 DAY\n    GROUP BY alert1, alert2\n)\nSELECT * FROM alert_pairs\nWHERE co_occurrence_count &gt; 10\nORDER BY co_occurrence_count DESC;\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#advanced-features","title":"Advanced Features","text":""},{"location":"users/observability/dashboards-alerts/#slo-dashboards","title":"SLO Dashboards","text":"<pre><code># slo-dashboard.yaml\napiVersion: observability/v1\nkind: SLODashboard\nmetadata:\n  name: platform-slos\nspec:\n  slos:\n    - name: api-availability\n      objective: 99.9\n      window: rolling_30d\n\n      sli:\n        type: ratio\n        good_events: |\n          sum(rate(http_requests_total{status!~\"5..\"}[5m]))\n        total_events: |\n          sum(rate(http_requests_total[5m]))\n\n      burn_rate_alerts:\n        - window: 1h\n          burn_rate: 14.4\n          severity: critical\n\n        - window: 6h\n          burn_rate: 6\n          severity: warning\n\n    - name: latency-slo\n      objective: 95\n      window: calendar_month\n\n      sli:\n        type: threshold\n        events: |\n          histogram_quantile(0.95, \n            sum(rate(http_request_duration_seconds_bucket[5m])) by (le)\n          ) &lt; 0.5\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#multi-tenant-dashboards","title":"Multi-Tenant Dashboards","text":"<pre><code>// multi-tenant-dashboard.js\nclass MultiTenantDashboard {\n  constructor(tenantId) {\n    this.tenantId = tenantId;\n    this.permissions = this.loadTenantPermissions(tenantId);\n  }\n\n  async loadDashboard(dashboardId) {\n    const dashboard = await this.fetchDashboard(dashboardId);\n\n    // Apply tenant-specific filters\n    dashboard.panels = dashboard.panels.map((panel) =&gt; {\n      panel.targets = panel.targets.map((target) =&gt; ({\n        ...target,\n        expr: this.injectTenantFilter(target.expr),\n      }));\n      return panel;\n    });\n\n    // Filter panels based on permissions\n    dashboard.panels = dashboard.panels.filter((panel) =&gt;\n      this.hasPermission(panel.requiredPermission)\n    );\n\n    return dashboard;\n  }\n\n  injectTenantFilter(query) {\n    // Add tenant_id label to all queries\n    return query.replace(\n      /{([^}]*)}/g,\n      '{tenant_id=\"' + this.tenantId + '\",$1}'\n    );\n  }\n}\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#best-practices","title":"Best Practices","text":""},{"location":"users/observability/dashboards-alerts/#1-dashboard-design","title":"1. Dashboard Design","text":"<ul> <li>Group related metrics logically</li> <li>Use consistent color schemes</li> <li>Include context and descriptions</li> <li>Optimize query performance</li> <li>Implement proper access controls</li> </ul>"},{"location":"users/observability/dashboards-alerts/#2-alert-configuration","title":"2. Alert Configuration","text":"<ul> <li>Alert on symptoms, not causes</li> <li>Include actionable information</li> <li>Set appropriate severity levels</li> <li>Implement alert fatigue prevention</li> <li>Test alert rules regularly</li> </ul>"},{"location":"users/observability/dashboards-alerts/#3-performance-optimization","title":"3. Performance Optimization","text":"<ul> <li>Use recording rules for complex queries</li> <li>Implement proper data retention</li> <li>Cache frequently accessed dashboards</li> <li>Monitor dashboard load times</li> </ul>"},{"location":"users/observability/dashboards-alerts/#4-maintenance","title":"4. Maintenance","text":"<ul> <li>Version control dashboards</li> <li>Document alert runbooks</li> <li>Regular review of alert effectiveness</li> <li>Archive unused dashboards</li> </ul>"},{"location":"users/observability/dashboards-alerts/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/observability/dashboards-alerts/#dashboard-issues","title":"Dashboard Issues","text":"<pre><code># Debug slow dashboards\nhxb dashboard analyze --uid app-overview --slow-queries\n\n# Validate dashboard configuration\nhxb dashboard validate dashboard.json\n\n# Export dashboard for backup\nhxb dashboard export --uid app-overview --output backup.json\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#alert-issues","title":"Alert Issues","text":"<pre><code># Test alert rules\nhxb alerts test --rule HighErrorRate --dry-run\n\n# Check alert delivery\nhxb alerts trace --fingerprint abc123def\n\n# Analyze alert patterns\nhxb alerts analyze --period 30d --noisy-alerts\n</code></pre>"},{"location":"users/observability/dashboards-alerts/#related-documentation","title":"Related Documentation","text":"<ul> <li>Logging Architecture</li> <li>Distributed Tracing</li> <li>ClickHouse Analytics</li> <li>Monitoring Best Practices</li> </ul>"},{"location":"users/observability/logging/","title":"Logging Architecture","text":"<p>This guide covers the comprehensive logging architecture in Hexabase.AI, including log collection, processing, storage, and analysis capabilities.</p>"},{"location":"users/observability/logging/#logging-overview","title":"Logging Overview","text":""},{"location":"users/observability/logging/#architecture-components","title":"Architecture Components","text":"<pre><code>graph TD\n    A[Application Logs] --&gt; B[Log Collectors]\n    C[System Logs] --&gt; B\n    D[Audit Logs] --&gt; B\n    E[Security Logs] --&gt; B\n\n    B --&gt; F[Log Processing Pipeline]\n    F --&gt; G[Log Storage]\n    F --&gt; H[Real-time Analysis]\n\n    G --&gt; I[ClickHouse]\n    G --&gt; J[Object Storage]\n\n    H --&gt; K[Alerts]\n    H --&gt; L[Dashboards]\n    H --&gt; M[AI Analysis]</code></pre>"},{"location":"users/observability/logging/#logging-capabilities-by-plan","title":"Logging Capabilities by Plan","text":"Plan Log Retention Real-time Analysis AI-Powered Insights Custom Pipelines Single 7 days Basic - - Team 30 days Advanced - Limited Enterprise Unlimited Advanced \u2713 Unlimited"},{"location":"users/observability/logging/#log-collection","title":"Log Collection","text":""},{"location":"users/observability/logging/#application-logging","title":"Application Logging","text":""},{"location":"users/observability/logging/#structured-logging-format","title":"Structured Logging Format","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"service\": \"api-gateway\",\n  \"trace_id\": \"abc123def456\",\n  \"span_id\": \"789ghi012\",\n  \"user_id\": \"user-12345\",\n  \"method\": \"POST\",\n  \"path\": \"/api/v1/resources\",\n  \"duration_ms\": 125,\n  \"status_code\": 200,\n  \"message\": \"Request processed successfully\",\n  \"metadata\": {\n    \"resource_type\": \"deployment\",\n    \"resource_id\": \"dep-67890\"\n  }\n}\n</code></pre>"},{"location":"users/observability/logging/#logging-sdk-integration","title":"Logging SDK Integration","text":"<p>Node.js Example</p> <pre><code>const { Logger } = require(\"@hexabase/logging\");\n\nconst logger = new Logger({\n  service: \"user-service\",\n  level: process.env.LOG_LEVEL || \"info\",\n  format: \"json\",\n  correlation: true,\n});\n\n// Basic logging\nlogger.info(\"User logged in\", {\n  userId: user.id,\n  ip: request.ip,\n});\n\n// Error logging with context\nlogger.error(\"Database connection failed\", {\n  error: err.message,\n  stack: err.stack,\n  database: config.database.host,\n  retry_count: retries,\n});\n\n// Performance logging\nconst timer = logger.startTimer();\nconst result = await processRequest(request);\ntimer.done({\n  message: \"Request processed\",\n  request_id: request.id,\n});\n</code></pre> <p>Python Example</p> <pre><code>from hexabase.logging import Logger\nimport time\n\nlogger = Logger(\n    service='data-processor',\n    level='INFO',\n    structured=True\n)\n\n# Context manager for automatic timing\nwith logger.timer('data_processing'):\n    processed_data = process_large_dataset(data)\n    logger.info('Dataset processed',\n                rows_processed=len(processed_data),\n                processing_time=time.time() - start_time)\n\n# Correlation with trace context\n@logger.trace\ndef handle_request(request):\n    logger.info('Handling request',\n                request_id=request.id,\n                user_id=request.user_id)\n    return process(request)\n</code></pre>"},{"location":"users/observability/logging/#system-log-collection","title":"System Log Collection","text":""},{"location":"users/observability/logging/#syslog-integration","title":"Syslog Integration","text":"<pre><code># syslog-config.yaml\napiVersion: logging/v1\nkind: SyslogCollector\nmetadata:\n  name: system-logs\nspec:\n  sources:\n    - type: syslog\n      protocol: udp\n      port: 514\n      format: rfc5424\n\n    - type: journald\n      units:\n        - kubelet\n        - docker\n        - containerd\n\n    - type: file\n      paths:\n        - /var/log/messages\n        - /var/log/secure\n        - /var/log/kernel.log\n      tail: true\n\n  processors:\n    - type: parser\n      format: syslog\n\n    - type: enrichment\n      fields:\n        node: \"${NODE_NAME}\"\n        cluster: \"${CLUSTER_NAME}\"\n\n  outputs:\n    - type: hexabase\n      endpoint: logs.hexabase.ai\n      compression: gzip\n</code></pre>"},{"location":"users/observability/logging/#container-log-collection","title":"Container Log Collection","text":"<pre><code># container-logging.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluent-bit-config\ndata:\n  fluent-bit.conf: |\n    [SERVICE]\n        Daemon Off\n        Log_Level info\n\n    [INPUT]\n        Name tail\n        Path /var/log/containers/*.log\n        Parser docker\n        Tag kube.*\n        Refresh_Interval 5\n\n    [FILTER]\n        Name kubernetes\n        Match kube.*\n        Merge_Log On\n        Keep_Log Off\n        K8S-Logging.Parser On\n        K8S-Logging.Exclude On\n\n    [FILTER]\n        Name nest\n        Match kube.*\n        Operation lift\n        Nested_under kubernetes\n        Add_prefix k8s_\n\n    [OUTPUT]\n        Name http\n        Match *\n        Host logs.hexabase.ai\n        Port 443\n        URI /v1/logs\n        Format json_lines\n        tls On\n        tls.verify On\n</code></pre>"},{"location":"users/observability/logging/#log-processing","title":"Log Processing","text":""},{"location":"users/observability/logging/#processing-pipeline","title":"Processing Pipeline","text":"<pre><code># log-pipeline.yaml\napiVersion: logging/v1\nkind: LogPipeline\nmetadata:\n  name: main-pipeline\nspec:\n  inputs:\n    - name: applications\n      type: http\n      port: 8080\n\n    - name: infrastructure\n      type: syslog\n      port: 514\n\n  processors:\n    - name: parse_json\n      type: json_parser\n      source: message\n\n    - name: extract_metadata\n      type: regex_parser\n      regex: \"^(?&lt;time&gt;[^ ]+) (?&lt;level&gt;[^ ]+) (?&lt;msg&gt;.*)$\"\n\n    - name: add_timestamp\n      type: timestamp\n      format: ISO8601\n\n    - name: sanitize_pii\n      type: redact\n      patterns:\n        - credit_card: '\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b'\n        - ssn: '\\b\\d{3}-\\d{2}-\\d{4}\\b'\n        - email: '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n\n    - name: enrich_geo\n      type: geoip\n      source: client_ip\n      database: /opt/geoip/GeoLite2-City.mmdb\n\n  routes:\n    - name: errors\n      match: level == \"ERROR\" || level == \"FATAL\"\n      outputs: [alerts, storage]\n\n    - name: security\n      match: tag =~ /security|audit/\n      outputs: [security_storage, siem]\n\n    - name: default\n      match: true\n      outputs: [storage]\n\n  outputs:\n    - name: storage\n      type: clickhouse\n      database: logs\n      table: application_logs\n      batch_size: 10000\n      flush_interval: 5s\n\n    - name: alerts\n      type: webhook\n      url: https://alerts.hexabase.ai/webhook\n\n    - name: security_storage\n      type: s3\n      bucket: security-logs\n      compression: gzip\n      encryption: AES256\n</code></pre>"},{"location":"users/observability/logging/#log-parsing-rules","title":"Log Parsing Rules","text":"<pre><code># parsing-rules.yaml\nparsers:\n  - name: nginx_access\n    type: regex\n    pattern: '^(?&lt;remote_addr&gt;\\S+) - (?&lt;remote_user&gt;\\S+) \\[(?&lt;time_local&gt;[^\\]]+)\\] \"(?&lt;request&gt;[^\"]+)\" (?&lt;status&gt;\\d+) (?&lt;body_bytes_sent&gt;\\d+) \"(?&lt;http_referer&gt;[^\"]+)\" \"(?&lt;http_user_agent&gt;[^\"]+)\"'\n\n  - name: json_structured\n    type: json\n    time_key: timestamp\n    time_format: \"%Y-%m-%dT%H:%M:%S.%LZ\"\n\n  - name: multiline_exception\n    type: multiline\n    pattern: '^\\d{4}-\\d{2}-\\d{2}'\n    negate: true\n    match: previous\n\n  - name: custom_app\n    type: grok\n    patterns:\n      - '%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \\[%{DATA:thread}\\] %{JAVACLASS:class} - %{GREEDYDATA:message}'\n</code></pre>"},{"location":"users/observability/logging/#log-storage","title":"Log Storage","text":""},{"location":"users/observability/logging/#clickhouse-schema","title":"ClickHouse Schema","text":"<pre><code>-- Create logs database\nCREATE DATABASE IF NOT EXISTS logs;\n\n-- Application logs table\nCREATE TABLE logs.application_logs\n(\n    timestamp DateTime64(3),\n    date Date DEFAULT toDate(timestamp),\n    level Enum8('DEBUG' = 1, 'INFO' = 2, 'WARN' = 3, 'ERROR' = 4, 'FATAL' = 5),\n    service String,\n    trace_id String,\n    span_id String,\n    user_id String,\n    method String,\n    path String,\n    status_code UInt16,\n    duration_ms UInt32,\n    message String,\n    metadata JSON,\n\n    INDEX idx_trace_id trace_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_user_id user_id TYPE bloom_filter GRANULARITY 1,\n    INDEX idx_level level TYPE minmax GRANULARITY 1\n)\nENGINE = MergeTree()\nPARTITION BY toYYYYMM(date)\nORDER BY (service, level, timestamp)\nTTL date + INTERVAL 30 DAY;\n\n-- Create materialized view for metrics\nCREATE MATERIALIZED VIEW logs.service_metrics_mv\nENGINE = SummingMergeTree()\nPARTITION BY toYYYYMM(date)\nORDER BY (date, service, level)\nAS SELECT\n    toStartOfMinute(timestamp) as date,\n    service,\n    level,\n    count() as count,\n    avg(duration_ms) as avg_duration,\n    quantile(0.95)(duration_ms) as p95_duration,\n    quantile(0.99)(duration_ms) as p99_duration\nFROM logs.application_logs\nGROUP BY date, service, level;\n</code></pre>"},{"location":"users/observability/logging/#storage-optimization","title":"Storage Optimization","text":"<pre><code># storage-policy.yaml\napiVersion: storage/v1\nkind: LogStoragePolicy\nmetadata:\n  name: log-retention\nspec:\n  tiers:\n    - name: hot\n      duration: 7d\n      storage_type: ssd\n      replication: 2\n      compression: lz4\n\n    - name: warm\n      duration: 30d\n      storage_type: hdd\n      replication: 1\n      compression: zstd\n      sampling: 0.1 # Keep 10% of logs\n\n    - name: cold\n      duration: 365d\n      storage_type: object_storage\n      compression: zstd_max\n      sampling: 0.01 # Keep 1% of logs\n\n  aggregations:\n    - name: hourly_stats\n      interval: 1h\n      retention: 90d\n      metrics:\n        - count\n        - error_rate\n        - p95_latency\n\n    - name: daily_summary\n      interval: 24h\n      retention: 2y\n      metrics:\n        - total_requests\n        - unique_users\n        - error_count\n</code></pre>"},{"location":"users/observability/logging/#log-analysis","title":"Log Analysis","text":""},{"location":"users/observability/logging/#real-time-analysis","title":"Real-time Analysis","text":"<pre><code># real-time-analyzer.py\nfrom hexabase.logging import StreamProcessor\nfrom hexabase.alerts import AlertManager\n\nclass LogAnalyzer(StreamProcessor):\n    def __init__(self):\n        super().__init__()\n        self.alert_manager = AlertManager()\n        self.error_threshold = 100\n        self.error_window = 300  # 5 minutes\n\n    async def process(self, log_entry):\n        # Detect error spikes\n        if log_entry['level'] in ['ERROR', 'FATAL']:\n            error_count = await self.count_recent_errors(\n                service=log_entry['service'],\n                window=self.error_window\n            )\n\n            if error_count &gt; self.error_threshold:\n                await self.alert_manager.trigger(\n                    alert_type='error_spike',\n                    service=log_entry['service'],\n                    error_count=error_count,\n                    sample_error=log_entry['message']\n                )\n\n        # Detect performance degradation\n        if 'duration_ms' in log_entry:\n            avg_duration = await self.get_average_duration(\n                service=log_entry['service'],\n                path=log_entry['path']\n            )\n\n            if log_entry['duration_ms'] &gt; avg_duration * 3:\n                await self.alert_manager.trigger(\n                    alert_type='slow_request',\n                    service=log_entry['service'],\n                    path=log_entry['path'],\n                    duration=log_entry['duration_ms'],\n                    expected=avg_duration\n                )\n</code></pre>"},{"location":"users/observability/logging/#log-queries","title":"Log Queries","text":"<pre><code>-- Find all errors for a specific user\nSELECT\n    timestamp,\n    service,\n    level,\n    message,\n    trace_id\nFROM logs.application_logs\nWHERE user_id = 'user-12345'\n  AND level IN ('ERROR', 'FATAL')\n  AND date &gt;= today() - 7\nORDER BY timestamp DESC\nLIMIT 100;\n\n-- Analyze error patterns\nSELECT\n    service,\n    substring(message, 1, 100) as error_pattern,\n    count() as occurrences,\n    min(timestamp) as first_seen,\n    max(timestamp) as last_seen,\n    uniq(user_id) as affected_users\nFROM logs.application_logs\nWHERE level = 'ERROR'\n  AND date &gt;= today() - 1\nGROUP BY service, error_pattern\nHAVING occurrences &gt; 10\nORDER BY occurrences DESC;\n\n-- Service performance analysis\nSELECT\n    service,\n    path,\n    count() as requests,\n    avg(duration_ms) as avg_duration,\n    quantile(0.5)(duration_ms) as median_duration,\n    quantile(0.95)(duration_ms) as p95_duration,\n    quantile(0.99)(duration_ms) as p99_duration,\n    max(duration_ms) as max_duration\nFROM logs.application_logs\nWHERE date &gt;= today()\n  AND status_code &lt; 500\nGROUP BY service, path\nORDER BY requests DESC\nLIMIT 50;\n</code></pre>"},{"location":"users/observability/logging/#security-logging","title":"Security Logging","text":""},{"location":"users/observability/logging/#audit-log-collection","title":"Audit Log Collection","text":"<pre><code># audit-logging.yaml\napiVersion: logging/v1\nkind: AuditLogger\nmetadata:\n  name: security-audit\nspec:\n  sources:\n    - type: kubernetes\n      audit_policy: /etc/kubernetes/audit-policy.yaml\n\n    - type: application\n      endpoints:\n        - service: api-gateway\n          path: /audit/events\n\n  events:\n    - action: user.login\n      level: INFO\n      capture:\n        - user_id\n        - ip_address\n        - user_agent\n        - success\n\n    - action: resource.modified\n      level: WARN\n      capture:\n        - user_id\n        - resource_type\n        - resource_id\n        - changes\n\n    - action: permission.denied\n      level: ERROR\n      capture:\n        - user_id\n        - requested_permission\n        - resource\n        - reason\n\n  compliance:\n    standards:\n      - SOC2\n      - HIPAA\n      - GDPR\n    retention: 7years\n    encryption: required\n    immutable: true\n</code></pre>"},{"location":"users/observability/logging/#security-analysis","title":"Security Analysis","text":"<pre><code># security-analyzer.py\nfrom hexabase.logging import SecurityAnalyzer\nfrom hexabase.ml import AnomalyDetector\n\nanalyzer = SecurityAnalyzer()\ndetector = AnomalyDetector(model='isolation_forest')\n\n# Train on normal behavior\nnormal_logs = analyzer.get_logs(\n    time_range='30d',\n    filter={'level': 'INFO', 'action': 'user.login'}\n)\ndetector.train(normal_logs)\n\n# Detect anomalies\n@analyzer.on_log\nasync def analyze_security_event(log):\n    if log['action'].startswith('user.'):\n        score = detector.predict(log)\n\n        if score &gt; 0.8:  # High anomaly score\n            await analyzer.alert(\n                type='security_anomaly',\n                log=log,\n                score=score,\n                reason=detector.explain(log)\n            )\n\n    # Check for brute force attempts\n    if log['action'] == 'user.login' and not log['success']:\n        failed_attempts = await analyzer.count_failures(\n            user_id=log['user_id'],\n            window='5m'\n        )\n\n        if failed_attempts &gt; 5:\n            await analyzer.block_user(log['user_id'])\n            await analyzer.alert(\n                type='brute_force',\n                user_id=log['user_id'],\n                attempts=failed_attempts\n            )\n</code></pre>"},{"location":"users/observability/logging/#integration-with-aiml","title":"Integration with AI/ML","text":""},{"location":"users/observability/logging/#log-anomaly-detection","title":"Log Anomaly Detection","text":"<pre><code># anomaly-detection.yaml\napiVersion: aiops/v1\nkind: LogAnomalyDetector\nmetadata:\n  name: ml-log-analyzer\nspec:\n  model:\n    type: autoencoder\n    training_window: 30d\n    update_frequency: daily\n\n  features:\n    - log_volume_per_service\n    - error_rate\n    - response_time_distribution\n    - unique_error_patterns\n    - user_behavior_patterns\n\n  detection:\n    sensitivity: 0.95\n    min_confidence: 0.8\n\n  actions:\n    - type: alert\n      condition: anomaly_score &gt; 0.9\n      channels: [slack, pagerduty]\n\n    - type: auto_investigate\n      condition: anomaly_score &gt; 0.95\n      gather:\n        - related_logs\n        - system_metrics\n        - trace_data\n</code></pre>"},{"location":"users/observability/logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/observability/logging/#common-issues","title":"Common Issues","text":""},{"location":"users/observability/logging/#log-ingestion-problems","title":"Log Ingestion Problems","text":"<pre><code># Check log collector status\nhxb logging status --component collectors\n\n# Verify log pipeline\nhxb logging test-pipeline --input sample.log\n\n# Debug log forwarding\nhxb logging debug --trace --component forwarder\n</code></pre>"},{"location":"users/observability/logging/#query-performance","title":"Query Performance","text":"<pre><code>-- Optimize slow queries\nEXPLAIN SELECT ... FROM logs.application_logs;\n\n-- Add custom indices\nALTER TABLE logs.application_logs\nADD INDEX idx_custom (service, user_id, timestamp);\n\n-- Analyze table statistics\nOPTIMIZE TABLE logs.application_logs FINAL;\n</code></pre>"},{"location":"users/observability/logging/#best-practices","title":"Best Practices","text":""},{"location":"users/observability/logging/#1-structured-logging","title":"1. Structured Logging","text":"<ul> <li>Use consistent field names</li> <li>Include correlation IDs</li> <li>Add contextual metadata</li> <li>Avoid logging sensitive data</li> </ul>"},{"location":"users/observability/logging/#2-log-levels","title":"2. Log Levels","text":"<ul> <li>DEBUG: Detailed diagnostic info</li> <li>INFO: General informational messages</li> <li>WARN: Warning conditions</li> <li>ERROR: Error conditions</li> <li>FATAL: Critical failures</li> </ul>"},{"location":"users/observability/logging/#3-performance-considerations","title":"3. Performance Considerations","text":"<ul> <li>Asynchronous logging</li> <li>Batch log submissions</li> <li>Sampling for high-volume logs</li> <li>Compression for transport</li> </ul>"},{"location":"users/observability/logging/#4-security","title":"4. Security","text":"<ul> <li>Encrypt logs in transit and at rest</li> <li>Implement access controls</li> <li>Audit log access</li> <li>Regular compliance reviews</li> </ul>"},{"location":"users/observability/logging/#related-documentation","title":"Related Documentation","text":"<ul> <li>Distributed Tracing</li> <li>Dashboards and Alerts</li> <li>ClickHouse Analytics</li> <li>Security Best Practices</li> </ul>"},{"location":"users/observability/tracing/","title":"Distributed Tracing","text":"<p>This guide covers distributed tracing in Hexabase.AI, enabling you to track requests across multiple services and understand system performance and dependencies.</p>"},{"location":"users/observability/tracing/#tracing-overview","title":"Tracing Overview","text":""},{"location":"users/observability/tracing/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[Client Request] --&gt; B[API Gateway]\n    B --&gt; C[Service A]\n    C --&gt; D[Service B]\n    C --&gt; E[Service C]\n    D --&gt; F[Database]\n    E --&gt; G[External API]\n\n    H[Trace Collector] --&gt; I[Trace Storage]\n    I --&gt; J[Trace Analysis]\n    J --&gt; K[Visualization]\n\n    B -.-&gt;|spans| H\n    C -.-&gt;|spans| H\n    D -.-&gt;|spans| H\n    E -.-&gt;|spans| H</code></pre>"},{"location":"users/observability/tracing/#tracing-features-by-plan","title":"Tracing Features by Plan","text":"Plan Basic Traces Advanced Analysis AI Insights Trace Retention Single \u2713 - - 24 hours Team \u2713 \u2713 - 7 days Enterprise \u2713 \u2713 \u2713 30+ days"},{"location":"users/observability/tracing/#instrumentation","title":"Instrumentation","text":""},{"location":"users/observability/tracing/#automatic-instrumentation","title":"Automatic Instrumentation","text":""},{"location":"users/observability/tracing/#nodejs-applications","title":"Node.js Applications","text":"<pre><code>// trace-setup.js\nconst { NodeTracerProvider } = require(\"@opentelemetry/sdk-trace-node\");\nconst { Resource } = require(\"@opentelemetry/resources\");\nconst {\n  SemanticResourceAttributes,\n} = require(\"@opentelemetry/semantic-conventions\");\nconst { HexabaseTraceExporter } = require(\"@hexabase/tracing\");\n\n// Initialize provider\nconst provider = new NodeTracerProvider({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: \"api-service\",\n    [SemanticResourceAttributes.SERVICE_VERSION]: \"1.0.0\",\n    environment: process.env.NODE_ENV,\n  }),\n});\n\n// Configure exporter\nconst exporter = new HexabaseTraceExporter({\n  endpoint: \"https://traces.hexabase.ai\",\n  apiKey: process.env.HXB_TRACE_API_KEY,\n});\n\n// Register provider\nprovider.addSpanProcessor(new BatchSpanProcessor(exporter));\nprovider.register();\n\n// Auto-instrument popular libraries\nrequire(\"@opentelemetry/instrumentation-express\").register();\nrequire(\"@opentelemetry/instrumentation-http\").register();\nrequire(\"@opentelemetry/instrumentation-grpc\").register();\nrequire(\"@opentelemetry/instrumentation-redis\").register();\nrequire(\"@opentelemetry/instrumentation-pg\").register();\n</code></pre>"},{"location":"users/observability/tracing/#python-applications","title":"Python Applications","text":"<pre><code># trace_setup.py\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.resources import Resource\nfrom hexabase.tracing import HexabaseSpanExporter\nfrom opentelemetry.instrumentation.auto_instrumentation import auto_instrument\n\n# Configure tracer\nresource = Resource.create({\n    \"service.name\": \"data-processor\",\n    \"service.version\": \"2.0.0\",\n    \"deployment.environment\": \"production\"\n})\n\nprovider = TracerProvider(resource=resource)\ntrace.set_tracer_provider(provider)\n\n# Configure exporter\nexporter = HexabaseSpanExporter(\n    endpoint=\"https://traces.hexabase.ai\",\n    api_key=os.environ[\"HXB_TRACE_API_KEY\"]\n)\n\nprovider.add_span_processor(\n    BatchSpanProcessor(exporter)\n)\n\n# Auto-instrument frameworks\nauto_instrument()\n</code></pre>"},{"location":"users/observability/tracing/#manual-instrumentation","title":"Manual Instrumentation","text":""},{"location":"users/observability/tracing/#creating-custom-spans","title":"Creating Custom Spans","text":"<pre><code>// manual-instrumentation.js\nconst opentelemetry = require(\"@opentelemetry/api\");\nconst tracer = opentelemetry.trace.getTracer(\"my-service\");\n\nasync function processOrder(orderId) {\n  // Create parent span\n  const span = tracer.startSpan(\"process-order\", {\n    attributes: {\n      \"order.id\": orderId,\n      \"order.source\": \"web\",\n      \"user.tier\": \"premium\",\n    },\n  });\n\n  try {\n    // Create child span for validation\n    const validationSpan = tracer.startSpan(\"validate-order\", {\n      parent: span,\n    });\n\n    const isValid = await validateOrder(orderId);\n    validationSpan.setAttributes({\n      \"validation.result\": isValid,\n      \"validation.rules_checked\": 5,\n    });\n    validationSpan.end();\n\n    if (!isValid) {\n      span.setStatus({ code: SpanStatusCode.ERROR });\n      span.recordException(new Error(\"Order validation failed\"));\n      return;\n    }\n\n    // Create child span for payment\n    const paymentSpan = tracer.startSpan(\"process-payment\", {\n      parent: span,\n    });\n\n    const paymentResult = await processPayment(orderId);\n    paymentSpan.setAttributes({\n      \"payment.method\": paymentResult.method,\n      \"payment.amount\": paymentResult.amount,\n      \"payment.currency\": paymentResult.currency,\n    });\n    paymentSpan.end();\n\n    // Add events to track important milestones\n    span.addEvent(\"order-confirmed\", {\n      \"confirmation.number\": generateConfirmationNumber(),\n    });\n\n    span.setStatus({ code: SpanStatusCode.OK });\n  } catch (error) {\n    span.recordException(error);\n    span.setStatus({\n      code: SpanStatusCode.ERROR,\n      message: error.message,\n    });\n    throw error;\n  } finally {\n    span.end();\n  }\n}\n</code></pre>"},{"location":"users/observability/tracing/#context-propagation","title":"Context Propagation","text":"<pre><code>// context-propagation.js\nconst { context, propagation } = require(\"@opentelemetry/api\");\n\n// HTTP Client with context propagation\nasync function callDownstreamService(data) {\n  const headers = {};\n\n  // Inject trace context into headers\n  propagation.inject(context.active(), headers);\n\n  const response = await fetch(\"https://downstream-service/api\", {\n    method: \"POST\",\n    headers: {\n      ...headers,\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify(data),\n  });\n\n  return response.json();\n}\n\n// HTTP Server extracting context\napp.use((req, res, next) =&gt; {\n  // Extract trace context from incoming headers\n  const extractedContext = propagation.extract(context.active(), req.headers);\n\n  // Run the rest of the request in the extracted context\n  context.with(extractedContext, () =&gt; {\n    next();\n  });\n});\n</code></pre>"},{"location":"users/observability/tracing/#trace-collection","title":"Trace Collection","text":""},{"location":"users/observability/tracing/#sampling-strategies","title":"Sampling Strategies","text":"<pre><code># sampling-config.yaml\napiVersion: tracing/v1\nkind: SamplingStrategy\nmetadata:\n  name: adaptive-sampling\nspec:\n  default:\n    type: probabilistic\n    rate: 0.1 # Sample 10% by default\n\n  rules:\n    - name: errors\n      condition: \"status.code == ERROR\"\n      type: always_on # Always sample errors\n\n    - name: slow_requests\n      condition: \"duration &gt; 1000\" # Over 1 second\n      type: always_on\n\n    - name: high_value_users\n      condition: \"attributes['user.tier'] == 'enterprise'\"\n      type: probabilistic\n      rate: 0.5 # Sample 50% for enterprise users\n\n    - name: health_checks\n      condition: \"attributes['http.path'] =~ '/health|/ping'\"\n      type: always_off # Never sample health checks\n\n  adaptive:\n    enabled: true\n    target_rate: 1000 # Target 1000 traces per minute\n    min_rate: 0.001\n    max_rate: 1.0\n</code></pre>"},{"location":"users/observability/tracing/#trace-processing-pipeline","title":"Trace Processing Pipeline","text":"<pre><code># trace-pipeline.yaml\napiVersion: tracing/v1\nkind: TracePipeline\nmetadata:\n  name: main-pipeline\nspec:\n  receivers:\n    - name: otlp\n      protocol: grpc\n      endpoint: 0.0.0.0:4317\n\n    - name: jaeger\n      protocol: thrift\n      endpoint: 0.0.0.0:14268\n\n  processors:\n    - name: batch\n      timeout: 5s\n      batch_size: 1000\n\n    - name: attributes\n      actions:\n        - action: insert\n          key: environment\n          value: production\n\n        - action: hash\n          key: user.email\n\n        - action: delete\n          key: internal.debug_info\n\n    - name: tail_sampling\n      decision_wait: 10s\n      policies:\n        - name: error-traces\n          type: status_code\n          status_code: ERROR\n\n        - name: slow-traces\n          type: latency\n          latency: 2s\n\n        - name: composite\n          type: composite\n          composite:\n            max_traces: 100\n            policy_order: [error-traces, slow-traces]\n\n  exporters:\n    - name: hexabase\n      endpoint: traces.hexabase.ai:443\n      compression: gzip\n      retry:\n        max_elapsed_time: 300s\n\n    - name: metrics\n      type: spanmetrics\n      dimensions:\n        - service.name\n        - span.kind\n        - status.code\n</code></pre>"},{"location":"users/observability/tracing/#trace-analysis","title":"Trace Analysis","text":""},{"location":"users/observability/tracing/#query-language","title":"Query Language","text":"<pre><code>-- Find slow database queries\nSELECT\n    span_name,\n    service_name,\n    duration_ms,\n    attributes['db.statement'] as query,\n    trace_id\nFROM traces.spans\nWHERE span_kind = 'CLIENT'\n  AND attributes['db.system'] IS NOT NULL\n  AND duration_ms &gt; 1000\n  AND timestamp &gt; now() - INTERVAL 1 HOUR\nORDER BY duration_ms DESC\nLIMIT 20;\n\n-- Analyze service dependencies\nWITH service_calls AS (\n    SELECT\n        parent.service_name as caller,\n        child.service_name as callee,\n        count(*) as call_count,\n        avg(child.duration_ms) as avg_duration,\n        quantile(0.95)(child.duration_ms) as p95_duration,\n        sum(case when child.status_code = 'ERROR' then 1 else 0 end) as error_count\n    FROM traces.spans parent\n    INNER JOIN traces.spans child\n        ON parent.span_id = child.parent_span_id\n        AND parent.trace_id = child.trace_id\n    WHERE parent.timestamp &gt; now() - INTERVAL 1 HOUR\n    GROUP BY caller, callee\n)\nSELECT * FROM service_calls\nORDER BY call_count DESC;\n\n-- Trace errors through the system\nSELECT\n    s1.timestamp,\n    s1.service_name,\n    s1.span_name,\n    s1.error_message,\n    s2.service_name as downstream_service,\n    s2.span_name as downstream_operation\nFROM traces.spans s1\nLEFT JOIN traces.spans s2\n    ON s1.trace_id = s2.trace_id\n    AND s2.timestamp &gt; s1.timestamp\nWHERE s1.status_code = 'ERROR'\n  AND s1.timestamp &gt; now() - INTERVAL 1 HOUR\nORDER BY s1.trace_id, s1.timestamp;\n</code></pre>"},{"location":"users/observability/tracing/#service-map-generation","title":"Service Map Generation","text":"<pre><code># service-map-generator.py\nfrom hexabase.tracing import TraceAnalyzer\nimport networkx as nx\nimport json\n\nanalyzer = TraceAnalyzer()\n\n# Build service dependency graph\ndef generate_service_map(time_range='1h'):\n    # Get all service interactions\n    interactions = analyzer.query(\"\"\"\n        SELECT\n            parent.service_name as source,\n            child.service_name as target,\n            count(*) as requests,\n            avg(child.duration_ms) as avg_latency,\n            sum(case when child.status_code = 'ERROR' then 1 else 0 end) / count(*) as error_rate\n        FROM spans parent\n        JOIN spans child ON parent.span_id = child.parent_span_id\n        WHERE parent.timestamp &gt; now() - INTERVAL {time_range}\n        GROUP BY source, target\n    \"\"\", time_range=time_range)\n\n    # Create directed graph\n    G = nx.DiGraph()\n\n    for interaction in interactions:\n        G.add_edge(\n            interaction['source'],\n            interaction['target'],\n            weight=interaction['requests'],\n            latency=interaction['avg_latency'],\n            error_rate=interaction['error_rate']\n        )\n\n    # Calculate service metrics\n    service_metrics = {}\n    for node in G.nodes():\n        service_metrics[node] = {\n            'in_degree': G.in_degree(node),\n            'out_degree': G.out_degree(node),\n            'betweenness_centrality': nx.betweenness_centrality(G)[node],\n            'critical_path': node in nx.dag_longest_path(G)\n        }\n\n    return {\n        'nodes': list(G.nodes()),\n        'edges': [\n            {\n                'source': u,\n                'target': v,\n                **data\n            }\n            for u, v, data in G.edges(data=True)\n        ],\n        'metrics': service_metrics\n    }\n</code></pre>"},{"location":"users/observability/tracing/#performance-analysis","title":"Performance Analysis","text":""},{"location":"users/observability/tracing/#latency-breakdown","title":"Latency Breakdown","text":"<pre><code>// latency-analyzer.js\nclass LatencyAnalyzer {\n  async analyzeTrace(traceId) {\n    const spans = await this.getTraceSpans(traceId);\n    const rootSpan = spans.find((s) =&gt; !s.parentSpanId);\n\n    // Build span tree\n    const spanTree = this.buildSpanTree(spans);\n\n    // Calculate latency breakdown\n    const breakdown = this.calculateBreakdown(spanTree, rootSpan);\n\n    return {\n      totalDuration: rootSpan.duration,\n      breakdown: breakdown,\n      criticalPath: this.findCriticalPath(spanTree, rootSpan),\n      parallelism: this.calculateParallelism(spanTree),\n    };\n  }\n\n  calculateBreakdown(tree, span, parentStart = 0) {\n    const selfTime = span.duration;\n    const children = tree[span.spanId] || [];\n\n    let childrenTime = 0;\n    const childBreakdowns = [];\n\n    for (const child of children) {\n      const childBreakdown = this.calculateBreakdown(\n        tree,\n        child,\n        span.startTime\n      );\n      childrenTime += child.duration;\n      childBreakdowns.push(childBreakdown);\n    }\n\n    return {\n      service: span.serviceName,\n      operation: span.spanName,\n      duration: span.duration,\n      selfTime: selfTime - childrenTime,\n      percentage: (span.duration / this.rootDuration) * 100,\n      children: childBreakdowns,\n    };\n  }\n}\n</code></pre>"},{"location":"users/observability/tracing/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code># trace-anomaly-detection.yaml\napiVersion: aiops/v1\nkind: TraceAnomalyDetector\nmetadata:\n  name: latency-anomalies\nspec:\n  model:\n    type: isolation_forest\n    features:\n      - total_duration\n      - span_count\n      - error_count\n      - service_hop_count\n      - max_span_duration\n\n  training:\n    window: 7d\n    sample_rate: 0.1\n    exclude_errors: false\n\n  detection:\n    threshold: 0.95\n    min_severity: 0.7\n\n  alerts:\n    - type: latency_spike\n      condition: \"anomaly_score &gt; 0.9 AND total_duration &gt; p99_baseline * 2\"\n      severity: high\n\n    - type: unusual_path\n      condition: \"new_service_combination = true\"\n      severity: medium\n\n    - type: cascade_failure\n      condition: \"error_count &gt; 5 AND affected_services &gt; 3\"\n      severity: critical\n</code></pre>"},{"location":"users/observability/tracing/#visualization","title":"Visualization","text":""},{"location":"users/observability/tracing/#trace-timeline","title":"Trace Timeline","text":"<pre><code>// trace-timeline.js\nclass TraceTimeline {\n  render(traceData) {\n    const spans = this.preprocessSpans(traceData);\n\n    return {\n      timeline: {\n        start: Math.min(...spans.map((s) =&gt; s.startTime)),\n        end: Math.max(...spans.map((s) =&gt; s.endTime)),\n        spans: spans.map((span) =&gt; ({\n          id: span.spanId,\n          service: span.serviceName,\n          operation: span.spanName,\n          start: span.startTime,\n          duration: span.duration,\n          status: span.statusCode,\n          parent: span.parentSpanId,\n          attributes: this.getKeyAttributes(span),\n          events: span.events,\n          logs: span.logs,\n        })),\n      },\n      waterfallView: this.generateWaterfall(spans),\n      ganttView: this.generateGantt(spans),\n      flameGraph: this.generateFlameGraph(spans),\n    };\n  }\n\n  generateWaterfall(spans) {\n    // Sort spans by start time and hierarchy\n    const sorted = this.topologicalSort(spans);\n\n    return sorted.map((span, index) =&gt; ({\n      index,\n      service: span.serviceName,\n      operation: span.spanName,\n      offset: span.startTime - this.traceStart,\n      duration: span.duration,\n      depth: this.calculateDepth(span),\n      hasError: span.statusCode === \"ERROR\",\n    }));\n  }\n}\n</code></pre>"},{"location":"users/observability/tracing/#service-dependency-graph","title":"Service Dependency Graph","text":"<pre><code># service-graph-config.yaml\napiVersion: visualization/v1\nkind: ServiceGraph\nmetadata:\n  name: real-time-dependencies\nspec:\n  data_source:\n    type: traces\n    window: 5m\n    refresh_interval: 30s\n\n  layout:\n    algorithm: force-directed\n    node_spacing: 100\n    edge_bundling: true\n\n  nodes:\n    size_by: request_rate\n    color_by: error_rate\n    thresholds:\n      healthy: \"&lt; 1%\"\n      warning: \"1% - 5%\"\n      critical: \"&gt; 5%\"\n\n  edges:\n    width_by: request_volume\n    color_by: latency\n    show_metrics: true\n\n  interactions:\n    hover: show_details\n    click: drill_down\n    double_click: show_traces\n</code></pre>"},{"location":"users/observability/tracing/#integration-with-metrics","title":"Integration with Metrics","text":""},{"location":"users/observability/tracing/#span-metrics","title":"Span Metrics","text":"<pre><code># span-metrics.yaml\napiVersion: telemetry/v1\nkind: SpanMetrics\nmetadata:\n  name: trace-derived-metrics\nspec:\n  dimensions:\n    - service.name\n    - span.name\n    - span.kind\n    - status.code\n    - http.method\n    - http.status_code\n\n  metrics:\n    - name: traces_spanmetrics_calls_total\n      type: counter\n      unit: calls\n\n    - name: traces_spanmetrics_duration\n      type: histogram\n      unit: milliseconds\n      buckets:\n        [0, 5, 10, 25, 50, 75, 100, 250, 500, 750, 1000, 2500, 5000, 10000]\n\n    - name: traces_spanmetrics_size\n      type: histogram\n      unit: bytes\n\n  aggregation_temporality: delta\n  export_interval: 60s\n</code></pre>"},{"location":"users/observability/tracing/#red-metrics-generation","title":"RED Metrics Generation","text":"<pre><code>// red-metrics.js\nclass REDMetricsGenerator {\n  constructor(traceStore) {\n    this.traceStore = traceStore;\n  }\n\n  async generateMetrics(timeWindow = \"5m\") {\n    const spans = await this.traceStore.query({\n      timeRange: timeWindow,\n      spanKind: \"SERVER\",\n    });\n\n    const metrics = {};\n\n    // Group by service and operation\n    const grouped = this.groupBy(\n      spans,\n      (s) =&gt; `${s.serviceName}:${s.spanName}`\n    );\n\n    for (const [key, serviceSpans] of Object.entries(grouped)) {\n      const [service, operation] = key.split(\":\");\n\n      metrics[key] = {\n        rate: serviceSpans.length / (5 * 60), // requests per second\n        errors: serviceSpans.filter((s) =&gt; s.statusCode === \"ERROR\").length,\n        duration: {\n          p50: this.percentile(\n            serviceSpans.map((s) =&gt; s.duration),\n            50\n          ),\n          p95: this.percentile(\n            serviceSpans.map((s) =&gt; s.duration),\n            95\n          ),\n          p99: this.percentile(\n            serviceSpans.map((s) =&gt; s.duration),\n            99\n          ),\n        },\n      };\n    }\n\n    return metrics;\n  }\n}\n</code></pre>"},{"location":"users/observability/tracing/#best-practices","title":"Best Practices","text":""},{"location":"users/observability/tracing/#1-instrumentation-guidelines","title":"1. Instrumentation Guidelines","text":"<ul> <li>Instrument all service boundaries</li> <li>Include relevant context in span attributes</li> <li>Use semantic conventions for attribute names</li> <li>Avoid high-cardinality attributes</li> </ul>"},{"location":"users/observability/tracing/#2-sampling-strategy","title":"2. Sampling Strategy","text":"<ul> <li>Always sample errors and slow requests</li> <li>Use adaptive sampling for high-volume services</li> <li>Implement head-based sampling at the edge</li> <li>Consider tail-based sampling for complex scenarios</li> </ul>"},{"location":"users/observability/tracing/#3-performance-optimization","title":"3. Performance Optimization","text":"<ul> <li>Batch span exports</li> <li>Use asynchronous exporters</li> <li>Implement circuit breakers</li> <li>Monitor instrumentation overhead</li> </ul>"},{"location":"users/observability/tracing/#4-security-considerations","title":"4. Security Considerations","text":"<ul> <li>Sanitize sensitive data in spans</li> <li>Use secure transport (TLS)</li> <li>Implement access controls</li> <li>Audit trace access</li> </ul>"},{"location":"users/observability/tracing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/observability/tracing/#missing-traces","title":"Missing Traces","text":"<pre><code># Check trace collector status\nhxb tracing status --component collector\n\n# Verify instrumentation\nhxb tracing verify --service my-service\n\n# Test trace export\nhxb tracing test --generate-trace\n</code></pre>"},{"location":"users/observability/tracing/#performance-issues","title":"Performance Issues","text":"<pre><code># Analyze trace overhead\nhxb tracing overhead --service my-service\n\n# Optimize sampling\nhxb tracing optimize-sampling --target-rate 1000\n\n# Check exporter queue\nhxb tracing exporter-stats\n</code></pre>"},{"location":"users/observability/tracing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Logging Architecture</li> <li>Dashboards and Alerts</li> <li>Performance Monitoring</li> <li>AIOps Integration</li> </ul>"},{"location":"users/rbac/best-practices/","title":"RBAC Best Practices","text":"<p>This guide provides comprehensive best practices for implementing and maintaining Role-Based Access Control in Hexabase.AI, ensuring security, scalability, and operational efficiency.</p>"},{"location":"users/rbac/best-practices/#design-principles","title":"Design Principles","text":""},{"location":"users/rbac/best-practices/#principle-of-least-privilege","title":"Principle of Least Privilege","text":"<pre><code># least-privilege-example.yaml\napiVersion: rbac/v1\nkind: BestPractice\nmetadata:\n  name: least-privilege\nspec:\n  # Bad Practice - Too Permissive\n  avoid:\n    - role: developer-all-access\n      rules:\n        - resources: [\"*\"]\n          verbs: [\"*\"]\n\n  # Good Practice - Specific Permissions\n  recommended:\n    - role: developer-read\n      rules:\n        - resources: [\"deployments\", \"pods\", \"services\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n\n    - role: developer-deploy\n      rules:\n        - resources: [\"deployments\"]\n          verbs: [\"create\", \"update\", \"patch\"]\n          namespaces: [\"dev-*\", \"staging-*\"]\n</code></pre>"},{"location":"users/rbac/best-practices/#role-granularity","title":"Role Granularity","text":"<pre><code># role-design-analyzer.py\nclass RoleDesignAnalyzer:\n    def __init__(self):\n        self.metrics = {\n            'optimal_permissions_per_role': (5, 20),\n            'optimal_roles_per_user': (1, 5),\n            'max_permission_overlap': 0.3\n        }\n\n    def analyze_role_design(self, roles):\n        \"\"\"Analyze role design for best practices\"\"\"\n        issues = []\n        recommendations = []\n\n        for role in roles:\n            # Check role size\n            perm_count = len(role.permissions)\n            if perm_count &lt; self.metrics['optimal_permissions_per_role'][0]:\n                issues.append({\n                    'role': role.name,\n                    'issue': 'Role too granular',\n                    'recommendation': 'Consider merging with similar roles'\n                })\n            elif perm_count &gt; self.metrics['optimal_permissions_per_role'][1]:\n                issues.append({\n                    'role': role.name,\n                    'issue': 'Role too broad',\n                    'recommendation': 'Consider splitting into multiple roles'\n                })\n\n        # Check for permission overlap\n        overlap_matrix = self.calculate_overlap(roles)\n        for i, role1 in enumerate(roles):\n            for j, role2 in enumerate(roles[i+1:], i+1):\n                if overlap_matrix[i][j] &gt; self.metrics['max_permission_overlap']:\n                    recommendations.append({\n                        'type': 'consolidation',\n                        'roles': [role1.name, role2.name],\n                        'overlap': overlap_matrix[i][j],\n                        'suggestion': 'Consider consolidating overlapping roles'\n                    })\n\n        return {\n            'issues': issues,\n            'recommendations': recommendations,\n            'metrics': self.calculate_metrics(roles)\n        }\n</code></pre>"},{"location":"users/rbac/best-practices/#role-design-patterns","title":"Role Design Patterns","text":""},{"location":"users/rbac/best-practices/#hierarchical-role-structure","title":"Hierarchical Role Structure","text":"<pre><code># role-hierarchy.yaml\napiVersion: rbac/v1\nkind: RoleHierarchy\nmetadata:\n  name: organization-roles\nspec:\n  # Base roles - building blocks\n  baseRoles:\n    - name: reader\n      description: \"Basic read access\"\n      permissions:\n        - resources: [\"*\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n\n    - name: writer\n      description: \"Write access to non-critical resources\"\n      permissions:\n        - resources: [\"configmaps\", \"services\"]\n          verbs: [\"create\", \"update\", \"patch\", \"delete\"]\n\n  # Composite roles - combine base roles\n  compositeRoles:\n    - name: developer\n      description: \"Standard developer access\"\n      includes: [\"reader\", \"writer\"]\n      additional:\n        - resources: [\"deployments\", \"pods\"]\n          verbs: [\"create\", \"update\", \"delete\"]\n          namespaces: [\"dev-*\", \"staging-*\"]\n\n    - name: senior-developer\n      description: \"Senior developer with production read\"\n      includes: [\"developer\"]\n      additional:\n        - resources: [\"*\"]\n          verbs: [\"get\", \"list\"]\n          namespaces: [\"production\"]\n\n  # Administrative roles\n  administrativeRoles:\n    - name: team-lead\n      description: \"Team management permissions\"\n      includes: [\"senior-developer\"]\n      additional:\n        - resources: [\"rolebindings\"]\n          verbs: [\"create\", \"update\", \"delete\"]\n          namespaces: [\"team-*\"]\n</code></pre>"},{"location":"users/rbac/best-practices/#environment-based-roles","title":"Environment-Based Roles","text":"<pre><code># environment-roles.yaml\napiVersion: rbac/v1\nkind: EnvironmentRoles\nmetadata:\n  name: environment-separation\nspec:\n  environments:\n    development:\n      roles:\n        - name: dev-full-access\n          permissions:\n            - resources: [\"*\"]\n              verbs: [\"*\"]\n\n    staging:\n      roles:\n        - name: staging-deployer\n          permissions:\n            - resources: [\"deployments\", \"services\", \"configmaps\"]\n              verbs: [\"get\", \"list\", \"create\", \"update\", \"patch\"]\n            - resources: [\"pods\", \"logs\"]\n              verbs: [\"get\", \"list\", \"watch\"]\n\n    production:\n      roles:\n        - name: prod-viewer\n          permissions:\n            - resources: [\"*\"]\n              verbs: [\"get\", \"list\", \"watch\"]\n\n        - name: prod-operator\n          permissions:\n            - resources: [\"deployments\"]\n              verbs: [\"get\", \"update\", \"patch\"]\n              conditions:\n                - requireApproval: true\n                - allowedHours: \"09:00-17:00\"\n</code></pre>"},{"location":"users/rbac/best-practices/#functional-roles","title":"Functional Roles","text":"<pre><code># functional-roles.py\nclass FunctionalRoleDesigner:\n    \"\"\"Design roles based on job functions\"\"\"\n\n    def create_functional_roles(self):\n        return {\n            'security-auditor': {\n                'description': 'Security audit and compliance',\n                'permissions': [\n                    {\n                        'resources': ['*'],\n                        'verbs': ['get', 'list'],\n                        'scope': 'cluster'\n                    },\n                    {\n                        'resources': ['events', 'audits'],\n                        'verbs': ['get', 'list', 'watch'],\n                        'scope': 'cluster'\n                    }\n                ]\n            },\n\n            'sre-engineer': {\n                'description': 'Site reliability engineering',\n                'permissions': [\n                    {\n                        'resources': ['nodes', 'pods', 'services'],\n                        'verbs': ['*'],\n                        'scope': 'cluster'\n                    },\n                    {\n                        'resources': ['metrics', 'logs'],\n                        'verbs': ['get', 'list'],\n                        'scope': 'cluster'\n                    }\n                ]\n            },\n\n            'data-scientist': {\n                'description': 'Data analysis and ML workloads',\n                'permissions': [\n                    {\n                        'resources': ['jobs', 'cronjobs'],\n                        'verbs': ['*'],\n                        'namespaces': ['data-science', 'ml-*']\n                    },\n                    {\n                        'resources': ['persistentvolumeclaims'],\n                        'verbs': ['create', 'delete'],\n                        'namespaces': ['data-science']\n                    }\n                ]\n            }\n        }\n</code></pre>"},{"location":"users/rbac/best-practices/#implementation-guidelines","title":"Implementation Guidelines","text":""},{"location":"users/rbac/best-practices/#role-naming-conventions","title":"Role Naming Conventions","text":"<pre><code># naming-conventions.yaml\napiVersion: rbac/v1\nkind: NamingConvention\nmetadata:\n  name: role-naming-standards\nspec:\n  patterns:\n    # Environment-based naming\n    - pattern: \"{environment}-{function}-{permission-level}\"\n      examples:\n        - \"prod-database-reader\"\n        - \"staging-api-admin\"\n        - \"dev-frontend-deployer\"\n\n    # Team-based naming\n    - pattern: \"{team}-{role-type}\"\n      examples:\n        - \"platform-engineer\"\n        - \"security-auditor\"\n        - \"data-analyst\"\n\n    # Service-based naming\n    - pattern: \"{service}-{action}-role\"\n      examples:\n        - \"payment-service-operator-role\"\n        - \"user-api-viewer-role\"\n        - \"notification-manager-role\"\n\n  rules:\n    - \"Use lowercase with hyphens\"\n    - \"Be descriptive but concise\"\n    - \"Include scope indicators (cluster-, namespace-)\"\n    - \"Avoid generic names (admin, user)\"\n</code></pre>"},{"location":"users/rbac/best-practices/#role-documentation","title":"Role Documentation","text":"<pre><code># Role Documentation Template\n\n## Role: production-deployment-manager\n\n### Purpose\n\nManages production deployments with approval workflow\n\n### Permissions\n\n- **Read**: All resources in production namespace\n- **Write**: Deployments (with approval)\n- **Execute**: Rollback operations\n\n### Assigned To\n\n- Groups: `sre-team`, `senior-developers`\n- Service Accounts: `ci-cd-prod`\n\n### Conditions\n\n- MFA required\n- Business hours only (Mon-Fri 9AM-5PM UTC)\n- Requires approval from 2 team leads\n\n### Dependencies\n\n- Inherits from: `production-viewer`\n- Required roles: `mfa-authenticated`\n\n### Audit Requirements\n\n- All actions logged to security SIEM\n- Monthly access review required\n</code></pre>"},{"location":"users/rbac/best-practices/#security-best-practices","title":"Security Best Practices","text":""},{"location":"users/rbac/best-practices/#regular-audits","title":"Regular Audits","text":"<pre><code># rbac-auditor.py\nimport datetime\nfrom typing import List, Dict\n\nclass RBACSecurityAuditor:\n    def __init__(self):\n        self.audit_checks = [\n            self.check_over_privileged_users,\n            self.check_stale_permissions,\n            self.check_service_account_usage,\n            self.check_dangerous_permissions,\n            self.check_separation_of_duties\n        ]\n\n    def run_security_audit(self) -&gt; Dict:\n        \"\"\"Run comprehensive RBAC security audit\"\"\"\n        audit_results = {\n            'timestamp': datetime.datetime.now(),\n            'findings': [],\n            'metrics': {},\n            'recommendations': []\n        }\n\n        for check in self.audit_checks:\n            result = check()\n            audit_results['findings'].extend(result['findings'])\n            audit_results['metrics'].update(result['metrics'])\n\n        audit_results['risk_score'] = self.calculate_risk_score(\n            audit_results['findings']\n        )\n\n        return audit_results\n\n    def check_over_privileged_users(self) -&gt; Dict:\n        \"\"\"Identify users with excessive permissions\"\"\"\n        findings = []\n\n        # Query users with admin roles\n        admin_users = self.get_users_with_role('*-admin')\n\n        for user in admin_users:\n            usage = self.get_permission_usage(user, days=90)\n\n            if usage['used_permissions_ratio'] &lt; 0.1:\n                findings.append({\n                    'severity': 'HIGH',\n                    'type': 'over-privileged',\n                    'user': user['email'],\n                    'message': f\"User has admin access but only uses {usage['used_permissions_ratio']*100:.1f}% of permissions\",\n                    'recommendation': 'Review and reduce permissions'\n                })\n\n        return {\n            'findings': findings,\n            'metrics': {\n                'over_privileged_users': len(findings),\n                'admin_user_count': len(admin_users)\n            }\n        }\n\n    def check_dangerous_permissions(self) -&gt; Dict:\n        \"\"\"Check for dangerous permission combinations\"\"\"\n        dangerous_combos = [\n            (['secrets:delete', 'secrets:create'], 'Can replace secrets'),\n            (['rbac:*', 'pods:exec'], 'Can escalate privileges'),\n            (['nodes:*', 'pods:create'], 'Can compromise nodes')\n        ]\n\n        findings = []\n\n        for user in self.get_all_users():\n            user_perms = self.get_effective_permissions(user)\n\n            for perms, risk in dangerous_combos:\n                if all(p in user_perms for p in perms):\n                    findings.append({\n                        'severity': 'CRITICAL',\n                        'type': 'dangerous-permissions',\n                        'user': user['email'],\n                        'permissions': perms,\n                        'risk': risk\n                    })\n\n        return {'findings': findings, 'metrics': {}}\n</code></pre>"},{"location":"users/rbac/best-practices/#separation-of-duties","title":"Separation of Duties","text":"<pre><code># separation-of-duties.yaml\napiVersion: rbac/v1\nkind: SeparationOfDuties\nmetadata:\n  name: security-controls\nspec:\n  incompatibleRoles:\n    # Development and Production\n    - roles: [\"dev-admin\", \"prod-admin\"]\n      reason: \"Prevent dev changes in production\"\n\n    # Approval and Execution\n    - roles: [\"change-approver\", \"change-executor\"]\n      reason: \"Ensure two-person control\"\n\n    # Audit and Operations\n    - roles: [\"security-auditor\", \"system-operator\"]\n      reason: \"Maintain audit independence\"\n\n  requiredApprovals:\n    - action: \"production-deployment\"\n      approvers:\n        - role: \"tech-lead\"\n        - role: \"sre-oncall\"\n      minimumApprovals: 2\n\n    - action: \"rbac-modification\"\n      approvers:\n        - role: \"security-admin\"\n        - role: \"platform-lead\"\n      minimumApprovals: 1\n\n  mutualExclusion:\n    - name: \"billing-separation\"\n      roles:\n        create: \"billing-creator\"\n        approve: \"billing-approver\"\n        execute: \"billing-executor\"\n</code></pre>"},{"location":"users/rbac/best-practices/#operational-best-practices","title":"Operational Best Practices","text":""},{"location":"users/rbac/best-practices/#role-lifecycle-management","title":"Role Lifecycle Management","text":"<pre><code># role-lifecycle.py\nclass RoleLifecycleManager:\n    def __init__(self):\n        self.lifecycle_stages = [\n            'proposed',\n            'reviewed',\n            'approved',\n            'active',\n            'deprecated',\n            'retired'\n        ]\n\n    def manage_role_lifecycle(self, role_name: str):\n        \"\"\"Manage the complete lifecycle of a role\"\"\"\n\n        role = self.get_role(role_name)\n\n        # Check role usage\n        usage_metrics = self.get_usage_metrics(role_name, days=30)\n\n        # Lifecycle decisions\n        if role['stage'] == 'active':\n            if usage_metrics['user_count'] == 0:\n                self.propose_deprecation(role_name,\n                    reason=\"No active users in 30 days\")\n\n            elif usage_metrics['permission_usage'] &lt; 0.2:\n                self.propose_modification(role_name,\n                    reason=\"Low permission utilization\")\n\n        elif role['stage'] == 'deprecated':\n            if usage_metrics['user_count'] == 0:\n                self.retire_role(role_name)\n\n    def automated_review_schedule(self):\n        \"\"\"Schedule for automated role reviews\"\"\"\n        return {\n            'daily': [\n                'check_critical_roles',\n                'verify_emergency_access'\n            ],\n            'weekly': [\n                'audit_privileged_roles',\n                'review_service_accounts'\n            ],\n            'monthly': [\n                'full_permission_audit',\n                'role_usage_analysis'\n            ],\n            'quarterly': [\n                'role_consolidation_review',\n                'compliance_audit'\n            ]\n        }\n</code></pre>"},{"location":"users/rbac/best-practices/#emergency-access-procedures","title":"Emergency Access Procedures","text":"<pre><code># emergency-access.yaml\napiVersion: rbac/v1\nkind: EmergencyAccess\nmetadata:\n  name: break-glass-procedure\nspec:\n  triggers:\n    - type: \"manual\"\n      authorizedBy: [\"security-team\", \"platform-lead\"]\n\n    - type: \"automatic\"\n      conditions:\n        - \"critical-incident-active\"\n        - \"on-call-engineer-present\"\n\n  procedure:\n    - step: \"authenticate\"\n      requirements:\n        - mfa: required\n        - justification: required\n\n    - step: \"grant-access\"\n      role: \"emergency-responder\"\n      duration: \"4h\"\n      permissions:\n        - resources: [\"*\"]\n          verbs: [\"*\"]\n          namespaces: [\"*\"]\n\n    - step: \"audit\"\n      actions:\n        - log_all_actions: true\n        - notify: [\"security-team\", \"compliance-team\"]\n        - require_report: true\n\n  post-incident:\n    - revoke_access: \"automatic\"\n    - review_actions: \"required\"\n    - update_runbook: \"if-needed\"\n</code></pre>"},{"location":"users/rbac/best-practices/#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"users/rbac/best-practices/#rbac-metrics-dashboard","title":"RBAC Metrics Dashboard","text":"<pre><code># rbac-metrics.yaml\napiVersion: monitoring/v1\nkind: RBACMetrics\nmetadata:\n  name: rbac-dashboard\nspec:\n  metrics:\n    # Usage metrics\n    - name: \"rbac_role_assignments_total\"\n      type: gauge\n      labels: [\"role\", \"namespace\"]\n\n    - name: \"rbac_permission_checks_total\"\n      type: counter\n      labels: [\"user\", \"resource\", \"verb\", \"allowed\"]\n\n    - name: \"rbac_role_binding_changes_total\"\n      type: counter\n      labels: [\"action\", \"role\", \"user\"]\n\n    # Security metrics\n    - name: \"rbac_privileged_users_count\"\n      type: gauge\n      labels: [\"role_type\"]\n\n    - name: \"rbac_failed_access_attempts\"\n      type: counter\n      labels: [\"user\", \"resource\", \"reason\"]\n\n    # Operational metrics\n    - name: \"rbac_evaluation_duration_seconds\"\n      type: histogram\n      buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n\n  alerts:\n    - name: \"HighPrivilegedUserCount\"\n      expr: \"rbac_privileged_users_count &gt; 50\"\n      severity: warning\n\n    - name: \"UnusedRoleDetected\"\n      expr: \"rbac_role_assignments_total == 0\"\n      for: \"7d\"\n      severity: info\n\n    - name: \"FrequentAccessDenials\"\n      expr: \"rate(rbac_failed_access_attempts[5m]) &gt; 10\"\n      severity: warning\n</code></pre>"},{"location":"users/rbac/best-practices/#compliance-reporting","title":"Compliance Reporting","text":"<pre><code># compliance-reporter.py\nclass RBACComplianceReporter:\n    def generate_compliance_report(self, standard='SOC2'):\n        \"\"\"Generate compliance report for RBAC controls\"\"\"\n\n        report = {\n            'standard': standard,\n            'period': self.get_reporting_period(),\n            'controls': {}\n        }\n\n        # Access Control\n        report['controls']['AC-2'] = {\n            'title': 'Account Management',\n            'status': self.check_account_management(),\n            'evidence': [\n                self.get_user_provisioning_logs(),\n                self.get_access_reviews(),\n                self.get_termination_procedures()\n            ]\n        }\n\n        # Least Privilege\n        report['controls']['AC-6'] = {\n            'title': 'Least Privilege',\n            'status': self.check_least_privilege(),\n            'evidence': [\n                self.get_permission_analysis(),\n                self.get_role_assignments(),\n                self.get_privilege_usage_stats()\n            ]\n        }\n\n        # Separation of Duties\n        report['controls']['AC-5'] = {\n            'title': 'Separation of Duties',\n            'status': self.check_separation_of_duties(),\n            'evidence': [\n                self.get_incompatible_roles(),\n                self.get_approval_workflows(),\n                self.get_dual_control_procedures()\n            ]\n        }\n\n        return report\n</code></pre>"},{"location":"users/rbac/best-practices/#migration-strategies","title":"Migration Strategies","text":""},{"location":"users/rbac/best-practices/#legacy-system-migration","title":"Legacy System Migration","text":"<pre><code># migration-strategy.yaml\napiVersion: rbac/v1\nkind: MigrationPlan\nmetadata:\n  name: legacy-rbac-migration\nspec:\n  phases:\n    - name: \"assessment\"\n      duration: \"2w\"\n      tasks:\n        - \"Inventory existing permissions\"\n        - \"Map users to roles\"\n        - \"Identify permission gaps\"\n        - \"Plan role hierarchy\"\n\n    - name: \"pilot\"\n      duration: \"4w\"\n      tasks:\n        - \"Migrate test environment\"\n        - \"Create initial roles\"\n        - \"Test with pilot users\"\n        - \"Gather feedback\"\n\n    - name: \"rollout\"\n      duration: \"8w\"\n      strategy: \"phased\"\n      tasks:\n        - \"Migrate by department\"\n        - \"Implement dual-running period\"\n        - \"Monitor for issues\"\n        - \"Provide training\"\n\n    - name: \"cleanup\"\n      duration: \"2w\"\n      tasks:\n        - \"Remove legacy permissions\"\n        - \"Audit final state\"\n        - \"Document changes\"\n        - \"Archive old system\"\n\n  rollback:\n    enabled: true\n    checkpoints: [\"after-pilot\", \"50%-rollout\", \"pre-cleanup\"]\n</code></pre>"},{"location":"users/rbac/best-practices/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"users/rbac/best-practices/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<pre><code># troubleshooting-guide.yaml\napiVersion: rbac/v1\nkind: TroubleshootingGuide\nmetadata:\n  name: rbac-issues\nspec:\n  issues:\n    - symptom: \"User cannot access resource despite having role\"\n      causes:\n        - \"Namespace mismatch\"\n        - \"RoleBinding not created\"\n        - \"Cache not updated\"\n      solutions:\n        - \"Verify namespace in RoleBinding\"\n        - \"Check RoleBinding exists: kubectl get rolebinding -A | grep &lt;user&gt;\"\n        - \"Clear RBAC cache: hxb rbac cache clear\"\n\n    - symptom: \"Permission denied after role change\"\n      causes:\n        - \"Token not refreshed\"\n        - \"Propagation delay\"\n        - \"Conflicting deny rules\"\n      solutions:\n        - \"Re-authenticate to get new token\"\n        - \"Wait 30-60 seconds for propagation\"\n        - \"Check for explicit deny rules\"\n\n    - symptom: \"Service account cannot authenticate\"\n      causes:\n        - \"Token expired\"\n        - \"Secret not mounted\"\n        - \"RBAC not configured\"\n      solutions:\n        - \"Recreate service account token\"\n        - \"Verify secret mount in pod spec\"\n        - \"Create appropriate RoleBinding\"\n</code></pre>"},{"location":"users/rbac/best-practices/#automation-tools","title":"Automation Tools","text":""},{"location":"users/rbac/best-practices/#rbac-management-scripts","title":"RBAC Management Scripts","text":"<pre><code># rbac-automation.py\nclass RBACAutomation:\n    def __init__(self):\n        self.templates = self.load_templates()\n\n    def onboard_new_team(self, team_name, team_members):\n        \"\"\"Automated team onboarding\"\"\"\n\n        # Create namespace\n        namespace = f\"team-{team_name}\"\n        self.create_namespace(namespace)\n\n        # Create team roles\n        roles = [\n            self.create_role_from_template('team-developer', namespace),\n            self.create_role_from_template('team-viewer', namespace)\n        ]\n\n        # Create group\n        group = self.create_group(f\"{team_name}-team\", team_members)\n\n        # Bind roles\n        self.create_rolebinding(\n            name=f\"{team_name}-developers\",\n            role='team-developer',\n            group=group,\n            namespace=namespace\n        )\n\n        # Set up monitoring\n        self.configure_monitoring(namespace)\n\n        # Send welcome email\n        self.send_onboarding_email(team_members, namespace)\n\n        return {\n            'namespace': namespace,\n            'roles': roles,\n            'group': group,\n            'status': 'completed'\n        }\n</code></pre>"},{"location":"users/rbac/best-practices/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC Overview</li> <li>Permission Model</li> <li>Role Mappings</li> <li>Security Architecture</li> </ul>"},{"location":"users/rbac/overview/","title":"Role-Based Access Control (RBAC)","text":"<p>This guide provides a comprehensive overview of Role-Based Access Control in Hexabase.AI, enabling fine-grained permission management across your infrastructure.</p>"},{"location":"users/rbac/overview/#rbac-overview","title":"RBAC Overview","text":""},{"location":"users/rbac/overview/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[User] --&gt; B[Authentication]\n    B --&gt; C[Identity Provider]\n    C --&gt; D[User Groups]\n    D --&gt; E[Role Bindings]\n    E --&gt; F[Roles]\n    F --&gt; G[Permissions]\n\n    H[Service Account] --&gt; I[API Key Auth]\n    I --&gt; E\n\n    J[Resource] --&gt; K[Resource Policy]\n    K --&gt; L[Access Decision]\n    G --&gt; L\n\n    M[Audit Log] --&gt; N[Compliance]\n    L --&gt; M</code></pre>"},{"location":"users/rbac/overview/#rbac-features-by-plan","title":"RBAC Features by Plan","text":"Plan Basic Roles Custom Roles Fine-grained Permissions API Access Control Single Predefined only - Limited Basic Team Predefined + Limited Custom 10 Namespace-level Standard Enterprise Unlimited Unlimited Resource-level Advanced"},{"location":"users/rbac/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"users/rbac/overview/#users-and-identity","title":"Users and Identity","text":"<pre><code># user-definition.yaml\napiVersion: auth/v1\nkind: User\nmetadata:\n  name: john.doe@example.com\n  namespace: platform-team\nspec:\n  displayName: John Doe\n  email: john.doe@example.com\n  groups:\n    - developers\n    - platform-team\n  attributes:\n    department: Engineering\n    employeeId: \"12345\"\n    manager: jane.smith@example.com\n  preferences:\n    timezone: America/New_York\n    language: en-US\n</code></pre>"},{"location":"users/rbac/overview/#groups","title":"Groups","text":"<pre><code># group-definition.yaml\napiVersion: auth/v1\nkind: Group\nmetadata:\n  name: platform-engineers\nspec:\n  displayName: Platform Engineering Team\n  description: Team responsible for platform infrastructure\n  members:\n    - john.doe@example.com\n    - alice.johnson@example.com\n    - bob.wilson@example.com\n  nestedGroups:\n    - sre-team\n    - devops-team\n  attributes:\n    costCenter: \"CC-1234\"\n    slack-channel: \"#platform-eng\"\n</code></pre>"},{"location":"users/rbac/overview/#service-accounts","title":"Service Accounts","text":"<pre><code># service-account.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: ci-pipeline\n  namespace: ci-cd\nspec:\n  description: Service account for CI/CD pipeline\n  secrets:\n    - name: ci-pipeline-token\n  imagePullSecrets:\n    - name: registry-credentials\n  automountServiceAccountToken: true\n</code></pre>"},{"location":"users/rbac/overview/#role-definition","title":"Role Definition","text":""},{"location":"users/rbac/overview/#built-in-roles","title":"Built-in Roles","text":"<pre><code># List of predefined roles\nroles:\n  - name: viewer\n    description: Read-only access to all resources\n    permissions:\n      - resource: \"*\"\n        verbs: [\"get\", \"list\", \"watch\"]\n\n  - name: editor\n    description: Read and write access to most resources\n    permissions:\n      - resource: \"*\"\n        verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n        excludes: [\"users\", \"roles\", \"rolebindings\"]\n\n  - name: admin\n    description: Full access to all resources in a namespace\n    permissions:\n      - resource: \"*\"\n        verbs: [\"*\"]\n        scope: namespace\n\n  - name: cluster-admin\n    description: Full access to all resources cluster-wide\n    permissions:\n      - resource: \"*\"\n        verbs: [\"*\"]\n        scope: cluster\n</code></pre>"},{"location":"users/rbac/overview/#custom-roles","title":"Custom Roles","text":"<pre><code># custom-role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: deployment-manager\n  namespace: production\nrules:\n  # Deployment management\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\", \"replicasets\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n\n  # Pod management\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"pods/log\", \"pods/exec\"]\n    verbs: [\"get\", \"list\", \"watch\", \"delete\"]\n\n  # Service management\n  - apiGroups: [\"\"]\n    resources: [\"services\", \"endpoints\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n\n  # ConfigMap and Secret read access\n  - apiGroups: [\"\"]\n    resources: [\"configmaps\", \"secrets\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n\n  # Horizontal Pod Autoscaler\n  - apiGroups: [\"autoscaling\"]\n    resources: [\"horizontalpodautoscalers\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"users/rbac/overview/#clusterroles","title":"ClusterRoles","text":"<pre><code># cluster-role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: monitoring-viewer\nrules:\n  # View metrics across all namespaces\n  - apiGroups: [\"metrics.k8s.io\"]\n    resources: [\"pods\", \"nodes\"]\n    verbs: [\"get\", \"list\"]\n\n  # View monitoring resources\n  - apiGroups: [\"monitoring.coreos.com\"]\n    resources: [\"prometheuses\", \"alertmanagers\", \"servicemonitors\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n\n  # View logs\n  - apiGroups: [\"\"]\n    resources: [\"pods/log\"]\n    verbs: [\"get\", \"list\"]\n\n  # Non-resource URLs\n  - nonResourceURLs: [\"/metrics\", \"/api/*\", \"/logs/*\"]\n    verbs: [\"get\"]\n</code></pre>"},{"location":"users/rbac/overview/#role-bindings","title":"Role Bindings","text":""},{"location":"users/rbac/overview/#rolebinding-namespace-scoped","title":"RoleBinding (Namespace-scoped)","text":"<pre><code># role-binding.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: deployment-managers\n  namespace: production\nsubjects:\n  # Bind to users\n  - kind: User\n    name: john.doe@example.com\n    apiGroup: rbac.authorization.k8s.io\n\n  # Bind to groups\n  - kind: Group\n    name: platform-engineers\n    apiGroup: rbac.authorization.k8s.io\n\n  # Bind to service accounts\n  - kind: ServiceAccount\n    name: deployment-automation\n    namespace: ci-cd\nroleRef:\n  kind: Role\n  name: deployment-manager\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"users/rbac/overview/#clusterrolebinding-cluster-wide","title":"ClusterRoleBinding (Cluster-wide)","text":"<pre><code># cluster-role-binding.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: global-monitoring-viewers\nsubjects:\n  - kind: Group\n    name: sre-team\n    apiGroup: rbac.authorization.k8s.io\n  - kind: User\n    name: monitoring-bot@example.com\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: monitoring-viewer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"users/rbac/overview/#advanced-rbac-patterns","title":"Advanced RBAC Patterns","text":""},{"location":"users/rbac/overview/#aggregated-clusterroles","title":"Aggregated ClusterRoles","text":"<pre><code># aggregated-roles.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: monitoring-edit\n  labels:\n    rbac.authorization.k8s.io/aggregate-to-monitoring: \"true\"\nrules:\n  - apiGroups: [\"monitoring.coreos.com\"]\n    resources: [\"prometheusrules\", \"servicemonitors\", \"podmonitors\"]\n    verbs: [\"create\", \"delete\", \"deletecollection\", \"patch\", \"update\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: monitoring-aggregate\naggregationRule:\n  clusterRoleSelectors:\n    - matchLabels:\n        rbac.authorization.k8s.io/aggregate-to-monitoring: \"true\"\nrules: [] # Rules are automatically filled in by the controller\n</code></pre>"},{"location":"users/rbac/overview/#dynamic-role-generation","title":"Dynamic Role Generation","text":"<pre><code># dynamic-role-generator.py\nfrom hexabase.rbac import RoleGenerator\nimport yaml\n\nclass TeamRoleGenerator:\n    def __init__(self, team_name, namespaces):\n        self.team_name = team_name\n        self.namespaces = namespaces\n\n    def generate_roles(self):\n        roles = []\n\n        # Generate namespace-specific roles\n        for ns in self.namespaces:\n            role = {\n                'apiVersion': 'rbac.authorization.k8s.io/v1',\n                'kind': 'Role',\n                'metadata': {\n                    'name': f'{self.team_name}-developer',\n                    'namespace': ns\n                },\n                'rules': self._get_developer_rules()\n            }\n            roles.append(role)\n\n        # Generate cluster role for cross-namespace access\n        cluster_role = {\n            'apiVersion': 'rbac.authorization.k8s.io/v1',\n            'kind': 'ClusterRole',\n            'metadata': {\n                'name': f'{self.team_name}-viewer'\n            },\n            'rules': self._get_viewer_rules()\n        }\n        roles.append(cluster_role)\n\n        return roles\n\n    def _get_developer_rules(self):\n        return [\n            {\n                'apiGroups': ['apps'],\n                'resources': ['deployments', 'statefulsets'],\n                'verbs': ['*']\n            },\n            {\n                'apiGroups': [''],\n                'resources': ['services', 'configmaps'],\n                'verbs': ['*']\n            }\n        ]\n</code></pre>"},{"location":"users/rbac/overview/#conditional-access-policies","title":"Conditional Access Policies","text":"<pre><code># conditional-access.yaml\napiVersion: policy/v1\nkind: ConditionalAccessPolicy\nmetadata:\n  name: production-access\nspec:\n  conditions:\n    # Time-based access\n    - type: TimeWindow\n      config:\n        timezone: UTC\n        allowedHours: \"08:00-18:00\"\n        allowedDays: [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"]\n\n    # Location-based access\n    - type: IPWhitelist\n      config:\n        allowedRanges:\n          - \"10.0.0.0/8\"\n          - \"172.16.0.0/12\"\n\n    # MFA requirement\n    - type: Authentication\n      config:\n        requireMFA: true\n        allowedMethods: [\"hardware-token\", \"authenticator-app\"]\n\n  target:\n    roles:\n      - production-admin\n    namespaces:\n      - production\n      - production-db\n</code></pre>"},{"location":"users/rbac/overview/#rbac-for-hexabase-resources","title":"RBAC for Hexabase Resources","text":""},{"location":"users/rbac/overview/#custom-resource-permissions","title":"Custom Resource Permissions","text":"<pre><code># hexabase-rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: hexabase-developer\n  namespace: my-workspace\nrules:\n  # Workspace management\n  - apiGroups: [\"hexabase.ai/v1\"]\n    resources: [\"workspaces\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n\n  # Node management\n  - apiGroups: [\"hexabase.ai/v1\"]\n    resources: [\"nodes\", \"nodeconfigs\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n    resourceNames: [\"shared-*\"] # Only shared nodes\n\n  # Application deployment\n  - apiGroups: [\"hexabase.ai/v1\"]\n    resources: [\"applications\", \"deployments\"]\n    verbs: [\"*\"]\n\n  # Function management\n  - apiGroups: [\"hexabase.ai/v1\"]\n    resources: [\"functions\", \"functiontriggers\"]\n    verbs: [\"*\"]\n\n  # Backup operations (read-only)\n  - apiGroups: [\"hexabase.ai/v1\"]\n    resources: [\"backups\", \"backuppolicies\"]\n    verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"users/rbac/overview/#resource-level-permissions","title":"Resource-level Permissions","text":"<pre><code># resource-permissions.yaml\napiVersion: hexabase.ai/v1\nkind: ResourcePermission\nmetadata:\n  name: database-access\nspec:\n  resource:\n    type: Database\n    name: production-db\n\n  permissions:\n    - principal:\n        type: Group\n        name: backend-developers\n      access:\n        - action: SELECT\n          tables: [\"users\", \"orders\", \"products\"]\n        - action: INSERT\n          tables: [\"logs\", \"events\"]\n\n    - principal:\n        type: User\n        name: analytics@example.com\n      access:\n        - action: SELECT\n          tables: [\"*\"]\n          conditions:\n            - type: RowFilter\n              expression: \"created_at &gt;= CURRENT_DATE - INTERVAL 30 DAY\"\n</code></pre>"},{"location":"users/rbac/overview/#identity-provider-integration","title":"Identity Provider Integration","text":""},{"location":"users/rbac/overview/#oidc-configuration","title":"OIDC Configuration","text":"<pre><code># oidc-provider.yaml\napiVersion: auth/v1\nkind: IdentityProvider\nmetadata:\n  name: corporate-sso\nspec:\n  type: OIDC\n  displayName: \"Corporate SSO\"\n\n  oidc:\n    issuerURL: \"https://sso.example.com\"\n    clientID: \"hexabase-prod\"\n    clientSecret:\n      secretKeyRef:\n        name: oidc-credentials\n        key: client-secret\n    scopes: [\"openid\", \"profile\", \"email\", \"groups\"]\n\n    usernameClaim: \"email\"\n    groupsClaim: \"groups\"\n\n    claimMappings:\n      displayName: \"name\"\n      email: \"email\"\n      groups: \"groups\"\n      department: \"custom:department\"\n\n  groupMappings:\n    - externalGroup: \"IT-Admins\"\n      internalGroup: \"cluster-admins\"\n    - externalGroup: \"Developers\"\n      internalGroup: \"developers\"\n</code></pre>"},{"location":"users/rbac/overview/#saml-integration","title":"SAML Integration","text":"<pre><code># saml-provider.yaml\napiVersion: auth/v1\nkind: IdentityProvider\nmetadata:\n  name: enterprise-saml\nspec:\n  type: SAML\n  displayName: \"Enterprise SAML\"\n\n  saml:\n    metadataURL: \"https://idp.example.com/metadata\"\n    entityID: \"hexabase-saml\"\n\n    attributeMappings:\n      username: \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress\"\n      displayName: \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name\"\n      groups: \"http://schemas.xmlsoap.org/claims/Group\"\n\n    signatureAlgorithm: \"rsa-sha256\"\n    assertionEncrypted: true\n</code></pre>"},{"location":"users/rbac/overview/#access-control-lists-acls","title":"Access Control Lists (ACLs)","text":""},{"location":"users/rbac/overview/#resource-acls","title":"Resource ACLs","text":"<pre><code># resource-acl.yaml\napiVersion: hexabase.ai/v1\nkind: AccessControlList\nmetadata:\n  name: project-resources\nspec:\n  resource:\n    type: Project\n    name: web-application\n\n  entries:\n    - principal: \"user:lead@example.com\"\n      permissions: [\"read\", \"write\", \"delete\", \"admin\"]\n\n    - principal: \"group:developers\"\n      permissions: [\"read\", \"write\"]\n      inheritance: true\n\n    - principal: \"serviceAccount:ci-pipeline\"\n      permissions: [\"read\", \"write\", \"deploy\"]\n      conditions:\n        - type: \"branch\"\n          value: \"main\"\n\n  defaultPermissions:\n    authenticated: [\"read\"]\n    owner: [\"read\", \"write\", \"delete\", \"admin\"]\n</code></pre>"},{"location":"users/rbac/overview/#audit-and-compliance","title":"Audit and Compliance","text":""},{"location":"users/rbac/overview/#audit-configuration","title":"Audit Configuration","text":"<pre><code># audit-policy.yaml\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  # Don't log read requests\n  - level: None\n    verbs: [\"get\", \"watch\", \"list\"]\n\n  # Log metadata for deletions\n  - level: Metadata\n    verbs: [\"delete\", \"deletecollection\"]\n\n  # Log request and response for role changes\n  - level: RequestResponse\n    resources:\n      - group: \"rbac.authorization.k8s.io\"\n        resources:\n          [\"roles\", \"rolebindings\", \"clusterroles\", \"clusterrolebindings\"]\n\n  # Log everything for production namespace\n  - level: RequestResponse\n    namespaces: [\"production\"]\n\n  # Default level\n  - level: Metadata\n</code></pre>"},{"location":"users/rbac/overview/#compliance-reports","title":"Compliance Reports","text":"<pre><code>-- User access report\nSELECT\n    u.email as user,\n    g.name as group,\n    r.name as role,\n    rb.namespace,\n    rb.created_at,\n    rb.created_by\nFROM users u\nJOIN group_members gm ON u.id = gm.user_id\nJOIN groups g ON gm.group_id = g.id\nJOIN role_bindings rb ON rb.subject_id = g.id AND rb.subject_type = 'Group'\nJOIN roles r ON rb.role_id = r.id\nWHERE rb.active = true\nORDER BY u.email, g.name, r.name;\n\n-- Permission usage analytics\nSELECT\n    date_trunc('day', al.timestamp) as date,\n    al.user,\n    al.verb,\n    al.resource,\n    count(*) as access_count,\n    count(DISTINCT al.object_ref) as unique_objects\nFROM audit_logs al\nWHERE al.timestamp &gt;= CURRENT_DATE - INTERVAL '30 days'\n    AND al.response_status &lt; 400\nGROUP BY date, al.user, al.verb, al.resource\nORDER BY date DESC, access_count DESC;\n</code></pre>"},{"location":"users/rbac/overview/#best-practices","title":"Best Practices","text":""},{"location":"users/rbac/overview/#1-principle-of-least-privilege","title":"1. Principle of Least Privilege","text":"<ul> <li>Grant minimum necessary permissions</li> <li>Use namespace-scoped roles when possible</li> <li>Regular permission audits</li> <li>Remove unused role bindings</li> </ul>"},{"location":"users/rbac/overview/#2-role-design","title":"2. Role Design","text":"<ul> <li>Create reusable roles</li> <li>Use aggregated roles for complex permissions</li> <li>Document role purposes</li> <li>Version control role definitions</li> </ul>"},{"location":"users/rbac/overview/#3-group-management","title":"3. Group Management","text":"<ul> <li>Use groups for team permissions</li> <li>Sync with corporate directory</li> <li>Regular membership reviews</li> <li>Hierarchical group structure</li> </ul>"},{"location":"users/rbac/overview/#4-service-account-security","title":"4. Service Account Security","text":"<ul> <li>Unique service accounts per application</li> <li>Rotate credentials regularly</li> <li>Limit token lifetimes</li> <li>Audit service account usage</li> </ul>"},{"location":"users/rbac/overview/#troubleshooting","title":"Troubleshooting","text":""},{"location":"users/rbac/overview/#common-issues","title":"Common Issues","text":"<pre><code># Check user permissions\nhxb rbac check-access --user john.doe@example.com --verb get --resource pods --namespace production\n\n# List all roles for a user\nhxb rbac get-roles --user john.doe@example.com\n\n# Debug permission denied\nhxb rbac debug --user john.doe@example.com --action \"create deployment\" --namespace production\n\n# Audit role bindings\nhxb rbac audit --namespace production --output-format table\n</code></pre>"},{"location":"users/rbac/overview/#rbac-simulator","title":"RBAC Simulator","text":"<pre><code># Test permission changes\nhxb rbac simulate --user john.doe@example.com --add-role deployment-manager --namespace staging\n\n# What-if analysis\nhxb rbac what-if --remove-group developers --user john.doe@example.com\n\n# Permission diff\nhxb rbac diff --from-role viewer --to-role editor\n</code></pre>"},{"location":"users/rbac/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>Role Mappings</li> <li>Permission Model</li> <li>Best Practices</li> <li>Security Architecture</li> </ul>"},{"location":"users/rbac/permission-model/","title":"Permission Model","text":"<p>This comprehensive guide covers the permission model in Hexabase.AI, including permission types, evaluation rules, and advanced access control patterns.</p>"},{"location":"users/rbac/permission-model/#permission-model-overview","title":"Permission Model Overview","text":""},{"location":"users/rbac/permission-model/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[Permission Request] --&gt; B[Authentication Check]\n    B --&gt; C[Subject Identification]\n    C --&gt; D[Permission Resolution]\n\n    E[Direct Permissions] --&gt; D\n    F[Role Permissions] --&gt; D\n    G[Group Permissions] --&gt; D\n    H[Inherited Permissions] --&gt; D\n\n    D --&gt; I[Policy Evaluation]\n    I --&gt; J[Context Evaluation]\n    J --&gt; K[Access Decision]\n\n    L[Allow Rules] --&gt; K\n    M[Deny Rules] --&gt; K\n    N[Conditional Rules] --&gt; K\n\n    K --&gt; O[Audit Log]\n    K --&gt; P[Grant/Deny Access]</code></pre>"},{"location":"users/rbac/permission-model/#permission-features-by-plan","title":"Permission Features by Plan","text":"Plan Basic Permissions Fine-grained Control Conditional Access Custom Policies Single Resource-level - - - Team Resource + Action Namespace-level Time-based - Enterprise Full granularity Field-level Complex conditions \u2713"},{"location":"users/rbac/permission-model/#permission-types","title":"Permission Types","text":""},{"location":"users/rbac/permission-model/#resource-permissions","title":"Resource Permissions","text":"<pre><code># resource-permissions.yaml\napiVersion: auth/v1\nkind: Permission\nmetadata:\n  name: application-permissions\nspec:\n  resources:\n    # Wildcard permissions\n    - pattern: \"*\"\n      actions: [\"list\", \"watch\"]\n      effect: \"allow\"\n\n    # Specific resource type\n    - pattern: \"applications/*\"\n      actions: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"delete\"]\n      effect: \"allow\"\n\n    # Named resource\n    - pattern: \"applications/production-app\"\n      actions: [\"get\", \"update\"]\n      effect: \"allow\"\n      conditions:\n        - type: \"time\"\n          value: \"business_hours\"\n\n    # Resource with field restrictions\n    - pattern: \"secrets/*\"\n      actions: [\"get\"]\n      effect: \"allow\"\n      fieldRestrictions:\n        allow: [\"metadata\", \"type\"]\n        deny: [\"data\", \"value\"]\n</code></pre>"},{"location":"users/rbac/permission-model/#action-based-permissions","title":"Action-Based Permissions","text":"<pre><code># action-permissions.yaml\napiVersion: auth/v1\nkind: ActionPermission\nmetadata:\n  name: deployment-actions\nspec:\n  actions:\n    - name: \"deploy\"\n      resources: [\"applications\", \"functions\"]\n      conditions:\n        - type: \"environment\"\n          operator: \"in\"\n          values: [\"development\", \"staging\"]\n\n    - name: \"scale\"\n      resources: [\"deployments\"]\n      conditions:\n        - type: \"replicas\"\n          operator: \"&lt;=\"\n          value: \"10\"\n\n    - name: \"delete\"\n      resources: [\"*\"]\n      effect: \"deny\"\n      exceptions:\n        - resource: \"temporary/*\"\n        - resource: \"test/*\"\n</code></pre>"},{"location":"users/rbac/permission-model/#data-permissions","title":"Data Permissions","text":"<pre><code># data-permissions.yaml\napiVersion: auth/v1\nkind: DataPermission\nmetadata:\n  name: database-access\nspec:\n  database: \"customer_db\"\n\n  tables:\n    - name: \"users\"\n      permissions:\n        - action: \"SELECT\"\n          columns: [\"id\", \"email\", \"created_at\"]\n          condition: \"department = ${user.department}\"\n\n        - action: \"UPDATE\"\n          columns: [\"profile\", \"preferences\"]\n          condition: \"id = ${user.id}\"\n\n    - name: \"orders\"\n      permissions:\n        - action: \"SELECT\"\n          columns: \"*\"\n          condition: |\n            CASE\n              WHEN ${user.role} = 'admin' THEN TRUE\n              WHEN ${user.role} = 'sales' THEN region = ${user.region}\n              ELSE customer_id = ${user.customer_id}\n            END\n</code></pre>"},{"location":"users/rbac/permission-model/#permission-evaluation","title":"Permission Evaluation","text":""},{"location":"users/rbac/permission-model/#evaluation-order","title":"Evaluation Order","text":"<pre><code># permission-evaluator.py\nfrom typing import List, Dict, Optional\nfrom enum import Enum\n\nclass Effect(Enum):\n    ALLOW = \"allow\"\n    DENY = \"deny\"\n\nclass PermissionEvaluator:\n    def __init__(self):\n        self.evaluation_order = [\n            self.check_explicit_deny,\n            self.check_explicit_allow,\n            self.check_role_permissions,\n            self.check_group_permissions,\n            self.check_inherited_permissions,\n            self.apply_default_policy\n        ]\n\n    def evaluate(self, subject: Dict, resource: str, action: str,\n                 context: Dict) -&gt; tuple[bool, str]:\n        \"\"\"\n        Evaluate permission request\n        Returns: (allowed: bool, reason: str)\n        \"\"\"\n        request = {\n            'subject': subject,\n            'resource': resource,\n            'action': action,\n            'context': context\n        }\n\n        # Check each evaluation step in order\n        for evaluator in self.evaluation_order:\n            result = evaluator(request)\n            if result is not None:\n                allowed, reason = result\n                self.audit_decision(request, allowed, reason)\n                return allowed, reason\n\n        # Default deny\n        return False, \"No matching permission found\"\n\n    def check_explicit_deny(self, request: Dict) -&gt; Optional[tuple[bool, str]]:\n        \"\"\"Explicit deny rules take precedence\"\"\"\n        deny_rules = self.get_deny_rules(request['subject'])\n\n        for rule in deny_rules:\n            if self.matches_rule(rule, request):\n                return False, f\"Explicitly denied by rule: {rule['name']}\"\n\n        return None\n\n    def check_explicit_allow(self, request: Dict) -&gt; Optional[tuple[bool, str]]:\n        \"\"\"Check direct permissions assigned to subject\"\"\"\n        allow_rules = self.get_allow_rules(request['subject'])\n\n        for rule in allow_rules:\n            if self.matches_rule(rule, request):\n                if self.check_conditions(rule.get('conditions', []), request):\n                    return True, f\"Allowed by rule: {rule['name']}\"\n\n        return None\n</code></pre>"},{"location":"users/rbac/permission-model/#condition-evaluation","title":"Condition Evaluation","text":"<pre><code># condition-types.yaml\napiVersion: auth/v1\nkind: ConditionTypes\nmetadata:\n  name: standard-conditions\nspec:\n  conditions:\n    # Time-based conditions\n    - name: time_window\n      parameters:\n        start_time: \"string\"\n        end_time: \"string\"\n        timezone: \"string\"\n      evaluation: |\n        current_time = now()\n        return current_time &gt;= start_time AND current_time &lt;= end_time\n\n    # Location-based conditions\n    - name: ip_range\n      parameters:\n        allowed_ranges: \"array\"\n        denied_ranges: \"array\"\n      evaluation: |\n        client_ip = context.client_ip\n        return in_range(client_ip, allowed_ranges) AND \n               NOT in_range(client_ip, denied_ranges)\n\n    # Attribute-based conditions\n    - name: attribute_match\n      parameters:\n        attribute: \"string\"\n        operator: \"string\"\n        value: \"any\"\n      evaluation: |\n        subject_value = subject.attributes[attribute]\n        return evaluate_condition(subject_value, operator, value)\n\n    # Resource state conditions\n    - name: resource_state\n      parameters:\n        state_field: \"string\"\n        allowed_states: \"array\"\n      evaluation: |\n        resource_state = resource.get_field(state_field)\n        return resource_state IN allowed_states\n</code></pre>"},{"location":"users/rbac/permission-model/#complex-permission-rules","title":"Complex Permission Rules","text":"<pre><code># complex-permissions.py\nclass ComplexPermissionRule:\n    def __init__(self, rule_config):\n        self.config = rule_config\n        self.condition_evaluator = ConditionEvaluator()\n\n    def evaluate(self, context):\n        # Evaluate boolean expression\n        if 'expression' in self.config:\n            return self.evaluate_expression(\n                self.config['expression'],\n                context\n            )\n\n        # Evaluate all conditions with logical operators\n        if 'all_of' in self.config:\n            return all(\n                self.evaluate_condition(cond, context)\n                for cond in self.config['all_of']\n            )\n\n        if 'any_of' in self.config:\n            return any(\n                self.evaluate_condition(cond, context)\n                for cond in self.config['any_of']\n            )\n\n        if 'none_of' in self.config:\n            return not any(\n                self.evaluate_condition(cond, context)\n                for cond in self.config['none_of']\n            )\n\n        return True\n\n    def evaluate_expression(self, expr, context):\n        \"\"\"\n        Evaluate complex boolean expressions like:\n        \"(role == 'admin' OR department == 'IT') AND time.hour &gt;= 9\"\n        \"\"\"\n        # Parse and evaluate expression safely\n        ast = self.parse_expression(expr)\n        return self.evaluate_ast(ast, context)\n</code></pre>"},{"location":"users/rbac/permission-model/#advanced-permission-patterns","title":"Advanced Permission Patterns","text":""},{"location":"users/rbac/permission-model/#hierarchical-permissions","title":"Hierarchical Permissions","text":"<pre><code># hierarchical-permissions.yaml\napiVersion: auth/v1\nkind: HierarchicalPermission\nmetadata:\n  name: organizational-hierarchy\nspec:\n  hierarchy:\n    - level: organization\n      permissions:\n        - resource: \"organization/*\"\n          actions: [\"*\"]\n\n    - level: department\n      permissions:\n        - resource: \"department/${department}/*\"\n          actions: [\"*\"]\n        - resource: \"organization/settings\"\n          actions: [\"read\"]\n\n    - level: team\n      permissions:\n        - resource: \"team/${team}/*\"\n          actions: [\"*\"]\n        - resource: \"department/${department}/reports\"\n          actions: [\"read\"]\n\n    - level: individual\n      permissions:\n        - resource: \"user/${user_id}/*\"\n          actions: [\"*\"]\n        - resource: \"team/${team}/members\"\n          actions: [\"read\"]\n\n  inheritance:\n    direction: top-down\n    override: true\n</code></pre>"},{"location":"users/rbac/permission-model/#delegated-permissions","title":"Delegated Permissions","text":"<pre><code># delegated-permissions.py\nclass DelegatedPermission:\n    def __init__(self):\n        self.delegations = {}\n\n    def delegate(self, delegator, delegatee, permissions, constraints):\n        \"\"\"\n        Allow a user to delegate their permissions to another user\n        \"\"\"\n        delegation = {\n            'id': generate_uuid(),\n            'delegator': delegator,\n            'delegatee': delegatee,\n            'permissions': permissions,\n            'constraints': constraints,\n            'created_at': datetime.now(),\n            'expires_at': constraints.get('expires_at'),\n            'revoked': False\n        }\n\n        # Validate delegation\n        if not self.can_delegate(delegator, permissions):\n            raise PermissionError(\"Cannot delegate permissions you don't have\")\n\n        # Check delegation limits\n        if self.exceeds_delegation_limit(delegator):\n            raise PermissionError(\"Delegation limit exceeded\")\n\n        self.delegations[delegation['id']] = delegation\n        return delegation\n\n    def evaluate_delegated_permission(self, subject, resource, action):\n        \"\"\"Check if subject has delegated permissions\"\"\"\n        for delegation in self.get_active_delegations(subject):\n            if self.matches_delegation(delegation, resource, action):\n                return True\n        return False\n</code></pre>"},{"location":"users/rbac/permission-model/#dynamic-permissions","title":"Dynamic Permissions","text":"<pre><code># dynamic-permissions.yaml\napiVersion: auth/v1\nkind: DynamicPermission\nmetadata:\n  name: context-aware-permissions\nspec:\n  rules:\n    # Workload-based permissions\n    - name: scale-based-access\n      trigger:\n        metric: system.load\n        threshold: 0.8\n      effect:\n        - restrict:\n            actions: [\"create\", \"scale\"]\n            reason: \"System under high load\"\n\n    # Time-sensitive permissions\n    - name: emergency-access\n      trigger:\n        event: incident.critical\n      effect:\n        - grant:\n            role: incident-responder\n            duration: 4h\n            permissions:\n              - resource: \"production/*\"\n                actions: [\"*\"]\n\n    # Approval-based permissions\n    - name: privileged-operation\n      resources: [\"production/database/*\"]\n      actions: [\"delete\", \"truncate\"]\n      requires:\n        approvals: 2\n        approvers:\n          - role: dba\n          - role: team-lead\n        timeout: 1h\n</code></pre>"},{"location":"users/rbac/permission-model/#permission-policies","title":"Permission Policies","text":""},{"location":"users/rbac/permission-model/#policy-language","title":"Policy Language","text":"<pre><code># permission-policy.yaml\napiVersion: policy/v1\nkind: PermissionPolicy\nmetadata:\n  name: production-access-policy\nspec:\n  # Policy metadata\n  description: \"Controls access to production resources\"\n  version: \"1.0.0\"\n  priority: 100\n\n  # Policy subjects\n  subjects:\n    - kind: User\n      selector:\n        matchLabels:\n          team: production-support\n    - kind: Group\n      name: sre-team\n\n  # Policy rules\n  rules:\n    - id: read-only-default\n      effect: allow\n      actions: [\"get\", \"list\", \"watch\"]\n      resources: [\"*\"]\n\n    - id: deployment-restrictions\n      effect: allow\n      actions: [\"create\", \"update\", \"patch\"]\n      resources: [\"deployments/*\"]\n      conditions:\n        - all:\n            - time_window:\n                days: [\"mon\", \"tue\", \"wed\", \"thu\", \"fri\"]\n                hours: \"09:00-17:00\"\n                timezone: \"UTC\"\n            - approval_required:\n                approvers: [\"team-lead\", \"sre-oncall\"]\n\n    - id: emergency-override\n      effect: allow\n      actions: [\"*\"]\n      resources: [\"*\"]\n      conditions:\n        - any:\n            - incident_active:\n                severity: [\"critical\", \"high\"]\n            - explicit_approval:\n                approver_role: \"cto\"\n</code></pre>"},{"location":"users/rbac/permission-model/#policy-composition","title":"Policy Composition","text":"<pre><code># policy-composer.py\nclass PolicyComposer:\n    def __init__(self):\n        self.policies = {}\n        self.policy_validator = PolicyValidator()\n\n    def compose_policies(self, subject, resource, action):\n        \"\"\"Compose multiple policies into final decision\"\"\"\n        applicable_policies = self.get_applicable_policies(\n            subject, resource, action\n        )\n\n        # Sort by priority\n        applicable_policies.sort(key=lambda p: p.priority, reverse=True)\n\n        # Evaluate policies in order\n        decision = None\n        matching_policies = []\n\n        for policy in applicable_policies:\n            result = self.evaluate_policy(policy, subject, resource, action)\n\n            if result.effect == 'deny':\n                # Deny takes precedence\n                return PolicyDecision(\n                    effect='deny',\n                    reason=f\"Denied by policy: {policy.name}\",\n                    matching_policies=[policy.name]\n                )\n\n            elif result.effect == 'allow':\n                matching_policies.append(policy.name)\n                if decision is None:\n                    decision = result\n\n        if decision:\n            decision.matching_policies = matching_policies\n            return decision\n\n        return PolicyDecision(\n            effect='deny',\n            reason=\"No matching allow policy found\"\n        )\n</code></pre>"},{"location":"users/rbac/permission-model/#permission-boundaries","title":"Permission Boundaries","text":""},{"location":"users/rbac/permission-model/#boundary-definition","title":"Boundary Definition","text":"<pre><code># permission-boundaries.yaml\napiVersion: auth/v1\nkind: PermissionBoundary\nmetadata:\n  name: developer-boundary\nspec:\n  description: \"Maximum permissions for developer role\"\n\n  # Maximum allowed permissions\n  maxPermissions:\n    - resources: [\"applications/*\", \"functions/*\"]\n      actions: [\"*\"]\n      namespaces: [\"dev-*\", \"staging-*\"]\n\n    - resources: [\"secrets/*\", \"configmaps/*\"]\n      actions: [\"get\", \"list\", \"watch\"]\n      namespaces: [\"*\"]\n\n    - resources: [\"deployments/*\"]\n      actions: [\"get\", \"list\", \"watch\", \"update\", \"patch\"]\n      namespaces: [\"dev-*\", \"staging-*\"]\n\n  # Explicitly denied permissions\n  explicitDeny:\n    - resources: [\"nodes/*\", \"clusters/*\"]\n      actions: [\"*\"]\n\n    - resources: [\"*/production/*\"]\n      actions: [\"delete\", \"create\"]\n\n    - resources: [\"rbac/*\"]\n      actions: [\"create\", \"update\", \"delete\"]\n\n  # Conditions that must be met\n  requiredConditions:\n    - mfa_enabled: true\n    - account_age_days: \"&gt;= 30\"\n    - training_completed: [\"security-basics\", \"platform-101\"]\n</code></pre>"},{"location":"users/rbac/permission-model/#boundary-enforcement","title":"Boundary Enforcement","text":"<pre><code># boundary-enforcement.py\nclass PermissionBoundaryEnforcer:\n    def __init__(self, boundary_config):\n        self.boundary = boundary_config\n\n    def enforce(self, requested_permissions, subject):\n        \"\"\"\n        Ensure requested permissions don't exceed boundaries\n        \"\"\"\n        violations = []\n        allowed_permissions = []\n\n        for permission in requested_permissions:\n            # Check against max permissions\n            if not self.within_max_permissions(permission):\n                violations.append({\n                    'permission': permission,\n                    'reason': 'Exceeds permission boundary'\n                })\n                continue\n\n            # Check against explicit deny\n            if self.explicitly_denied(permission):\n                violations.append({\n                    'permission': permission,\n                    'reason': 'Explicitly denied by boundary'\n                })\n                continue\n\n            # Check required conditions\n            if not self.meets_conditions(subject):\n                violations.append({\n                    'permission': permission,\n                    'reason': 'Required conditions not met'\n                })\n                continue\n\n            allowed_permissions.append(permission)\n\n        return {\n            'allowed': allowed_permissions,\n            'denied': violations,\n            'boundary_applied': self.boundary['name']\n        }\n</code></pre>"},{"location":"users/rbac/permission-model/#permission-inheritance","title":"Permission Inheritance","text":""},{"location":"users/rbac/permission-model/#inheritance-models","title":"Inheritance Models","text":"<pre><code># inheritance-models.yaml\napiVersion: auth/v1\nkind: InheritanceModel\nmetadata:\n  name: resource-inheritance\nspec:\n  models:\n    # Hierarchical inheritance\n    - type: hierarchical\n      rules:\n        - parent: \"organization\"\n          child: \"department\"\n          inheritance: \"all\"\n\n        - parent: \"department\"\n          child: \"team\"\n          inheritance: \"filtered\"\n          filter:\n            exclude: [\"admin\", \"delete\"]\n\n    # Path-based inheritance\n    - type: path-based\n      rules:\n        - pattern: \"/projects/{project}/*\"\n          inherit_from: \"/projects/{project}\"\n\n        - pattern: \"/teams/{team}/members/{member}\"\n          inherit_from: \"/teams/{team}\"\n          additional:\n            - action: \"read\"\n              resource: \"self\"\n\n    # Role-based inheritance\n    - type: role-hierarchy\n      rules:\n        - parent_role: \"admin\"\n          child_role: \"power-user\"\n          inherit: 0.8 # Inherit 80% of permissions\n\n        - parent_role: \"power-user\"\n          child_role: \"user\"\n          inherit: 0.5 # Inherit 50% of permissions\n</code></pre>"},{"location":"users/rbac/permission-model/#monitoring-and-auditing","title":"Monitoring and Auditing","text":""},{"location":"users/rbac/permission-model/#permission-usage-analytics","title":"Permission Usage Analytics","text":"<pre><code>-- Permission usage patterns\nWITH permission_usage AS (\n    SELECT\n        user_id,\n        resource_type,\n        action,\n        count(*) as usage_count,\n        count(DISTINCT date_trunc('day', timestamp)) as active_days,\n        avg(CASE WHEN granted THEN 1 ELSE 0 END) as success_rate\n    FROM permission_checks\n    WHERE timestamp &gt;= CURRENT_DATE - INTERVAL '30 days'\n    GROUP BY user_id, resource_type, action\n)\nSELECT\n    u.email,\n    pu.resource_type,\n    pu.action,\n    pu.usage_count,\n    pu.active_days,\n    pu.success_rate,\n    CASE\n        WHEN pu.usage_count = 0 THEN 'Unused'\n        WHEN pu.success_rate &lt; 0.5 THEN 'Frequently Denied'\n        WHEN pu.active_days = 1 THEN 'Rarely Used'\n        ELSE 'Active'\n    END as usage_status\nFROM permission_usage pu\nJOIN users u ON pu.user_id = u.id\nORDER BY pu.usage_count DESC;\n\n-- Over-privileged users detection\nWITH user_permissions AS (\n    SELECT\n        u.id,\n        u.email,\n        count(DISTINCT rp.permission_id) as total_permissions,\n        count(DISTINCT pc.permission_id) as used_permissions\n    FROM users u\n    JOIN role_assignments ra ON u.id = ra.user_id\n    JOIN role_permissions rp ON ra.role_id = rp.role_id\n    LEFT JOIN permission_checks pc ON u.id = pc.user_id\n        AND pc.permission_id = rp.permission_id\n        AND pc.timestamp &gt;= CURRENT_DATE - INTERVAL '90 days'\n    GROUP BY u.id, u.email\n)\nSELECT\n    email,\n    total_permissions,\n    used_permissions,\n    total_permissions - used_permissions as unused_permissions,\n    (used_permissions::float / NULLIF(total_permissions, 0) * 100) as usage_percentage\nFROM user_permissions\nWHERE total_permissions &gt; 0\n    AND (used_permissions::float / total_permissions) &lt; 0.2\nORDER BY unused_permissions DESC;\n</code></pre>"},{"location":"users/rbac/permission-model/#permission-debugging","title":"Permission Debugging","text":"<pre><code># permission-debugger.py\nclass PermissionDebugger:\n    def __init__(self):\n        self.trace = []\n\n    def debug_permission_check(self, subject, resource, action, context):\n        \"\"\"\n        Detailed debugging of permission evaluation\n        \"\"\"\n        self.trace = []\n\n        # Start debugging session\n        self.log(\"=== Permission Debug Session ===\")\n        self.log(f\"Subject: {subject}\")\n        self.log(f\"Resource: {resource}\")\n        self.log(f\"Action: {action}\")\n        self.log(f\"Context: {context}\")\n\n        # Check each permission source\n        result = self.check_with_trace(subject, resource, action, context)\n\n        # Generate debug report\n        return {\n            'allowed': result['allowed'],\n            'reason': result['reason'],\n            'trace': self.trace,\n            'applicable_rules': result['rules'],\n            'evaluation_time': result['time_ms'],\n            'recommendations': self.generate_recommendations()\n        }\n\n    def generate_recommendations(self):\n        \"\"\"Suggest permission fixes based on trace\"\"\"\n        recommendations = []\n\n        if self.has_near_match():\n            recommendations.append({\n                'type': 'near_match',\n                'suggestion': 'Similar permission exists',\n                'details': self.get_near_matches()\n            })\n\n        if self.has_inheritance_gap():\n            recommendations.append({\n                'type': 'inheritance_gap',\n                'suggestion': 'Permission could be inherited',\n                'details': self.get_inheritance_suggestions()\n            })\n\n        return recommendations\n</code></pre>"},{"location":"users/rbac/permission-model/#best-practices","title":"Best Practices","text":""},{"location":"users/rbac/permission-model/#1-permission-design","title":"1. Permission Design","text":"<ul> <li>Follow principle of least privilege</li> <li>Use positive permissions (allow) over negative (deny)</li> <li>Group related permissions into roles</li> <li>Document permission purposes</li> </ul>"},{"location":"users/rbac/permission-model/#2-performance","title":"2. Performance","text":"<ul> <li>Cache permission evaluations</li> <li>Optimize permission queries</li> <li>Use permission boundaries to limit checks</li> <li>Implement efficient inheritance algorithms</li> </ul>"},{"location":"users/rbac/permission-model/#3-security","title":"3. Security","text":"<ul> <li>Regular permission audits</li> <li>Monitor for privilege escalation</li> <li>Implement permission expiry</li> <li>Use MFA for sensitive permissions</li> </ul>"},{"location":"users/rbac/permission-model/#4-maintenance","title":"4. Maintenance","text":"<ul> <li>Version control permission changes</li> <li>Test permission changes in staging</li> <li>Regular cleanup of unused permissions</li> <li>Maintain permission documentation</li> </ul>"},{"location":"users/rbac/permission-model/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC Overview</li> <li>Role Mappings</li> <li>Best Practices</li> <li>Security Architecture</li> </ul>"},{"location":"users/rbac/role-mappings/","title":"Role Mappings","text":"<p>This guide covers role mapping strategies in Hexabase.AI, including mapping external identities to internal roles, dynamic role assignment, and role hierarchy management.</p>"},{"location":"users/rbac/role-mappings/#role-mapping-overview","title":"Role Mapping Overview","text":""},{"location":"users/rbac/role-mappings/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[External Identity] --&gt; B[Identity Provider]\n    B --&gt; C[Claim Extraction]\n    C --&gt; D[Mapping Rules]\n    D --&gt; E[Role Assignment]\n\n    F[LDAP Groups] --&gt; D\n    G[SAML Attributes] --&gt; D\n    H[OIDC Claims] --&gt; D\n    I[Custom Attributes] --&gt; D\n\n    E --&gt; J[Static Roles]\n    E --&gt; K[Dynamic Roles]\n    E --&gt; L[Conditional Roles]\n\n    M[Role Hierarchy] --&gt; N[Effective Permissions]\n    J --&gt; N\n    K --&gt; N\n    L --&gt; N</code></pre>"},{"location":"users/rbac/role-mappings/#mapping-features-by-plan","title":"Mapping Features by Plan","text":"Plan Static Mappings Dynamic Mappings Conditional Logic Custom Transformations Single Basic - - - Team Advanced Limited Basic - Enterprise Advanced Unlimited Advanced \u2713"},{"location":"users/rbac/role-mappings/#identity-provider-mappings","title":"Identity Provider Mappings","text":""},{"location":"users/rbac/role-mappings/#oidc-claim-mappings","title":"OIDC Claim Mappings","text":"<pre><code># oidc-mappings.yaml\napiVersion: auth/v1\nkind: ClaimMapping\nmetadata:\n  name: corporate-oidc-mappings\nspec:\n  provider: corporate-sso\n\n  userAttributes:\n    username:\n      claim: \"preferred_username\"\n      transform: \"lowercase\"\n    email:\n      claim: \"email\"\n      required: true\n    displayName:\n      claim: \"name\"\n      default: \"{{ .preferred_username }}\"\n    department:\n      claim: \"custom:department\"\n    employeeType:\n      claim: \"custom:employee_type\"\n    manager:\n      claim: \"custom:manager_email\"\n\n  groupMappings:\n    # Direct claim mapping\n    - claim: \"groups\"\n      prefix: \"oidc:\"\n\n    # Nested claim mapping\n    - claim: \"resource_access.hexabase.roles\"\n      prefix: \"app:\"\n\n    # Conditional group mapping\n    - claim: \"department\"\n      mappings:\n        Engineering: [\"developers\", \"tech-users\"]\n        Sales: [\"sales-team\", \"crm-users\"]\n        Finance: [\"finance-team\", \"read-only-users\"]\n</code></pre>"},{"location":"users/rbac/role-mappings/#saml-attribute-mappings","title":"SAML Attribute Mappings","text":"<pre><code># saml-mappings.yaml\napiVersion: auth/v1\nkind: AttributeMapping\nmetadata:\n  name: enterprise-saml-mappings\nspec:\n  provider: enterprise-saml\n\n  attributes:\n    # User attributes\n    - attribute: \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress\"\n      mapTo: \"email\"\n      required: true\n\n    - attribute: \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name\"\n      mapTo: \"displayName\"\n\n    - attribute: \"http://schemas.microsoft.com/ws/2008/06/identity/claims/groups\"\n      mapTo: \"groups\"\n      multiValued: true\n\n    - attribute: \"urn:oid:1.3.6.1.4.1.5923.1.1.1.7\"\n      mapTo: \"eduPersonEntitlement\"\n      transform: |\n        {{ range . }}\n          {{ if hasPrefix . \"urn:mace:example.com:hexabase:\" }}\n            {{ trimPrefix . \"urn:mace:example.com:hexabase:\" }}\n          {{ end }}\n        {{ end }}\n\n  roleMappings:\n    - attribute: \"memberOf\"\n      pattern: \"CN=([^,]+),OU=Groups\"\n      roleTemplate: 'ldap-{{ .1 | lower | replace \" \" \"-\" }}'\n</code></pre>"},{"location":"users/rbac/role-mappings/#ldap-group-mappings","title":"LDAP Group Mappings","text":"<pre><code># ldap-mappings.yaml\napiVersion: auth/v1\nkind: LDAPMapping\nmetadata:\n  name: corporate-ldap\nspec:\n  connection:\n    url: \"ldaps://ldap.example.com:636\"\n    bindDN: \"cn=hexabase,ou=services,dc=example,dc=com\"\n    bindPassword:\n      secretKeyRef:\n        name: ldap-credentials\n        key: password\n\n  userSearch:\n    baseDN: \"ou=users,dc=example,dc=com\"\n    filter: \"(&amp;(objectClass=person)(mail={{.username}}))\"\n    attributes:\n      username: \"sAMAccountName\"\n      email: \"mail\"\n      displayName: \"displayName\"\n\n  groupSearch:\n    baseDN: \"ou=groups,dc=example,dc=com\"\n    filter: \"(member={{.userDN}})\"\n    attributes:\n      name: \"cn\"\n      description: \"description\"\n\n  groupMappings:\n    # Direct mapping\n    \"Domain Admins\": \"cluster-admin\"\n    \"Developers\": \"developer\"\n    \"QA Team\": \"tester\"\n\n    # Pattern-based mapping\n    patterns:\n      - match: \"^App-(.+)-Admin$\"\n        role: \"{{ .1 | lower }}-admin\"\n      - match: \"^App-(.+)-User$\"\n        role: \"{{ .1 | lower }}-user\"\n</code></pre>"},{"location":"users/rbac/role-mappings/#dynamic-role-assignment","title":"Dynamic Role Assignment","text":""},{"location":"users/rbac/role-mappings/#rule-based-assignment","title":"Rule-Based Assignment","text":"<pre><code># dynamic-roles.yaml\napiVersion: auth/v1\nkind: DynamicRoleAssignment\nmetadata:\n  name: automatic-roles\nspec:\n  rules:\n    # Department-based roles\n    - name: engineering-roles\n      conditions:\n        - field: \"department\"\n          operator: \"in\"\n          values: [\"Engineering\", \"DevOps\", \"SRE\"]\n      assign:\n        roles:\n          - \"developer\"\n          - \"metrics-viewer\"\n        namespaces:\n          - \"development\"\n          - \"staging\"\n\n    # Seniority-based roles\n    - name: senior-privileges\n      conditions:\n        - field: \"title\"\n          operator: \"contains\"\n          value: \"Senior\"\n        - field: \"yearsOfService\"\n          operator: \"&gt;\"\n          value: \"3\"\n      assign:\n        roles:\n          - \"senior-developer\"\n          - \"prod-read-only\"\n\n    # Location-based access\n    - name: regional-access\n      conditions:\n        - field: \"location\"\n          operator: \"equals\"\n          value: \"EU\"\n      assign:\n        roles:\n          - \"eu-resources-manager\"\n        namespaces:\n          - \"eu-west-1\"\n          - \"eu-central-1\"\n</code></pre>"},{"location":"users/rbac/role-mappings/#attribute-based-role-assignment","title":"Attribute-Based Role Assignment","text":"<pre><code># attribute-role-mapper.py\nfrom hexabase.auth import RoleMapper, User\nfrom typing import List, Dict\n\nclass AttributeRoleMapper(RoleMapper):\n    def __init__(self):\n        self.role_rules = self.load_role_rules()\n\n    def map_roles(self, user: User) -&gt; List[str]:\n        roles = set()\n\n        # Apply static mappings\n        for group in user.groups:\n            if group in self.static_mappings:\n                roles.add(self.static_mappings[group])\n\n        # Apply dynamic rules\n        for rule in self.role_rules:\n            if self.evaluate_rule(rule, user):\n                roles.update(rule['roles'])\n\n        # Apply hierarchy\n        roles = self.expand_role_hierarchy(roles)\n\n        return list(roles)\n\n    def evaluate_rule(self, rule: Dict, user: User) -&gt; bool:\n        for condition in rule['conditions']:\n            if not self.check_condition(condition, user):\n                return False\n        return True\n\n    def check_condition(self, condition: Dict, user: User) -&gt; bool:\n        field_value = user.get_attribute(condition['field'])\n        operator = condition['operator']\n        expected = condition['value']\n\n        if operator == 'equals':\n            return field_value == expected\n        elif operator == 'contains':\n            return expected in field_value\n        elif operator == 'matches':\n            return re.match(expected, field_value) is not None\n        elif operator == 'in':\n            return field_value in expected\n        elif operator == '&gt;':\n            return float(field_value) &gt; float(expected)\n\n        return False\n</code></pre>"},{"location":"users/rbac/role-mappings/#time-based-role-assignment","title":"Time-Based Role Assignment","text":"<pre><code># temporal-roles.yaml\napiVersion: auth/v1\nkind: TemporalRoleAssignment\nmetadata:\n  name: scheduled-access\nspec:\n  assignments:\n    # On-call rotation\n    - name: on-call-access\n      schedule:\n        type: rotation\n        pattern: \"weekly\"\n        participants:\n          - user: alice@example.com\n            weeks: [1, 3]\n          - user: bob@example.com\n            weeks: [2, 4]\n      roles:\n        - production-admin\n        - incident-responder\n      duration: \"1w\"\n\n    # Temporary elevated access\n    - name: maintenance-window\n      schedule:\n        type: fixed\n        start: \"2024-01-15T22:00:00Z\"\n        end: \"2024-01-16T02:00:00Z\"\n      users:\n        - maintenance-team@example.com\n      roles:\n        - cluster-admin\n\n    # Business hours access\n    - name: business-hours-only\n      schedule:\n        type: recurring\n        timezone: \"America/New_York\"\n        days: [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"]\n        hours: \"08:00-18:00\"\n      groups:\n        - contractors\n      roles:\n        - developer\n        - staging-access\n</code></pre>"},{"location":"users/rbac/role-mappings/#role-hierarchy","title":"Role Hierarchy","text":""},{"location":"users/rbac/role-mappings/#hierarchical-role-definition","title":"Hierarchical Role Definition","text":"<pre><code># role-hierarchy.yaml\napiVersion: auth/v1\nkind: RoleHierarchy\nmetadata:\n  name: organization-hierarchy\nspec:\n  roles:\n    # Top-level roles\n    - name: super-admin\n      inherits: []\n      permissions:\n        - resource: \"*\"\n          verbs: [\"*\"]\n\n    - name: org-admin\n      inherits: [\"super-admin\"]\n      excludes:\n        - resource: \"system-config\"\n          verbs: [\"delete\"]\n\n    # Department heads\n    - name: engineering-lead\n      inherits: [\"senior-developer\", \"team-manager\"]\n      additionalPermissions:\n        - resource: \"budgets\"\n          verbs: [\"read\", \"approve\"]\n\n    - name: team-manager\n      inherits: [\"developer\"]\n      additionalPermissions:\n        - resource: \"team-members\"\n          verbs: [\"manage\"]\n\n    # Individual contributors\n    - name: senior-developer\n      inherits: [\"developer\"]\n      additionalPermissions:\n        - resource: \"production-deployments\"\n          verbs: [\"approve\", \"execute\"]\n\n    - name: developer\n      inherits: [\"viewer\"]\n      additionalPermissions:\n        - resource: \"applications\"\n          verbs: [\"create\", \"update\", \"delete\"]\n\n    - name: viewer\n      inherits: []\n      permissions:\n        - resource: \"*\"\n          verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"users/rbac/role-mappings/#role-inheritance-rules","title":"Role Inheritance Rules","text":"<pre><code># role-hierarchy-engine.py\nfrom typing import Dict, Set, List\nimport networkx as nx\n\nclass RoleHierarchyEngine:\n    def __init__(self, hierarchy_config: Dict):\n        self.graph = nx.DiGraph()\n        self.build_hierarchy(hierarchy_config)\n\n    def build_hierarchy(self, config: Dict):\n        for role in config['roles']:\n            self.graph.add_node(role['name'],\n                              permissions=role.get('permissions', []),\n                              excludes=role.get('excludes', []))\n\n            for parent in role.get('inherits', []):\n                self.graph.add_edge(role['name'], parent)\n\n    def get_effective_permissions(self, role: str) -&gt; Set[str]:\n        \"\"\"Calculate all permissions for a role including inherited ones\"\"\"\n        permissions = set()\n        excludes = set()\n\n        # Traverse the hierarchy\n        for node in nx.descendants(self.graph, role) | {role}:\n            node_data = self.graph.nodes[node]\n\n            # Add permissions\n            for perm in node_data.get('permissions', []):\n                permissions.add(self.permission_to_string(perm))\n\n            # Add excludes\n            for excl in node_data.get('excludes', []):\n                excludes.add(self.permission_to_string(excl))\n\n        # Remove excluded permissions\n        return permissions - excludes\n\n    def find_minimal_roles(self, required_permissions: Set[str]) -&gt; List[str]:\n        \"\"\"Find minimal set of roles that provide required permissions\"\"\"\n        candidates = []\n\n        for role in self.graph.nodes():\n            perms = self.get_effective_permissions(role)\n            if required_permissions.issubset(perms):\n                candidates.append(role)\n\n        # Remove roles that inherit from other candidates\n        minimal = []\n        for role in candidates:\n            ancestors = nx.ancestors(self.graph, role)\n            if not any(c in ancestors for c in candidates if c != role):\n                minimal.append(role)\n\n        return minimal\n</code></pre>"},{"location":"users/rbac/role-mappings/#mapping-transformations","title":"Mapping Transformations","text":""},{"location":"users/rbac/role-mappings/#custom-transformation-functions","title":"Custom Transformation Functions","text":"<pre><code>// transform-functions.js\nconst transformFunctions = {\n  // Convert department codes to role names\n  departmentToRole: (dept) =&gt; {\n    const mapping = {\n      ENG: \"engineering\",\n      FIN: \"finance\",\n      HR: \"human-resources\",\n      OPS: \"operations\",\n    };\n    return mapping[dept] || \"general-user\";\n  },\n\n  // Generate namespace access based on team\n  teamToNamespaces: (team) =&gt; {\n    const baseNamespaces = [`team-${team.toLowerCase()}`];\n\n    // Add shared namespaces\n    baseNamespaces.push(\"shared-resources\");\n\n    // Add environment-specific namespaces\n    if (team.includes(\"prod\")) {\n      baseNamespaces.push(\"production\");\n    } else {\n      baseNamespaces.push(\"development\", \"staging\");\n    }\n\n    return baseNamespaces;\n  },\n\n  // Calculate role level based on attributes\n  calculateRoleLevel: (attributes) =&gt; {\n    let score = 0;\n\n    // Years of experience\n    if (attributes.experience) {\n      score += Math.min(attributes.experience * 10, 50);\n    }\n\n    // Certifications\n    if (attributes.certifications) {\n      score += attributes.certifications.length * 15;\n    }\n\n    // Management responsibility\n    if (attributes.directReports &gt; 0) {\n      score += 30;\n    }\n\n    // Determine level\n    if (score &gt;= 80) return \"senior\";\n    if (score &gt;= 50) return \"mid\";\n    return \"junior\";\n  },\n};\n</code></pre>"},{"location":"users/rbac/role-mappings/#mapping-templates","title":"Mapping Templates","text":"<pre><code># mapping-templates.yaml\napiVersion: auth/v1\nkind: MappingTemplate\nmetadata:\n  name: standard-mappings\nspec:\n  templates:\n    # Project-based access\n    - name: project-access\n      template: |\n        {{- range .projects }}\n        - role: project-{{ . }}-developer\n          namespace: project-{{ . }}\n        {{- end }}\n\n    # Environment-based access\n    - name: environment-access\n      template: |\n        {{- if eq .seniority \"senior\" }}\n        - role: {{ .team }}-admin\n          namespaces: [dev, staging, production]\n        {{- else if eq .seniority \"mid\" }}\n        - role: {{ .team }}-developer\n          namespaces: [dev, staging]\n        {{- else }}\n        - role: {{ .team }}-junior\n          namespaces: [dev]\n        {{- end }}\n\n    # Cost center based access\n    - name: budget-access\n      template: |\n        {{- if .isBudgetOwner }}\n        - role: budget-viewer\n          filters:\n            costCenter: {{ .costCenter }}\n        {{- end }}\n</code></pre>"},{"location":"users/rbac/role-mappings/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"users/rbac/role-mappings/#priority-based-resolution","title":"Priority-Based Resolution","text":"<pre><code># conflict-resolution.yaml\napiVersion: auth/v1\nkind: ConflictResolution\nmetadata:\n  name: role-priority\nspec:\n  strategy: priority\n\n  priorities:\n    # Higher number = higher priority\n    - source: direct-assignment\n      priority: 100\n\n    - source: group-membership\n      priority: 80\n\n    - source: oidc-claims\n      priority: 60\n\n    - source: ldap-groups\n      priority: 40\n\n    - source: default-roles\n      priority: 20\n\n  rules:\n    # Admin roles always win\n    - pattern: \"*-admin\"\n      priority: 200\n\n    # Deny rules always win\n    - pattern: \"deny-*\"\n      priority: 300\n\n    # Time-limited roles have precedence\n    - hasExpiry: true\n      priorityBoost: 50\n</code></pre>"},{"location":"users/rbac/role-mappings/#merge-strategies","title":"Merge Strategies","text":"<pre><code># merge-strategies.py\nfrom typing import List, Dict, Set\nfrom enum import Enum\n\nclass MergeStrategy(Enum):\n    UNION = \"union\"           # Combine all roles\n    INTERSECTION = \"intersection\"  # Only common roles\n    PRIORITY = \"priority\"     # Highest priority source wins\n    CUSTOM = \"custom\"         # Custom merge logic\n\nclass RoleMerger:\n    def __init__(self, strategy: MergeStrategy):\n        self.strategy = strategy\n\n    def merge_roles(self, role_sets: List[Dict[str, Set[str]]]) -&gt; Set[str]:\n        if self.strategy == MergeStrategy.UNION:\n            return self._merge_union(role_sets)\n        elif self.strategy == MergeStrategy.INTERSECTION:\n            return self._merge_intersection(role_sets)\n        elif self.strategy == MergeStrategy.PRIORITY:\n            return self._merge_priority(role_sets)\n        elif self.strategy == MergeStrategy.CUSTOM:\n            return self._merge_custom(role_sets)\n\n    def _merge_union(self, role_sets: List[Dict[str, Set[str]]]) -&gt; Set[str]:\n        merged = set()\n        for role_set in role_sets:\n            merged.update(role_set['roles'])\n        return merged\n\n    def _merge_intersection(self, role_sets: List[Dict[str, Set[str]]]) -&gt; Set[str]:\n        if not role_sets:\n            return set()\n        merged = role_sets[0]['roles'].copy()\n        for role_set in role_sets[1:]:\n            merged.intersection_update(role_set['roles'])\n        return merged\n\n    def _merge_priority(self, role_sets: List[Dict[str, Set[str]]]) -&gt; Set[str]:\n        # Sort by priority\n        sorted_sets = sorted(role_sets,\n                           key=lambda x: x.get('priority', 0),\n                           reverse=True)\n\n        merged = set()\n        for role_set in sorted_sets:\n            # Add roles not already present\n            for role in role_set['roles']:\n                if not any(self._conflicts(role, r) for r in merged):\n                    merged.add(role)\n\n        return merged\n</code></pre>"},{"location":"users/rbac/role-mappings/#testing-and-validation","title":"Testing and Validation","text":""},{"location":"users/rbac/role-mappings/#mapping-test-framework","title":"Mapping Test Framework","text":"<pre><code># mapping-tests.yaml\napiVersion: auth/v1\nkind: MappingTest\nmetadata:\n  name: role-mapping-tests\nspec:\n  testCases:\n    - name: \"Engineering team member gets developer role\"\n      input:\n        user:\n          email: \"test@example.com\"\n          groups: [\"Engineering\"]\n          attributes:\n            department: \"Engineering\"\n            title: \"Software Engineer\"\n      expected:\n        roles: [\"developer\", \"metrics-viewer\"]\n        namespaces: [\"development\", \"staging\"]\n\n    - name: \"Senior engineer gets additional privileges\"\n      input:\n        user:\n          email: \"senior@example.com\"\n          groups: [\"Engineering\"]\n          attributes:\n            department: \"Engineering\"\n            title: \"Senior Software Engineer\"\n            yearsOfService: \"5\"\n      expected:\n        roles: [\"senior-developer\", \"prod-read-only\"]\n        namespaces: [\"development\", \"staging\", \"production\"]\n\n    - name: \"Cross-functional team member\"\n      input:\n        user:\n          email: \"cross@example.com\"\n          groups: [\"Engineering\", \"Security\"]\n      expected:\n        roles: [\"developer\", \"security-auditor\"]\n</code></pre>"},{"location":"users/rbac/role-mappings/#validation-rules","title":"Validation Rules","text":"<pre><code># mapping-validator.py\nclass MappingValidator:\n    def __init__(self):\n        self.validation_rules = [\n            self.check_role_exists,\n            self.check_namespace_access,\n            self.check_conflicting_roles,\n            self.check_permission_boundaries\n        ]\n\n    def validate_mapping(self, user, mapped_roles):\n        errors = []\n        warnings = []\n\n        for rule in self.validation_rules:\n            result = rule(user, mapped_roles)\n            errors.extend(result.get('errors', []))\n            warnings.extend(result.get('warnings', []))\n\n        return {\n            'valid': len(errors) == 0,\n            'errors': errors,\n            'warnings': warnings\n        }\n\n    def check_conflicting_roles(self, user, roles):\n        conflicts = [\n            ('admin', 'viewer'),\n            ('prod-admin', 'dev-only'),\n            ('security-admin', 'external-contractor')\n        ]\n\n        errors = []\n        for role1, role2 in conflicts:\n            if role1 in roles and role2 in roles:\n                errors.append(f\"Conflicting roles: {role1} and {role2}\")\n\n        return {'errors': errors}\n</code></pre>"},{"location":"users/rbac/role-mappings/#monitoring-and-auditing","title":"Monitoring and Auditing","text":""},{"location":"users/rbac/role-mappings/#mapping-analytics","title":"Mapping Analytics","text":"<pre><code>-- Role mapping effectiveness\nSELECT\n    mapping_source,\n    target_role,\n    count(DISTINCT user_id) as users_mapped,\n    count(*) as total_mappings,\n    avg(CASE WHEN used_within_24h THEN 1 ELSE 0 END) as usage_rate\nFROM role_mapping_events\nWHERE timestamp &gt;= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY mapping_source, target_role\nORDER BY users_mapped DESC;\n\n-- Mapping failures\nSELECT\n    date_trunc('hour', timestamp) as hour,\n    mapping_rule,\n    error_type,\n    count(*) as failure_count,\n    array_agg(DISTINCT user_email) as affected_users\nFROM mapping_failures\nWHERE timestamp &gt;= CURRENT_DATE - INTERVAL '7 days'\nGROUP BY hour, mapping_rule, error_type\nHAVING count(*) &gt; 5\nORDER BY hour DESC, failure_count DESC;\n</code></pre>"},{"location":"users/rbac/role-mappings/#best-practices","title":"Best Practices","text":""},{"location":"users/rbac/role-mappings/#1-mapping-design","title":"1. Mapping Design","text":"<ul> <li>Keep mappings simple and understandable</li> <li>Use consistent naming conventions</li> <li>Document mapping logic thoroughly</li> <li>Version control mapping configurations</li> </ul>"},{"location":"users/rbac/role-mappings/#2-security-considerations","title":"2. Security Considerations","text":"<ul> <li>Validate all external claims</li> <li>Implement deny rules for sensitive roles</li> <li>Regular audit of role assignments</li> <li>Monitor for privilege escalation</li> </ul>"},{"location":"users/rbac/role-mappings/#3-performance","title":"3. Performance","text":"<ul> <li>Cache mapping results appropriately</li> <li>Optimize complex transformation logic</li> <li>Batch process bulk updates</li> <li>Monitor mapping latency</li> </ul>"},{"location":"users/rbac/role-mappings/#4-maintenance","title":"4. Maintenance","text":"<ul> <li>Regular review of mapping rules</li> <li>Clean up obsolete mappings</li> <li>Test changes in staging first</li> <li>Maintain mapping documentation</li> </ul>"},{"location":"users/rbac/role-mappings/#related-documentation","title":"Related Documentation","text":"<ul> <li>RBAC Overview</li> <li>Permission Model</li> <li>Best Practices</li> <li>Identity Management</li> </ul>"}]}